{"cells":[{"cell_type":"markdown","source":["# Combinatorial Generalization with Homomorphism Autoencoders"],"metadata":{"id":"B3vGve_dzoGj"}},{"cell_type":"markdown","source":["The project aim to test several degree of combinatorial generalization capabilities a generative model is expected to exhibit.\n","\n","Specifically, from the study PAPER_NAME by Montero et al., after a first elicitation of the combinatorial generalization problem, three types of combinatorial testing have been designed in an increasing difficulty fashion.\n","\n","1. Example of Recombination-to-Element \\\\\n","    ```[shape = ellipse, scale = 1, orientation < 120◦, position-x > 0.5, position-y > 0.5]``` \n","2. Example of Recombination-to-Range \\\\\n","    ```[shape = square, position-x > 0.5```\n","3. Example of Extrapolation \\\\\n","    ```[position-x > 0.5]```\n","\n","Lately Keurti et al. proposed a multi-step autoencoder that aims to solve the combinatorial generation issue by enforcing the knwoledge that the encoder learns by exploiting the information given by the transformation action between k different images. Practically, instead of simply learning to generate a sample that exhibit a combination G of generative features, the model learns to encode the transformation from a first initial sample (generated using G_0 - set of generative figures) to a second one (G_1), and it continues like this for n ideal steps.\n","\n","The goal of the project is to test the combinatorial testing types used by Montero et al. in the Homomorphism Autoencoder framework."],"metadata":{"id":"ZhnAroSbzz_L"}},{"cell_type":"markdown","source":["## Preliminary Imports"],"metadata":{"id":"XlsXa95aC3h4"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Advanced_Machine_Learning"],"metadata":{"id":"gqztPbLvunn3","executionInfo":{"status":"ok","timestamp":1682177642068,"user_tz":-120,"elapsed":18746,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"517997b9-6172-485b-8ce6-b239b28f03bf"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Advanced_Machine_Learning\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a9ROM-b5zFkA","outputId":"b3f061bd-febb-4fdb-8e65-fbfe2f26c899","executionInfo":{"status":"ok","timestamp":1682177651086,"user_tz":-120,"elapsed":9025,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.15.0-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting GitPython!=3.1.29,>=1.0.0\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (67.6.1)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.20.0-py2.py3-none-any.whl (198 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.8/198.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.5)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.27.1)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=1e7605a99b8ea54cf65afd922df1ad2bca1e97d1cf551dd87810215cb05b1508\n","  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n","Successfully built pathtools\n","Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.20.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.0\n"]}],"source":["!pip install wandb"]},{"cell_type":"markdown","source":["## DSprite"],"metadata":{"id":"VNolbCPpC8AL"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import itertools\n","import json"],"metadata":{"id":"Go0yGkHl27_x","executionInfo":{"status":"ok","timestamp":1682177693981,"user_tz":-120,"elapsed":325,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Helper function to show images\n","def show_images_grid(imgs_, num_images=25):\n","    \"\"\"\n","    \"\"\"\n","    ncols = int(np.ceil(num_images**0.5))\n","    nrows = int(np.ceil(num_images / ncols))\n","    _, axes = plt.subplots(ncols, \n","                           nrows, \n","                           figsize=(nrows * 3, ncols * 3))\n","    axes = axes.flatten()\n","\n","    for ax_i, ax in enumerate(axes):\n","        if ax_i < num_images:\n","            ax.imshow(imgs_[ax_i], \n","                    cmap='Greys_r',  \n","                    interpolation='nearest')\n","            ax.set_xticks([])\n","            ax.set_yticks([])\n","        else:\n","            ax.axis('off')"],"metadata":{"id":"NFMiG3G8kw5Z","executionInfo":{"status":"ok","timestamp":1682177695538,"user_tz":-120,"elapsed":2,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def show_density(imgs):\n","    \"\"\"\n","    \"\"\"\n","    _, ax = plt.subplots()\n","    ax.imshow(imgs.mean(axis=0), \n","              interpolation='nearest', \n","              cmap='Greys_r')\n","    ax.grid('off')\n","    ax.set_xticks([])\n","    ax.set_yticks([])"],"metadata":{"id":"EtVkVUji26L8","executionInfo":{"status":"ok","timestamp":1682177697381,"user_tz":-120,"elapsed":4,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def load_dsprite():\n","    \"\"\"\n","    \"\"\"\n","    dataset_zip = np.load('/content/drive/MyDrive/Advanced_Machine_Learning/dsprites-dataset/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz', \n","                          allow_pickle=True, \n","                          encoding='latin1')\n","\n","    imgs = dataset_zip['imgs']\n","    latents_values = dataset_zip['latents_values']\n","    latents_classes = dataset_zip['latents_classes']\n","    metadata = dataset_zip['metadata'][()]\n","\n","    return imgs, metadata"],"metadata":{"id":"LptpRCn45lX_","executionInfo":{"status":"ok","timestamp":1682177699338,"user_tz":-120,"elapsed":5,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def exclude_from_training(imgs, metadata, shape=None, scale=None, orientation=None, posX=None, posY=None):\n","    \"\"\"Extract the images given a specific set of latents value and operator.\n","    Example:\n","\n","    >> exclude_from_training(imgs, metadata, shape=\"== 0\", orientation=\"> 10\")\n","    # Return all images of shape 0 and orientation > 10\n","\n","    Latents order is ('color', 'shape', 'scale', 'orientation', 'posX', 'posY')\n","    Shape order is (square, ellipse, heart)\n","    \"\"\"\n","    def _latent_to_index(latents, metadata):\n","        latents_sizes = metadata['latents_sizes']\n","        latents_bases = np.concatenate((latents_sizes[::-1].cumprod()[::-1][1:],\n","                                        np.array([1,])))\n","        return np.dot(latents, latents_bases).astype(int)\n","\n","    num_given_factors = bool(shape) \\\n","                      + bool(scale) \\\n","                      + bool(orientation) \\\n","                      + bool(posX) \\\n","                      + bool(posY)\n","\n","    factors = [None, shape, scale, orientation, posX, posY]\n","    factors = [\">= 0\" if not f else f for f in factors]\n","    factors = [{\"compare\": f.split(\" \")[0], \"value\": int(f.split(\" \")[1])}\n","               for f in factors]\n","\n","    if num_given_factors == 5:\n","        combination_type = \"rec2element\" \n","    elif num_given_factors < 5 and num_given_factors >= 2:\n","        combination_type = \"rec2range\"\n","    elif num_given_factors == 1:\n","        combination_type = \"extrap\"\n","    else:\n","        raise ValueError(\"Invalid combination type\")\n","\n","    latents_2_sample = []\n","\n","    # Color is fixed so first element is excluded\n","    for idx, factor_name in enumerate(metadata[\"latents_names\"]): \n","\n","        if factors[idx][\"compare\"] == \"<\":\n","            latents_2_sample.append(list(range(0, factors[idx][\"value\"])))\n","\n","        elif factors[idx][\"compare\"] == \"<=\":\n","            latents_2_sample.append(list(range(0, factors[idx][\"value\"]+1)))\n","\n","        elif factors[idx][\"compare\"] == \"==\":\n","            latents_2_sample.append([factors[idx][\"value\"]])\n","\n","        elif factors[idx][\"compare\"] == \">=\":\n","            latents_2_sample.append(list(range(factors[idx][\"value\"], metadata[\"latents_sizes\"][idx])))\n","\n","        elif factors[idx][\"compare\"] == \">\":\n","            latents_2_sample.append(list(range(factors[idx][\"value\"]+1, metadata[\"latents_sizes\"][idx])))\n","\n","        else:\n","            raise ValueError(\"Invalid comparison symbol\")\n","\n","    latents_sampled = np.asarray(list(itertools.product(*latents_2_sample)))\n","\n","    # Select images\n","    indices_sampled = _latent_to_index(latents_sampled, metadata)\n","    indices_sampled = list(set(indices_sampled))\n","    imgs_sampled = imgs[indices_sampled]\n","\n","    return imgs_sampled, indices_sampled, combination_type"],"metadata":{"id":"A4ktrLV7mZxn","executionInfo":{"status":"ok","timestamp":1682177699925,"user_tz":-120,"elapsed":4,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["imgs, metadata = load_dsprite()"],"metadata":{"id":"05BRj80IyEin","executionInfo":{"status":"ok","timestamp":1682177719276,"user_tz":-120,"elapsed":12086,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["metadata"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2Te2nbimtUH","executionInfo":{"status":"ok","timestamp":1682177719963,"user_tz":-120,"elapsed":8,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"outputId":"79af1cf2-2d1b-44f3-9db2-e2dd26b705e4"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'date': 'April 2017',\n"," 'description': 'Disentanglement test Sprites dataset.Procedurally generated 2D shapes, from 6 disentangled latent factors.This dataset uses 6 latents, controlling the color, shape, scale, rotation and position of a sprite. All possible variations of the latents are present. Ordering along dimension 1 is fixed and can be mapped back to the exact latent values that generated that image.We made sure that the pixel outputs are different. No noise added.',\n"," 'version': 1,\n"," 'latents_names': ('color', 'shape', 'scale', 'orientation', 'posX', 'posY'),\n"," 'latents_possible_values': {'orientation': array([0.        , 0.16110732, 0.32221463, 0.48332195, 0.64442926,\n","         0.80553658, 0.96664389, 1.12775121, 1.28885852, 1.44996584,\n","         1.61107316, 1.77218047, 1.93328779, 2.0943951 , 2.25550242,\n","         2.41660973, 2.57771705, 2.73882436, 2.89993168, 3.061039  ,\n","         3.22214631, 3.38325363, 3.54436094, 3.70546826, 3.86657557,\n","         4.02768289, 4.1887902 , 4.34989752, 4.51100484, 4.67211215,\n","         4.83321947, 4.99432678, 5.1554341 , 5.31654141, 5.47764873,\n","         5.63875604, 5.79986336, 5.96097068, 6.12207799, 6.28318531]),\n","  'posX': array([0.        , 0.03225806, 0.06451613, 0.09677419, 0.12903226,\n","         0.16129032, 0.19354839, 0.22580645, 0.25806452, 0.29032258,\n","         0.32258065, 0.35483871, 0.38709677, 0.41935484, 0.4516129 ,\n","         0.48387097, 0.51612903, 0.5483871 , 0.58064516, 0.61290323,\n","         0.64516129, 0.67741935, 0.70967742, 0.74193548, 0.77419355,\n","         0.80645161, 0.83870968, 0.87096774, 0.90322581, 0.93548387,\n","         0.96774194, 1.        ]),\n","  'posY': array([0.        , 0.03225806, 0.06451613, 0.09677419, 0.12903226,\n","         0.16129032, 0.19354839, 0.22580645, 0.25806452, 0.29032258,\n","         0.32258065, 0.35483871, 0.38709677, 0.41935484, 0.4516129 ,\n","         0.48387097, 0.51612903, 0.5483871 , 0.58064516, 0.61290323,\n","         0.64516129, 0.67741935, 0.70967742, 0.74193548, 0.77419355,\n","         0.80645161, 0.83870968, 0.87096774, 0.90322581, 0.93548387,\n","         0.96774194, 1.        ]),\n","  'scale': array([0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n","  'shape': array([1., 2., 3.]),\n","  'color': array([1.])},\n"," 'latents_sizes': array([ 1,  3,  6, 40, 32, 32]),\n"," 'author': 'lmatthey@google.com',\n"," 'title': 'dSprites dataset'}"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["imgs_sampled, indices_sampled, combination_type = exclude_from_training(imgs, \n","                                                                        metadata, \n","                                                                        shape=\"== 2\", \n","                                                                        posX=\"== 0\", \n","                                                                        posY=\"== 0\", \n","                                                                        orientation=\"== 0\", \n","                                                                        scale=\"== 0\")"],"metadata":{"id":"BWcm3hJhJWVW","executionInfo":{"status":"ok","timestamp":1682182638750,"user_tz":-120,"elapsed":7,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["show_density(imgs_sampled)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"id":"AdT09vBCJbR9","executionInfo":{"status":"ok","timestamp":1682182640227,"user_tz":-120,"elapsed":1125,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"outputId":"53b5e258-bfe6-44d5-f258-5069b2beac8c"},"execution_count":82,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["imgs_sampled, indices_sampled, combination_type = exclude_from_training(imgs, \n","                                                                        metadata, \n","                                                                        shape=\"== 2\", \n","                                                                        posX=\">= 15\", \n","                                                                        posY=\"== 0\", \n","                                                                        orientation=\"== 0\", \n","                                                                        scale=\"== 0\")"],"metadata":{"id":"_nNux2c38mLH","executionInfo":{"status":"ok","timestamp":1682182642596,"user_tz":-120,"elapsed":4,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["show_density(imgs_sampled)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"id":"VhQaPzDPzMTt","executionInfo":{"status":"ok","timestamp":1682182645280,"user_tz":-120,"elapsed":9,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"outputId":"5123e137-37be-4ad8-b38d-cc15bebffb9d"},"execution_count":84,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["imgs_sampled, indices_sampled, combination_type = exclude_from_training(imgs, \n","                                                                        metadata, \n","                                                                        shape=\"== 1\",\n","                                                                        scale=\"== 5\",\n","                                                                        orientation=\"== 14\",\n","                                                                        posX=\"== 15\",\n","                                                                        posY=\">= 15\")"],"metadata":{"id":"G16LxbuqYiON","executionInfo":{"status":"ok","timestamp":1682182648603,"user_tz":-120,"elapsed":263,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["show_density(imgs_sampled)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"id":"kraDC1oRYh1B","executionInfo":{"status":"ok","timestamp":1682182649484,"user_tz":-120,"elapsed":10,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"outputId":"78820fa4-bd5b-4be4-f408-28c5c7b8ab64"},"execution_count":86,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["name = \"/content/drive/MyDrive/Advanced_Machine_Learning/remove_from_train_shape_equal_1__scale_equal_5__orientation_equal_14__posX_equal_15__posY_greater_equal_15.json\""],"metadata":{"id":"9Iiwb1-qYhUm","executionInfo":{"status":"ok","timestamp":1682182655809,"user_tz":-120,"elapsed":4,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["with open(name, \"w\") as f:\n","    json.dump([int(i) for i in indices_sampled], f)"],"metadata":{"id":"WBxcYSTuZCj9","executionInfo":{"status":"ok","timestamp":1682182657137,"user_tz":-120,"elapsed":2,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["# Extrapolation\n","imgs_sampled, indices_sampled, combination_type = exclude_from_training(imgs, \n","                                                                        metadata, \n","                                                                        shape=\"== 1\",\n","                                                                        posX=\">= 15\",\n","                                                                        posY=\">= 15\")"],"metadata":{"id":"S-9dbZteXSst","executionInfo":{"status":"ok","timestamp":1682182792889,"user_tz":-120,"elapsed":237,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":99,"outputs":[]},{"cell_type":"code","source":["show_density(imgs_sampled)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"id":"Uy_qgigEXSY2","executionInfo":{"status":"ok","timestamp":1682182794945,"user_tz":-120,"elapsed":318,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"outputId":"1be97f54-a43a-43a0-ac2b-37fd2dec55a7"},"execution_count":100,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAPBElEQVR4nO3dy1Id17IF0IUk0MvYDjcV9v9/mCNo20YSQg84vXkbZMJObm02oDGa61QUVYWkecprRtbR9fX19QKAtdaLQ18AAI+HUAAghAIAIRQACKEAQAgFAEIoABCvdjno6upqnZ2drdPT03V0dLTvawJgY9fX1+v8/Hx9+PBhvXjRvw/sFApnZ2frr7/+2uziADiMv//+e/3555/t/77Tfz46PT3d7IIAOJy7/j3fKRT8JyOA5+Guf89tNAMQQgGAEAoAhFAAIIQCACEUAAihAEAIBQBCKAAQQgGAEAoAhFAAIIQCACEUAAihAEAIBQBCKAAQQgGAEAoAhFAAIIQCACEUAAihAEAIBQBCKAAQQgGAEAoAhFAAIIQCACEUAAihAEAIBQBCKAAQQgGAEAoAhFAAIIQCACEUAAihAEAIBQBCKAAQQgGAEAoAhFAAIIQCACEUAAihAEAIBQBCKAAQQgGAEAoAhFAAIIQCACEUAAihAEAIBQBCKAAQQgGAEAoAhFAAIIQCACEUAAihAEAIBQBCKAAQQgGAEAoAhFAAIIQCACEUAAihAEAIBQBCKAAQQgGAEAoAhFAAIIQCACEUAAihAEAIBQBCKAAQQgGAEAoAhFAAIIQCACEUAAihAEAIBQBCKAAQQgGAEAoAhFAAIIQCACEUAAihAEAIBQBCKAAQQgGAEAoAhFAAIIQCACEUAAihAEAIBQBCKAAQQgGAEAoAhFAAIIQCACEUAAihAEAIBQBCKAAQrw59AfBUHR0dHfoSDub6+vrQl8CeeFMAIIQCACEUAAihAEDYaOZZ2GLT92feOJ6aPqstNqZtbj8MbwoAhFAAIIQCACEUAAihAEBoH/EoTdstk+O3OvdDt5W6n3eIVs70Z06O3+p+tJXux5sCACEUAAihAEAIBQBCKAAQ2kcc1FbNnur47hwvXtT/X6hb36LZ9BTmKm3REOrWr66u/t/nmK5PaCr9H28KAIRQACCEAgAhFAAIoQBAaB/xYCYNoel61Rx6+fLlzsdutb7PNtXUFvOJpo2fHz9+7Hx81Ui6bX1y7u483bGPaa7UoXlTACCEAgAhFAAIoQBACAUAQvuIzU0aONP5RK9e1X9kq+O7Y7tW0uTc3XkOMVeps8UMoa7xM20Off/+fedzd+vdM6zO3dlqftJzbiV5UwAghAIAIRQACKEAQNho5t62GEUx3VDuNomPj493Wrvt3N3xk/NMr7tbr2y10TzZJO42fbvN3a9fv+58/Ldv38pju/XuZ3bPpbr2yab0Ws97Q7njTQGAEAoAhFAAIIQCACEUAAjtI+601YdwqvVpE6g7/uTk5Mba69evy2PfvHlTrk+Pr37mtME0GaExNf0QTrXeNYG6ltHl5eXO6xcXF5ucu/vz1p2nMm02dZ5DW8mbAgAhFAAIoQBACAUAQigAENpH3NsWH8iZfvBm0hB6//59eey7d+82Wa9+5rQ11d1/9QynTZgtPoTTtXK6JtDnz593Xu+eVddKmn6oaNIE6p7JFm2ip9ZI8qYAQAgFAEIoABBCAYAQCgCE9hGxzxlHa9Xtka6BMp1DdHp6emPtl19+2fnYtfq20tu3b3e+lu66qzlJa82+yDZt2UxnH1Vzjrr5QV++fCnXu2dVrU+fSWdy/9Ov0W11/FPiTQGAEAoAhFAAIIQCAGGjmXvrNj4noyu6jeZuE7LbDK42lX/99dfy2G69G2cxGZfRbbR2G9Dd/U82mjuTcRZr1ZvK3YZyN87i06dP5Xr1u5+Oreh091ltqHf33v2Z7TblO9W1P7XNZ28KAIRQACCEAgAhFAAIoQBAaB9xpy3GWaxVNzy6llE3zqJrCFWjK7qW0XT8RbdenWc6KqNrJU3aOp2uaVONs1irbhp1baJpm6q6n61aRt39VOvdM+laRl0raTLmYouPAD0kbwoAhFAAIIQCACEUAAihAEBoHxFbtYy69aqBUq2t1bePJrOPumO7NtFvv/1Wrnctpur47tjuWrr7nLR1ph+C6do61Tyjjx8/lsdO20eTmUDT6+7mM11eXt5Y6z4aNJ3DNFl/rC2jjjcFAEIoABBCAYAQCgCEUAAgtI9+UtO5M5NzdPNiqvWurTKdfVTNFpq2j7rm0B9//LHzeneOfc4+6tot3TyfrsVTPdtJO2qtWUNqen1dc2jyFbjuuqdNui3+/jxW3hQACKEAQAgFAEIoABBCAYDQPuJOW8x/WatucnRtkOkX2aoWT9f46b681s0+6tpHv//++421rtnUtaa6+9ziS2XTdk/1DKdtnW5uUXUtXZuoW+9mHHV/JqpnO2nGrTWf+9U986fEmwIAIRQACKEAQAgFAMJGM/c23YSbjLnoNmAnYzG6jeZu/EU3oqJbrzaVu03sQ2w0d5u+3UZu9WynozW6TezqgzcXFxflsdV4irX6ZzX5s9JtKE/HXHSew/gLbwoAhFAAIIQCACEUAAihAEBoHxHTsRVTVZOja3d04xW69app0o0/mI6/6I6v1ifHrtW3qaqWzFbto0kDpztH1zLqml3V+vn5eXns5MNDa82e4XScRec5tIw63hQACKEAQAgFAEIoABBCAYDQPuLetvj4zvSjJ9161UyZzElaq2+9TNa7Y7tr2aJ91M0h6ppDk/NMPsizVj+HqDq+u/dpy2gya2urD0Y9Z94UAAihAEAIBQBCKAAQQgGA0D5ic5OvVU2aI7cdX61v0WCarnfHbtGymraPpsdXP3Or+6maQ9NzT7+OVq0fok00/T0cmjcFAEIoABBCAYAQCgCEjWYezBabfJNxBNONye7ck+O3GqOwxbmnG9CTn7nFs933aInHMqLisW4od7wpABBCAYAQCgCEUAAghAIAoX3EkzJpcnQfmZmee7q+r5+573EJk/Ps81k9tbbOc+NNAYAQCgCEUAAghAIAIRQACO0jNte1fqpWSXfs5BzTc//48WN07u746vzT++nWq6bRtJWzxbOd3Ptt69V5tvgdT9c1m+7mTQGAEAoAhFAAIIQCACEUAAjtIx7MpA0ybb18//5953N8/fp1tP7t27ed17tzvHz5slyfzDPqvmrWPcNp+6q6n8m937ZePZfuWVW/y7Xmfyaq4/c5x+q58KYAQAgFAEIoABBCAYAQCgCE9hGxz5kz3foWLaNu/fLysjz2y5cv5frnz5/L9Xfv3pXrr1+/vrF2fHxcHjttDlVtpa6p1OmeYdcQqp5L9wwvLi52Pkd3fHfuaQus+zN0iHlLz4E3BQBCKAAQQgGAEAoAhI1m7m26CVdt8k1HUXQbzdXx3Ubmp0+fyvWPHz+W62/evCnXX726+den21CebpxXG83TzerJOIu16ufVPZNuU/6///4r16tn3m1Wd7+3yQiNtWajT6ajQjrPYQPamwIAIRQACKEAQAgFAEIoABDaR2xu0oaZNkomoyu6hkw1nmKttf79999yvWoZrVU3hLp77+6zu5ZJ+6gzbR9VbaDuGf7zzz+j9aqV1J27G5XR/e4nbaXJSIy1tmslPSXeFAAIoQBACAUAQigAEEIBgNA+4k5bzDjq1idzeNbq5+VU84m6Zk/XJurWu4/bVPfTtabev39frp+cnJTrW8w+2uIjO90so2n76Pz8/MZaN4Nq2kqatJWmH3V6DrOMprwpABBCAYAQCgCEUAAghAIAoX30k5q0Kqbto67hUX0Jq/vyWNcomcwz6tpEXYunaxl191lde9eaevv2bbnefdXt+Pj4xtpWX16bzI+qWkNr9V9k646vWkzdsV3DrGsrdcdXLavuz9ukMbfW/O/EU+JNAYAQCgCEUAAghAIAYaOZe+s2MrsN0er4bixEt3lYbcCuVW8qT8dWbLFhOxnDsVZ/P9X69LqnYy6q++k29rv77Dagq/Vu47jbgJ6Oxajup7v36Ud2nsOGcsebAgAhFAAIoQBACAUAQigAENpH3Gmrj+xUIwa6Nsi0lVR9lGbycZy1+gZKdy1Vu6VryEw/+DO5n87k97BWfZ/T30O3XjWEuqZS92GfrpXUjUSprr37HU/XJ38nnlpTyZsCACEUAAihAEAIBQBCKAAQ2kfEtCUxbR9VTY5JE2atfq5SZfJxnLX6j89011K1Xk5OTspju5ZRN/uous/p7KPpLKeqCTaZk7RW3wSqWlld+2g646j7mZP7+Rk/ptPxpgBACAUAQigAEEIBgBAKAIT2Efc2bR9V610bZDrnp7qWrmUzbR9NvqbWtY8mLaPb1if2OZtq+qyqhtB0flL3MyetsX3OOLpt/SnxpgBACAUAQigAEEIBgBAKAIT2EXeaNiqmX/yqdPOGJq2P7ud1jZrJV8PWqptGky+p3bZeta+mjaTpF+Yms6m2mB81/epet96dp7rG7t6ns4+eM28KAIRQACCEAgAhFAAIG81sbrIZ3G38bfEzp5ukk4/prFVvEnebwd2Gcnf8dMxHZTrmYvL7mY4Q2WITe3Lu7vitPqbznDegvSkAEEIBgBAKAIRQACCEAgChfcS9dQ2MrjnTNT8m5558wKdr9nRtlW5cwqRR1N37dH2fJo2aLX4Pa9XPfDpyYjq2ozpey+hu3hQACKEAQAgFAEIoABBCAYDQPmJzk1ZS1yjpWjmTlkh3jq6tMp1DVK13x04/kDO5jq0aMvts60yaTd3vZ58/82dsGXW8KQAQQgGAEAoAhFAAIIQCAKF9xIPZZ8OjaqxMZzBtMZ9oi5bR9GdOTX4Pk3lVt5178jP3OZ9Iy+hu3hQACKEAQAgFAEIoABBCAYDQPuJR2qIlMv0yXGdyfDe35xBfWJvaZzNnnw0hjaJteVMAIIQCACEUAAihAEDYaOZJOcSmoo3M/fBcHydvCgCEUAAghAIAIRQACKEAQGgf8dPReoGeNwUAQigAEEIBgBAKAIRQACCEAgAhFAAIoQBACAUAQigAEEIBgBAKAIRQACCEAgAhFAAIoQBACAUAQigAEEIBgBAKAIRQACCEAgAhFAAIoQBACAUAQigAEEIBgNgpFK6vr/d9HQA8gLv+Pd8pFM7Pzze5GAAO665/z4+ud3gNuLq6WmdnZ+v09HQdHR1tdnEAPIzr6+t1fn6+Pnz4sF686N8HdgoFAH4ONpoBCKEAQAgFAEIoABBCAYAQCgCEUAAg/gccpyODtOaI/gAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"code","source":["name = \"/content/drive/MyDrive/Advanced_Machine_Learning/remove_from_train_shape_equal_1___posX_greater_equal_15__posY_greater_equal_15.json\""],"metadata":{"id":"Wx751Q8WXY8m","executionInfo":{"status":"ok","timestamp":1682182802719,"user_tz":-120,"elapsed":308,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":101,"outputs":[]},{"cell_type":"code","source":["with open(name, \"w\") as f:\n","    json.dump([int(i) for i in indices_sampled], f)"],"metadata":{"id":"QtPFSK2zYUHV","executionInfo":{"status":"ok","timestamp":1682182804618,"user_tz":-120,"elapsed":336,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","source":["# Extrapolation\n","imgs_sampled, indices_sampled, combination_type = exclude_from_training(imgs, \n","                                                                        metadata, \n","                                                                        shape=\"== 1\", \n","                                                                        posX=\">= 15\")"],"metadata":{"id":"D84c5QU3BW46","executionInfo":{"status":"ok","timestamp":1682182812047,"user_tz":-120,"elapsed":1045,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["show_density(imgs_sampled)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"id":"pQRZTflUBhZ9","executionInfo":{"status":"ok","timestamp":1682182814063,"user_tz":-120,"elapsed":666,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"outputId":"7d4739c0-aabb-461f-ad86-066b86ade19c"},"execution_count":104,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["name = \"/content/drive/MyDrive/Advanced_Machine_Learning/remove_from_train_shape_equal_1__posX_greater_equal_15.json\""],"metadata":{"id":"Te3Rf5LlI9tk","executionInfo":{"status":"ok","timestamp":1682182817410,"user_tz":-120,"elapsed":3,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","source":["with open(name, \"w\") as f:\n","    json.dump([int(i) for i in indices_sampled], f)"],"metadata":{"id":"pmsYftMsIfNZ","executionInfo":{"status":"ok","timestamp":1682182820230,"user_tz":-120,"elapsed":943,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":106,"outputs":[]},{"cell_type":"markdown","source":["## Run Homomorphismae in python"],"metadata":{"id":"zglxBWC_EpL3"}},{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2\n","%cd /content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae\n","\n","from utils import misc\n","from torch.utils.data import DataLoader\n","from data.dsprites import DspritesDataset\n","import homomorphism.train_args as train_args\n","import homomorphism.train_utils as tutils\n","from grouprepr.representation_utils import Representation\n","from argparse import Namespace\n","from contextlib import ExitStack\n","import wandb\n","import copy\n","import utils.sim_utils as sim_utils\n","import data.data_utils as data_utils\n","import networks.network_utils as net_utils\n","from datetime import datetime\n","import argparse\n","from datetime import datetime\n","import torch\n","import utils.args as args\n","from grouprepr.representation_utils import Representation"],"metadata":{"id":"DPZFwDY2LSuQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682182824250,"user_tz":-120,"elapsed":7,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"outputId":"e48a92ef-2302-4fd9-cece-03a730e63659"},"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae\n"]}]},{"cell_type":"code","source":["input_args = \"--dataset=dsprites --data_root=/content/drive/MyDrive/Advanced_Machine_Learning/dsprites-dataset --cyclic_trans --fixed_in_intervention=0,1,2,3 --fixed_in_sampling=0,1,2,3 --fixed_values=0,1,5,14 --distrib=uniform --displacement_range=-10,10 --n_steps=2 --rotate_actions=45 --num_train=10000 --batch_size=500 --epochs=101 --log_wandb --lr=0.001 --toggle_training_every=2,2 --shuffle=1 --use_adam --use_cuda --conv_channels=64,64,64,64 --kernel_sizes=6,4,4,4 --strides=2,2,1,1 --lin_channels=1024 --net_act=relu --dims=2,2 --group_hidden_units=128,128 --reconstruct_first --exponential_map --latent_loss --latent_loss_weight=400 --val_epoch=10 --num_val=500 --plot_epoch=10 --plot_manifold_latent=[0,1] --plot_manifold --plot_reconstruction --plot_pca --plot_vary_latents=[4,5]\".split(\" \")\n","# input_args = \"--combinatorial_indices=/content/drive/MyDrive/Advanced_Machine_Learning/remove_from_train_shape_equal_1__posX_greater_equal_15.json --dataset=dsprites --data_root=/content/drive/MyDrive/Advanced_Machine_Learning/dsprites-dataset --cyclic_trans --fixed_in_intervention=0,1,2,3 --fixed_in_sampling=0,1,2,3 --fixed_values=0,1,5,14 --distrib=uniform --displacement_range=-10,10 --n_steps=2 --rotate_actions=45 --num_train=10000 --batch_size=500 --epochs=101 --log_wandb --lr=0.001 --toggle_training_every=2,2 --shuffle=1 --use_adam --use_cuda --conv_channels=64,64,64,64 --kernel_sizes=6,4,4,4 --strides=2,2,1,1 --lin_channels=1024 --net_act=relu --dims=2,2 --group_hidden_units=128,128 --reconstruct_first --exponential_map --latent_loss --latent_loss_weight=400 --val_epoch=10 --num_val=500 --plot_epoch=10 --plot_manifold_latent=[0,1] --plot_manifold --plot_reconstruction --plot_pca --plot_vary_latents=[4,5]\".split(\" \")\n","input_args # Test with ellipsis subset"],"metadata":{"id":"EDiIzA0MbfK-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682182845961,"user_tz":-120,"elapsed":7,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"outputId":"7c8c23c9-d636-438b-d802-2600da035906"},"execution_count":113,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['--dataset=dsprites',\n"," '--data_root=/content/drive/MyDrive/Advanced_Machine_Learning/dsprites-dataset',\n"," '--cyclic_trans',\n"," '--fixed_in_intervention=0,1,2,3',\n"," '--fixed_in_sampling=0,1,2,3',\n"," '--fixed_values=0,1,5,14',\n"," '--distrib=uniform',\n"," '--displacement_range=-10,10',\n"," '--n_steps=2',\n"," '--rotate_actions=45',\n"," '--num_train=10000',\n"," '--batch_size=500',\n"," '--epochs=101',\n"," '--log_wandb',\n"," '--lr=0.001',\n"," '--toggle_training_every=2,2',\n"," '--shuffle=1',\n"," '--use_adam',\n"," '--use_cuda',\n"," '--conv_channels=64,64,64,64',\n"," '--kernel_sizes=6,4,4,4',\n"," '--strides=2,2,1,1',\n"," '--lin_channels=1024',\n"," '--net_act=relu',\n"," '--dims=2,2',\n"," '--group_hidden_units=128,128',\n"," '--reconstruct_first',\n"," '--exponential_map',\n"," '--latent_loss',\n"," '--latent_loss_weight=400',\n"," '--val_epoch=10',\n"," '--num_val=500',\n"," '--plot_epoch=10',\n"," '--plot_manifold_latent=[0,1]',\n"," '--plot_manifold',\n"," '--plot_reconstruction',\n"," '--plot_pca',\n"," '--plot_vary_latents=[4,5]']"]},"metadata":{},"execution_count":113}]},{"cell_type":"code","source":["def setup_data(config, mode='homomorphism'):\n","    \"\"\"\n","    \"\"\"\n","    if config.dataset == 'dsprites':\n","        return setup_dsprites_dataset(config, mode)\n","\n","def setup_dsprites_dataset(config, mode='homomorphism'):\n","    \"\"\"\n","    \"\"\"\n","    fixed_in_sampling = misc.str_to_ints(config.fixed_in_sampling)\n","    fixed_values = misc.str_to_ints(config.fixed_values)\n","    fixed_in_action = misc.str_to_ints(config.fixed_in_intervention)\n","    action_range = misc.str_to_ints(config.displacement_range)\n","    if mode == 'homomorphism':\n","        config.intervene = True\n","    dhandler = DspritesDataset(\n","        root=config.data_root,\n","        num_train=config.num_train,\n","        num_val=config.num_val,\n","        rseed=config.data_random_seed,\n","        fixed_in_sampling=fixed_in_sampling,\n","        fixed_values=fixed_values,\n","        fixed_in_action=fixed_in_action,\n","        transitions_on=config.intervene,\n","        n_transitions=config.n_steps,\n","        action_range=action_range,\n","        cyclic_trans=config.cyclic_trans,\n","        dist=config.distrib,\n","        return_integer_actions=config.integer_actions,\n","        rotate_actions=config.rotate_actions,\n","        combinatorial_indices_file=config.combinatorial_indices,\n","        )\n","    dloader = DataLoader(\n","        dataset=dhandler, batch_size=config.batch_size,\n","        shuffle=config.shuffle)\n","    return dhandler, dloader"],"metadata":{"id":"6RcSdZpBErTq","executionInfo":{"status":"ok","timestamp":1682182847472,"user_tz":-120,"elapsed":4,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":114,"outputs":[]},{"cell_type":"code","source":["def parse_cmd_arguments(representation=Representation.BLOCK_ROTS,\n","                        description='', argv=None):\n","    \"\"\"\n","    \"\"\"\n","    mode='homomorphism'\n","    curr_date = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n","    if not description:\n","        description = 'N Steps Autoencoder'\n","    dout_dir = './out/run_' + curr_date\n","    parser = argparse.ArgumentParser(description=description)\n","    args.data_args(parser,mode)\n","    args.train_args(parser)\n","    args.net_args(parser)\n","    args.misc_args(parser, dout_dir)\n","    args.group_repr_args(parser,representation)\n","\n","    config = parser.parse_args(args=argv)\n","\n","    config.intervene = True\n","    return config"],"metadata":{"id":"7M511nSgZvXv","executionInfo":{"status":"ok","timestamp":1682182848527,"user_tz":-120,"elapsed":2,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":115,"outputs":[]},{"cell_type":"code","source":["representation = Representation.BLOCK_MLP\n","mode = \"homomorphism\"\n","\n","config = train_args.parse_cmd_arguments(representation, argv=input_args)\n","device = torch.device(\"cuda\")\n","device, logger = sim_utils.setup_environment(config)\n","sim_utils.backup_cli_command(config)\n","\n","dhandler, dloader = setup_data(config, mode)\n","nets = net_utils.setup_network(config, dhandler, device, mode=mode,\n","                                   representation=representation)\n","\n","shared = Namespace()\n","sim_utils.setup_summary_dict(config, shared, nets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WMkmJte2I8Fl","executionInfo":{"status":"ok","timestamp":1682182850731,"user_tz":-120,"elapsed":739,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"outputId":"5ddbf153-4648-49f9-e8e5-f7df73758bd2"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["Created output folder ./out/run_2023-04-22_17-00-49.\n","04/22/2023 05:00:49 PM - INFO - Using cuda : True\n","04/22/2023 05:00:49 PM - INFO - Using cuda : True\n","04/22/2023 05:00:49 PM - INFO - Using cuda : True\n","04/22/2023 05:00:49 PM - INFO - Using cuda : True\n","04/22/2023 05:00:49 PM - INFO - Using cuda : True\n","04/22/2023 05:00:49 PM - INFO - Using cuda : True\n","04/22/2023 05:00:49 PM - INFO - Using cuda : True\n","04/22/2023 05:00:49 PM - INFO - Using cuda : True\n"]},{"output_type":"stream","name":"stderr","text":["INFO:logger:Using cuda : True\n"]}]},{"cell_type":"markdown","source":["### Train images"],"metadata":{"id":"3J_-JSlYH3XJ"}},{"cell_type":"code","source":["imgs, metadata = load_dsprite()\n","\n","show_density(imgs[dhandler.all_indices[dhandler.train_idx.flatten()]])"],"metadata":{"id":"vKO3nKNo98MR","executionInfo":{"status":"ok","timestamp":1682182860787,"user_tz":-120,"elapsed":8659,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"colab":{"base_uri":"https://localhost:8080/","height":406},"outputId":"497597b3-99be-40f1-f212-63de29945f1e"},"execution_count":117,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["new_train_idx = []\n","\n","for k in range(copy.deepcopy(dhandler.train_idx.shape[0])):\n","    if not set(dhandler.all_indices[dhandler.train_idx[k]].tolist()).intersection(set(indices_sampled)):\n","        new_train_idx.append(dhandler.train_idx[k].tolist())\n","\n","dhandler.train_idx = np.asarray(new_train_idx)"],"metadata":{"id":"kEjP193SE4jt","executionInfo":{"status":"ok","timestamp":1682182907992,"user_tz":-120,"elapsed":42877,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":118,"outputs":[]},{"cell_type":"code","source":["show_density(imgs[dhandler.all_indices[dhandler.train_idx.flatten()]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"id":"f5lBjBf6FPLU","executionInfo":{"status":"ok","timestamp":1682183061795,"user_tz":-120,"elapsed":426,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"outputId":"87250053-cf23-430f-c63d-7fd66227c196"},"execution_count":119,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["### Validation images"],"metadata":{"id":"TUPfONdEH7Uy"}},{"cell_type":"code","source":["show_density(imgs[dhandler.all_indices[dhandler.val_idx.flatten()]])"],"metadata":{"id":"wsfLPUfjLfim","colab":{"base_uri":"https://localhost:8080/","height":406},"executionInfo":{"status":"ok","timestamp":1682183064933,"user_tz":-120,"elapsed":6,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"outputId":"a95ac8cf-46f5-4049-bc27-2bc9bf01e4e6"},"execution_count":120,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["new_val_idx = []\n","\n","for k in range(copy.deepcopy(dhandler.val_idx.shape[0])):\n","    if set([dhandler.all_indices[dhandler.val_idx[k, 0]]]).intersection(set(indices_sampled)):\n","        new_val_idx.append(dhandler.val_idx[k].tolist())\n","\n","dhandler.val_idx = np.asarray(new_val_idx)"],"metadata":{"id":"sr6wF9rXF2Q-","executionInfo":{"status":"ok","timestamp":1682183069758,"user_tz":-120,"elapsed":1965,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["show_density(imgs[dhandler.all_indices[dhandler.val_idx.flatten()]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"id":"cRBuZ0y9GDCk","executionInfo":{"status":"ok","timestamp":1682183082463,"user_tz":-120,"elapsed":334,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"outputId":"041334cb-f0f9-4ddc-9c2c-94972182d9dc"},"execution_count":122,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## Homomorphism Autoencoder Ellipsis Dataset"],"metadata":{"id":"hxs31RpXDFyu"}},{"cell_type":"code","source":["# WAND_API_KEY = \"7bb6efe911fc751a25083e6f77d38c5900d85304\""],"metadata":{"id":"S5a8uayrykCH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### No Recombination"],"metadata":{"id":"IID2cRc1F05c"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T40UXOWhuB0S","outputId":"f3dbb341-a8e6-4220-aca6-0a44a8bd05e6","executionInfo":{"status":"ok","timestamp":1681918836247,"user_tz":-120,"elapsed":1273484,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism\n","Created output folder ./out/run_2023-04-19_15-19-26.\n","04/19/2023 03:19:26 PM - INFO - Using cuda : True\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/wandb/run-20230419_151940-969ss2ye\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexpert-shadow-9\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/simonecaldarella/homomorphism-autoencoder\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/simonecaldarella/homomorphism-autoencoder/runs/969ss2ye\u001b[0m\n","04/19/2023 03:19:43 PM - INFO - ### Training ###\n","04/19/2023 03:19:45 PM - INFO - EVALUATION prior to epoch [0]...\n","04/19/2023 03:19:45 PM - INFO - [0] loss\t2897.60=\tBCE 2897.60 \tLL 0.00052 \n","04/19/2023 03:19:47 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/0_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:19:53 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/0_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:19:57 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/0_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/19/2023 03:19:58 PM - INFO - Training epoch 0.\n","04/19/2023 03:19:59 PM - INFO - [0:0] loss\t2897.61 =\tBCE 2897.60938 \tLL 0.00054 \tTotal 2204.18/2204.13/3.43 \n","04/19/2023 03:19:59 PM - INFO - [0:1] loss\t2873.67 =\tBCE 2873.66626 \tLL 0.03449 \tTotal 2182.76/2148.80/201.43 \n","04/19/2023 03:20:00 PM - INFO - [0:2] loss\t2780.57 =\tBCE 2780.57495 \tLL 0.00007 \tTotal 2136.56/2136.55/1.84 \n","04/19/2023 03:20:00 PM - INFO - [0:3] loss\t2595.67 =\tBCE 2595.66772 \tLL 0.00015 \tTotal 2171.17/2170.93/4.65 \n","04/19/2023 03:20:01 PM - INFO - [0:4] loss\t2395.43 =\tBCE 2395.43091 \tLL 0.00094 \tTotal 1569.61/1569.56/10.42 \n","04/19/2023 03:20:01 PM - INFO - [0:5] loss\t2467.30 =\tBCE 2467.29736 \tLL 0.00291 \tTotal 2237.95/2194.83/240.60 \n","04/19/2023 03:20:02 PM - INFO - [0:6] loss\t2312.98 =\tBCE 2312.98193 \tLL 0.00017 \tTotal 1725.89/1724.94/13.67 \n","04/19/2023 03:20:02 PM - INFO - [0:7] loss\t2156.57 =\tBCE 2156.57056 \tLL 0.00007 \tTotal 1187.86/1187.83/1.03 \n","04/19/2023 03:20:03 PM - INFO - [0:8] loss\t2073.74 =\tBCE 2073.74219 \tLL 0.00006 \tTotal 1571.99/1571.90/1.79 \n","04/19/2023 03:20:04 PM - INFO - [0:9] loss\t1998.46 =\tBCE 1998.45532 \tLL 0.00006 \tTotal 1737.42/1737.33/1.97 \n","04/19/2023 03:20:04 PM - INFO - [0:10] loss\t1875.01 =\tBCE 1875.00684 \tLL 0.00007 \tTotal 1416.50/1416.41/1.45 \n","04/19/2023 03:20:05 PM - INFO - [0:11] loss\t1762.66 =\tBCE 1762.66101 \tLL 0.00008 \tTotal 929.04/928.98/1.55 \n","04/19/2023 03:20:05 PM - INFO - [0:12] loss\t1693.67 =\tBCE 1693.67163 \tLL 0.00012 \tTotal 1187.30/1187.28/2.63 \n","04/19/2023 03:20:06 PM - INFO - [0:13] loss\t1593.77 =\tBCE 1593.77283 \tLL 0.00025 \tTotal 1251.35/1251.34/3.58 \n","04/19/2023 03:20:06 PM - INFO - [0:14] loss\t1468.46 =\tBCE 1468.45691 \tLL 0.00055 \tTotal 904.29/904.27/5.21 \n","04/19/2023 03:20:07 PM - INFO - [0:15] loss\t1357.28 =\tBCE 1357.27576 \tLL 0.00122 \tTotal 684.97/684.72/10.83 \n","04/19/2023 03:20:07 PM - INFO - [0:16] loss\t1266.81 =\tBCE 1266.80811 \tLL 0.00301 \tTotal 774.13/772.63/24.10 \n","04/19/2023 03:20:08 PM - INFO - [0:17] loss\t1178.20 =\tBCE 1178.20447 \tLL 0.00978 \tTotal 690.91/685.84/42.72 \n","04/19/2023 03:20:08 PM - INFO - [0:18] loss\t1108.32 =\tBCE 1108.32202 \tLL 0.02882 \tTotal 527.34/419.69/307.14 \n","04/19/2023 03:20:09 PM - INFO - [0:19] loss\t1056.94 =\tBCE 1056.94202 \tLL 0.01728 \tTotal 431.42/398.45/135.75 \n","04/19/2023 03:20:09 PM - INFO - Training epoch 1.\n","04/19/2023 03:20:09 PM - INFO - [1:0] loss\t1011.43 =\tBCE 1011.42645 \tLL 0.00917 \tTotal 356.72/334.98/109.54 \n","04/19/2023 03:20:10 PM - INFO - [1:1] loss\t974.88 =\tBCE 974.88226 \tLL 0.00638 \tTotal 276.69/245.16/125.05 \n","04/19/2023 03:20:10 PM - INFO - [1:2] loss\t964.34 =\tBCE 964.34003 \tLL 0.00444 \tTotal 250.53/224.00/110.60 \n","04/19/2023 03:20:11 PM - INFO - [1:3] loss\t948.58 =\tBCE 948.57660 \tLL 0.00269 \tTotal 258.24/242.99/85.96 \n","04/19/2023 03:20:11 PM - INFO - [1:4] loss\t928.39 =\tBCE 928.39270 \tLL 0.00158 \tTotal 266.78/259.24/58.94 \n","04/19/2023 03:20:12 PM - INFO - [1:5] loss\t939.39 =\tBCE 939.39117 \tLL 0.00166 \tTotal 251.97/248.42/32.25 \n","04/19/2023 03:20:12 PM - INFO - [1:6] loss\t917.02 =\tBCE 917.02081 \tLL 0.00267 \tTotal 245.94/215.41/110.14 \n","04/19/2023 03:20:13 PM - INFO - [1:7] loss\t920.44 =\tBCE 920.44226 \tLL 0.00211 \tTotal 242.41/216.07/96.23 \n","04/19/2023 03:20:13 PM - INFO - [1:8] loss\t904.63 =\tBCE 904.63257 \tLL 0.00080 \tTotal 194.41/192.69/19.85 \n","04/19/2023 03:20:14 PM - INFO - [1:9] loss\t901.34 =\tBCE 901.34344 \tLL 0.00042 \tTotal 193.20/192.93/6.70 \n","04/19/2023 03:20:14 PM - INFO - [1:10] loss\t886.74 =\tBCE 886.74146 \tLL 0.00024 \tTotal 181.33/181.25/2.96 \n","04/19/2023 03:20:15 PM - INFO - [1:11] loss\t887.66 =\tBCE 887.65845 \tLL 0.00017 \tTotal 167.40/167.33/3.20 \n","04/19/2023 03:20:15 PM - INFO - [1:12] loss\t872.43 =\tBCE 872.43274 \tLL 0.00014 \tTotal 159.59/159.50/4.12 \n","04/19/2023 03:20:16 PM - INFO - [1:13] loss\t860.07 =\tBCE 860.06775 \tLL 0.00012 \tTotal 148.28/148.21/3.35 \n","04/19/2023 03:20:17 PM - INFO - [1:14] loss\t859.14 =\tBCE 859.13928 \tLL 0.00011 \tTotal 125.86/125.81/2.54 \n","04/19/2023 03:20:17 PM - INFO - [1:15] loss\t855.23 =\tBCE 855.23035 \tLL 0.00010 \tTotal 114.84/114.80/1.68 \n","04/19/2023 03:20:18 PM - INFO - [1:16] loss\t847.90 =\tBCE 847.89557 \tLL 0.00010 \tTotal 113.17/113.13/1.66 \n","04/19/2023 03:20:18 PM - INFO - [1:17] loss\t845.62 =\tBCE 845.62500 \tLL 0.00011 \tTotal 96.43/96.37/1.97 \n","04/19/2023 03:20:19 PM - INFO - [1:18] loss\t848.43 =\tBCE 848.43164 \tLL 0.00011 \tTotal 103.06/103.00/1.72 \n","04/19/2023 03:20:19 PM - INFO - [1:19] loss\t840.84 =\tBCE 840.84204 \tLL 0.00011 \tTotal 98.10/97.93/2.42 \n","04/19/2023 03:20:19 PM - INFO - Training epoch 2.\n","04/19/2023 03:20:20 PM - INFO - [2:0] loss\t840.67 =\tBCE 840.66583 \tLL 0.00011 \tTotal 110.06/109.92/2.16 \n","04/19/2023 03:20:20 PM - INFO - [2:1] loss\t821.06 =\tBCE 821.05750 \tLL 0.00010 \tTotal 129.51/129.16/3.22 \n","04/19/2023 03:20:21 PM - INFO - [2:2] loss\t823.40 =\tBCE 823.40021 \tLL 0.00009 \tTotal 86.47/86.26/2.34 \n","04/19/2023 03:20:21 PM - INFO - [2:3] loss\t831.15 =\tBCE 831.14508 \tLL 0.00008 \tTotal 106.13/106.11/1.32 \n","04/19/2023 03:20:22 PM - INFO - [2:4] loss\t831.89 =\tBCE 831.88879 \tLL 0.00007 \tTotal 104.45/104.43/1.00 \n","04/19/2023 03:20:22 PM - INFO - [2:5] loss\t823.29 =\tBCE 823.29425 \tLL 0.00007 \tTotal 75.82/75.78/1.57 \n","04/19/2023 03:20:23 PM - INFO - [2:6] loss\t828.28 =\tBCE 828.27954 \tLL 0.00006 \tTotal 79.16/79.12/1.41 \n","04/19/2023 03:20:24 PM - INFO - [2:7] loss\t823.97 =\tBCE 823.97064 \tLL 0.00006 \tTotal 73.62/73.49/1.84 \n","04/19/2023 03:20:24 PM - INFO - [2:8] loss\t810.80 =\tBCE 810.80035 \tLL 0.00006 \tTotal 122.82/122.62/2.46 \n","04/19/2023 03:20:25 PM - INFO - [2:9] loss\t823.93 =\tBCE 823.92865 \tLL 0.00006 \tTotal 54.53/54.42/1.85 \n","04/19/2023 03:20:25 PM - INFO - [2:10] loss\t811.89 =\tBCE 811.88806 \tLL 0.00006 \tTotal 61.80/61.67/2.35 \n","04/19/2023 03:20:26 PM - INFO - [2:11] loss\t820.77 =\tBCE 820.76672 \tLL 0.00007 \tTotal 95.95/95.91/1.63 \n","04/19/2023 03:20:26 PM - INFO - [2:12] loss\t813.87 =\tBCE 813.87109 \tLL 0.00008 \tTotal 55.78/55.69/2.36 \n","04/19/2023 03:20:27 PM - INFO - [2:13] loss\t810.55 =\tBCE 810.54913 \tLL 0.00010 \tTotal 56.59/56.38/3.28 \n","04/19/2023 03:20:27 PM - INFO - [2:14] loss\t808.46 =\tBCE 808.45868 \tLL 0.00013 \tTotal 71.31/71.03/4.11 \n","04/19/2023 03:20:28 PM - INFO - [2:15] loss\t812.02 =\tBCE 812.01678 \tLL 0.00015 \tTotal 46.52/46.18/3.93 \n","04/19/2023 03:20:28 PM - INFO - [2:16] loss\t811.44 =\tBCE 811.43591 \tLL 0.00018 \tTotal 57.56/57.32/3.44 \n","04/19/2023 03:20:29 PM - INFO - [2:17] loss\t811.21 =\tBCE 811.20587 \tLL 0.00025 \tTotal 60.59/60.45/2.43 \n","04/19/2023 03:20:29 PM - INFO - [2:18] loss\t813.32 =\tBCE 813.32019 \tLL 0.00036 \tTotal 61.00/60.83/1.78 \n","04/19/2023 03:20:30 PM - INFO - [2:19] loss\t804.90 =\tBCE 804.90472 \tLL 0.00061 \tTotal 40.55/39.85/2.30 \n","04/19/2023 03:20:30 PM - INFO - Training epoch 3.\n","04/19/2023 03:20:31 PM - INFO - [3:0] loss\t804.03 =\tBCE 804.02502 \tLL 0.00114 \tTotal 73.09/72.03/7.24 \n","04/19/2023 03:20:31 PM - INFO - [3:1] loss\t808.83 =\tBCE 808.82648 \tLL 0.00201 \tTotal 67.31/63.76/20.97 \n","04/19/2023 03:20:32 PM - INFO - [3:2] loss\t811.63 =\tBCE 811.62653 \tLL 0.00273 \tTotal 73.94/62.09/35.94 \n","04/19/2023 03:20:32 PM - INFO - [3:3] loss\t802.70 =\tBCE 802.70209 \tLL 0.00220 \tTotal 61.14/54.77/16.54 \n","04/19/2023 03:20:33 PM - INFO - [3:4] loss\t812.11 =\tBCE 812.10925 \tLL 0.00245 \tTotal 58.49/54.25/21.15 \n","04/19/2023 03:20:33 PM - INFO - [3:5] loss\t803.00 =\tBCE 803.00238 \tLL 0.00265 \tTotal 88.26/66.73/55.93 \n","04/19/2023 03:20:34 PM - INFO - [3:6] loss\t809.92 =\tBCE 809.92181 \tLL 0.00339 \tTotal 134.04/111.02/45.19 \n","04/19/2023 03:20:34 PM - INFO - [3:7] loss\t805.31 =\tBCE 805.30511 \tLL 0.00208 \tTotal 71.81/64.64/14.36 \n","04/19/2023 03:20:35 PM - INFO - [3:8] loss\t811.88 =\tBCE 811.87915 \tLL 0.00211 \tTotal 86.79/84.73/13.26 \n","04/19/2023 03:20:35 PM - INFO - [3:9] loss\t802.66 =\tBCE 802.65540 \tLL 0.00216 \tTotal 64.43/52.09/24.93 \n","04/19/2023 03:20:36 PM - INFO - [3:10] loss\t806.11 =\tBCE 806.11493 \tLL 0.00266 \tTotal 149.54/113.58/78.79 \n","04/19/2023 03:20:36 PM - INFO - [3:11] loss\t809.52 =\tBCE 809.52002 \tLL 0.00210 \tTotal 57.30/53.95/9.64 \n","04/19/2023 03:20:37 PM - INFO - [3:12] loss\t801.09 =\tBCE 801.08832 \tLL 0.00219 \tTotal 159.79/111.73/93.06 \n","04/19/2023 03:20:38 PM - INFO - [3:13] loss\t805.03 =\tBCE 805.02826 \tLL 0.00249 \tTotal 104.46/90.74/48.52 \n","04/19/2023 03:20:38 PM - INFO - [3:14] loss\t801.25 =\tBCE 801.24854 \tLL 0.00367 \tTotal 179.89/112.30/119.15 \n","04/19/2023 03:20:39 PM - INFO - [3:15] loss\t803.44 =\tBCE 803.43524 \tLL 0.00303 \tTotal 55.40/51.51/14.60 \n","04/19/2023 03:20:39 PM - INFO - [3:16] loss\t812.43 =\tBCE 812.42664 \tLL 0.00335 \tTotal 95.29/73.19/57.98 \n","04/19/2023 03:20:40 PM - INFO - [3:17] loss\t804.36 =\tBCE 804.36115 \tLL 0.00339 \tTotal 90.81/69.87/41.85 \n","04/19/2023 03:20:40 PM - INFO - [3:18] loss\t796.31 =\tBCE 796.31244 \tLL 0.00456 \tTotal 86.00/46.60/66.45 \n","04/19/2023 03:20:41 PM - INFO - [3:19] loss\t803.85 =\tBCE 803.84985 \tLL 0.00457 \tTotal 194.67/105.77/136.01 \n","04/19/2023 03:20:41 PM - INFO - Training epoch 4.\n","04/19/2023 03:20:41 PM - INFO - [4:0] loss\t796.28 =\tBCE 796.28333 \tLL 0.00371 \tTotal 182.75/109.97/113.38 \n","04/19/2023 03:20:42 PM - INFO - [4:1] loss\t804.58 =\tBCE 804.58447 \tLL 0.00440 \tTotal 90.75/38.94/77.88 \n","04/19/2023 03:20:42 PM - INFO - [4:2] loss\t799.22 =\tBCE 799.22131 \tLL 0.00546 \tTotal 94.87/76.57/34.50 \n","04/19/2023 03:20:43 PM - INFO - [4:3] loss\t798.73 =\tBCE 798.72687 \tLL 0.00665 \tTotal 140.63/97.41/73.59 \n","04/19/2023 03:20:43 PM - INFO - [4:4] loss\t802.52 =\tBCE 802.51599 \tLL 0.00573 \tTotal 83.00/73.88/24.29 \n","04/19/2023 03:20:44 PM - INFO - [4:5] loss\t798.56 =\tBCE 798.56360 \tLL 0.00532 \tTotal 153.03/116.29/12.92 \n","04/19/2023 03:20:45 PM - INFO - [4:6] loss\t811.53 =\tBCE 811.52808 \tLL 0.00779 \tTotal 110.12/62.71/65.21 \n","04/19/2023 03:20:45 PM - INFO - [4:7] loss\t802.73 =\tBCE 802.72833 \tLL 0.00797 \tTotal 66.82/39.17/30.70 \n","04/19/2023 03:20:46 PM - INFO - [4:8] loss\t801.30 =\tBCE 801.30188 \tLL 0.00731 \tTotal 116.44/56.57/88.21 \n","04/19/2023 03:20:46 PM - INFO - [4:9] loss\t802.32 =\tBCE 802.32245 \tLL 0.00669 \tTotal 88.09/72.28/44.01 \n","04/19/2023 03:20:47 PM - INFO - [4:10] loss\t803.44 =\tBCE 803.43726 \tLL 0.00782 \tTotal 127.63/100.99/57.85 \n","04/19/2023 03:20:47 PM - INFO - [4:11] loss\t800.66 =\tBCE 800.65698 \tLL 0.00894 \tTotal 76.65/58.73/36.49 \n","04/19/2023 03:20:48 PM - INFO - [4:12] loss\t796.63 =\tBCE 796.62665 \tLL 0.01011 \tTotal 63.38/50.60/28.77 \n","04/19/2023 03:20:48 PM - INFO - [4:13] loss\t789.17 =\tBCE 789.17334 \tLL 0.01066 \tTotal 94.91/83.96/41.05 \n","04/19/2023 03:20:49 PM - INFO - [4:14] loss\t797.11 =\tBCE 797.10883 \tLL 0.01192 \tTotal 121.05/54.42/67.65 \n","04/19/2023 03:20:49 PM - INFO - [4:15] loss\t798.83 =\tBCE 798.83405 \tLL 0.00951 \tTotal 244.57/110.17/169.24 \n","04/19/2023 03:20:50 PM - INFO - [4:16] loss\t799.75 =\tBCE 799.75366 \tLL 0.01130 \tTotal 143.79/82.67/36.78 \n","04/19/2023 03:20:51 PM - INFO - [4:17] loss\t785.93 =\tBCE 785.92651 \tLL 0.01175 \tTotal 103.02/77.27/44.83 \n","04/19/2023 03:20:51 PM - INFO - [4:18] loss\t789.98 =\tBCE 789.98138 \tLL 0.01320 \tTotal 185.91/74.58/142.71 \n","04/19/2023 03:20:52 PM - INFO - [4:19] loss\t788.64 =\tBCE 788.64386 \tLL 0.01191 \tTotal 162.35/69.96/50.17 \n","04/19/2023 03:20:52 PM - INFO - Training epoch 5.\n","04/19/2023 03:20:52 PM - INFO - [5:0] loss\t789.43 =\tBCE 789.43127 \tLL 0.01572 \tTotal 119.36/76.50/54.72 \n","04/19/2023 03:20:53 PM - INFO - [5:1] loss\t797.58 =\tBCE 797.57550 \tLL 0.01628 \tTotal 156.56/49.39/65.12 \n","04/19/2023 03:20:53 PM - INFO - [5:2] loss\t793.28 =\tBCE 793.27698 \tLL 0.01352 \tTotal 406.80/110.17/242.36 \n","04/19/2023 03:20:54 PM - INFO - [5:3] loss\t788.21 =\tBCE 788.21307 \tLL 0.01828 \tTotal 128.21/56.28/40.14 \n","04/19/2023 03:20:54 PM - INFO - [5:4] loss\t790.31 =\tBCE 790.31152 \tLL 0.01972 \tTotal 476.32/144.57/295.95 \n","04/19/2023 03:20:55 PM - INFO - [5:5] loss\t787.23 =\tBCE 787.23352 \tLL 0.01320 \tTotal 536.58/126.46/307.16 \n","04/19/2023 03:20:55 PM - INFO - [5:6] loss\t776.89 =\tBCE 776.88916 \tLL 0.01661 \tTotal 195.46/75.63/63.92 \n","04/19/2023 03:20:56 PM - INFO - [5:7] loss\t788.14 =\tBCE 788.14136 \tLL 0.02994 \tTotal 1033.51/198.63/787.69 \n","04/19/2023 03:20:56 PM - INFO - [5:8] loss\t777.41 =\tBCE 777.41406 \tLL 0.02209 \tTotal 308.74/124.82/190.43 \n","04/19/2023 03:20:57 PM - INFO - [5:9] loss\t783.65 =\tBCE 783.64594 \tLL 0.02277 \tTotal 620.99/153.34/426.88 \n","04/19/2023 03:20:57 PM - INFO - [5:10] loss\t765.80 =\tBCE 765.80066 \tLL 0.03036 \tTotal 306.42/82.91/280.97 \n","04/19/2023 03:20:58 PM - INFO - [5:11] loss\t783.68 =\tBCE 783.68085 \tLL 0.03697 \tTotal 724.48/258.74/317.54 \n","04/19/2023 03:20:59 PM - INFO - [5:12] loss\t766.71 =\tBCE 766.71112 \tLL 0.03171 \tTotal 224.49/77.71/93.53 \n","04/19/2023 03:20:59 PM - INFO - [5:13] loss\t763.79 =\tBCE 763.78674 \tLL 0.02621 \tTotal 561.71/185.12/312.99 \n","04/19/2023 03:21:00 PM - INFO - [5:14] loss\t754.12 =\tBCE 754.12482 \tLL 0.02818 \tTotal 391.79/157.24/119.81 \n","04/19/2023 03:21:00 PM - INFO - [5:15] loss\t751.08 =\tBCE 751.08423 \tLL 0.04024 \tTotal 563.73/127.12/480.16 \n","04/19/2023 03:21:01 PM - INFO - [5:16] loss\t744.26 =\tBCE 744.25586 \tLL 0.03971 \tTotal 318.61/136.64/256.12 \n","04/19/2023 03:21:01 PM - INFO - [5:17] loss\t740.66 =\tBCE 740.65906 \tLL 0.04139 \tTotal 263.67/95.20/157.31 \n","04/19/2023 03:21:02 PM - INFO - [5:18] loss\t727.84 =\tBCE 727.84259 \tLL 0.05358 \tTotal 279.21/92.03/199.97 \n","04/19/2023 03:21:02 PM - INFO - [5:19] loss\t710.97 =\tBCE 710.97260 \tLL 0.05945 \tTotal 188.05/98.92/106.41 \n","04/19/2023 03:21:02 PM - INFO - Training epoch 6.\n","04/19/2023 03:21:03 PM - INFO - [6:0] loss\t716.35 =\tBCE 716.35162 \tLL 0.07564 \tTotal 346.10/118.84/216.07 \n","04/19/2023 03:21:03 PM - INFO - [6:1] loss\t682.37 =\tBCE 682.37384 \tLL 0.05627 \tTotal 205.11/130.37/129.24 \n","04/19/2023 03:21:04 PM - INFO - [6:2] loss\t670.57 =\tBCE 670.56628 \tLL 0.05833 \tTotal 301.45/126.96/220.15 \n","04/19/2023 03:21:04 PM - INFO - [6:3] loss\t649.38 =\tBCE 649.37738 \tLL 0.05235 \tTotal 314.60/126.91/207.02 \n","04/19/2023 03:21:05 PM - INFO - [6:4] loss\t649.07 =\tBCE 649.06616 \tLL 0.06099 \tTotal 334.27/149.17/206.65 \n","04/19/2023 03:21:06 PM - INFO - [6:5] loss\t638.34 =\tBCE 638.33624 \tLL 0.07184 \tTotal 440.98/147.56/291.66 \n","04/19/2023 03:21:06 PM - INFO - [6:6] loss\t613.63 =\tBCE 613.63086 \tLL 0.06026 \tTotal 317.67/157.22/206.86 \n","04/19/2023 03:21:07 PM - INFO - [6:7] loss\t608.19 =\tBCE 608.19421 \tLL 0.07106 \tTotal 416.93/150.60/297.29 \n","04/19/2023 03:21:07 PM - INFO - [6:8] loss\t584.19 =\tBCE 584.19287 \tLL 0.07394 \tTotal 312.70/144.14/224.45 \n","04/19/2023 03:21:08 PM - INFO - [6:9] loss\t564.96 =\tBCE 564.95593 \tLL 0.07563 \tTotal 519.89/149.55/397.05 \n","04/19/2023 03:21:08 PM - INFO - [6:10] loss\t560.32 =\tBCE 560.31842 \tLL 0.05977 \tTotal 781.85/149.95/539.54 \n","04/19/2023 03:21:09 PM - INFO - [6:11] loss\t555.74 =\tBCE 555.73633 \tLL 0.07296 \tTotal 1023.31/142.71/777.94 \n","04/19/2023 03:21:09 PM - INFO - [6:12] loss\t522.41 =\tBCE 522.41254 \tLL 0.05717 \tTotal 416.88/164.66/250.71 \n","04/19/2023 03:21:10 PM - INFO - [6:13] loss\t516.60 =\tBCE 516.59851 \tLL 0.06794 \tTotal 939.45/167.40/680.36 \n","04/19/2023 03:21:10 PM - INFO - [6:14] loss\t509.53 =\tBCE 509.52567 \tLL 0.07237 \tTotal 971.61/169.22/717.49 \n","04/19/2023 03:21:11 PM - INFO - [6:15] loss\t477.32 =\tBCE 477.32416 \tLL 0.06013 \tTotal 365.17/160.22/196.73 \n","04/19/2023 03:21:11 PM - INFO - [6:16] loss\t473.92 =\tBCE 473.91592 \tLL 0.05653 \tTotal 804.88/143.45/619.78 \n","04/19/2023 03:21:12 PM - INFO - [6:17] loss\t445.90 =\tBCE 445.89548 \tLL 0.05219 \tTotal 537.61/154.22/341.21 \n","04/19/2023 03:21:13 PM - INFO - [6:18] loss\t429.66 =\tBCE 429.65509 \tLL 0.05291 \tTotal 1082.50/166.02/820.02 \n","04/19/2023 03:21:13 PM - INFO - [6:19] loss\t424.78 =\tBCE 424.77725 \tLL 0.04933 \tTotal 1351.42/205.35/941.19 \n","04/19/2023 03:21:13 PM - INFO - Training epoch 7.\n","04/19/2023 03:21:14 PM - INFO - [7:0] loss\t385.29 =\tBCE 385.28555 \tLL 0.03806 \tTotal 471.12/215.03/271.02 \n","04/19/2023 03:21:14 PM - INFO - [7:1] loss\t361.53 =\tBCE 361.52731 \tLL 0.03997 \tTotal 1070.81/198.24/739.38 \n","04/19/2023 03:21:15 PM - INFO - [7:2] loss\t331.21 =\tBCE 331.20505 \tLL 0.03642 \tTotal 854.69/264.01/571.33 \n","04/19/2023 03:21:15 PM - INFO - [7:3] loss\t301.08 =\tBCE 301.08463 \tLL 0.03478 \tTotal 1165.73/400.28/593.87 \n","04/19/2023 03:21:16 PM - INFO - [7:4] loss\t301.84 =\tBCE 301.83664 \tLL 0.03522 \tTotal 2790.05/1345.82/1605.23 \n","04/19/2023 03:21:16 PM - INFO - [7:5] loss\t445.91 =\tBCE 445.90741 \tLL 0.04618 \tTotal 6889.89/3356.62/4202.52 \n","04/19/2023 03:21:17 PM - INFO - [7:6] loss\t330.44 =\tBCE 330.43597 \tLL 0.03348 \tTotal 5362.28/2228.48/3404.55 \n","04/19/2023 03:21:18 PM - INFO - [7:7] loss\t277.73 =\tBCE 277.73471 \tLL 0.02717 \tTotal 2760.00/1382.74/1748.43 \n","04/19/2023 03:21:18 PM - INFO - [7:8] loss\t272.78 =\tBCE 272.78278 \tLL 0.02700 \tTotal 2708.40/1227.58/1797.19 \n","04/19/2023 03:21:19 PM - INFO - [7:9] loss\t270.65 =\tBCE 270.64597 \tLL 0.02389 \tTotal 2436.43/1510.96/1253.62 \n","04/19/2023 03:21:19 PM - INFO - [7:10] loss\t231.27 =\tBCE 231.26532 \tLL 0.02396 \tTotal 2025.48/511.08/1318.06 \n","04/19/2023 03:21:20 PM - INFO - [7:11] loss\t246.43 =\tBCE 246.42569 \tLL 0.01638 \tTotal 2264.25/1309.83/1543.59 \n","04/19/2023 03:21:20 PM - INFO - [7:12] loss\t199.31 =\tBCE 199.31088 \tLL 0.01523 \tTotal 2006.37/572.44/1188.37 \n","04/19/2023 03:21:21 PM - INFO - [7:13] loss\t204.14 =\tBCE 204.13745 \tLL 0.02140 \tTotal 1869.17/764.02/1381.59 \n","04/19/2023 03:21:21 PM - INFO - [7:14] loss\t198.84 =\tBCE 198.84351 \tLL 0.02329 \tTotal 2081.19/730.99/1639.43 \n","04/19/2023 03:21:22 PM - INFO - [7:15] loss\t173.96 =\tBCE 173.96443 \tLL 0.01632 \tTotal 2200.14/513.62/1473.89 \n","04/19/2023 03:21:22 PM - INFO - [7:16] loss\t179.58 =\tBCE 179.57620 \tLL 0.01823 \tTotal 2979.52/971.39/2173.86 \n","04/19/2023 03:21:23 PM - INFO - [7:17] loss\t158.44 =\tBCE 158.44493 \tLL 0.01908 \tTotal 1937.53/325.21/1399.48 \n","04/19/2023 03:21:24 PM - INFO - [7:18] loss\t153.55 =\tBCE 153.55266 \tLL 0.01496 \tTotal 1816.84/700.81/1171.66 \n","04/19/2023 03:21:24 PM - INFO - [7:19] loss\t147.41 =\tBCE 147.41298 \tLL 0.01407 \tTotal 1859.18/652.06/1433.74 \n","04/19/2023 03:21:24 PM - INFO - Training epoch 8.\n","04/19/2023 03:21:25 PM - INFO - [8:0] loss\t145.00 =\tBCE 145.00307 \tLL 0.01658 \tTotal 2096.53/490.76/1477.02 \n","04/19/2023 03:21:25 PM - INFO - [8:1] loss\t135.70 =\tBCE 135.69676 \tLL 0.01454 \tTotal 2015.45/797.83/1441.86 \n","04/19/2023 03:21:26 PM - INFO - [8:2] loss\t121.73 =\tBCE 121.72613 \tLL 0.01311 \tTotal 1203.08/254.78/608.30 \n","04/19/2023 03:21:26 PM - INFO - [8:3] loss\t125.64 =\tBCE 125.64045 \tLL 0.01396 \tTotal 1728.45/804.99/908.59 \n","04/19/2023 03:21:27 PM - INFO - [8:4] loss\t116.73 =\tBCE 116.73446 \tLL 0.01338 \tTotal 1698.56/182.90/1344.22 \n","04/19/2023 03:21:27 PM - INFO - [8:5] loss\t130.24 =\tBCE 130.23691 \tLL 0.01493 \tTotal 3352.24/739.42/2427.43 \n","04/19/2023 03:21:28 PM - INFO - [8:6] loss\t115.82 =\tBCE 115.81792 \tLL 0.01223 \tTotal 3651.19/520.84/2805.51 \n","04/19/2023 03:21:29 PM - INFO - [8:7] loss\t141.09 =\tBCE 141.08731 \tLL 0.01419 \tTotal 5320.89/938.24/3937.98 \n","04/19/2023 03:21:29 PM - INFO - [8:8] loss\t129.91 =\tBCE 129.90529 \tLL 0.01204 \tTotal 5395.36/900.53/3956.13 \n","04/19/2023 03:21:30 PM - INFO - [8:9] loss\t127.11 =\tBCE 127.11157 \tLL 0.01066 \tTotal 4491.07/882.40/3380.19 \n","04/19/2023 03:21:30 PM - INFO - [8:10] loss\t98.83 =\tBCE 98.82653 \tLL 0.00976 \tTotal 1174.80/232.25/828.48 \n","04/19/2023 03:21:31 PM - INFO - [8:11] loss\t119.94 =\tBCE 119.93725 \tLL 0.01005 \tTotal 3885.70/722.11/3034.58 \n","04/19/2023 03:21:31 PM - INFO - [8:12] loss\t114.28 =\tBCE 114.27544 \tLL 0.00848 \tTotal 4158.35/724.20/2869.96 \n","04/19/2023 03:21:32 PM - INFO - [8:13] loss\t111.58 =\tBCE 111.58176 \tLL 0.00890 \tTotal 3489.58/570.78/2660.15 \n","04/19/2023 03:21:32 PM - INFO - [8:14] loss\t89.75 =\tBCE 89.75140 \tLL 0.00746 \tTotal 1521.36/333.69/1018.71 \n","04/19/2023 03:21:33 PM - INFO - [8:15] loss\t99.60 =\tBCE 99.59556 \tLL 0.00733 \tTotal 3341.20/520.45/2549.75 \n","04/19/2023 03:21:34 PM - INFO - [8:16] loss\t89.36 =\tBCE 89.36256 \tLL 0.00745 \tTotal 1273.95/377.06/719.18 \n","04/19/2023 03:21:34 PM - INFO - [8:17] loss\t93.49 =\tBCE 93.48602 \tLL 0.00692 \tTotal 2578.10/456.74/1853.19 \n","04/19/2023 03:21:35 PM - INFO - [8:18] loss\t99.73 =\tBCE 99.72870 \tLL 0.00720 \tTotal 3636.18/622.75/2729.57 \n","04/19/2023 03:21:35 PM - INFO - [8:19] loss\t82.24 =\tBCE 82.23512 \tLL 0.00739 \tTotal 2061.45/434.00/1414.18 \n","Not implemented\n","04/19/2023 03:21:35 PM - INFO - Training epoch 9.\n","04/19/2023 03:21:36 PM - INFO - [9:0] loss\t79.68 =\tBCE 79.67712 \tLL 0.00780 \tTotal 2334.32/402.17/1783.00 \n","04/19/2023 03:21:36 PM - INFO - [9:1] loss\t82.46 =\tBCE 82.45757 \tLL 0.00722 \tTotal 2983.70/520.06/1963.11 \n","04/19/2023 03:21:37 PM - INFO - [9:2] loss\t86.17 =\tBCE 86.16799 \tLL 0.00714 \tTotal 3541.05/627.90/2569.61 \n","04/19/2023 03:21:37 PM - INFO - [9:3] loss\t75.21 =\tBCE 75.21097 \tLL 0.00663 \tTotal 2076.27/365.35/1379.25 \n","04/19/2023 03:21:38 PM - INFO - [9:4] loss\t77.79 =\tBCE 77.79121 \tLL 0.00769 \tTotal 2966.73/469.97/1979.66 \n","04/19/2023 03:21:38 PM - INFO - [9:5] loss\t86.24 =\tBCE 86.23611 \tLL 0.00746 \tTotal 4264.85/676.66/3065.23 \n","04/19/2023 03:21:39 PM - INFO - [9:6] loss\t82.35 =\tBCE 82.35193 \tLL 0.00761 \tTotal 3963.83/651.79/2725.33 \n","04/19/2023 03:21:40 PM - INFO - [9:7] loss\t76.70 =\tBCE 76.69878 \tLL 0.00696 \tTotal 3418.58/415.47/2558.38 \n","04/19/2023 03:21:40 PM - INFO - [9:8] loss\t74.22 =\tBCE 74.22015 \tLL 0.00855 \tTotal 2301.97/438.05/1349.68 \n","04/19/2023 03:21:41 PM - INFO - [9:9] loss\t64.21 =\tBCE 64.21150 \tLL 0.00590 \tTotal 1468.19/379.32/983.08 \n","04/19/2023 03:21:41 PM - INFO - [9:10] loss\t72.82 =\tBCE 72.81814 \tLL 0.00750 \tTotal 3175.75/442.78/2256.78 \n","04/19/2023 03:21:42 PM - INFO - [9:11] loss\t79.94 =\tBCE 79.93718 \tLL 0.00770 \tTotal 4986.81/835.94/3780.36 \n","04/19/2023 03:21:42 PM - INFO - [9:12] loss\t87.47 =\tBCE 87.46532 \tLL 0.00806 \tTotal 5162.28/892.00/3652.59 \n","04/19/2023 03:21:43 PM - INFO - [9:13] loss\t82.17 =\tBCE 82.16880 \tLL 0.00600 \tTotal 5371.58/793.11/3920.52 \n","04/19/2023 03:21:43 PM - INFO - [9:14] loss\t85.45 =\tBCE 85.44826 \tLL 0.00784 \tTotal 5731.84/455.47/4665.47 \n","04/19/2023 03:21:44 PM - INFO - [9:15] loss\t70.04 =\tBCE 70.04252 \tLL 0.00618 \tTotal 3504.28/809.70/2400.94 \n","04/19/2023 03:21:45 PM - INFO - [9:16] loss\t65.23 =\tBCE 65.23224 \tLL 0.00722 \tTotal 2330.85/574.16/1441.54 \n","04/19/2023 03:21:45 PM - INFO - [9:17] loss\t63.23 =\tBCE 63.23311 \tLL 0.00641 \tTotal 1681.98/443.11/785.21 \n","04/19/2023 03:21:46 PM - INFO - [9:18] loss\t65.81 =\tBCE 65.81460 \tLL 0.00714 \tTotal 3152.89/655.39/2220.80 \n","04/19/2023 03:21:46 PM - INFO - [9:19] loss\t64.71 =\tBCE 64.71085 \tLL 0.00706 \tTotal 3350.05/353.66/2484.77 \n","04/19/2023 03:21:46 PM - INFO - EVALUATION prior to epoch [10]...\n","04/19/2023 03:21:46 PM - INFO - [10] loss\t62.19=\tBCE 62.19 \tLL 0.00646 \n","04/19/2023 03:21:48 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/10_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:21:52 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/10_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:21:58 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/10_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/19/2023 03:21:59 PM - INFO - Training epoch 10.\n","04/19/2023 03:22:00 PM - INFO - [10:0] loss\t63.27 =\tBCE 63.26805 \tLL 0.00640 \tTotal 2415.19/596.72/1595.50 \n","04/19/2023 03:22:00 PM - INFO - [10:1] loss\t58.62 =\tBCE 58.62076 \tLL 0.00682 \tTotal 1916.23/264.06/515.85 \n","04/19/2023 03:22:01 PM - INFO - [10:2] loss\t55.14 =\tBCE 55.13573 \tLL 0.00488 \tTotal 2299.33/420.05/1759.37 \n","04/19/2023 03:22:01 PM - INFO - [10:3] loss\t60.96 =\tBCE 60.95972 \tLL 0.00703 \tTotal 2860.56/372.75/1769.70 \n","04/19/2023 03:22:02 PM - INFO - [10:4] loss\t55.87 =\tBCE 55.87109 \tLL 0.00555 \tTotal 2119.31/537.68/1130.00 \n","04/19/2023 03:22:02 PM - INFO - [10:5] loss\t49.96 =\tBCE 49.95541 \tLL 0.00561 \tTotal 1278.38/192.54/827.47 \n","04/19/2023 03:22:03 PM - INFO - [10:6] loss\t53.87 =\tBCE 53.86733 \tLL 0.00613 \tTotal 2356.42/302.46/1477.97 \n","04/19/2023 03:22:03 PM - INFO - [10:7] loss\t50.21 =\tBCE 50.21291 \tLL 0.00585 \tTotal 2321.27/245.52/1818.22 \n","04/19/2023 03:22:04 PM - INFO - [10:8] loss\t54.03 =\tBCE 54.02729 \tLL 0.00618 \tTotal 2416.33/400.28/1439.92 \n","04/19/2023 03:22:04 PM - INFO - [10:9] loss\t49.56 =\tBCE 49.56261 \tLL 0.00457 \tTotal 2001.18/323.96/1322.61 \n","04/19/2023 03:22:05 PM - INFO - [10:10] loss\t48.95 =\tBCE 48.94543 \tLL 0.00567 \tTotal 2068.89/262.16/1588.54 \n","04/19/2023 03:22:06 PM - INFO - [10:11] loss\t46.86 =\tBCE 46.86275 \tLL 0.00572 \tTotal 2260.34/390.22/1571.00 \n","04/19/2023 03:22:06 PM - INFO - [10:12] loss\t52.21 =\tBCE 52.20901 \tLL 0.00556 \tTotal 3270.17/471.21/2256.18 \n","04/19/2023 03:22:07 PM - INFO - [10:13] loss\t58.78 =\tBCE 58.77890 \tLL 0.00646 \tTotal 5071.00/705.97/3988.79 \n","04/19/2023 03:22:07 PM - INFO - [10:14] loss\t78.14 =\tBCE 78.14143 \tLL 0.00585 \tTotal 7658.65/1163.01/5827.44 \n","04/19/2023 03:22:08 PM - INFO - [10:15] loss\t108.27 =\tBCE 108.27325 \tLL 0.00776 \tTotal 10236.02/1561.30/7707.54 \n","04/19/2023 03:22:08 PM - INFO - [10:16] loss\t136.43 =\tBCE 136.43156 \tLL 0.00990 \tTotal 11441.50/1765.49/8597.38 \n","04/19/2023 03:22:09 PM - INFO - [10:17] loss\t103.84 =\tBCE 103.84293 \tLL 0.00825 \tTotal 9477.19/1294.65/7203.43 \n","04/19/2023 03:22:09 PM - INFO - [10:18] loss\t55.31 =\tBCE 55.30545 \tLL 0.00869 \tTotal 2790.37/406.61/1681.09 \n","04/19/2023 03:22:10 PM - INFO - [10:19] loss\t78.12 =\tBCE 78.12257 \tLL 0.00995 \tTotal 6120.26/712.60/4718.77 \n","04/19/2023 03:22:10 PM - INFO - Training epoch 11.\n","04/19/2023 03:22:10 PM - INFO - [11:0] loss\t78.05 =\tBCE 78.04830 \tLL 0.00974 \tTotal 5390.85/844.12/3994.67 \n","04/19/2023 03:22:11 PM - INFO - [11:1] loss\t55.37 =\tBCE 55.36736 \tLL 0.00727 \tTotal 2837.44/420.93/2138.32 \n","04/19/2023 03:22:12 PM - INFO - [11:2] loss\t79.48 =\tBCE 79.47685 \tLL 0.00607 \tTotal 5782.90/936.22/4255.91 \n","04/19/2023 03:22:12 PM - INFO - [11:3] loss\t52.61 =\tBCE 52.61128 \tLL 0.00420 \tTotal 1586.68/457.78/1085.84 \n","04/19/2023 03:22:13 PM - INFO - [11:4] loss\t67.03 =\tBCE 67.02940 \tLL 0.00413 \tTotal 4888.62/726.61/3587.73 \n","04/19/2023 03:22:13 PM - INFO - [11:5] loss\t57.41 =\tBCE 57.40914 \tLL 0.00460 \tTotal 3493.75/670.62/2677.42 \n","04/19/2023 03:22:14 PM - INFO - [11:6] loss\t51.32 =\tBCE 51.32384 \tLL 0.00509 \tTotal 2669.80/411.99/2005.20 \n","04/19/2023 03:22:14 PM - INFO - [11:7] loss\t60.08 =\tBCE 60.07760 \tLL 0.00523 \tTotal 3757.92/775.65/2638.20 \n","04/19/2023 03:22:15 PM - INFO - [11:8] loss\t48.36 =\tBCE 48.35721 \tLL 0.00479 \tTotal 1184.82/198.30/790.71 \n","04/19/2023 03:22:15 PM - INFO - [11:9] loss\t61.66 =\tBCE 61.65903 \tLL 0.00527 \tTotal 4275.27/678.27/3077.43 \n","04/19/2023 03:22:16 PM - INFO - [11:10] loss\t42.16 =\tBCE 42.15739 \tLL 0.00382 \tTotal 1366.01/280.72/1063.36 \n","04/19/2023 03:22:16 PM - INFO - [11:11] loss\t62.53 =\tBCE 62.53233 \tLL 0.00494 \tTotal 4558.35/544.89/3196.44 \n","04/19/2023 03:22:17 PM - INFO - [11:12] loss\t50.54 =\tBCE 50.53673 \tLL 0.00323 \tTotal 3265.43/594.33/2380.39 \n","04/19/2023 03:22:18 PM - INFO - [11:13] loss\t47.52 =\tBCE 47.51805 \tLL 0.00456 \tTotal 2227.32/404.77/1488.41 \n","04/19/2023 03:22:18 PM - INFO - [11:14] loss\t57.00 =\tBCE 57.00466 \tLL 0.00429 \tTotal 3379.82/754.99/2250.02 \n","04/19/2023 03:22:19 PM - INFO - [11:15] loss\t42.03 =\tBCE 42.03215 \tLL 0.00330 \tTotal 1114.97/180.82/635.03 \n","04/19/2023 03:22:19 PM - INFO - [11:16] loss\t52.69 =\tBCE 52.68624 \tLL 0.00539 \tTotal 3213.76/583.17/2011.71 \n","04/19/2023 03:22:20 PM - INFO - [11:17] loss\t41.43 =\tBCE 41.43137 \tLL 0.00345 \tTotal 2247.50/292.27/1717.81 \n","04/19/2023 03:22:20 PM - INFO - [11:18] loss\t41.20 =\tBCE 41.19994 \tLL 0.00353 \tTotal 2103.76/366.74/1383.45 \n","04/19/2023 03:22:21 PM - INFO - [11:19] loss\t51.61 =\tBCE 51.60770 \tLL 0.00427 \tTotal 4740.36/501.73/3670.00 \n","04/19/2023 03:22:21 PM - INFO - Training epoch 12.\n","04/19/2023 03:22:21 PM - INFO - [12:0] loss\t39.65 =\tBCE 39.64793 \tLL 0.00323 \tTotal 2708.45/410.00/2100.07 \n","04/19/2023 03:22:22 PM - INFO - [12:1] loss\t39.31 =\tBCE 39.31291 \tLL 0.00429 \tTotal 2185.40/218.88/1554.32 \n","04/19/2023 03:22:22 PM - INFO - [12:2] loss\t49.10 =\tBCE 49.10302 \tLL 0.00424 \tTotal 4349.93/697.52/3275.50 \n","04/19/2023 03:22:23 PM - INFO - [12:3] loss\t40.11 =\tBCE 40.11234 \tLL 0.00418 \tTotal 3162.07/452.25/2400.33 \n","04/19/2023 03:22:24 PM - INFO - [12:4] loss\t35.14 =\tBCE 35.13669 \tLL 0.00434 \tTotal 1424.99/293.66/620.48 \n","04/19/2023 03:22:24 PM - INFO - [12:5] loss\t40.97 =\tBCE 40.96667 \tLL 0.00442 \tTotal 3563.17/579.56/2758.62 \n","04/19/2023 03:22:25 PM - INFO - [12:6] loss\t38.32 =\tBCE 38.32015 \tLL 0.00391 \tTotal 3704.20/434.02/2702.80 \n","04/19/2023 03:22:25 PM - INFO - [12:7] loss\t32.70 =\tBCE 32.69575 \tLL 0.00342 \tTotal 1414.13/217.51/1099.88 \n","04/19/2023 03:22:26 PM - INFO - [12:8] loss\t35.93 =\tBCE 35.93467 \tLL 0.00429 \tTotal 2584.18/313.95/1925.38 \n","04/19/2023 03:22:26 PM - INFO - [12:9] loss\t39.53 =\tBCE 39.52949 \tLL 0.00433 \tTotal 4118.43/609.88/3232.11 \n","04/19/2023 03:22:27 PM - INFO - [12:10] loss\t43.56 =\tBCE 43.55610 \tLL 0.00466 \tTotal 4175.48/714.94/3158.57 \n","04/19/2023 03:22:28 PM - INFO - [12:11] loss\t34.19 =\tBCE 34.19450 \tLL 0.00410 \tTotal 2582.22/420.22/1923.97 \n","04/19/2023 03:22:28 PM - INFO - [12:12] loss\t29.61 =\tBCE 29.60729 \tLL 0.00360 \tTotal 1425.23/242.69/999.08 \n","04/19/2023 03:22:29 PM - INFO - [12:13] loss\t40.94 =\tBCE 40.94058 \tLL 0.00444 \tTotal 4586.52/593.35/3569.64 \n","04/19/2023 03:22:29 PM - INFO - [12:14] loss\t51.06 =\tBCE 51.05553 \tLL 0.00536 \tTotal 6450.38/942.37/4993.23 \n","04/19/2023 03:22:30 PM - INFO - [12:15] loss\t58.60 =\tBCE 58.59712 \tLL 0.00530 \tTotal 7207.78/1119.35/5379.83 \n","04/19/2023 03:22:30 PM - INFO - [12:16] loss\t53.46 =\tBCE 53.45812 \tLL 0.00491 \tTotal 6402.95/968.67/4978.98 \n","04/19/2023 03:22:31 PM - INFO - [12:17] loss\t36.23 =\tBCE 36.22755 \tLL 0.00484 \tTotal 3235.22/629.47/2534.20 \n","04/19/2023 03:22:31 PM - INFO - [12:18] loss\t38.97 =\tBCE 38.97384 \tLL 0.00506 \tTotal 2867.31/508.06/2162.91 \n","04/19/2023 03:22:32 PM - INFO - [12:19] loss\t50.04 =\tBCE 50.04030 \tLL 0.00553 \tTotal 5996.38/799.57/4642.99 \n","04/19/2023 03:22:32 PM - INFO - Training epoch 13.\n","04/19/2023 03:22:32 PM - INFO - [13:0] loss\t52.92 =\tBCE 52.91661 \tLL 0.00530 \tTotal 6042.41/1104.27/4367.68 \n","04/19/2023 03:22:33 PM - INFO - [13:1] loss\t38.37 =\tBCE 38.37239 \tLL 0.00498 \tTotal 3235.24/790.55/2177.64 \n","04/19/2023 03:22:34 PM - INFO - [13:2] loss\t31.51 =\tBCE 31.50743 \tLL 0.00437 \tTotal 1780.07/310.08/1191.45 \n","04/19/2023 03:22:34 PM - INFO - [13:3] loss\t44.87 =\tBCE 44.86739 \tLL 0.00473 \tTotal 4637.14/846.94/3356.22 \n","04/19/2023 03:22:35 PM - INFO - [13:4] loss\t40.05 =\tBCE 40.04727 \tLL 0.00502 \tTotal 3798.82/825.53/2870.04 \n","04/19/2023 03:22:35 PM - INFO - [13:5] loss\t34.32 =\tBCE 34.31853 \tLL 0.00525 \tTotal 1972.43/169.12/894.11 \n","04/19/2023 03:22:36 PM - INFO - [13:6] loss\t38.24 =\tBCE 38.23666 \tLL 0.00411 \tTotal 3878.85/800.62/2892.31 \n","04/19/2023 03:22:36 PM - INFO - [13:7] loss\t58.65 =\tBCE 58.65068 \tLL 0.00575 \tTotal 7136.28/974.18/5286.60 \n","04/19/2023 03:22:37 PM - INFO - [13:8] loss\t67.44 =\tBCE 67.44273 \tLL 0.00624 \tTotal 9163.25/706.82/7676.99 \n","04/19/2023 03:22:37 PM - INFO - [13:9] loss\t48.86 =\tBCE 48.86137 \tLL 0.00609 \tTotal 5053.66/547.89/3862.77 \n","04/19/2023 03:22:38 PM - INFO - [13:10] loss\t48.24 =\tBCE 48.24328 \tLL 0.00575 \tTotal 3840.28/328.32/2854.80 \n","04/19/2023 03:22:39 PM - INFO - [13:11] loss\t47.66 =\tBCE 47.66068 \tLL 0.00553 \tTotal 4436.94/671.63/3019.21 \n","04/19/2023 03:22:39 PM - INFO - [13:12] loss\t47.71 =\tBCE 47.71101 \tLL 0.00770 \tTotal 3753.81/602.79/2368.68 \n","04/19/2023 03:22:40 PM - INFO - [13:13] loss\t46.35 =\tBCE 46.35434 \tLL 0.00554 \tTotal 3759.54/362.41/2947.88 \n","04/19/2023 03:22:40 PM - INFO - [13:14] loss\t48.72 =\tBCE 48.72190 \tLL 0.00545 \tTotal 5110.99/644.14/3504.56 \n","04/19/2023 03:22:41 PM - INFO - [13:15] loss\t40.77 =\tBCE 40.77056 \tLL 0.00388 \tTotal 3867.11/592.39/2685.82 \n","04/19/2023 03:22:41 PM - INFO - [13:16] loss\t41.33 =\tBCE 41.33185 \tLL 0.00635 \tTotal 2186.76/332.44/991.56 \n","04/19/2023 03:22:42 PM - INFO - [13:17] loss\t41.83 =\tBCE 41.82690 \tLL 0.00462 \tTotal 3126.91/589.61/2306.19 \n","04/19/2023 03:22:42 PM - INFO - [13:18] loss\t35.16 =\tBCE 35.15652 \tLL 0.00340 \tTotal 2052.61/256.48/1448.72 \n","04/19/2023 03:22:43 PM - INFO - [13:19] loss\t35.07 =\tBCE 35.07414 \tLL 0.00418 \tTotal 2153.89/388.69/1431.53 \n","04/19/2023 03:22:43 PM - INFO - Training epoch 14.\n","04/19/2023 03:22:44 PM - INFO - [14:0] loss\t37.34 =\tBCE 37.34389 \tLL 0.00376 \tTotal 3133.44/351.03/2484.40 \n","04/19/2023 03:22:44 PM - INFO - [14:1] loss\t31.74 =\tBCE 31.74203 \tLL 0.00331 \tTotal 1880.53/306.57/1345.81 \n","04/19/2023 03:22:45 PM - INFO - [14:2] loss\t30.36 =\tBCE 30.36012 \tLL 0.00296 \tTotal 1177.31/198.91/960.01 \n","04/19/2023 03:22:45 PM - INFO - [14:3] loss\t32.77 =\tBCE 32.77115 \tLL 0.00330 \tTotal 1637.74/341.17/1045.07 \n","04/19/2023 03:22:46 PM - INFO - [14:4] loss\t27.44 =\tBCE 27.43828 \tLL 0.00306 \tTotal 727.66/125.56/430.84 \n","04/19/2023 03:22:46 PM - INFO - [14:5] loss\t30.55 =\tBCE 30.55296 \tLL 0.00323 \tTotal 1752.27/257.35/1129.12 \n","04/19/2023 03:22:47 PM - INFO - [14:6] loss\t30.77 =\tBCE 30.77303 \tLL 0.00351 \tTotal 1757.57/191.94/1405.53 \n","04/19/2023 03:22:47 PM - INFO - [14:7] loss\t29.43 =\tBCE 29.42801 \tLL 0.00344 \tTotal 1620.33/210.25/632.06 \n","04/19/2023 03:22:48 PM - INFO - [14:8] loss\t25.75 =\tBCE 25.74588 \tLL 0.00248 \tTotal 1194.22/204.46/841.17 \n","04/19/2023 03:22:48 PM - INFO - [14:9] loss\t30.53 =\tBCE 30.53432 \tLL 0.00331 \tTotal 2127.58/301.50/1424.96 \n","04/19/2023 03:22:49 PM - INFO - [14:10] loss\t26.10 =\tBCE 26.09715 \tLL 0.00266 \tTotal 1477.19/228.51/1041.81 \n","04/19/2023 03:22:49 PM - INFO - [14:11] loss\t25.97 =\tBCE 25.96513 \tLL 0.00259 \tTotal 1117.25/180.85/745.54 \n","04/19/2023 03:22:50 PM - INFO - [14:12] loss\t25.05 =\tBCE 25.05346 \tLL 0.00271 \tTotal 1137.28/174.10/563.10 \n","04/19/2023 03:22:51 PM - INFO - [14:13] loss\t24.90 =\tBCE 24.90165 \tLL 0.00285 \tTotal 1091.39/228.22/856.59 \n","04/19/2023 03:22:51 PM - INFO - [14:14] loss\t23.69 =\tBCE 23.68716 \tLL 0.00313 \tTotal 940.69/102.59/391.02 \n","04/19/2023 03:22:52 PM - INFO - [14:15] loss\t24.12 =\tBCE 24.11632 \tLL 0.00278 \tTotal 1543.47/246.20/1130.24 \n","04/19/2023 03:22:52 PM - INFO - [14:16] loss\t24.75 =\tBCE 24.74806 \tLL 0.00310 \tTotal 2050.36/311.87/1470.86 \n","04/19/2023 03:22:53 PM - INFO - [14:17] loss\t26.31 =\tBCE 26.31177 \tLL 0.00318 \tTotal 2901.58/408.64/2261.76 \n","04/19/2023 03:22:53 PM - INFO - [14:18] loss\t27.02 =\tBCE 27.01922 \tLL 0.00242 \tTotal 3527.24/569.32/2593.91 \n","04/19/2023 03:22:54 PM - INFO - [14:19] loss\t27.52 =\tBCE 27.52314 \tLL 0.00297 \tTotal 3641.13/604.62/2765.39 \n","04/19/2023 03:22:54 PM - INFO - Training epoch 15.\n","04/19/2023 03:22:54 PM - INFO - [15:0] loss\t27.83 =\tBCE 27.82762 \tLL 0.00305 \tTotal 3449.25/568.83/2678.22 \n","04/19/2023 03:22:55 PM - INFO - [15:1] loss\t23.50 =\tBCE 23.49528 \tLL 0.00297 \tTotal 2015.53/371.15/1450.52 \n","04/19/2023 03:22:56 PM - INFO - [15:2] loss\t19.99 =\tBCE 19.99370 \tLL 0.00257 \tTotal 853.21/175.93/611.84 \n","04/19/2023 03:22:56 PM - INFO - [15:3] loss\t23.07 =\tBCE 23.07155 \tLL 0.00294 \tTotal 2214.35/371.99/1674.68 \n","04/19/2023 03:22:57 PM - INFO - [15:4] loss\t26.28 =\tBCE 26.28217 \tLL 0.00290 \tTotal 3540.02/578.19/2733.83 \n","04/19/2023 03:22:57 PM - INFO - [15:5] loss\t31.88 =\tBCE 31.87607 \tLL 0.00356 \tTotal 5212.63/829.78/3877.99 \n","04/19/2023 03:22:58 PM - INFO - [15:6] loss\t44.57 =\tBCE 44.57134 \tLL 0.00315 \tTotal 7354.00/1208.48/5659.64 \n","04/19/2023 03:22:58 PM - INFO - [15:7] loss\t77.17 =\tBCE 77.16788 \tLL 0.00485 \tTotal 11924.04/1650.91/9332.72 \n","04/19/2023 03:22:59 PM - INFO - [15:8] loss\t165.13 =\tBCE 165.12704 \tLL 0.00882 \tTotal 20171.90/2497.60/16121.79 \n","04/19/2023 03:22:59 PM - INFO - [15:9] loss\t350.53 =\tBCE 350.52621 \tLL 0.01838 \tTotal 27004.42/3775.34/21125.04 \n","04/19/2023 03:23:00 PM - INFO - [15:10] loss\t263.44 =\tBCE 263.43845 \tLL 0.02124 \tTotal 19397.67/3386.19/13937.86 \n","04/19/2023 03:23:00 PM - INFO - [15:11] loss\t80.18 =\tBCE 80.17552 \tLL 0.02888 \tTotal 5272.83/789.13/3429.50 \n","04/19/2023 03:23:01 PM - INFO - [15:12] loss\t205.12 =\tBCE 205.11911 \tLL 0.03734 \tTotal 13958.00/2210.87/9694.81 \n","04/19/2023 03:23:02 PM - INFO - [15:13] loss\t80.24 =\tBCE 80.24194 \tLL 0.03501 \tTotal 3593.69/702.20/2310.42 \n","04/19/2023 03:23:02 PM - INFO - [15:14] loss\t148.09 =\tBCE 148.08737 \tLL 0.03125 \tTotal 8112.40/1314.39/5357.25 \n","04/19/2023 03:23:03 PM - INFO - [15:15] loss\t113.69 =\tBCE 113.69430 \tLL 0.02510 \tTotal 5588.32/830.59/4114.80 \n","04/19/2023 03:23:03 PM - INFO - [15:16] loss\t81.55 =\tBCE 81.54741 \tLL 0.02061 \tTotal 1883.74/432.91/1237.70 \n","04/19/2023 03:23:04 PM - INFO - [15:17] loss\t113.16 =\tBCE 113.16437 \tLL 0.01663 \tTotal 4866.98/828.04/3437.40 \n","04/19/2023 03:23:04 PM - INFO - [15:18] loss\t98.07 =\tBCE 98.07428 \tLL 0.01059 \tTotal 4015.49/568.86/2876.24 \n","04/19/2023 03:23:05 PM - INFO - [15:19] loss\t82.64 =\tBCE 82.64027 \tLL 0.00641 \tTotal 1589.64/318.07/955.82 \n","04/19/2023 03:23:05 PM - INFO - Training epoch 16.\n","04/19/2023 03:23:05 PM - INFO - [16:0] loss\t91.89 =\tBCE 91.89040 \tLL 0.00499 \tTotal 3002.52/562.01/2116.50 \n","04/19/2023 03:23:06 PM - INFO - [16:1] loss\t100.42 =\tBCE 100.41592 \tLL 0.00561 \tTotal 3451.03/544.27/2477.71 \n","04/19/2023 03:23:06 PM - INFO - [16:2] loss\t88.99 =\tBCE 88.98874 \tLL 0.00573 \tTotal 1801.42/233.72/1200.55 \n","04/19/2023 03:23:07 PM - INFO - [16:3] loss\t86.87 =\tBCE 86.86598 \tLL 0.00699 \tTotal 1793.47/400.82/1145.26 \n","04/19/2023 03:23:08 PM - INFO - [16:4] loss\t94.70 =\tBCE 94.70393 \tLL 0.00863 \tTotal 2749.45/538.84/1947.05 \n","04/19/2023 03:23:08 PM - INFO - [16:5] loss\t82.93 =\tBCE 82.92591 \tLL 0.00962 \tTotal 1888.25/362.10/1291.65 \n","04/19/2023 03:23:09 PM - INFO - [16:6] loss\t76.41 =\tBCE 76.41135 \tLL 0.01088 \tTotal 1684.42/232.11/1194.24 \n","04/19/2023 03:23:09 PM - INFO - [16:7] loss\t81.39 =\tBCE 81.39435 \tLL 0.01158 \tTotal 2596.49/446.89/1835.01 \n","04/19/2023 03:23:10 PM - INFO - [16:8] loss\t74.19 =\tBCE 74.19247 \tLL 0.01050 \tTotal 1776.27/373.43/1097.75 \n","04/19/2023 03:23:10 PM - INFO - [16:9] loss\t68.93 =\tBCE 68.92963 \tLL 0.00967 \tTotal 1935.29/228.91/1486.07 \n","04/19/2023 03:23:11 PM - INFO - [16:10] loss\t71.59 =\tBCE 71.59464 \tLL 0.00930 \tTotal 2922.33/316.04/2270.19 \n","04/19/2023 03:23:11 PM - INFO - [16:11] loss\t64.57 =\tBCE 64.57279 \tLL 0.00808 \tTotal 1254.13/255.05/681.08 \n","04/19/2023 03:23:12 PM - INFO - [16:12] loss\t64.11 =\tBCE 64.11243 \tLL 0.00611 \tTotal 2669.01/274.13/2009.43 \n","04/19/2023 03:23:12 PM - INFO - [16:13] loss\t53.40 =\tBCE 53.40280 \tLL 0.00434 \tTotal 1958.64/231.73/1523.30 \n","04/19/2023 03:23:13 PM - INFO - [16:14] loss\t49.19 =\tBCE 49.19254 \tLL 0.00341 \tTotal 869.02/182.05/562.90 \n","04/19/2023 03:23:14 PM - INFO - [16:15] loss\t54.78 =\tBCE 54.78159 \tLL 0.00312 \tTotal 2772.70/285.45/2110.60 \n","04/19/2023 03:23:14 PM - INFO - [16:16] loss\t47.62 =\tBCE 47.61697 \tLL 0.00252 \tTotal 1611.87/166.41/1150.40 \n","04/19/2023 03:23:15 PM - INFO - [16:17] loss\t42.53 =\tBCE 42.52829 \tLL 0.00175 \tTotal 1493.88/176.14/987.46 \n","04/19/2023 03:23:15 PM - INFO - [16:18] loss\t41.29 =\tBCE 41.29080 \tLL 0.00184 \tTotal 1690.46/275.10/1253.89 \n","04/19/2023 03:23:16 PM - INFO - [16:19] loss\t36.87 =\tBCE 36.87010 \tLL 0.00224 \tTotal 928.85/125.88/587.35 \n","04/19/2023 03:23:16 PM - INFO - Training epoch 17.\n","04/19/2023 03:23:16 PM - INFO - [17:0] loss\t37.35 =\tBCE 37.34872 \tLL 0.00246 \tTotal 1722.57/263.25/1189.08 \n","04/19/2023 03:23:17 PM - INFO - [17:1] loss\t35.98 =\tBCE 35.97688 \tLL 0.00227 \tTotal 1371.74/232.11/906.35 \n","04/19/2023 03:23:17 PM - INFO - [17:2] loss\t32.17 =\tBCE 32.16741 \tLL 0.00220 \tTotal 1091.29/206.68/697.17 \n","04/19/2023 03:23:18 PM - INFO - [17:3] loss\t31.60 =\tBCE 31.60246 \tLL 0.00230 \tTotal 1179.08/196.87/744.31 \n","04/19/2023 03:23:18 PM - INFO - [17:4] loss\t30.34 =\tBCE 30.34044 \tLL 0.00244 \tTotal 1475.15/238.84/1016.15 \n","04/19/2023 03:23:19 PM - INFO - [17:5] loss\t25.53 =\tBCE 25.53224 \tLL 0.00219 \tTotal 968.06/173.17/719.22 \n","04/19/2023 03:23:19 PM - INFO - [17:6] loss\t27.18 =\tBCE 27.18423 \tLL 0.00279 \tTotal 1337.94/232.08/955.03 \n","04/19/2023 03:23:20 PM - INFO - [17:7] loss\t26.20 =\tBCE 26.20125 \tLL 0.00297 \tTotal 1397.59/232.24/1068.10 \n","04/19/2023 03:23:20 PM - INFO - [17:8] loss\t24.99 =\tBCE 24.98584 \tLL 0.00275 \tTotal 1254.35/212.88/883.12 \n","04/19/2023 03:23:21 PM - INFO - [17:9] loss\t24.46 =\tBCE 24.46146 \tLL 0.00281 \tTotal 1255.69/265.91/880.71 \n","04/19/2023 03:23:22 PM - INFO - [17:10] loss\t23.80 =\tBCE 23.79881 \tLL 0.00279 \tTotal 1299.89/220.08/986.93 \n","04/19/2023 03:23:22 PM - INFO - [17:11] loss\t24.01 =\tBCE 24.00625 \tLL 0.00260 \tTotal 1005.91/301.47/694.16 \n","04/19/2023 03:23:23 PM - INFO - [17:12] loss\t21.19 =\tBCE 21.18853 \tLL 0.00238 \tTotal 940.40/199.88/660.70 \n","04/19/2023 03:23:23 PM - INFO - [17:13] loss\t21.03 =\tBCE 21.02750 \tLL 0.00231 \tTotal 866.70/300.44/518.22 \n","04/19/2023 03:23:24 PM - INFO - [17:14] loss\t21.31 =\tBCE 21.31175 \tLL 0.00259 \tTotal 759.02/192.14/513.39 \n","04/19/2023 03:23:24 PM - INFO - [17:15] loss\t21.33 =\tBCE 21.32551 \tLL 0.00277 \tTotal 1341.32/261.48/1071.53 \n","04/19/2023 03:23:25 PM - INFO - [17:16] loss\t19.99 =\tBCE 19.99331 \tLL 0.00266 \tTotal 863.62/157.17/564.65 \n","04/19/2023 03:23:25 PM - INFO - [17:17] loss\t18.32 =\tBCE 18.31746 \tLL 0.00243 \tTotal 507.20/204.34/281.13 \n","04/19/2023 03:23:26 PM - INFO - [17:18] loss\t19.56 =\tBCE 19.55634 \tLL 0.00239 \tTotal 1095.06/193.49/808.82 \n","04/19/2023 03:23:26 PM - INFO - [17:19] loss\t19.09 =\tBCE 19.09186 \tLL 0.00271 \tTotal 1106.47/109.11/866.06 \n","04/19/2023 03:23:26 PM - INFO - Training epoch 18.\n","04/19/2023 03:23:27 PM - INFO - [18:0] loss\t18.55 =\tBCE 18.55429 \tLL 0.00273 \tTotal 1145.77/218.94/835.61 \n","04/19/2023 03:23:28 PM - INFO - [18:1] loss\t18.02 =\tBCE 18.01706 \tLL 0.00290 \tTotal 706.41/106.96/273.15 \n","04/19/2023 03:23:28 PM - INFO - [18:2] loss\t18.20 =\tBCE 18.19919 \tLL 0.00274 \tTotal 1550.51/216.51/1184.63 \n","04/19/2023 03:23:29 PM - INFO - [18:3] loss\t19.03 =\tBCE 19.02854 \tLL 0.00282 \tTotal 1599.46/308.77/1169.95 \n","04/19/2023 03:23:29 PM - INFO - [18:4] loss\t16.69 =\tBCE 16.68662 \tLL 0.00251 \tTotal 483.83/223.70/188.38 \n","04/19/2023 03:23:30 PM - INFO - [18:5] loss\t16.44 =\tBCE 16.44478 \tLL 0.00235 \tTotal 1104.48/187.31/785.91 \n","04/19/2023 03:23:30 PM - INFO - [18:6] loss\t16.60 =\tBCE 16.59994 \tLL 0.00238 \tTotal 1290.41/271.09/960.85 \n","04/19/2023 03:23:31 PM - INFO - [18:7] loss\t15.90 =\tBCE 15.89782 \tLL 0.00235 \tTotal 694.05/82.88/512.80 \n","04/19/2023 03:23:31 PM - INFO - [18:8] loss\t15.81 =\tBCE 15.81025 \tLL 0.00241 \tTotal 975.66/154.47/773.06 \n","04/19/2023 03:23:32 PM - INFO - [18:9] loss\t15.78 =\tBCE 15.77735 \tLL 0.00232 \tTotal 1387.83/238.27/1053.24 \n","04/19/2023 03:23:32 PM - INFO - [18:10] loss\t15.91 =\tBCE 15.90584 \tLL 0.00251 \tTotal 1032.13/189.82/626.99 \n","04/19/2023 03:23:33 PM - INFO - [18:11] loss\t15.81 =\tBCE 15.80787 \tLL 0.00258 \tTotal 571.48/85.15/384.27 \n","04/19/2023 03:23:33 PM - INFO - [18:12] loss\t15.18 =\tBCE 15.17861 \tLL 0.00239 \tTotal 987.21/178.43/710.33 \n","04/19/2023 03:23:34 PM - INFO - [18:13] loss\t16.52 =\tBCE 16.51757 \tLL 0.00254 \tTotal 2008.92/253.62/1640.70 \n","04/19/2023 03:23:35 PM - INFO - [18:14] loss\t15.95 =\tBCE 15.95190 \tLL 0.00237 \tTotal 1859.88/297.22/1406.75 \n","04/19/2023 03:23:35 PM - INFO - [18:15] loss\t14.54 =\tBCE 14.54301 \tLL 0.00227 \tTotal 1280.22/219.35/941.01 \n","04/19/2023 03:23:36 PM - INFO - [18:16] loss\t15.10 =\tBCE 15.10268 \tLL 0.00243 \tTotal 884.66/113.92/676.10 \n","04/19/2023 03:23:36 PM - INFO - [18:17] loss\t13.89 =\tBCE 13.89192 \tLL 0.00237 \tTotal 648.74/101.31/498.14 \n","04/19/2023 03:23:37 PM - INFO - [18:18] loss\t13.86 =\tBCE 13.85671 \tLL 0.00241 \tTotal 776.15/81.54/584.40 \n","04/19/2023 03:23:37 PM - INFO - [18:19] loss\t14.29 =\tBCE 14.29205 \tLL 0.00240 \tTotal 1270.04/213.72/909.35 \n","Not implemented\n","04/19/2023 03:23:37 PM - INFO - Training epoch 19.\n","04/19/2023 03:23:38 PM - INFO - [19:0] loss\t14.51 =\tBCE 14.51246 \tLL 0.00240 \tTotal 1227.81/209.87/907.17 \n","04/19/2023 03:23:38 PM - INFO - [19:1] loss\t13.88 =\tBCE 13.87506 \tLL 0.00239 \tTotal 1159.41/212.79/830.90 \n","04/19/2023 03:23:39 PM - INFO - [19:2] loss\t13.53 =\tBCE 13.52766 \tLL 0.00227 \tTotal 954.26/201.59/669.42 \n","04/19/2023 03:23:40 PM - INFO - [19:3] loss\t13.85 =\tBCE 13.85380 \tLL 0.00232 \tTotal 879.67/115.77/527.45 \n","04/19/2023 03:23:40 PM - INFO - [19:4] loss\t12.75 =\tBCE 12.75228 \tLL 0.00214 \tTotal 659.56/114.41/451.04 \n","04/19/2023 03:23:41 PM - INFO - [19:5] loss\t13.32 =\tBCE 13.31580 \tLL 0.00249 \tTotal 752.12/144.90/336.18 \n","04/19/2023 03:23:41 PM - INFO - [19:6] loss\t13.73 =\tBCE 13.72704 \tLL 0.00245 \tTotal 785.22/155.64/442.54 \n","04/19/2023 03:23:42 PM - INFO - [19:7] loss\t13.24 =\tBCE 13.24230 \tLL 0.00231 \tTotal 930.82/135.51/547.11 \n","04/19/2023 03:23:42 PM - INFO - [19:8] loss\t12.80 =\tBCE 12.80194 \tLL 0.00214 \tTotal 819.50/128.09/644.14 \n","04/19/2023 03:23:43 PM - INFO - [19:9] loss\t13.47 =\tBCE 13.46658 \tLL 0.00222 \tTotal 1279.71/178.58/940.37 \n","04/19/2023 03:23:43 PM - INFO - [19:10] loss\t13.49 =\tBCE 13.49462 \tLL 0.00222 \tTotal 1505.18/247.94/1161.90 \n","04/19/2023 03:23:44 PM - INFO - [19:11] loss\t14.29 =\tBCE 14.28520 \tLL 0.00253 \tTotal 1550.29/285.75/979.41 \n","04/19/2023 03:23:44 PM - INFO - [19:12] loss\t13.20 =\tBCE 13.20344 \tLL 0.00202 \tTotal 1734.97/274.93/1335.20 \n","04/19/2023 03:23:45 PM - INFO - [19:13] loss\t14.90 =\tBCE 14.89569 \tLL 0.00242 \tTotal 2354.36/346.29/1869.85 \n","04/19/2023 03:23:45 PM - INFO - [19:14] loss\t15.34 =\tBCE 15.33776 \tLL 0.00230 \tTotal 2436.06/524.51/1711.77 \n","04/19/2023 03:23:46 PM - INFO - [19:15] loss\t18.68 =\tBCE 18.67798 \tLL 0.00262 \tTotal 3862.72/659.27/2848.70 \n","04/19/2023 03:23:47 PM - INFO - [19:16] loss\t28.96 =\tBCE 28.95978 \tLL 0.00326 \tTotal 6783.87/1048.45/5327.08 \n","04/19/2023 03:23:47 PM - INFO - [19:17] loss\t76.23 =\tBCE 76.23145 \tLL 0.00402 \tTotal 13927.36/2225.11/10716.92 \n","04/19/2023 03:23:48 PM - INFO - [19:18] loss\t363.91 =\tBCE 363.90546 \tLL 0.01565 \tTotal 32174.14/4660.55/25062.88 \n","04/19/2023 03:23:48 PM - INFO - [19:19] loss\t2061.28 =\tBCE 2061.28003 \tLL 0.04119 \tTotal 45940.31/5742.53/35090.79 \n","04/19/2023 03:23:48 PM - INFO - EVALUATION prior to epoch [20]...\n","04/19/2023 03:23:48 PM - INFO - [20] loss\t391.57=\tBCE 391.57 \tLL 0.04465 \n","04/19/2023 03:23:50 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/20_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:23:56 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/20_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:24:00 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/20_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/19/2023 03:24:01 PM - INFO - Training epoch 20.\n","04/19/2023 03:24:01 PM - INFO - [20:0] loss\t437.72 =\tBCE 437.72183 \tLL 0.04550 \tTotal 19313.34/5553.02/13445.31 \n","04/19/2023 03:24:02 PM - INFO - [20:1] loss\t537.60 =\tBCE 537.59924 \tLL 0.06911 \tTotal 28613.22/4731.51/20283.01 \n","04/19/2023 03:24:03 PM - INFO - [20:2] loss\t323.11 =\tBCE 323.11301 \tLL 0.09457 \tTotal 15836.01/2715.39/11890.26 \n","04/19/2023 03:24:03 PM - INFO - [20:3] loss\t306.68 =\tBCE 306.67957 \tLL 0.09401 \tTotal 13128.26/1667.27/9267.04 \n","04/19/2023 03:24:04 PM - INFO - [20:4] loss\t238.69 =\tBCE 238.69057 \tLL 0.07751 \tTotal 6214.58/2362.84/3712.34 \n","04/19/2023 03:24:04 PM - INFO - [20:5] loss\t158.63 =\tBCE 158.62994 \tLL 0.06214 \tTotal 3080.57/1212.54/1893.19 \n","04/19/2023 03:24:05 PM - INFO - [20:6] loss\t192.72 =\tBCE 192.72356 \tLL 0.04917 \tTotal 4696.01/731.94/3440.50 \n","04/19/2023 03:24:05 PM - INFO - [20:7] loss\t232.84 =\tBCE 232.84256 \tLL 0.03709 \tTotal 4993.54/1173.68/3408.68 \n","04/19/2023 03:24:06 PM - INFO - [20:8] loss\t197.21 =\tBCE 197.21204 \tLL 0.02768 \tTotal 3979.64/778.72/2802.15 \n","04/19/2023 03:24:06 PM - INFO - [20:9] loss\t159.43 =\tBCE 159.43407 \tLL 0.02012 \tTotal 2130.31/307.70/1525.45 \n","04/19/2023 03:24:07 PM - INFO - [20:10] loss\t165.46 =\tBCE 165.46443 \tLL 0.01377 \tTotal 1463.08/629.68/820.23 \n","04/19/2023 03:24:08 PM - INFO - [20:11] loss\t172.58 =\tBCE 172.57768 \tLL 0.00963 \tTotal 1538.07/729.48/767.86 \n","04/19/2023 03:24:08 PM - INFO - [20:12] loss\t171.30 =\tBCE 171.29890 \tLL 0.00753 \tTotal 1811.79/600.02/1044.40 \n","04/19/2023 03:24:09 PM - INFO - [20:13] loss\t167.96 =\tBCE 167.95596 \tLL 0.00871 \tTotal 1684.77/392.89/954.64 \n","04/19/2023 03:24:09 PM - INFO - [20:14] loss\t156.07 =\tBCE 156.06860 \tLL 0.01054 \tTotal 1308.64/354.64/752.26 \n","04/19/2023 03:24:10 PM - INFO - [20:15] loss\t159.14 =\tBCE 159.14119 \tLL 0.01368 \tTotal 1554.58/471.26/1040.27 \n","04/19/2023 03:24:10 PM - INFO - [20:16] loss\t160.20 =\tBCE 160.20055 \tLL 0.01640 \tTotal 1543.75/564.39/934.88 \n","04/19/2023 03:24:11 PM - INFO - [20:17] loss\t152.65 =\tBCE 152.64734 \tLL 0.01897 \tTotal 1526.58/553.22/931.59 \n","04/19/2023 03:24:11 PM - INFO - [20:18] loss\t136.32 =\tBCE 136.32013 \tLL 0.01987 \tTotal 969.15/445.92/491.35 \n","04/19/2023 03:24:12 PM - INFO - [20:19] loss\t135.29 =\tBCE 135.29068 \tLL 0.02284 \tTotal 1109.11/277.39/808.44 \n","04/19/2023 03:24:12 PM - INFO - Training epoch 21.\n","04/19/2023 03:24:12 PM - INFO - [21:0] loss\t125.00 =\tBCE 125.00072 \tLL 0.02454 \tTotal 1138.76/204.32/876.71 \n","04/19/2023 03:24:13 PM - INFO - [21:1] loss\t126.32 =\tBCE 126.31914 \tLL 0.02523 \tTotal 1320.09/292.93/1040.35 \n","04/19/2023 03:24:14 PM - INFO - [21:2] loss\t125.22 =\tBCE 125.22086 \tLL 0.02778 \tTotal 1083.86/371.72/702.70 \n","04/19/2023 03:24:14 PM - INFO - [21:3] loss\t113.92 =\tBCE 113.91641 \tLL 0.02370 \tTotal 988.47/310.24/602.80 \n","04/19/2023 03:24:15 PM - INFO - [21:4] loss\t116.67 =\tBCE 116.66830 \tLL 0.01923 \tTotal 1538.39/193.30/1135.72 \n","04/19/2023 03:24:15 PM - INFO - [21:5] loss\t98.48 =\tBCE 98.48001 \tLL 0.01494 \tTotal 1036.91/151.59/729.26 \n","04/19/2023 03:24:16 PM - INFO - [21:6] loss\t91.78 =\tBCE 91.77560 \tLL 0.01033 \tTotal 842.06/243.52/505.04 \n","04/19/2023 03:24:16 PM - INFO - [21:7] loss\t93.87 =\tBCE 93.86710 \tLL 0.00847 \tTotal 741.51/307.60/199.32 \n","04/19/2023 03:24:17 PM - INFO - [21:8] loss\t87.31 =\tBCE 87.31115 \tLL 0.00721 \tTotal 1274.44/243.77/875.50 \n","04/19/2023 03:24:17 PM - INFO - [21:9] loss\t82.80 =\tBCE 82.80040 \tLL 0.00662 \tTotal 1269.25/158.65/912.00 \n","04/19/2023 03:24:18 PM - INFO - [21:10] loss\t75.69 =\tBCE 75.68861 \tLL 0.00583 \tTotal 928.08/177.30/498.67 \n","04/19/2023 03:24:19 PM - INFO - [21:11] loss\t70.96 =\tBCE 70.96133 \tLL 0.00559 \tTotal 684.89/252.45/409.96 \n","04/19/2023 03:24:19 PM - INFO - [21:12] loss\t65.85 =\tBCE 65.84777 \tLL 0.00480 \tTotal 961.48/193.21/706.63 \n","04/19/2023 03:24:20 PM - INFO - [21:13] loss\t62.19 =\tBCE 62.19374 \tLL 0.00438 \tTotal 1067.11/144.64/719.46 \n","04/19/2023 03:24:20 PM - INFO - [21:14] loss\t60.08 =\tBCE 60.07966 \tLL 0.00446 \tTotal 1230.00/171.22/855.60 \n","04/19/2023 03:24:21 PM - INFO - [21:15] loss\t54.86 =\tBCE 54.86391 \tLL 0.00420 \tTotal 921.74/161.91/546.16 \n","04/19/2023 03:24:21 PM - INFO - [21:16] loss\t54.17 =\tBCE 54.17159 \tLL 0.00421 \tTotal 890.79/140.83/480.14 \n","04/19/2023 03:24:22 PM - INFO - [21:17] loss\t49.47 =\tBCE 49.47017 \tLL 0.00363 \tTotal 1099.53/141.42/776.63 \n","04/19/2023 03:24:22 PM - INFO - [21:18] loss\t44.96 =\tBCE 44.95661 \tLL 0.00348 \tTotal 786.94/112.56/529.26 \n","04/19/2023 03:24:23 PM - INFO - [21:19] loss\t44.45 =\tBCE 44.45163 \tLL 0.00376 \tTotal 880.40/88.25/682.16 \n","04/19/2023 03:24:23 PM - INFO - Training epoch 22.\n","04/19/2023 03:24:24 PM - INFO - [22:0] loss\t43.51 =\tBCE 43.50806 \tLL 0.00413 \tTotal 1085.39/114.92/813.54 \n","04/19/2023 03:24:24 PM - INFO - [22:1] loss\t41.16 =\tBCE 41.16495 \tLL 0.00420 \tTotal 817.36/84.49/401.76 \n","04/19/2023 03:24:25 PM - INFO - [22:2] loss\t37.49 =\tBCE 37.49200 \tLL 0.00348 \tTotal 768.81/85.65/476.78 \n","04/19/2023 03:24:25 PM - INFO - [22:3] loss\t37.12 =\tBCE 37.12148 \tLL 0.00348 \tTotal 706.80/94.69/548.20 \n","04/19/2023 03:24:26 PM - INFO - [22:4] loss\t35.93 =\tBCE 35.92995 \tLL 0.00371 \tTotal 843.87/99.36/521.50 \n","04/19/2023 03:24:26 PM - INFO - [22:5] loss\t35.16 =\tBCE 35.15770 \tLL 0.00422 \tTotal 977.13/105.31/679.22 \n","04/19/2023 03:24:27 PM - INFO - [22:6] loss\t32.03 =\tBCE 32.03084 \tLL 0.00419 \tTotal 519.40/80.60/304.86 \n","04/19/2023 03:24:27 PM - INFO - [22:7] loss\t30.45 =\tBCE 30.44959 \tLL 0.00391 \tTotal 418.41/81.66/234.35 \n","04/19/2023 03:24:28 PM - INFO - [22:8] loss\t30.64 =\tBCE 30.64070 \tLL 0.00437 \tTotal 890.62/92.83/623.37 \n","04/19/2023 03:24:28 PM - INFO - [22:9] loss\t29.45 =\tBCE 29.44587 \tLL 0.00415 \tTotal 646.96/72.62/337.12 \n","04/19/2023 03:24:29 PM - INFO - [22:10] loss\t27.29 =\tBCE 27.29115 \tLL 0.00333 \tTotal 419.85/74.32/281.22 \n","04/19/2023 03:24:30 PM - INFO - [22:11] loss\t27.08 =\tBCE 27.07634 \tLL 0.00311 \tTotal 786.45/93.85/547.16 \n","04/19/2023 03:24:30 PM - INFO - [22:12] loss\t27.13 =\tBCE 27.13293 \tLL 0.00298 \tTotal 702.20/68.13/469.30 \n","04/19/2023 03:24:31 PM - INFO - [22:13] loss\t24.29 =\tBCE 24.28976 \tLL 0.00271 \tTotal 538.57/72.25/363.16 \n","04/19/2023 03:24:31 PM - INFO - [22:14] loss\t24.19 =\tBCE 24.19309 \tLL 0.00264 \tTotal 605.49/96.93/450.06 \n","04/19/2023 03:24:32 PM - INFO - [22:15] loss\t23.06 =\tBCE 23.05689 \tLL 0.00267 \tTotal 528.84/79.16/345.27 \n","04/19/2023 03:24:32 PM - INFO - [22:16] loss\t22.46 =\tBCE 22.46372 \tLL 0.00280 \tTotal 639.04/80.43/336.49 \n","04/19/2023 03:24:33 PM - INFO - [22:17] loss\t21.14 =\tBCE 21.13531 \tLL 0.00262 \tTotal 536.58/105.06/388.99 \n","04/19/2023 03:24:33 PM - INFO - [22:18] loss\t21.13 =\tBCE 21.12933 \tLL 0.00256 \tTotal 436.42/100.90/295.40 \n","04/19/2023 03:24:34 PM - INFO - [22:19] loss\t20.97 =\tBCE 20.97332 \tLL 0.00247 \tTotal 542.98/74.05/336.01 \n","04/19/2023 03:24:34 PM - INFO - Training epoch 23.\n","04/19/2023 03:24:35 PM - INFO - [23:0] loss\t19.78 =\tBCE 19.78387 \tLL 0.00235 \tTotal 426.84/82.55/285.72 \n","04/19/2023 03:24:35 PM - INFO - [23:1] loss\t19.79 =\tBCE 19.79128 \tLL 0.00236 \tTotal 359.40/115.47/248.57 \n","04/19/2023 03:24:36 PM - INFO - [23:2] loss\t19.29 =\tBCE 19.28904 \tLL 0.00240 \tTotal 481.53/56.41/362.91 \n","04/19/2023 03:24:36 PM - INFO - [23:3] loss\t18.37 =\tBCE 18.37242 \tLL 0.00235 \tTotal 452.65/131.56/299.97 \n","04/19/2023 03:24:37 PM - INFO - [23:4] loss\t18.37 =\tBCE 18.37178 \tLL 0.00248 \tTotal 371.05/116.08/265.31 \n","04/19/2023 03:24:37 PM - INFO - [23:5] loss\t18.18 =\tBCE 18.18430 \tLL 0.00245 \tTotal 417.16/63.36/260.88 \n","04/19/2023 03:24:38 PM - INFO - [23:6] loss\t18.15 =\tBCE 18.15131 \tLL 0.00254 \tTotal 417.42/127.48/258.99 \n","04/19/2023 03:24:38 PM - INFO - [23:7] loss\t17.44 =\tBCE 17.43575 \tLL 0.00231 \tTotal 437.56/77.15/318.03 \n","04/19/2023 03:24:39 PM - INFO - [23:8] loss\t17.79 =\tBCE 17.79132 \tLL 0.00243 \tTotal 484.61/118.71/402.20 \n","04/19/2023 03:24:39 PM - INFO - [23:9] loss\t16.58 =\tBCE 16.57687 \tLL 0.00223 \tTotal 600.91/123.01/434.43 \n","04/19/2023 03:24:40 PM - INFO - [23:10] loss\t16.89 =\tBCE 16.88730 \tLL 0.00237 \tTotal 438.36/49.71/310.33 \n","04/19/2023 03:24:41 PM - INFO - [23:11] loss\t16.91 =\tBCE 16.90614 \tLL 0.00234 \tTotal 561.33/117.38/435.05 \n","04/19/2023 03:24:41 PM - INFO - [23:12] loss\t16.49 =\tBCE 16.49469 \tLL 0.00227 \tTotal 410.26/99.36/267.84 \n","04/19/2023 03:24:42 PM - INFO - [23:13] loss\t15.76 =\tBCE 15.75843 \tLL 0.00215 \tTotal 518.06/73.82/406.03 \n","04/19/2023 03:24:42 PM - INFO - [23:14] loss\t15.94 =\tBCE 15.93507 \tLL 0.00236 \tTotal 415.27/148.37/315.60 \n","04/19/2023 03:24:43 PM - INFO - [23:15] loss\t15.43 =\tBCE 15.42616 \tLL 0.00240 \tTotal 465.57/80.73/279.30 \n","04/19/2023 03:24:43 PM - INFO - [23:16] loss\t16.17 =\tBCE 16.17459 \tLL 0.00235 \tTotal 682.90/157.24/587.00 \n","04/19/2023 03:24:44 PM - INFO - [23:17] loss\t14.83 =\tBCE 14.83225 \tLL 0.00226 \tTotal 810.86/148.29/623.66 \n","04/19/2023 03:24:44 PM - INFO - [23:18] loss\t15.54 =\tBCE 15.53957 \tLL 0.00222 \tTotal 490.30/166.57/352.59 \n","04/19/2023 03:24:45 PM - INFO - [23:19] loss\t14.84 =\tBCE 14.83514 \tLL 0.00221 \tTotal 576.83/146.35/456.47 \n","04/19/2023 03:24:45 PM - INFO - Training epoch 24.\n","04/19/2023 03:24:45 PM - INFO - [24:0] loss\t14.88 =\tBCE 14.88014 \tLL 0.00222 \tTotal 805.45/144.61/647.22 \n","04/19/2023 03:24:46 PM - INFO - [24:1] loss\t14.41 =\tBCE 14.41259 \tLL 0.00206 \tTotal 475.92/137.07/359.18 \n","04/19/2023 03:24:47 PM - INFO - [24:2] loss\t13.76 =\tBCE 13.75658 \tLL 0.00203 \tTotal 661.49/122.81/476.06 \n","04/19/2023 03:24:47 PM - INFO - [24:3] loss\t14.17 =\tBCE 14.16796 \tLL 0.00215 \tTotal 440.32/111.41/324.19 \n","04/19/2023 03:24:48 PM - INFO - [24:4] loss\t13.99 =\tBCE 13.98985 \tLL 0.00218 \tTotal 813.14/117.69/637.11 \n","04/19/2023 03:24:48 PM - INFO - [24:5] loss\t13.64 =\tBCE 13.63643 \tLL 0.00218 \tTotal 557.56/76.34/435.72 \n","04/19/2023 03:24:49 PM - INFO - [24:6] loss\t13.49 =\tBCE 13.48609 \tLL 0.00209 \tTotal 661.49/88.70/497.24 \n","04/19/2023 03:24:49 PM - INFO - [24:7] loss\t13.57 =\tBCE 13.57182 \tLL 0.00218 \tTotal 726.07/110.31/545.59 \n","04/19/2023 03:24:50 PM - INFO - [24:8] loss\t13.25 =\tBCE 13.24809 \tLL 0.00207 \tTotal 338.39/49.09/221.40 \n","04/19/2023 03:24:50 PM - INFO - [24:9] loss\t13.14 =\tBCE 13.13640 \tLL 0.00207 \tTotal 681.42/102.13/537.91 \n","04/19/2023 03:24:51 PM - INFO - [24:10] loss\t12.89 =\tBCE 12.88806 \tLL 0.00200 \tTotal 508.45/91.64/375.42 \n","04/19/2023 03:24:52 PM - INFO - [24:11] loss\t12.90 =\tBCE 12.90427 \tLL 0.00208 \tTotal 603.85/65.20/503.50 \n","04/19/2023 03:24:52 PM - INFO - [24:12] loss\t13.08 =\tBCE 13.07639 \tLL 0.00207 \tTotal 675.93/127.82/489.81 \n","04/19/2023 03:24:53 PM - INFO - [24:13] loss\t12.63 =\tBCE 12.63001 \tLL 0.00197 \tTotal 285.89/35.23/216.39 \n","04/19/2023 03:24:53 PM - INFO - [24:14] loss\t12.49 =\tBCE 12.49441 \tLL 0.00194 \tTotal 415.36/74.78/326.77 \n","04/19/2023 03:24:54 PM - INFO - [24:15] loss\t12.35 =\tBCE 12.35173 \tLL 0.00200 \tTotal 222.10/40.87/174.22 \n","04/19/2023 03:24:54 PM - INFO - [24:16] loss\t12.61 =\tBCE 12.61077 \tLL 0.00213 \tTotal 404.40/72.98/333.79 \n","04/19/2023 03:24:55 PM - INFO - [24:17] loss\t12.34 =\tBCE 12.34141 \tLL 0.00209 \tTotal 375.04/84.49/252.79 \n","04/19/2023 03:24:55 PM - INFO - [24:18] loss\t12.12 =\tBCE 12.12013 \tLL 0.00217 \tTotal 199.79/41.39/149.11 \n","04/19/2023 03:24:56 PM - INFO - [24:19] loss\t11.71 =\tBCE 11.71106 \tLL 0.00192 \tTotal 411.89/76.42/319.72 \n","04/19/2023 03:24:56 PM - INFO - Training epoch 25.\n","04/19/2023 03:24:56 PM - INFO - [25:0] loss\t11.55 =\tBCE 11.55486 \tLL 0.00201 \tTotal 305.38/40.11/239.01 \n","04/19/2023 03:24:57 PM - INFO - [25:1] loss\t12.33 =\tBCE 12.33130 \tLL 0.00198 \tTotal 620.02/104.00/497.06 \n","04/19/2023 03:24:57 PM - INFO - [25:2] loss\t11.55 =\tBCE 11.54995 \tLL 0.00191 \tTotal 443.14/99.02/263.45 \n","04/19/2023 03:24:58 PM - INFO - [25:3] loss\t11.63 =\tBCE 11.63130 \tLL 0.00195 \tTotal 337.25/58.23/192.26 \n","04/19/2023 03:24:58 PM - INFO - [25:4] loss\t11.59 =\tBCE 11.59475 \tLL 0.00204 \tTotal 432.67/87.57/309.40 \n","04/19/2023 03:24:59 PM - INFO - [25:5] loss\t11.11 =\tBCE 11.11418 \tLL 0.00193 \tTotal 280.54/65.94/145.15 \n","04/19/2023 03:25:00 PM - INFO - [25:6] loss\t11.17 =\tBCE 11.16510 \tLL 0.00185 \tTotal 502.47/92.92/373.07 \n","04/19/2023 03:25:00 PM - INFO - [25:7] loss\t11.51 =\tBCE 11.51247 \tLL 0.00188 \tTotal 372.78/108.14/218.13 \n","04/19/2023 03:25:01 PM - INFO - [25:8] loss\t10.78 =\tBCE 10.77939 \tLL 0.00193 \tTotal 427.54/65.30/298.15 \n","04/19/2023 03:25:01 PM - INFO - [25:9] loss\t11.41 =\tBCE 11.40560 \tLL 0.00192 \tTotal 814.51/157.69/607.72 \n","04/19/2023 03:25:02 PM - INFO - [25:10] loss\t10.69 =\tBCE 10.68970 \tLL 0.00194 \tTotal 609.17/48.66/493.96 \n","04/19/2023 03:25:02 PM - INFO - [25:11] loss\t11.60 =\tBCE 11.59686 \tLL 0.00207 \tTotal 593.33/82.84/421.80 \n","04/19/2023 03:25:03 PM - INFO - [25:12] loss\t11.01 =\tBCE 11.00969 \tLL 0.00199 \tTotal 568.61/79.06/432.81 \n","04/19/2023 03:25:03 PM - INFO - [25:13] loss\t10.64 =\tBCE 10.64492 \tLL 0.00182 \tTotal 298.34/31.87/182.16 \n","04/19/2023 03:25:04 PM - INFO - [25:14] loss\t10.10 =\tBCE 10.09742 \tLL 0.00172 \tTotal 393.72/71.56/251.13 \n","04/19/2023 03:25:05 PM - INFO - [25:15] loss\t10.91 =\tBCE 10.90618 \tLL 0.00204 \tTotal 466.66/57.93/365.51 \n","04/19/2023 03:25:05 PM - INFO - [25:16] loss\t10.81 =\tBCE 10.81434 \tLL 0.00214 \tTotal 403.44/44.13/213.19 \n","04/19/2023 03:25:06 PM - INFO - [25:17] loss\t10.44 =\tBCE 10.44240 \tLL 0.00187 \tTotal 318.14/48.98/137.07 \n","04/19/2023 03:25:06 PM - INFO - [25:18] loss\t10.37 =\tBCE 10.37117 \tLL 0.00188 \tTotal 331.59/53.28/233.27 \n","04/19/2023 03:25:07 PM - INFO - [25:19] loss\t10.67 =\tBCE 10.66851 \tLL 0.00199 \tTotal 495.05/48.42/361.99 \n","04/19/2023 03:25:07 PM - INFO - Training epoch 26.\n","04/19/2023 03:25:07 PM - INFO - [26:0] loss\t10.35 =\tBCE 10.34908 \tLL 0.00185 \tTotal 512.05/73.45/389.24 \n","04/19/2023 03:25:08 PM - INFO - [26:1] loss\t10.50 =\tBCE 10.49857 \tLL 0.00191 \tTotal 477.95/82.74/304.38 \n","04/19/2023 03:25:08 PM - INFO - [26:2] loss\t9.95 =\tBCE 9.95278 \tLL 0.00182 \tTotal 371.46/29.39/295.50 \n","04/19/2023 03:25:09 PM - INFO - [26:3] loss\t9.83 =\tBCE 9.82512 \tLL 0.00175 \tTotal 323.26/38.31/201.67 \n","04/19/2023 03:25:09 PM - INFO - [26:4] loss\t9.93 =\tBCE 9.93168 \tLL 0.00186 \tTotal 334.89/44.16/244.79 \n","04/19/2023 03:25:10 PM - INFO - [26:5] loss\t10.34 =\tBCE 10.33938 \tLL 0.00208 \tTotal 435.45/63.51/289.44 \n","04/19/2023 03:25:10 PM - INFO - [26:6] loss\t9.97 =\tBCE 9.96964 \tLL 0.00188 \tTotal 372.21/67.33/274.91 \n","04/19/2023 03:25:11 PM - INFO - [26:7] loss\t9.72 =\tBCE 9.71866 \tLL 0.00187 \tTotal 357.28/47.99/195.59 \n","04/19/2023 03:25:11 PM - INFO - [26:8] loss\t10.26 =\tBCE 10.26302 \tLL 0.00184 \tTotal 446.75/42.23/352.54 \n","04/19/2023 03:25:12 PM - INFO - [26:9] loss\t10.22 =\tBCE 10.21893 \tLL 0.00194 \tTotal 466.94/93.72/313.38 \n","04/19/2023 03:25:13 PM - INFO - [26:10] loss\t9.47 =\tBCE 9.46646 \tLL 0.00171 \tTotal 483.91/77.86/354.36 \n","04/19/2023 03:25:13 PM - INFO - [26:11] loss\t9.44 =\tBCE 9.43979 \tLL 0.00183 \tTotal 334.30/60.98/277.05 \n","04/19/2023 03:25:14 PM - INFO - [26:12] loss\t9.63 =\tBCE 9.62993 \tLL 0.00186 \tTotal 358.66/50.77/182.64 \n","04/19/2023 03:25:14 PM - INFO - [26:13] loss\t9.42 =\tBCE 9.42482 \tLL 0.00175 \tTotal 368.86/79.56/296.08 \n","04/19/2023 03:25:15 PM - INFO - [26:14] loss\t8.98 =\tBCE 8.98310 \tLL 0.00167 \tTotal 371.28/73.99/214.29 \n","04/19/2023 03:25:15 PM - INFO - [26:15] loss\t9.32 =\tBCE 9.32470 \tLL 0.00177 \tTotal 342.26/48.12/266.20 \n","04/19/2023 03:25:16 PM - INFO - [26:16] loss\t8.78 =\tBCE 8.77757 \tLL 0.00176 \tTotal 366.98/65.30/163.70 \n","04/19/2023 03:25:16 PM - INFO - [26:17] loss\t8.91 =\tBCE 8.90845 \tLL 0.00166 \tTotal 444.21/55.30/331.36 \n","04/19/2023 03:25:17 PM - INFO - [26:18] loss\t9.40 =\tBCE 9.39795 \tLL 0.00177 \tTotal 624.50/67.73/436.87 \n","04/19/2023 03:25:17 PM - INFO - [26:19] loss\t8.96 =\tBCE 8.95637 \tLL 0.00168 \tTotal 481.38/93.05/371.32 \n","04/19/2023 03:25:17 PM - INFO - Training epoch 27.\n","04/19/2023 03:25:18 PM - INFO - [27:0] loss\t9.06 =\tBCE 9.05584 \tLL 0.00171 \tTotal 399.18/101.18/282.39 \n","04/19/2023 03:25:19 PM - INFO - [27:1] loss\t9.10 =\tBCE 9.09650 \tLL 0.00175 \tTotal 296.80/28.61/214.91 \n","04/19/2023 03:25:19 PM - INFO - [27:2] loss\t8.60 =\tBCE 8.59720 \tLL 0.00156 \tTotal 429.95/90.33/339.88 \n","04/19/2023 03:25:20 PM - INFO - [27:3] loss\t8.71 =\tBCE 8.71478 \tLL 0.00167 \tTotal 327.86/82.09/209.15 \n","04/19/2023 03:25:20 PM - INFO - [27:4] loss\t8.61 =\tBCE 8.61193 \tLL 0.00172 \tTotal 329.53/43.18/195.15 \n","04/19/2023 03:25:21 PM - INFO - [27:5] loss\t9.29 =\tBCE 9.29063 \tLL 0.00183 \tTotal 353.14/101.44/209.37 \n","04/19/2023 03:25:21 PM - INFO - [27:6] loss\t8.86 =\tBCE 8.85870 \tLL 0.00177 \tTotal 343.47/61.31/241.86 \n","04/19/2023 03:25:22 PM - INFO - [27:7] loss\t8.49 =\tBCE 8.49153 \tLL 0.00168 \tTotal 653.87/134.55/468.75 \n","04/19/2023 03:25:22 PM - INFO - [27:8] loss\t8.63 =\tBCE 8.63092 \tLL 0.00170 \tTotal 705.34/130.14/554.23 \n","04/19/2023 03:25:23 PM - INFO - [27:9] loss\t8.62 =\tBCE 8.62202 \tLL 0.00173 \tTotal 507.68/73.94/377.45 \n","04/19/2023 03:25:23 PM - INFO - [27:10] loss\t8.61 =\tBCE 8.60831 \tLL 0.00179 \tTotal 403.56/46.40/305.00 \n","04/19/2023 03:25:24 PM - INFO - [27:11] loss\t8.28 =\tBCE 8.28079 \tLL 0.00169 \tTotal 303.06/35.44/219.56 \n","04/19/2023 03:25:24 PM - INFO - [27:12] loss\t8.89 =\tBCE 8.89381 \tLL 0.00174 \tTotal 609.16/77.70/483.29 \n","04/19/2023 03:25:25 PM - INFO - [27:13] loss\t8.12 =\tBCE 8.11695 \tLL 0.00158 \tTotal 658.48/133.08/451.52 \n","04/19/2023 03:25:25 PM - INFO - [27:14] loss\t8.60 =\tBCE 8.59559 \tLL 0.00171 \tTotal 824.42/143.32/673.99 \n","04/19/2023 03:25:26 PM - INFO - [27:15] loss\t8.44 =\tBCE 8.44038 \tLL 0.00170 \tTotal 783.25/119.00/597.11 \n","04/19/2023 03:25:27 PM - INFO - [27:16] loss\t8.22 =\tBCE 8.21842 \tLL 0.00168 \tTotal 460.52/61.87/275.56 \n","04/19/2023 03:25:27 PM - INFO - [27:17] loss\t8.46 =\tBCE 8.46440 \tLL 0.00171 \tTotal 510.81/85.34/332.90 \n","04/19/2023 03:25:28 PM - INFO - [27:18] loss\t8.61 =\tBCE 8.60651 \tLL 0.00179 \tTotal 525.25/75.11/378.42 \n","04/19/2023 03:25:28 PM - INFO - [27:19] loss\t8.52 =\tBCE 8.52399 \tLL 0.00174 \tTotal 512.22/134.20/238.72 \n","04/19/2023 03:25:28 PM - INFO - Training epoch 28.\n","04/19/2023 03:25:29 PM - INFO - [28:0] loss\t8.49 =\tBCE 8.48505 \tLL 0.00171 \tTotal 605.12/86.84/442.27 \n","04/19/2023 03:25:29 PM - INFO - [28:1] loss\t8.11 =\tBCE 8.11241 \tLL 0.00161 \tTotal 661.85/97.91/517.31 \n","04/19/2023 03:25:30 PM - INFO - [28:2] loss\t7.76 =\tBCE 7.75994 \tLL 0.00151 \tTotal 557.83/83.14/454.79 \n","04/19/2023 03:25:30 PM - INFO - [28:3] loss\t7.95 =\tBCE 7.95455 \tLL 0.00167 \tTotal 677.34/137.95/431.23 \n","04/19/2023 03:25:31 PM - INFO - [28:4] loss\t8.17 =\tBCE 8.16729 \tLL 0.00164 \tTotal 802.80/145.57/601.71 \n","04/19/2023 03:25:31 PM - INFO - [28:5] loss\t8.26 =\tBCE 8.25522 \tLL 0.00167 \tTotal 1021.20/150.12/764.88 \n","04/19/2023 03:25:32 PM - INFO - [28:6] loss\t8.27 =\tBCE 8.27376 \tLL 0.00169 \tTotal 983.25/148.37/763.16 \n","04/19/2023 03:25:33 PM - INFO - [28:7] loss\t8.24 =\tBCE 8.23591 \tLL 0.00176 \tTotal 625.12/134.39/473.62 \n","04/19/2023 03:25:33 PM - INFO - [28:8] loss\t7.61 =\tBCE 7.60963 \tLL 0.00154 \tTotal 433.06/76.49/252.26 \n","04/19/2023 03:25:34 PM - INFO - [28:9] loss\t7.92 =\tBCE 7.91864 \tLL 0.00165 \tTotal 501.22/85.60/331.52 \n","04/19/2023 03:25:34 PM - INFO - [28:10] loss\t8.21 =\tBCE 8.20655 \tLL 0.00172 \tTotal 893.30/170.78/713.41 \n","04/19/2023 03:25:35 PM - INFO - [28:11] loss\t8.11 =\tBCE 8.11349 \tLL 0.00160 \tTotal 1290.58/201.12/1026.56 \n","04/19/2023 03:25:35 PM - INFO - [28:12] loss\t8.17 =\tBCE 8.17439 \tLL 0.00163 \tTotal 1344.27/239.85/1001.52 \n","04/19/2023 03:25:36 PM - INFO - [28:13] loss\t8.29 =\tBCE 8.28929 \tLL 0.00177 \tTotal 1245.51/215.99/965.77 \n","04/19/2023 03:25:36 PM - INFO - [28:14] loss\t7.91 =\tBCE 7.90745 \tLL 0.00164 \tTotal 947.15/177.27/749.33 \n","04/19/2023 03:25:37 PM - INFO - [28:15] loss\t8.02 =\tBCE 8.01561 \tLL 0.00160 \tTotal 688.83/143.81/469.83 \n","04/19/2023 03:25:37 PM - INFO - [28:16] loss\t7.58 =\tBCE 7.58184 \tLL 0.00166 \tTotal 580.77/80.36/404.94 \n","04/19/2023 03:25:38 PM - INFO - [28:17] loss\t7.85 =\tBCE 7.84548 \tLL 0.00176 \tTotal 556.13/99.11/356.84 \n","04/19/2023 03:25:38 PM - INFO - [28:18] loss\t7.43 =\tBCE 7.43484 \tLL 0.00159 \tTotal 509.12/87.50/400.46 \n","04/19/2023 03:25:39 PM - INFO - [28:19] loss\t7.80 =\tBCE 7.79915 \tLL 0.00171 \tTotal 938.44/159.12/679.99 \n","Not implemented\n","04/19/2023 03:25:39 PM - INFO - Training epoch 29.\n","04/19/2023 03:25:40 PM - INFO - [29:0] loss\t8.20 =\tBCE 8.20373 \tLL 0.00163 \tTotal 1503.74/242.22/1196.90 \n","04/19/2023 03:25:40 PM - INFO - [29:1] loss\t8.90 =\tBCE 8.89981 \tLL 0.00165 \tTotal 2275.86/388.55/1788.10 \n","04/19/2023 03:25:41 PM - INFO - [29:2] loss\t11.90 =\tBCE 11.90393 \tLL 0.00162 \tTotal 3800.38/627.22/2903.99 \n","04/19/2023 03:25:41 PM - INFO - [29:3] loss\t20.06 =\tBCE 20.06460 \tLL 0.00248 \tTotal 6486.84/997.42/5079.34 \n","04/19/2023 03:25:42 PM - INFO - [29:4] loss\t50.14 =\tBCE 50.13508 \tLL 0.00374 \tTotal 13666.94/2034.52/10958.91 \n","04/19/2023 03:25:42 PM - INFO - [29:5] loss\t314.29 =\tBCE 314.29034 \tLL 0.01435 \tTotal 34944.91/5071.53/27777.14 \n","04/19/2023 03:25:43 PM - INFO - [29:6] loss\t3835.93 =\tBCE 3835.92603 \tLL 0.07555 \tTotal 53925.43/6311.52/42338.51 \n","04/19/2023 03:25:43 PM - INFO - [29:7] loss\t981.32 =\tBCE 981.31500 \tLL 0.07616 \tTotal 25233.50/4382.84/18330.59 \n","04/19/2023 03:25:44 PM - INFO - [29:8] loss\t919.32 =\tBCE 919.31897 \tLL 0.11152 \tTotal 41213.45/5934.12/31442.94 \n","04/19/2023 03:25:45 PM - INFO - [29:9] loss\t777.56 =\tBCE 777.56104 \tLL 0.14011 \tTotal 33090.75/2992.35/25163.21 \n","04/19/2023 03:25:45 PM - INFO - [29:10] loss\t497.01 =\tBCE 497.00964 \tLL 0.14698 \tTotal 22100.44/2979.59/16525.13 \n","04/19/2023 03:25:46 PM - INFO - [29:11] loss\t161.55 =\tBCE 161.54730 \tLL 0.12819 \tTotal 3728.98/804.82/1889.69 \n","04/19/2023 03:25:46 PM - INFO - [29:12] loss\t323.15 =\tBCE 323.14597 \tLL 0.10534 \tTotal 12115.76/1480.68/8701.75 \n","04/19/2023 03:25:47 PM - INFO - [29:13] loss\t367.45 =\tBCE 367.45148 \tLL 0.08213 \tTotal 10884.48/1371.69/7559.98 \n","04/19/2023 03:25:47 PM - INFO - [29:14] loss\t227.87 =\tBCE 227.87076 \tLL 0.05955 \tTotal 5688.32/662.59/3913.92 \n","04/19/2023 03:25:48 PM - INFO - [29:15] loss\t166.33 =\tBCE 166.33076 \tLL 0.04411 \tTotal 2294.74/237.86/1457.08 \n","04/19/2023 03:25:49 PM - INFO - [29:16] loss\t179.56 =\tBCE 179.55894 \tLL 0.03191 \tTotal 2547.51/521.96/1571.68 \n","04/19/2023 03:25:49 PM - INFO - [29:17] loss\t210.70 =\tBCE 210.70053 \tLL 0.02403 \tTotal 3433.10/702.76/2264.80 \n","04/19/2023 03:25:50 PM - INFO - [29:18] loss\t227.15 =\tBCE 227.15132 \tLL 0.01798 \tTotal 3468.18/621.05/2320.34 \n","04/19/2023 03:25:50 PM - INFO - [29:19] loss\t230.09 =\tBCE 230.09315 \tLL 0.01336 \tTotal 3099.71/469.38/2112.02 \n","04/19/2023 03:25:50 PM - INFO - EVALUATION prior to epoch [30]...\n","04/19/2023 03:25:50 PM - INFO - [30] loss\t218.37=\tBCE 218.37 \tLL 0.01023 \n","04/19/2023 03:25:52 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/30_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:25:56 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/30_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:26:03 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/30_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/19/2023 03:26:03 PM - INFO - Training epoch 30.\n","04/19/2023 03:26:04 PM - INFO - [30:0] loss\t217.21 =\tBCE 217.20897 \tLL 0.01010 \tTotal 2490.68/326.09/1677.50 \n","04/19/2023 03:26:04 PM - INFO - [30:1] loss\t204.02 =\tBCE 204.01849 \tLL 0.00871 \tTotal 1826.85/292.69/1056.54 \n","04/19/2023 03:26:05 PM - INFO - [30:2] loss\t195.31 =\tBCE 195.31453 \tLL 0.00792 \tTotal 1263.17/326.93/490.29 \n","04/19/2023 03:26:05 PM - INFO - [30:3] loss\t188.40 =\tBCE 188.40425 \tLL 0.00970 \tTotal 1417.05/371.73/862.47 \n","04/19/2023 03:26:06 PM - INFO - [30:4] loss\t184.90 =\tBCE 184.90100 \tLL 0.01294 \tTotal 1941.63/401.19/1400.72 \n","04/19/2023 03:26:06 PM - INFO - [30:5] loss\t183.16 =\tBCE 183.15887 \tLL 0.01538 \tTotal 2031.14/371.78/1519.59 \n","04/19/2023 03:26:07 PM - INFO - [30:6] loss\t176.11 =\tBCE 176.11026 \tLL 0.01754 \tTotal 1790.89/288.08/1343.88 \n","04/19/2023 03:26:07 PM - INFO - [30:7] loss\t163.46 =\tBCE 163.46326 \tLL 0.01795 \tTotal 1270.07/240.75/753.00 \n","04/19/2023 03:26:08 PM - INFO - [30:8] loss\t158.90 =\tBCE 158.90286 \tLL 0.01935 \tTotal 932.41/255.64/257.08 \n","04/19/2023 03:26:09 PM - INFO - [30:9] loss\t157.88 =\tBCE 157.87827 \tLL 0.02324 \tTotal 1131.14/316.60/591.92 \n","04/19/2023 03:26:09 PM - INFO - [30:10] loss\t149.66 =\tBCE 149.66429 \tLL 0.02668 \tTotal 1408.64/344.28/957.50 \n","04/19/2023 03:26:10 PM - INFO - [30:11] loss\t141.58 =\tBCE 141.57866 \tLL 0.02905 \tTotal 1521.01/285.76/1104.68 \n","04/19/2023 03:26:10 PM - INFO - [30:12] loss\t132.39 =\tBCE 132.39456 \tLL 0.02913 \tTotal 1055.83/196.42/769.43 \n","04/19/2023 03:26:11 PM - INFO - [30:13] loss\t122.08 =\tBCE 122.08062 \tLL 0.02721 \tTotal 814.85/145.75/507.38 \n","04/19/2023 03:26:11 PM - INFO - [30:14] loss\t115.62 =\tBCE 115.62490 \tLL 0.02428 \tTotal 1286.37/249.91/718.61 \n","04/19/2023 03:26:12 PM - INFO - [30:15] loss\t113.16 =\tBCE 113.16283 \tLL 0.01953 \tTotal 1173.44/266.78/649.82 \n","04/19/2023 03:26:12 PM - INFO - [30:16] loss\t104.20 =\tBCE 104.19800 \tLL 0.01562 \tTotal 1102.86/245.90/651.18 \n","04/19/2023 03:26:13 PM - INFO - [30:17] loss\t99.03 =\tBCE 99.03382 \tLL 0.01181 \tTotal 978.76/159.52/638.46 \n","04/19/2023 03:26:13 PM - INFO - [30:18] loss\t90.67 =\tBCE 90.67041 \tLL 0.00954 \tTotal 862.03/120.24/638.08 \n","\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n","04/19/2023 03:26:14 PM - INFO - [30:19] loss\t84.54 =\tBCE 84.53985 \tLL 0.00694 \tTotal 1008.65/144.19/716.61 \n","04/19/2023 03:26:14 PM - INFO - Training epoch 31.\n","04/19/2023 03:26:14 PM - INFO - [31:0] loss\t76.97 =\tBCE 76.96841 \tLL 0.00551 \tTotal 595.13/118.63/349.47 \n","04/19/2023 03:26:15 PM - INFO - [31:1] loss\t77.46 =\tBCE 77.45978 \tLL 0.00518 \tTotal 642.63/97.14/366.33 \n","04/19/2023 03:26:16 PM - INFO - [31:2] loss\t70.95 =\tBCE 70.94894 \tLL 0.00456 \tTotal 677.04/92.62/502.38 \n","04/19/2023 03:26:16 PM - INFO - [31:3] loss\t69.52 =\tBCE 69.52020 \tLL 0.00452 \tTotal 725.18/93.71/504.72 \n","04/19/2023 03:26:17 PM - INFO - [31:4] loss\t65.30 =\tBCE 65.30389 \tLL 0.00420 \tTotal 622.58/118.60/433.85 \n","04/19/2023 03:26:17 PM - INFO - [31:5] loss\t67.23 =\tBCE 67.23260 \tLL 0.00439 \tTotal 645.85/135.04/378.47 \n","04/19/2023 03:26:18 PM - INFO - [31:6] loss\t62.57 =\tBCE 62.57469 \tLL 0.00435 \tTotal 631.44/114.55/319.03 \n","04/19/2023 03:26:18 PM - INFO - [31:7] loss\t49.23 =\tBCE 49.23417 \tLL 0.00310 \tTotal 435.14/73.74/224.56 \n","04/19/2023 03:26:19 PM - INFO - [31:8] loss\t47.61 =\tBCE 47.61296 \tLL 0.00309 \tTotal 615.92/79.01/424.77 \n","04/19/2023 03:26:19 PM - INFO - [31:9] loss\t49.32 =\tBCE 49.31894 \tLL 0.00359 \tTotal 692.12/86.87/455.05 \n","04/19/2023 03:26:20 PM - INFO - [31:10] loss\t47.10 =\tBCE 47.09737 \tLL 0.00379 \tTotal 701.55/96.98/462.68 \n","04/19/2023 03:26:20 PM - INFO - [31:11] loss\t44.38 =\tBCE 44.38156 \tLL 0.00367 \tTotal 612.00/85.61/373.86 \n","04/19/2023 03:26:21 PM - INFO - [31:12] loss\t39.03 =\tBCE 39.03015 \tLL 0.00362 \tTotal 550.55/80.21/329.22 \n","04/19/2023 03:26:22 PM - INFO - [31:13] loss\t37.60 =\tBCE 37.59734 \tLL 0.00360 \tTotal 415.93/79.84/211.94 \n","04/19/2023 03:26:22 PM - INFO - [31:14] loss\t37.61 =\tBCE 37.61203 \tLL 0.00380 \tTotal 481.57/74.44/256.02 \n","04/19/2023 03:26:23 PM - INFO - [31:15] loss\t35.80 =\tBCE 35.79945 \tLL 0.00399 \tTotal 552.98/78.61/252.62 \n","04/19/2023 03:26:23 PM - INFO - [31:16] loss\t36.33 =\tBCE 36.33181 \tLL 0.00401 \tTotal 630.04/82.13/370.04 \n","04/19/2023 03:26:24 PM - INFO - [31:17] loss\t33.64 =\tBCE 33.63531 \tLL 0.00372 \tTotal 450.49/67.71/228.68 \n","04/19/2023 03:26:24 PM - INFO - [31:18] loss\t32.94 =\tBCE 32.94059 \tLL 0.00354 \tTotal 595.87/78.58/447.95 \n","04/19/2023 03:26:25 PM - INFO - [31:19] loss\t30.63 =\tBCE 30.62576 \tLL 0.00353 \tTotal 600.93/61.29/268.77 \n","04/19/2023 03:26:25 PM - INFO - Training epoch 32.\n","04/19/2023 03:26:25 PM - INFO - [32:0] loss\t29.65 =\tBCE 29.65341 \tLL 0.00349 \tTotal 597.66/73.45/208.14 \n","04/19/2023 03:26:26 PM - INFO - [32:1] loss\t27.19 =\tBCE 27.18772 \tLL 0.00329 \tTotal 359.62/57.91/203.89 \n","04/19/2023 03:26:26 PM - INFO - [32:2] loss\t27.29 =\tBCE 27.28978 \tLL 0.00312 \tTotal 492.20/62.91/183.08 \n","04/19/2023 03:26:27 PM - INFO - [32:3] loss\t26.52 =\tBCE 26.51630 \tLL 0.00329 \tTotal 619.75/83.96/308.83 \n","04/19/2023 03:26:28 PM - INFO - [32:4] loss\t24.90 =\tBCE 24.89861 \tLL 0.00307 \tTotal 383.95/43.85/199.44 \n","04/19/2023 03:26:28 PM - INFO - [32:5] loss\t26.07 =\tBCE 26.06651 \tLL 0.00312 \tTotal 620.89/51.91/443.56 \n","04/19/2023 03:26:29 PM - INFO - [32:6] loss\t25.03 =\tBCE 25.03367 \tLL 0.00287 \tTotal 649.59/52.17/374.80 \n","04/19/2023 03:26:29 PM - INFO - [32:7] loss\t24.68 =\tBCE 24.68427 \tLL 0.00281 \tTotal 342.69/38.20/200.33 \n","04/19/2023 03:26:30 PM - INFO - [32:8] loss\t22.53 =\tBCE 22.52700 \tLL 0.00271 \tTotal 448.47/50.42/298.47 \n","04/19/2023 03:26:30 PM - INFO - [32:9] loss\t22.69 =\tBCE 22.69467 \tLL 0.00269 \tTotal 536.50/43.00/299.33 \n","04/19/2023 03:26:31 PM - INFO - [32:10] loss\t22.56 =\tBCE 22.55667 \tLL 0.00282 \tTotal 513.74/47.56/243.65 \n","04/19/2023 03:26:31 PM - INFO - [32:11] loss\t21.07 =\tBCE 21.07346 \tLL 0.00238 \tTotal 442.01/63.03/326.21 \n","04/19/2023 03:26:32 PM - INFO - [32:12] loss\t20.61 =\tBCE 20.60764 \tLL 0.00250 \tTotal 519.28/54.82/322.75 \n","04/19/2023 03:26:33 PM - INFO - [32:13] loss\t21.29 =\tBCE 21.29351 \tLL 0.00258 \tTotal 628.06/38.41/436.29 \n","04/19/2023 03:26:33 PM - INFO - [32:14] loss\t20.05 =\tBCE 20.04663 \tLL 0.00268 \tTotal 435.17/72.77/336.12 \n","04/19/2023 03:26:34 PM - INFO - [32:15] loss\t19.15 =\tBCE 19.15125 \tLL 0.00264 \tTotal 436.03/63.04/307.03 \n","04/19/2023 03:26:34 PM - INFO - [32:16] loss\t19.48 =\tBCE 19.47569 \tLL 0.00276 \tTotal 411.88/44.20/241.96 \n","04/19/2023 03:26:35 PM - INFO - [32:17] loss\t18.80 =\tBCE 18.79591 \tLL 0.00250 \tTotal 485.63/72.47/331.38 \n","04/19/2023 03:26:35 PM - INFO - [32:18] loss\t18.68 =\tBCE 18.67691 \tLL 0.00249 \tTotal 385.77/81.27/251.49 \n","04/19/2023 03:26:36 PM - INFO - [32:19] loss\t18.06 =\tBCE 18.05636 \tLL 0.00245 \tTotal 363.19/38.36/198.69 \n","04/19/2023 03:26:36 PM - INFO - Training epoch 33.\n","04/19/2023 03:26:36 PM - INFO - [33:0] loss\t17.52 =\tBCE 17.51847 \tLL 0.00226 \tTotal 518.33/89.91/315.38 \n","04/19/2023 03:26:37 PM - INFO - [33:1] loss\t16.73 =\tBCE 16.73050 \tLL 0.00218 \tTotal 479.28/85.50/275.21 \n","04/19/2023 03:26:37 PM - INFO - [33:2] loss\t16.73 =\tBCE 16.73154 \tLL 0.00247 \tTotal 431.03/47.82/330.79 \n","04/19/2023 03:26:38 PM - INFO - [33:3] loss\t16.38 =\tBCE 16.37529 \tLL 0.00227 \tTotal 656.32/91.96/489.66 \n","04/19/2023 03:26:38 PM - INFO - [33:4] loss\t16.35 =\tBCE 16.35253 \tLL 0.00227 \tTotal 423.94/53.73/230.85 \n","04/19/2023 03:26:39 PM - INFO - [33:5] loss\t15.91 =\tBCE 15.90754 \tLL 0.00219 \tTotal 516.89/86.08/347.31 \n","04/19/2023 03:26:40 PM - INFO - [33:6] loss\t15.52 =\tBCE 15.52165 \tLL 0.00215 \tTotal 369.25/59.20/240.02 \n","04/19/2023 03:26:40 PM - INFO - [33:7] loss\t15.07 =\tBCE 15.07306 \tLL 0.00205 \tTotal 425.05/77.76/290.30 \n","04/19/2023 03:26:41 PM - INFO - [33:8] loss\t15.21 =\tBCE 15.21413 \tLL 0.00212 \tTotal 201.24/37.03/136.81 \n","04/19/2023 03:26:41 PM - INFO - [33:9] loss\t14.91 =\tBCE 14.90952 \tLL 0.00198 \tTotal 613.73/69.08/476.79 \n","04/19/2023 03:26:42 PM - INFO - [33:10] loss\t14.67 =\tBCE 14.66686 \tLL 0.00189 \tTotal 346.48/37.16/211.73 \n","04/19/2023 03:26:42 PM - INFO - [33:11] loss\t14.41 =\tBCE 14.41408 \tLL 0.00179 \tTotal 323.96/48.85/230.83 \n","04/19/2023 03:26:43 PM - INFO - [33:12] loss\t14.72 =\tBCE 14.72359 \tLL 0.00192 \tTotal 429.25/51.09/286.47 \n","04/19/2023 03:26:43 PM - INFO - [33:13] loss\t14.30 =\tBCE 14.30417 \tLL 0.00196 \tTotal 274.64/29.49/166.55 \n","04/19/2023 03:26:44 PM - INFO - [33:14] loss\t14.15 =\tBCE 14.14905 \tLL 0.00198 \tTotal 274.26/47.11/208.93 \n","04/19/2023 03:26:45 PM - INFO - [33:15] loss\t13.68 =\tBCE 13.68334 \tLL 0.00183 \tTotal 329.35/55.41/258.55 \n","04/19/2023 03:26:45 PM - INFO - [33:16] loss\t13.82 =\tBCE 13.82027 \tLL 0.00185 \tTotal 262.44/48.32/142.86 \n","04/19/2023 03:26:46 PM - INFO - [33:17] loss\t13.23 =\tBCE 13.22792 \tLL 0.00192 \tTotal 196.58/55.00/102.11 \n","04/19/2023 03:26:46 PM - INFO - [33:18] loss\t13.33 =\tBCE 13.33353 \tLL 0.00195 \tTotal 285.57/51.17/160.05 \n","04/19/2023 03:26:47 PM - INFO - [33:19] loss\t12.77 =\tBCE 12.77061 \tLL 0.00171 \tTotal 208.13/37.99/96.67 \n","04/19/2023 03:26:47 PM - INFO - Training epoch 34.\n","04/19/2023 03:26:47 PM - INFO - [34:0] loss\t13.23 =\tBCE 13.22902 \tLL 0.00183 \tTotal 433.00/57.51/296.28 \n","04/19/2023 03:26:48 PM - INFO - [34:1] loss\t12.76 =\tBCE 12.75925 \tLL 0.00187 \tTotal 332.56/45.20/245.29 \n","04/19/2023 03:26:48 PM - INFO - [34:2] loss\t12.32 =\tBCE 12.31936 \tLL 0.00183 \tTotal 324.26/39.09/245.03 \n","04/19/2023 03:26:49 PM - INFO - [34:3] loss\t12.48 =\tBCE 12.47771 \tLL 0.00184 \tTotal 342.91/45.90/245.05 \n","04/19/2023 03:26:49 PM - INFO - [34:4] loss\t12.06 =\tBCE 12.06132 \tLL 0.00178 \tTotal 417.81/59.93/324.90 \n","04/19/2023 03:26:50 PM - INFO - [34:5] loss\t11.51 =\tBCE 11.50679 \tLL 0.00171 \tTotal 316.99/61.03/182.12 \n","04/19/2023 03:26:50 PM - INFO - [34:6] loss\t11.90 =\tBCE 11.89537 \tLL 0.00184 \tTotal 265.12/51.22/154.52 \n","04/19/2023 03:26:51 PM - INFO - [34:7] loss\t11.93 =\tBCE 11.92909 \tLL 0.00172 \tTotal 161.11/25.28/107.23 \n","04/19/2023 03:26:52 PM - INFO - [34:8] loss\t11.34 =\tBCE 11.34049 \tLL 0.00159 \tTotal 324.68/54.24/230.76 \n","04/19/2023 03:26:52 PM - INFO - [34:9] loss\t11.85 =\tBCE 11.84973 \tLL 0.00180 \tTotal 185.05/35.19/119.33 \n","04/19/2023 03:26:53 PM - INFO - [34:10] loss\t11.56 =\tBCE 11.55658 \tLL 0.00169 \tTotal 268.08/36.79/175.93 \n","04/19/2023 03:26:53 PM - INFO - [34:11] loss\t11.12 =\tBCE 11.12058 \tLL 0.00165 \tTotal 370.48/49.88/281.85 \n","04/19/2023 03:26:54 PM - INFO - [34:12] loss\t11.31 =\tBCE 11.31393 \tLL 0.00182 \tTotal 226.71/47.41/136.31 \n","04/19/2023 03:26:54 PM - INFO - [34:13] loss\t11.78 =\tBCE 11.78442 \tLL 0.00175 \tTotal 538.41/73.10/377.20 \n","04/19/2023 03:26:55 PM - INFO - [34:14] loss\t11.20 =\tBCE 11.19751 \tLL 0.00167 \tTotal 439.51/62.22/334.40 \n","04/19/2023 03:26:55 PM - INFO - [34:15] loss\t11.13 =\tBCE 11.12888 \tLL 0.00160 \tTotal 302.95/52.79/199.42 \n","04/19/2023 03:26:56 PM - INFO - [34:16] loss\t10.81 =\tBCE 10.80605 \tLL 0.00173 \tTotal 375.79/53.82/273.01 \n","04/19/2023 03:26:56 PM - INFO - [34:17] loss\t10.93 =\tBCE 10.92576 \tLL 0.00172 \tTotal 348.87/46.35/270.57 \n","04/19/2023 03:26:57 PM - INFO - [34:18] loss\t10.68 =\tBCE 10.67884 \tLL 0.00159 \tTotal 422.52/61.38/314.29 \n","04/19/2023 03:26:57 PM - INFO - [34:19] loss\t10.59 =\tBCE 10.58737 \tLL 0.00163 \tTotal 243.44/37.78/161.38 \n","04/19/2023 03:26:57 PM - INFO - Training epoch 35.\n","04/19/2023 03:26:58 PM - INFO - [35:0] loss\t10.09 =\tBCE 10.08587 \tLL 0.00159 \tTotal 406.57/55.64/298.52 \n","04/19/2023 03:26:59 PM - INFO - [35:1] loss\t10.64 =\tBCE 10.63909 \tLL 0.00171 \tTotal 156.98/25.00/96.69 \n","04/19/2023 03:26:59 PM - INFO - [35:2] loss\t9.96 =\tBCE 9.96185 \tLL 0.00156 \tTotal 277.18/36.63/182.63 \n","04/19/2023 03:27:00 PM - INFO - [35:3] loss\t10.46 =\tBCE 10.46438 \tLL 0.00167 \tTotal 378.43/44.81/254.01 \n","04/19/2023 03:27:00 PM - INFO - [35:4] loss\t10.03 =\tBCE 10.03018 \tLL 0.00157 \tTotal 421.84/52.12/329.44 \n","04/19/2023 03:27:01 PM - INFO - [35:5] loss\t9.93 =\tBCE 9.93185 \tLL 0.00154 \tTotal 195.75/29.01/138.89 \n","04/19/2023 03:27:01 PM - INFO - [35:6] loss\t10.15 =\tBCE 10.14966 \tLL 0.00162 \tTotal 345.96/53.91/244.60 \n","04/19/2023 03:27:02 PM - INFO - [35:7] loss\t10.39 =\tBCE 10.38628 \tLL 0.00166 \tTotal 228.91/27.41/124.82 \n","04/19/2023 03:27:02 PM - INFO - [35:8] loss\t9.97 =\tBCE 9.97282 \tLL 0.00157 \tTotal 414.93/54.27/300.28 \n","04/19/2023 03:27:03 PM - INFO - [35:9] loss\t9.60 =\tBCE 9.60478 \tLL 0.00157 \tTotal 233.38/42.91/156.13 \n","04/19/2023 03:27:03 PM - INFO - [35:10] loss\t9.61 =\tBCE 9.61096 \tLL 0.00155 \tTotal 367.25/48.45/283.37 \n","04/19/2023 03:27:04 PM - INFO - [35:11] loss\t9.32 =\tBCE 9.31792 \tLL 0.00145 \tTotal 302.79/67.13/223.27 \n","04/19/2023 03:27:04 PM - INFO - [35:12] loss\t9.70 =\tBCE 9.69949 \tLL 0.00164 \tTotal 218.39/44.65/164.03 \n","04/19/2023 03:27:05 PM - INFO - [35:13] loss\t9.66 =\tBCE 9.66441 \tLL 0.00159 \tTotal 430.41/70.23/304.69 \n","04/19/2023 03:27:05 PM - INFO - [35:14] loss\t9.42 =\tBCE 9.42360 \tLL 0.00150 \tTotal 296.41/41.81/230.73 \n","04/19/2023 03:27:06 PM - INFO - [35:15] loss\t9.56 =\tBCE 9.55910 \tLL 0.00158 \tTotal 418.39/54.19/320.84 \n","04/19/2023 03:27:07 PM - INFO - [35:16] loss\t9.12 =\tBCE 9.12307 \tLL 0.00146 \tTotal 461.55/76.64/349.35 \n","04/19/2023 03:27:07 PM - INFO - [35:17] loss\t9.17 =\tBCE 9.16653 \tLL 0.00151 \tTotal 224.46/31.96/158.77 \n","04/19/2023 03:27:08 PM - INFO - [35:18] loss\t9.10 =\tBCE 9.09775 \tLL 0.00149 \tTotal 503.45/69.38/397.64 \n","04/19/2023 03:27:08 PM - INFO - [35:19] loss\t9.02 =\tBCE 9.01933 \tLL 0.00144 \tTotal 194.15/35.53/80.24 \n","04/19/2023 03:27:08 PM - INFO - Training epoch 36.\n","04/19/2023 03:27:09 PM - INFO - [36:0] loss\t9.00 =\tBCE 8.99689 \tLL 0.00156 \tTotal 499.70/63.76/395.30 \n","04/19/2023 03:27:09 PM - INFO - [36:1] loss\t8.84 =\tBCE 8.83710 \tLL 0.00149 \tTotal 215.48/39.89/122.17 \n","04/19/2023 03:27:10 PM - INFO - [36:2] loss\t9.06 =\tBCE 9.05649 \tLL 0.00154 \tTotal 415.38/63.34/312.31 \n","04/19/2023 03:27:10 PM - INFO - [36:3] loss\t8.70 =\tBCE 8.70468 \tLL 0.00143 \tTotal 420.13/61.75/319.02 \n","04/19/2023 03:27:11 PM - INFO - [36:4] loss\t8.55 =\tBCE 8.54817 \tLL 0.00145 \tTotal 182.53/21.32/134.76 \n","04/19/2023 03:27:11 PM - INFO - [36:5] loss\t8.51 =\tBCE 8.50542 \tLL 0.00149 \tTotal 263.71/34.17/179.24 \n","04/19/2023 03:27:12 PM - INFO - [36:6] loss\t8.38 =\tBCE 8.38373 \tLL 0.00139 \tTotal 212.97/38.54/155.12 \n","04/19/2023 03:27:13 PM - INFO - [36:7] loss\t8.35 =\tBCE 8.35366 \tLL 0.00137 \tTotal 208.87/36.86/133.71 \n","04/19/2023 03:27:13 PM - INFO - [36:8] loss\t8.36 =\tBCE 8.36173 \tLL 0.00142 \tTotal 225.90/36.81/170.68 \n","04/19/2023 03:27:14 PM - INFO - [36:9] loss\t8.40 =\tBCE 8.40222 \tLL 0.00146 \tTotal 187.21/35.27/139.02 \n","04/19/2023 03:27:14 PM - INFO - [36:10] loss\t8.49 =\tBCE 8.48661 \tLL 0.00140 \tTotal 251.19/44.50/162.71 \n","04/19/2023 03:27:15 PM - INFO - [36:11] loss\t8.35 =\tBCE 8.35439 \tLL 0.00144 \tTotal 223.04/28.83/123.87 \n","04/19/2023 03:27:15 PM - INFO - [36:12] loss\t8.52 =\tBCE 8.51608 \tLL 0.00149 \tTotal 147.65/28.33/99.19 \n","04/19/2023 03:27:16 PM - INFO - [36:13] loss\t8.37 =\tBCE 8.37245 \tLL 0.00155 \tTotal 345.91/36.09/197.80 \n","04/19/2023 03:27:16 PM - INFO - [36:14] loss\t8.26 =\tBCE 8.25964 \tLL 0.00147 \tTotal 188.97/32.81/138.45 \n","04/19/2023 03:27:17 PM - INFO - [36:15] loss\t8.06 =\tBCE 8.05566 \tLL 0.00141 \tTotal 229.24/36.14/117.84 \n","04/19/2023 03:27:17 PM - INFO - [36:16] loss\t8.20 =\tBCE 8.19876 \tLL 0.00143 \tTotal 246.18/34.99/135.93 \n","04/19/2023 03:27:18 PM - INFO - [36:17] loss\t8.46 =\tBCE 8.45887 \tLL 0.00156 \tTotal 360.73/69.32/283.66 \n","04/19/2023 03:27:18 PM - INFO - [36:18] loss\t8.31 =\tBCE 8.31315 \tLL 0.00147 \tTotal 337.44/44.24/221.85 \n","04/19/2023 03:27:19 PM - INFO - [36:19] loss\t8.16 =\tBCE 8.16299 \tLL 0.00147 \tTotal 300.16/60.74/213.04 \n","04/19/2023 03:27:19 PM - INFO - Training epoch 37.\n","04/19/2023 03:27:19 PM - INFO - [37:0] loss\t7.95 =\tBCE 7.95411 \tLL 0.00132 \tTotal 384.85/54.20/251.95 \n","04/19/2023 03:27:20 PM - INFO - [37:1] loss\t8.19 =\tBCE 8.18665 \tLL 0.00147 \tTotal 255.34/55.87/172.81 \n","04/19/2023 03:27:21 PM - INFO - [37:2] loss\t7.83 =\tBCE 7.82657 \tLL 0.00148 \tTotal 523.80/73.09/403.69 \n","04/19/2023 03:27:21 PM - INFO - [37:3] loss\t8.13 =\tBCE 8.12664 \tLL 0.00152 \tTotal 546.38/68.36/404.67 \n","04/19/2023 03:27:22 PM - INFO - [37:4] loss\t7.91 =\tBCE 7.90538 \tLL 0.00146 \tTotal 374.29/58.35/240.94 \n","04/19/2023 03:27:22 PM - INFO - [37:5] loss\t7.76 =\tBCE 7.76221 \tLL 0.00152 \tTotal 291.65/44.32/150.03 \n","04/19/2023 03:27:23 PM - INFO - [37:6] loss\t7.82 =\tBCE 7.81554 \tLL 0.00143 \tTotal 414.54/67.72/298.14 \n","04/19/2023 03:27:23 PM - INFO - [37:7] loss\t7.68 =\tBCE 7.68182 \tLL 0.00150 \tTotal 289.65/46.95/173.14 \n","04/19/2023 03:27:24 PM - INFO - [37:8] loss\t7.50 =\tBCE 7.50220 \tLL 0.00135 \tTotal 355.26/57.70/276.32 \n","04/19/2023 03:27:24 PM - INFO - [37:9] loss\t7.85 =\tBCE 7.85117 \tLL 0.00144 \tTotal 560.96/81.95/400.88 \n","04/19/2023 03:27:25 PM - INFO - [37:10] loss\t7.53 =\tBCE 7.52847 \tLL 0.00133 \tTotal 235.48/57.37/174.26 \n","04/19/2023 03:27:25 PM - INFO - [37:11] loss\t7.54 =\tBCE 7.54200 \tLL 0.00141 \tTotal 387.68/56.79/251.30 \n","04/19/2023 03:27:26 PM - INFO - [37:12] loss\t7.34 =\tBCE 7.33802 \tLL 0.00139 \tTotal 461.94/77.13/311.58 \n","04/19/2023 03:27:27 PM - INFO - [37:13] loss\t7.40 =\tBCE 7.39525 \tLL 0.00140 \tTotal 293.47/50.04/144.42 \n","04/19/2023 03:27:27 PM - INFO - [37:14] loss\t7.16 =\tBCE 7.16249 \tLL 0.00136 \tTotal 384.82/68.61/260.56 \n","04/19/2023 03:27:28 PM - INFO - [37:15] loss\t7.34 =\tBCE 7.34067 \tLL 0.00131 \tTotal 365.56/74.54/271.03 \n","04/19/2023 03:27:28 PM - INFO - [37:16] loss\t7.39 =\tBCE 7.38696 \tLL 0.00142 \tTotal 301.07/60.73/198.22 \n","04/19/2023 03:27:29 PM - INFO - [37:17] loss\t7.31 =\tBCE 7.31159 \tLL 0.00134 \tTotal 490.01/82.64/365.01 \n","04/19/2023 03:27:29 PM - INFO - [37:18] loss\t7.32 =\tBCE 7.31605 \tLL 0.00141 \tTotal 272.93/58.32/189.21 \n","04/19/2023 03:27:30 PM - INFO - [37:19] loss\t7.29 =\tBCE 7.29229 \tLL 0.00143 \tTotal 341.61/65.74/245.38 \n","04/19/2023 03:27:30 PM - INFO - Training epoch 38.\n","04/19/2023 03:27:30 PM - INFO - [38:0] loss\t6.99 =\tBCE 6.98512 \tLL 0.00137 \tTotal 274.97/57.29/188.08 \n","04/19/2023 03:27:31 PM - INFO - [38:1] loss\t7.06 =\tBCE 7.06475 \tLL 0.00143 \tTotal 418.87/70.81/299.52 \n","04/19/2023 03:27:31 PM - INFO - [38:2] loss\t7.28 =\tBCE 7.28161 \tLL 0.00141 \tTotal 539.41/97.65/425.57 \n","04/19/2023 03:27:32 PM - INFO - [38:3] loss\t7.25 =\tBCE 7.25138 \tLL 0.00149 \tTotal 312.13/40.67/152.83 \n","04/19/2023 03:27:32 PM - INFO - [38:4] loss\t7.11 =\tBCE 7.11329 \tLL 0.00146 \tTotal 411.58/75.22/288.49 \n","04/19/2023 03:27:33 PM - INFO - [38:5] loss\t6.86 =\tBCE 6.85980 \tLL 0.00133 \tTotal 293.99/35.12/134.10 \n","04/19/2023 03:27:34 PM - INFO - [38:6] loss\t6.79 =\tBCE 6.79129 \tLL 0.00125 \tTotal 438.69/81.73/292.35 \n","04/19/2023 03:27:34 PM - INFO - [38:7] loss\t7.06 =\tBCE 7.06380 \tLL 0.00139 \tTotal 522.80/68.50/388.38 \n","04/19/2023 03:27:35 PM - INFO - [38:8] loss\t7.08 =\tBCE 7.07944 \tLL 0.00142 \tTotal 269.17/58.63/175.85 \n","04/19/2023 03:27:35 PM - INFO - [38:9] loss\t7.20 =\tBCE 7.20340 \tLL 0.00148 \tTotal 850.72/116.14/656.13 \n","04/19/2023 03:27:36 PM - INFO - [38:10] loss\t7.11 =\tBCE 7.11018 \tLL 0.00136 \tTotal 711.44/100.84/563.57 \n","04/19/2023 03:27:36 PM - INFO - [38:11] loss\t6.99 =\tBCE 6.99195 \tLL 0.00141 \tTotal 174.01/33.12/86.20 \n","04/19/2023 03:27:37 PM - INFO - [38:12] loss\t6.94 =\tBCE 6.94475 \tLL 0.00143 \tTotal 561.27/88.93/454.81 \n","04/19/2023 03:27:37 PM - INFO - [38:13] loss\t6.70 =\tBCE 6.70326 \tLL 0.00134 \tTotal 495.59/82.47/357.42 \n","04/19/2023 03:27:38 PM - INFO - [38:14] loss\t6.57 =\tBCE 6.56876 \tLL 0.00131 \tTotal 173.25/21.22/80.04 \n","04/19/2023 03:27:38 PM - INFO - [38:15] loss\t6.72 =\tBCE 6.72005 \tLL 0.00143 \tTotal 347.96/67.52/239.84 \n","04/19/2023 03:27:39 PM - INFO - [38:16] loss\t6.67 =\tBCE 6.66776 \tLL 0.00137 \tTotal 409.20/50.29/249.50 \n","04/19/2023 03:27:39 PM - INFO - [38:17] loss\t6.65 =\tBCE 6.64585 \tLL 0.00135 \tTotal 214.50/57.34/120.61 \n","04/19/2023 03:27:40 PM - INFO - [38:18] loss\t6.49 =\tBCE 6.49178 \tLL 0.00133 \tTotal 397.66/61.21/256.32 \n","04/19/2023 03:27:41 PM - INFO - [38:19] loss\t6.64 =\tBCE 6.63681 \tLL 0.00136 \tTotal 434.85/69.81/312.05 \n","Not implemented\n","04/19/2023 03:27:41 PM - INFO - Training epoch 39.\n","04/19/2023 03:27:41 PM - INFO - [39:0] loss\t6.52 =\tBCE 6.52403 \tLL 0.00140 \tTotal 264.99/58.82/175.90 \n","04/19/2023 03:27:42 PM - INFO - [39:1] loss\t6.36 =\tBCE 6.35613 \tLL 0.00127 \tTotal 615.25/93.60/478.92 \n","04/19/2023 03:27:42 PM - INFO - [39:2] loss\t6.61 =\tBCE 6.61183 \tLL 0.00134 \tTotal 636.65/110.83/467.68 \n","04/19/2023 03:27:43 PM - INFO - [39:3] loss\t6.38 =\tBCE 6.37825 \tLL 0.00139 \tTotal 386.61/56.32/282.99 \n","04/19/2023 03:27:43 PM - INFO - [39:4] loss\t6.47 =\tBCE 6.46653 \tLL 0.00139 \tTotal 356.54/77.08/246.22 \n","04/19/2023 03:27:44 PM - INFO - [39:5] loss\t6.39 =\tBCE 6.38544 \tLL 0.00136 \tTotal 484.20/89.38/339.78 \n","04/19/2023 03:27:44 PM - INFO - [39:6] loss\t6.25 =\tBCE 6.25312 \tLL 0.00128 \tTotal 372.01/70.68/226.29 \n","04/19/2023 03:27:45 PM - INFO - [39:7] loss\t6.51 =\tBCE 6.51003 \tLL 0.00137 \tTotal 291.00/62.07/106.29 \n","04/19/2023 03:27:45 PM - INFO - [39:8] loss\t6.21 =\tBCE 6.21430 \tLL 0.00133 \tTotal 356.11/52.15/262.31 \n","04/19/2023 03:27:46 PM - INFO - [39:9] loss\t6.42 =\tBCE 6.42205 \tLL 0.00133 \tTotal 321.41/68.05/182.33 \n","04/19/2023 03:27:46 PM - INFO - [39:10] loss\t6.26 =\tBCE 6.26479 \tLL 0.00129 \tTotal 402.74/33.89/337.16 \n","04/19/2023 03:27:47 PM - INFO - [39:11] loss\t6.27 =\tBCE 6.26525 \tLL 0.00131 \tTotal 540.05/90.44/382.05 \n","04/19/2023 03:27:48 PM - INFO - [39:12] loss\t6.28 =\tBCE 6.27770 \tLL 0.00139 \tTotal 492.01/82.40/354.00 \n","04/19/2023 03:27:48 PM - INFO - [39:13] loss\t6.47 =\tBCE 6.46929 \tLL 0.00142 \tTotal 397.60/81.73/314.92 \n","04/19/2023 03:27:49 PM - INFO - [39:14] loss\t6.19 =\tBCE 6.19304 \tLL 0.00132 \tTotal 299.75/50.34/160.06 \n","04/19/2023 03:27:49 PM - INFO - [39:15] loss\t6.17 =\tBCE 6.17065 \tLL 0.00137 \tTotal 328.78/63.78/258.55 \n","04/19/2023 03:27:50 PM - INFO - [39:16] loss\t6.18 =\tBCE 6.17836 \tLL 0.00136 \tTotal 271.34/28.47/197.51 \n","04/19/2023 03:27:50 PM - INFO - [39:17] loss\t6.15 =\tBCE 6.14690 \tLL 0.00136 \tTotal 290.52/83.37/147.36 \n","04/19/2023 03:27:51 PM - INFO - [39:18] loss\t5.88 =\tBCE 5.87994 \tLL 0.00127 \tTotal 248.76/33.47/195.45 \n","04/19/2023 03:27:51 PM - INFO - [39:19] loss\t6.31 =\tBCE 6.30925 \tLL 0.00140 \tTotal 318.26/52.74/161.33 \n","04/19/2023 03:27:51 PM - INFO - EVALUATION prior to epoch [40]...\n","04/19/2023 03:27:52 PM - INFO - [40] loss\t6.16=\tBCE 6.16 \tLL 0.00139 \n","04/19/2023 03:27:54 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/40_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:27:59 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/40_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:28:03 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/40_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/19/2023 03:28:04 PM - INFO - Training epoch 40.\n","04/19/2023 03:28:05 PM - INFO - [40:0] loss\t5.99 =\tBCE 5.98992 \tLL 0.00137 \tTotal 221.31/35.02/150.80 \n","04/19/2023 03:28:05 PM - INFO - [40:1] loss\t5.95 =\tBCE 5.94536 \tLL 0.00133 \tTotal 325.70/61.58/247.47 \n","04/19/2023 03:28:06 PM - INFO - [40:2] loss\t6.12 =\tBCE 6.12484 \tLL 0.00136 \tTotal 329.20/38.61/242.62 \n","04/19/2023 03:28:06 PM - INFO - [40:3] loss\t5.88 =\tBCE 5.88042 \tLL 0.00133 \tTotal 186.16/64.63/110.95 \n","04/19/2023 03:28:07 PM - INFO - [40:4] loss\t5.90 =\tBCE 5.90478 \tLL 0.00136 \tTotal 371.15/44.15/228.48 \n","04/19/2023 03:28:07 PM - INFO - [40:5] loss\t5.78 =\tBCE 5.78256 \tLL 0.00129 \tTotal 342.74/51.84/267.65 \n","04/19/2023 03:28:08 PM - INFO - [40:6] loss\t5.93 =\tBCE 5.93055 \tLL 0.00129 \tTotal 312.72/40.12/225.56 \n","04/19/2023 03:28:08 PM - INFO - [40:7] loss\t5.93 =\tBCE 5.92783 \tLL 0.00137 \tTotal 349.51/52.20/222.54 \n","04/19/2023 03:28:09 PM - INFO - [40:8] loss\t6.06 =\tBCE 6.06382 \tLL 0.00135 \tTotal 369.23/53.36/199.86 \n","04/19/2023 03:28:09 PM - INFO - [40:9] loss\t5.81 =\tBCE 5.81106 \tLL 0.00130 \tTotal 569.31/80.97/383.70 \n","04/19/2023 03:28:10 PM - INFO - [40:10] loss\t6.06 =\tBCE 6.06342 \tLL 0.00144 \tTotal 720.15/106.08/528.50 \n","04/19/2023 03:28:10 PM - INFO - [40:11] loss\t6.21 =\tBCE 6.20635 \tLL 0.00147 \tTotal 740.84/90.34/508.86 \n","04/19/2023 03:28:11 PM - INFO - [40:12] loss\t5.70 =\tBCE 5.70112 \tLL 0.00138 \tTotal 370.41/49.33/214.75 \n","04/19/2023 03:28:12 PM - INFO - [40:13] loss\t6.20 =\tBCE 6.20205 \tLL 0.00135 \tTotal 736.31/95.91/496.14 \n","04/19/2023 03:28:12 PM - INFO - [40:14] loss\t5.92 =\tBCE 5.91933 \tLL 0.00126 \tTotal 855.38/142.55/628.58 \n","04/19/2023 03:28:13 PM - INFO - [40:15] loss\t6.02 =\tBCE 6.02023 \tLL 0.00143 \tTotal 961.47/144.05/636.01 \n","04/19/2023 03:28:13 PM - INFO - [40:16] loss\t5.67 =\tBCE 5.66532 \tLL 0.00126 \tTotal 519.85/92.48/391.08 \n","04/19/2023 03:28:14 PM - INFO - [40:17] loss\t5.75 =\tBCE 5.75251 \tLL 0.00131 \tTotal 430.89/63.55/237.65 \n","04/19/2023 03:28:14 PM - INFO - [40:18] loss\t6.00 =\tBCE 6.00333 \tLL 0.00139 \tTotal 894.49/137.69/684.25 \n","04/19/2023 03:28:15 PM - INFO - [40:19] loss\t5.82 =\tBCE 5.81740 \tLL 0.00138 \tTotal 861.75/127.65/677.17 \n","04/19/2023 03:28:15 PM - INFO - Training epoch 41.\n","04/19/2023 03:28:15 PM - INFO - [41:0] loss\t5.69 =\tBCE 5.69214 \tLL 0.00131 \tTotal 511.35/88.97/311.56 \n","04/19/2023 03:28:16 PM - INFO - [41:1] loss\t5.40 =\tBCE 5.39786 \tLL 0.00123 \tTotal 405.56/57.46/298.16 \n","04/19/2023 03:28:16 PM - INFO - [41:2] loss\t5.57 =\tBCE 5.56922 \tLL 0.00128 \tTotal 679.22/103.74/487.62 \n","04/19/2023 03:28:17 PM - INFO - [41:3] loss\t5.68 =\tBCE 5.68174 \tLL 0.00140 \tTotal 591.05/87.96/466.34 \n","04/19/2023 03:28:17 PM - INFO - [41:4] loss\t5.42 =\tBCE 5.42028 \tLL 0.00127 \tTotal 241.08/50.58/131.30 \n","04/19/2023 03:28:18 PM - INFO - [41:5] loss\t5.53 =\tBCE 5.52958 \tLL 0.00128 \tTotal 306.74/61.08/207.76 \n","04/19/2023 03:28:19 PM - INFO - [41:6] loss\t5.59 =\tBCE 5.59229 \tLL 0.00138 \tTotal 423.24/74.68/278.31 \n","04/19/2023 03:28:19 PM - INFO - [41:7] loss\t5.63 =\tBCE 5.63189 \tLL 0.00134 \tTotal 415.74/53.56/274.67 \n","04/19/2023 03:28:20 PM - INFO - [41:8] loss\t5.66 =\tBCE 5.65859 \tLL 0.00139 \tTotal 225.07/33.90/149.35 \n","04/19/2023 03:28:20 PM - INFO - [41:9] loss\t5.30 =\tBCE 5.29514 \tLL 0.00130 \tTotal 318.82/49.46/205.46 \n","04/19/2023 03:28:21 PM - INFO - [41:10] loss\t5.53 =\tBCE 5.52967 \tLL 0.00131 \tTotal 429.40/58.10/299.08 \n","04/19/2023 03:28:21 PM - INFO - [41:11] loss\t5.51 =\tBCE 5.51422 \tLL 0.00129 \tTotal 380.95/67.70/273.72 \n","04/19/2023 03:28:22 PM - INFO - [41:12] loss\t5.32 =\tBCE 5.32143 \tLL 0.00131 \tTotal 369.67/44.06/295.49 \n","04/19/2023 03:28:22 PM - INFO - [41:13] loss\t5.28 =\tBCE 5.28477 \tLL 0.00123 \tTotal 278.80/32.59/147.76 \n","04/19/2023 03:28:23 PM - INFO - [41:14] loss\t5.50 =\tBCE 5.49805 \tLL 0.00140 \tTotal 264.25/27.34/163.05 \n","04/19/2023 03:28:24 PM - INFO - [41:15] loss\t5.22 =\tBCE 5.21631 \tLL 0.00125 \tTotal 366.22/50.34/255.64 \n","04/19/2023 03:28:24 PM - INFO - [41:16] loss\t5.37 =\tBCE 5.37473 \tLL 0.00131 \tTotal 597.60/77.40/464.81 \n","04/19/2023 03:28:25 PM - INFO - [41:17] loss\t5.24 =\tBCE 5.24054 \tLL 0.00128 \tTotal 637.60/115.81/479.53 \n","04/19/2023 03:28:25 PM - INFO - [41:18] loss\t5.18 =\tBCE 5.17530 \tLL 0.00127 \tTotal 382.14/72.83/198.76 \n","04/19/2023 03:28:26 PM - INFO - [41:19] loss\t5.14 =\tBCE 5.14390 \tLL 0.00118 \tTotal 299.53/47.92/175.30 \n","04/19/2023 03:28:26 PM - INFO - Training epoch 42.\n","04/19/2023 03:28:26 PM - INFO - [42:0] loss\t5.13 =\tBCE 5.13164 \tLL 0.00121 \tTotal 329.90/65.86/172.03 \n","04/19/2023 03:28:27 PM - INFO - [42:1] loss\t5.22 =\tBCE 5.22122 \tLL 0.00133 \tTotal 311.17/46.62/199.03 \n","04/19/2023 03:28:27 PM - INFO - [42:2] loss\t5.18 =\tBCE 5.17756 \tLL 0.00129 \tTotal 327.41/46.53/179.85 \n","04/19/2023 03:28:28 PM - INFO - [42:3] loss\t5.01 =\tBCE 5.00824 \tLL 0.00127 \tTotal 238.93/37.66/167.47 \n","04/19/2023 03:28:28 PM - INFO - [42:4] loss\t5.20 =\tBCE 5.19845 \tLL 0.00132 \tTotal 354.17/37.52/161.55 \n","04/19/2023 03:28:29 PM - INFO - [42:5] loss\t5.01 =\tBCE 5.01010 \tLL 0.00120 \tTotal 270.32/51.26/202.91 \n","04/19/2023 03:28:30 PM - INFO - [42:6] loss\t5.28 =\tBCE 5.28081 \tLL 0.00134 \tTotal 470.65/59.28/268.29 \n","04/19/2023 03:28:30 PM - INFO - [42:7] loss\t4.94 =\tBCE 4.93705 \tLL 0.00114 \tTotal 407.45/87.27/308.93 \n","04/19/2023 03:28:31 PM - INFO - [42:8] loss\t5.16 =\tBCE 5.16256 \tLL 0.00126 \tTotal 467.43/68.04/341.77 \n","04/19/2023 03:28:31 PM - INFO - [42:9] loss\t4.92 =\tBCE 4.92077 \tLL 0.00119 \tTotal 348.05/43.65/206.91 \n","04/19/2023 03:28:32 PM - INFO - [42:10] loss\t5.08 =\tBCE 5.07715 \tLL 0.00127 \tTotal 324.11/46.53/195.44 \n","04/19/2023 03:28:32 PM - INFO - [42:11] loss\t5.10 =\tBCE 5.10496 \tLL 0.00137 \tTotal 497.46/73.98/315.64 \n","04/19/2023 03:28:33 PM - INFO - [42:12] loss\t5.03 =\tBCE 5.02861 \tLL 0.00131 \tTotal 504.12/68.61/313.35 \n","04/19/2023 03:28:33 PM - INFO - [42:13] loss\t4.95 =\tBCE 4.94837 \tLL 0.00124 \tTotal 417.53/84.78/269.40 \n","04/19/2023 03:28:34 PM - INFO - [42:14] loss\t5.14 =\tBCE 5.13596 \tLL 0.00129 \tTotal 223.49/25.38/144.39 \n","04/19/2023 03:28:34 PM - INFO - [42:15] loss\t4.88 =\tBCE 4.87921 \tLL 0.00123 \tTotal 422.17/87.08/289.60 \n","04/19/2023 03:28:35 PM - INFO - [42:16] loss\t4.90 =\tBCE 4.90450 \tLL 0.00127 \tTotal 575.06/100.56/405.48 \n","04/19/2023 03:28:36 PM - INFO - [42:17] loss\t4.95 =\tBCE 4.95419 \tLL 0.00128 \tTotal 438.00/64.27/328.90 \n","04/19/2023 03:28:36 PM - INFO - [42:18] loss\t4.98 =\tBCE 4.97596 \tLL 0.00125 \tTotal 330.86/78.24/243.14 \n","04/19/2023 03:28:37 PM - INFO - [42:19] loss\t5.12 =\tBCE 5.11812 \tLL 0.00120 \tTotal 1092.86/159.38/868.96 \n","04/19/2023 03:28:37 PM - INFO - Training epoch 43.\n","04/19/2023 03:28:37 PM - INFO - [43:0] loss\t5.89 =\tBCE 5.88522 \tLL 0.00131 \tTotal 1925.98/275.52/1532.10 \n","04/19/2023 03:28:38 PM - INFO - [43:1] loss\t6.56 =\tBCE 6.56296 \tLL 0.00133 \tTotal 2460.47/361.08/1932.90 \n","04/19/2023 03:28:38 PM - INFO - [43:2] loss\t6.54 =\tBCE 6.53550 \tLL 0.00137 \tTotal 2492.70/385.70/1934.92 \n","04/19/2023 03:28:39 PM - INFO - [43:3] loss\t6.05 =\tBCE 6.05375 \tLL 0.00129 \tTotal 1957.00/310.48/1509.37 \n","04/19/2023 03:28:40 PM - INFO - [43:4] loss\t5.24 =\tBCE 5.24119 \tLL 0.00133 \tTotal 929.10/129.12/717.61 \n","04/19/2023 03:28:40 PM - INFO - [43:5] loss\t5.07 =\tBCE 5.07163 \tLL 0.00132 \tTotal 545.51/79.55/403.87 \n","04/19/2023 03:28:41 PM - INFO - [43:6] loss\t5.24 =\tBCE 5.23566 \tLL 0.00126 \tTotal 1229.04/197.27/952.01 \n","04/19/2023 03:28:41 PM - INFO - [43:7] loss\t5.82 =\tBCE 5.81658 \tLL 0.00127 \tTotal 1755.61/256.32/1362.84 \n","04/19/2023 03:28:42 PM - INFO - [43:8] loss\t5.57 =\tBCE 5.56631 \tLL 0.00134 \tTotal 1494.82/216.35/1155.89 \n","04/19/2023 03:28:42 PM - INFO - [43:9] loss\t4.76 =\tBCE 4.75902 \tLL 0.00131 \tTotal 474.55/73.61/274.99 \n","04/19/2023 03:28:43 PM - INFO - [43:10] loss\t5.22 =\tBCE 5.22437 \tLL 0.00134 \tTotal 1230.86/164.87/958.14 \n","04/19/2023 03:28:43 PM - INFO - [43:11] loss\t6.12 =\tBCE 6.11889 \tLL 0.00130 \tTotal 2190.20/342.56/1683.28 \n","04/19/2023 03:28:44 PM - INFO - [43:12] loss\t7.39 =\tBCE 7.39081 \tLL 0.00141 \tTotal 2906.16/452.04/2295.13 \n","04/19/2023 03:28:44 PM - INFO - [43:13] loss\t7.80 =\tBCE 7.80066 \tLL 0.00144 \tTotal 3221.34/493.29/2589.69 \n","04/19/2023 03:28:45 PM - INFO - [43:14] loss\t7.53 =\tBCE 7.52828 \tLL 0.00131 \tTotal 3204.24/468.97/2485.29 \n","04/19/2023 03:28:45 PM - INFO - [43:15] loss\t7.18 =\tBCE 7.17530 \tLL 0.00139 \tTotal 2867.09/412.17/2248.51 \n","04/19/2023 03:28:46 PM - INFO - [43:16] loss\t6.03 =\tBCE 6.03302 \tLL 0.00143 \tTotal 1908.90/289.09/1493.02 \n","04/19/2023 03:28:47 PM - INFO - [43:17] loss\t4.99 =\tBCE 4.98599 \tLL 0.00125 \tTotal 552.39/110.06/356.62 \n","04/19/2023 03:28:47 PM - INFO - [43:18] loss\t5.20 =\tBCE 5.20312 \tLL 0.00133 \tTotal 1193.06/166.80/863.61 \n","04/19/2023 03:28:48 PM - INFO - [43:19] loss\t6.00 =\tBCE 5.99936 \tLL 0.00126 \tTotal 1966.14/315.12/1546.24 \n","04/19/2023 03:28:48 PM - INFO - Training epoch 44.\n","04/19/2023 03:28:48 PM - INFO - [44:0] loss\t6.48 =\tBCE 6.47652 \tLL 0.00156 \tTotal 2198.19/329.64/1737.13 \n","04/19/2023 03:28:49 PM - INFO - [44:1] loss\t5.76 =\tBCE 5.75577 \tLL 0.00130 \tTotal 1882.26/290.08/1448.47 \n","04/19/2023 03:28:49 PM - INFO - [44:2] loss\t5.86 =\tBCE 5.85804 \tLL 0.00149 \tTotal 1632.63/234.17/1095.85 \n","04/19/2023 03:28:50 PM - INFO - [44:3] loss\t4.84 =\tBCE 4.83514 \tLL 0.00120 \tTotal 942.89/132.01/761.92 \n","04/19/2023 03:28:50 PM - INFO - [44:4] loss\t5.01 =\tBCE 5.00701 \tLL 0.00136 \tTotal 681.38/78.00/240.35 \n","04/19/2023 03:28:51 PM - INFO - [44:5] loss\t4.97 =\tBCE 4.96989 \tLL 0.00130 \tTotal 653.57/85.57/456.24 \n","04/19/2023 03:28:52 PM - INFO - [44:6] loss\t5.33 =\tBCE 5.32645 \tLL 0.00128 \tTotal 1371.48/192.13/1038.41 \n","04/19/2023 03:28:52 PM - INFO - [44:7] loss\t5.75 =\tBCE 5.75047 \tLL 0.00140 \tTotal 1731.46/267.85/1340.14 \n","04/19/2023 03:28:53 PM - INFO - [44:8] loss\t5.52 =\tBCE 5.52191 \tLL 0.00140 \tTotal 1302.32/229.38/937.92 \n","04/19/2023 03:28:53 PM - INFO - [44:9] loss\t5.01 =\tBCE 5.00556 \tLL 0.00131 \tTotal 685.33/84.91/354.65 \n","04/19/2023 03:28:54 PM - INFO - [44:10] loss\t4.74 =\tBCE 4.74279 \tLL 0.00125 \tTotal 581.84/120.47/371.06 \n","04/19/2023 03:28:54 PM - INFO - [44:11] loss\t5.01 =\tBCE 5.01034 \tLL 0.00120 \tTotal 1062.14/153.19/711.72 \n","04/19/2023 03:28:55 PM - INFO - [44:12] loss\t4.99 =\tBCE 4.98711 \tLL 0.00130 \tTotal 1010.43/148.22/760.03 \n","04/19/2023 03:28:55 PM - INFO - [44:13] loss\t4.50 =\tBCE 4.49832 \tLL 0.00115 \tTotal 788.85/92.02/575.34 \n","04/19/2023 03:28:56 PM - INFO - [44:14] loss\t4.62 =\tBCE 4.61747 \tLL 0.00123 \tTotal 381.97/98.84/208.75 \n","04/19/2023 03:28:56 PM - INFO - [44:15] loss\t4.66 =\tBCE 4.66177 \tLL 0.00122 \tTotal 760.23/101.59/580.99 \n","04/19/2023 03:28:57 PM - INFO - [44:16] loss\t4.66 =\tBCE 4.66167 \tLL 0.00120 \tTotal 906.66/158.41/696.77 \n","04/19/2023 03:28:57 PM - INFO - [44:17] loss\t4.74 =\tBCE 4.74455 \tLL 0.00123 \tTotal 995.32/189.91/762.92 \n","04/19/2023 03:28:58 PM - INFO - [44:18] loss\t4.77 =\tBCE 4.77155 \tLL 0.00121 \tTotal 916.69/170.16/619.42 \n","04/19/2023 03:28:59 PM - INFO - [44:19] loss\t4.68 =\tBCE 4.68373 \tLL 0.00124 \tTotal 670.24/96.39/469.30 \n","04/19/2023 03:28:59 PM - INFO - Training epoch 45.\n","04/19/2023 03:28:59 PM - INFO - [45:0] loss\t4.60 =\tBCE 4.60295 \tLL 0.00120 \tTotal 626.31/124.75/408.61 \n","04/19/2023 03:29:00 PM - INFO - [45:1] loss\t4.27 =\tBCE 4.27286 \tLL 0.00122 \tTotal 423.16/65.47/285.09 \n","04/19/2023 03:29:00 PM - INFO - [45:2] loss\t4.58 =\tBCE 4.57943 \tLL 0.00120 \tTotal 485.53/112.61/309.55 \n","04/19/2023 03:29:01 PM - INFO - [45:3] loss\t4.69 =\tBCE 4.69115 \tLL 0.00127 \tTotal 633.08/103.74/446.91 \n","04/19/2023 03:29:01 PM - INFO - [45:4] loss\t4.48 =\tBCE 4.47575 \tLL 0.00118 \tTotal 340.17/99.06/186.69 \n","04/19/2023 03:29:02 PM - INFO - [45:5] loss\t4.65 =\tBCE 4.65436 \tLL 0.00120 \tTotal 653.91/121.03/438.03 \n","04/19/2023 03:29:02 PM - INFO - [45:6] loss\t4.45 =\tBCE 4.45449 \tLL 0.00113 \tTotal 733.76/141.25/551.17 \n","04/19/2023 03:29:03 PM - INFO - [45:7] loss\t4.62 =\tBCE 4.62021 \tLL 0.00122 \tTotal 899.34/145.81/622.90 \n","04/19/2023 03:29:03 PM - INFO - [45:8] loss\t4.62 =\tBCE 4.62279 \tLL 0.00125 \tTotal 941.91/128.12/721.70 \n","04/19/2023 03:29:04 PM - INFO - [45:9] loss\t4.43 =\tBCE 4.42955 \tLL 0.00119 \tTotal 635.79/138.43/460.04 \n","04/19/2023 03:29:04 PM - INFO - [45:10] loss\t4.14 =\tBCE 4.14099 \tLL 0.00110 \tTotal 403.60/76.70/303.95 \n","04/19/2023 03:29:05 PM - INFO - [45:11] loss\t4.24 =\tBCE 4.23901 \tLL 0.00114 \tTotal 474.70/88.69/209.70 \n","04/19/2023 03:29:06 PM - INFO - [45:12] loss\t4.29 =\tBCE 4.29294 \tLL 0.00111 \tTotal 752.65/145.03/589.41 \n","04/19/2023 03:29:06 PM - INFO - [45:13] loss\t4.56 =\tBCE 4.55965 \tLL 0.00120 \tTotal 891.65/145.64/658.96 \n","04/19/2023 03:29:07 PM - INFO - [45:14] loss\t4.27 =\tBCE 4.27197 \tLL 0.00116 \tTotal 571.89/105.11/413.97 \n","04/19/2023 03:29:07 PM - INFO - [45:15] loss\t4.55 =\tBCE 4.54840 \tLL 0.00130 \tTotal 547.50/82.75/302.87 \n","04/19/2023 03:29:08 PM - INFO - [45:16] loss\t4.24 =\tBCE 4.24030 \tLL 0.00121 \tTotal 483.74/66.26/349.27 \n","04/19/2023 03:29:08 PM - INFO - [45:17] loss\t4.19 =\tBCE 4.19491 \tLL 0.00114 \tTotal 704.40/87.73/523.30 \n","04/19/2023 03:29:09 PM - INFO - [45:18] loss\t4.24 =\tBCE 4.24438 \tLL 0.00115 \tTotal 708.26/95.77/468.64 \n","04/19/2023 03:29:09 PM - INFO - [45:19] loss\t4.36 =\tBCE 4.36201 \tLL 0.00117 \tTotal 693.33/102.39/528.91 \n","04/19/2023 03:29:09 PM - INFO - Training epoch 46.\n","04/19/2023 03:29:10 PM - INFO - [46:0] loss\t4.34 =\tBCE 4.34396 \tLL 0.00117 \tTotal 786.25/135.88/594.62 \n","04/19/2023 03:29:10 PM - INFO - [46:1] loss\t4.01 =\tBCE 4.01421 \tLL 0.00104 \tTotal 576.03/116.61/425.23 \n","04/19/2023 03:29:11 PM - INFO - [46:2] loss\t3.96 =\tBCE 3.95814 \tLL 0.00117 \tTotal 280.57/44.21/149.82 \n","04/19/2023 03:29:12 PM - INFO - [46:3] loss\t4.05 =\tBCE 4.04546 \tLL 0.00112 \tTotal 408.28/69.69/246.66 \n","04/19/2023 03:29:12 PM - INFO - [46:4] loss\t4.32 =\tBCE 4.32350 \tLL 0.00122 \tTotal 463.43/91.69/330.08 \n","04/19/2023 03:29:13 PM - INFO - [46:5] loss\t4.00 =\tBCE 4.00409 \tLL 0.00110 \tTotal 304.30/54.32/125.60 \n","04/19/2023 03:29:13 PM - INFO - [46:6] loss\t4.11 =\tBCE 4.10829 \tLL 0.00112 \tTotal 396.70/58.47/281.74 \n","04/19/2023 03:29:14 PM - INFO - [46:7] loss\t4.24 =\tBCE 4.24238 \tLL 0.00114 \tTotal 741.38/121.60/556.75 \n","04/19/2023 03:29:14 PM - INFO - [46:8] loss\t4.08 =\tBCE 4.08193 \tLL 0.00111 \tTotal 942.36/139.99/735.00 \n","04/19/2023 03:29:15 PM - INFO - [46:9] loss\t4.17 =\tBCE 4.16774 \tLL 0.00107 \tTotal 906.22/145.61/688.98 \n","04/19/2023 03:29:15 PM - INFO - [46:10] loss\t4.19 =\tBCE 4.18698 \tLL 0.00117 \tTotal 690.78/110.65/532.31 \n","04/19/2023 03:29:16 PM - INFO - [46:11] loss\t4.07 =\tBCE 4.06677 \tLL 0.00114 \tTotal 438.05/71.14/283.99 \n","04/19/2023 03:29:16 PM - INFO - [46:12] loss\t3.92 =\tBCE 3.91709 \tLL 0.00118 \tTotal 263.43/42.77/154.43 \n","04/19/2023 03:29:17 PM - INFO - [46:13] loss\t4.03 =\tBCE 4.02753 \tLL 0.00115 \tTotal 324.38/45.49/186.45 \n","04/19/2023 03:29:17 PM - INFO - [46:14] loss\t3.98 =\tBCE 3.98156 \tLL 0.00114 \tTotal 466.71/60.93/342.20 \n","04/19/2023 03:29:18 PM - INFO - [46:15] loss\t3.92 =\tBCE 3.91665 \tLL 0.00110 \tTotal 608.38/87.10/461.09 \n","04/19/2023 03:29:19 PM - INFO - [46:16] loss\t4.12 =\tBCE 4.12027 \tLL 0.00120 \tTotal 667.76/107.23/496.45 \n","04/19/2023 03:29:19 PM - INFO - [46:17] loss\t4.07 =\tBCE 4.07041 \tLL 0.00113 \tTotal 567.29/110.79/416.38 \n","04/19/2023 03:29:20 PM - INFO - [46:18] loss\t3.91 =\tBCE 3.90526 \tLL 0.00112 \tTotal 285.91/51.94/183.04 \n","04/19/2023 03:29:20 PM - INFO - [46:19] loss\t3.85 =\tBCE 3.84517 \tLL 0.00113 \tTotal 500.28/74.60/380.66 \n","04/19/2023 03:29:20 PM - INFO - Training epoch 47.\n","04/19/2023 03:29:21 PM - INFO - [47:0] loss\t4.29 =\tBCE 4.29315 \tLL 0.00122 \tTotal 702.70/139.57/469.26 \n","04/19/2023 03:29:21 PM - INFO - [47:1] loss\t3.87 =\tBCE 3.86573 \tLL 0.00114 \tTotal 672.31/95.23/465.65 \n","04/19/2023 03:29:22 PM - INFO - [47:2] loss\t3.90 =\tBCE 3.89613 \tLL 0.00111 \tTotal 634.01/92.56/505.58 \n","04/19/2023 03:29:22 PM - INFO - [47:3] loss\t4.06 =\tBCE 4.06105 \tLL 0.00115 \tTotal 697.24/90.27/498.80 \n","04/19/2023 03:29:23 PM - INFO - [47:4] loss\t3.85 =\tBCE 3.85135 \tLL 0.00113 \tTotal 497.56/67.62/401.89 \n","04/19/2023 03:29:23 PM - INFO - [47:5] loss\t3.95 =\tBCE 3.95217 \tLL 0.00113 \tTotal 454.06/89.77/286.85 \n","04/19/2023 03:29:24 PM - INFO - [47:6] loss\t3.71 =\tBCE 3.70629 \tLL 0.00111 \tTotal 369.36/67.24/232.92 \n","04/19/2023 03:29:24 PM - INFO - [47:7] loss\t4.01 =\tBCE 4.01163 \tLL 0.00117 \tTotal 710.55/120.74/519.31 \n","04/19/2023 03:29:25 PM - INFO - [47:8] loss\t4.28 =\tBCE 4.27935 \tLL 0.00112 \tTotal 1072.62/194.62/857.23 \n","04/19/2023 03:29:26 PM - INFO - [47:9] loss\t4.27 =\tBCE 4.27466 \tLL 0.00119 \tTotal 1038.73/226.70/779.04 \n","04/19/2023 03:29:26 PM - INFO - [47:10] loss\t4.18 =\tBCE 4.17917 \tLL 0.00110 \tTotal 1226.68/211.54/971.76 \n","04/19/2023 03:29:27 PM - INFO - [47:11] loss\t4.41 =\tBCE 4.41481 \tLL 0.00123 \tTotal 1437.45/179.46/1188.15 \n","04/19/2023 03:29:27 PM - INFO - [47:12] loss\t4.76 =\tBCE 4.76083 \tLL 0.00123 \tTotal 1649.51/253.68/1294.19 \n","04/19/2023 03:29:28 PM - INFO - [47:13] loss\t5.11 =\tBCE 5.11185 \tLL 0.00130 \tTotal 2032.87/314.82/1573.40 \n","04/19/2023 03:29:28 PM - INFO - [47:14] loss\t5.34 =\tBCE 5.33840 \tLL 0.00124 \tTotal 2336.90/358.41/1786.92 \n","04/19/2023 03:29:29 PM - INFO - [47:15] loss\t6.13 =\tBCE 6.13146 \tLL 0.00135 \tTotal 2821.95/486.38/2259.88 \n","04/19/2023 03:29:29 PM - INFO - [47:16] loss\t8.50 =\tBCE 8.50000 \tLL 0.00141 \tTotal 4103.52/688.59/3260.37 \n","04/19/2023 03:29:30 PM - INFO - [47:17] loss\t17.31 =\tBCE 17.31313 \tLL 0.00188 \tTotal 8147.63/1227.28/6324.07 \n","04/19/2023 03:29:30 PM - INFO - [47:18] loss\t113.60 =\tBCE 113.60249 \tLL 0.00627 \tTotal 24302.81/3112.61/19106.04 \n","04/19/2023 03:29:31 PM - INFO - [47:19] loss\t2058.51 =\tBCE 2058.50830 \tLL 0.05813 \tTotal 54571.42/7003.33/42366.58 \n","04/19/2023 03:29:31 PM - INFO - Training epoch 48.\n","04/19/2023 03:29:32 PM - INFO - [48:0] loss\t5108.68 =\tBCE 5108.67725 \tLL 0.11347 \tTotal 54732.56/6087.19/42173.95 \n","04/19/2023 03:29:32 PM - INFO - [48:1] loss\t1690.75 =\tBCE 1690.74890 \tLL 0.09899 \tTotal 15453.15/7904.07/8882.98 \n","04/19/2023 03:29:33 PM - INFO - [48:2] loss\t2175.54 =\tBCE 2175.54028 \tLL 0.15975 \tTotal 48142.38/7668.62/36363.97 \n","04/19/2023 03:29:33 PM - INFO - [48:3] loss\t625.21 =\tBCE 625.21448 \tLL 0.16649 \tTotal 18940.67/5764.41/10103.66 \n","04/19/2023 03:29:34 PM - INFO - [48:4] loss\t1273.15 =\tBCE 1273.14600 \tLL 0.12902 \tTotal 29713.88/4004.73/21935.13 \n","04/19/2023 03:29:34 PM - INFO - [48:5] loss\t717.91 =\tBCE 717.91394 \tLL 0.10982 \tTotal 9295.73/5535.88/3837.90 \n","04/19/2023 03:29:35 PM - INFO - [48:6] loss\t350.14 =\tBCE 350.14337 \tLL 0.09409 \tTotal 11986.92/2615.58/8262.01 \n","04/19/2023 03:29:36 PM - INFO - [48:7] loss\t284.47 =\tBCE 284.46890 \tLL 0.07194 \tTotal 11060.65/1231.98/8032.45 \n","04/19/2023 03:29:36 PM - INFO - [48:8] loss\t317.93 =\tBCE 317.93207 \tLL 0.05131 \tTotal 7407.23/2178.77/4771.48 \n","04/19/2023 03:29:37 PM - INFO - [48:9] loss\t272.05 =\tBCE 272.04855 \tLL 0.03521 \tTotal 5008.62/1991.55/2828.09 \n","04/19/2023 03:29:37 PM - INFO - [48:10] loss\t203.48 =\tBCE 203.48337 \tLL 0.02487 \tTotal 5305.67/1207.56/3383.06 \n","04/19/2023 03:29:38 PM - INFO - [48:11] loss\t134.97 =\tBCE 134.97414 \tLL 0.01592 \tTotal 3644.37/397.43/2436.68 \n","04/19/2023 03:29:38 PM - INFO - [48:12] loss\t168.24 =\tBCE 168.23817 \tLL 0.01062 \tTotal 3123.79/625.35/2057.59 \n","04/19/2023 03:29:39 PM - INFO - [48:13] loss\t196.59 =\tBCE 196.58954 \tLL 0.00703 \tTotal 2066.01/999.83/1156.57 \n","04/19/2023 03:29:39 PM - INFO - [48:14] loss\t208.21 =\tBCE 208.20538 \tLL 0.00525 \tTotal 1772.97/1036.52/858.46 \n","04/19/2023 03:29:40 PM - INFO - [48:15] loss\t200.91 =\tBCE 200.90619 \tLL 0.00504 \tTotal 1711.01/846.10/890.35 \n","04/19/2023 03:29:40 PM - INFO - [48:16] loss\t196.05 =\tBCE 196.04982 \tLL 0.00534 \tTotal 1605.62/579.18/864.48 \n","04/19/2023 03:29:41 PM - INFO - [48:17] loss\t180.15 =\tBCE 180.14552 \tLL 0.00653 \tTotal 1280.68/341.24/669.22 \n","04/19/2023 03:29:42 PM - INFO - [48:18] loss\t171.80 =\tBCE 171.80362 \tLL 0.00785 \tTotal 1133.85/247.26/600.44 \n","04/19/2023 03:29:42 PM - INFO - [48:19] loss\t171.24 =\tBCE 171.24097 \tLL 0.00950 \tTotal 921.77/341.35/391.65 \n","Not implemented\n","04/19/2023 03:29:42 PM - INFO - Training epoch 49.\n","04/19/2023 03:29:43 PM - INFO - [49:0] loss\t179.74 =\tBCE 179.74178 \tLL 0.01053 \tTotal 976.04/441.52/448.26 \n","04/19/2023 03:29:43 PM - INFO - [49:1] loss\t186.70 =\tBCE 186.69943 \tLL 0.01252 \tTotal 1200.16/526.17/659.56 \n","04/19/2023 03:29:44 PM - INFO - [49:2] loss\t186.48 =\tBCE 186.48195 \tLL 0.01321 \tTotal 1212.01/544.50/694.26 \n","04/19/2023 03:29:44 PM - INFO - [49:3] loss\t178.50 =\tBCE 178.50029 \tLL 0.01428 \tTotal 1422.27/550.49/883.71 \n","04/19/2023 03:29:45 PM - INFO - [49:4] loss\t174.08 =\tBCE 174.07861 \tLL 0.01593 \tTotal 1172.28/464.80/684.23 \n","04/19/2023 03:29:45 PM - INFO - [49:5] loss\t158.13 =\tBCE 158.13358 \tLL 0.01602 \tTotal 1038.13/387.31/588.13 \n","04/19/2023 03:29:46 PM - INFO - [49:6] loss\t144.72 =\tBCE 144.71533 \tLL 0.01688 \tTotal 720.84/296.66/353.52 \n","04/19/2023 03:29:46 PM - INFO - [49:7] loss\t144.27 =\tBCE 144.27113 \tLL 0.01767 \tTotal 672.94/216.17/340.91 \n","04/19/2023 03:29:47 PM - INFO - [49:8] loss\t137.74 =\tBCE 137.74451 \tLL 0.01717 \tTotal 826.92/178.83/502.98 \n","04/19/2023 03:29:48 PM - INFO - [49:9] loss\t133.89 =\tBCE 133.88826 \tLL 0.01727 \tTotal 753.72/208.38/448.85 \n","04/19/2023 03:29:48 PM - INFO - [49:10] loss\t134.45 =\tBCE 134.44547 \tLL 0.01787 \tTotal 1064.18/252.02/726.50 \n","04/19/2023 03:29:49 PM - INFO - [49:11] loss\t121.74 =\tBCE 121.74340 \tLL 0.01637 \tTotal 839.49/275.77/472.52 \n","04/19/2023 03:29:49 PM - INFO - [49:12] loss\t116.68 =\tBCE 116.68015 \tLL 0.01585 \tTotal 1053.03/250.58/742.47 \n","04/19/2023 03:29:50 PM - INFO - [49:13] loss\t106.96 =\tBCE 106.96306 \tLL 0.01479 \tTotal 935.11/196.67/720.16 \n","04/19/2023 03:29:50 PM - INFO - [49:14] loss\t102.78 =\tBCE 102.78320 \tLL 0.01419 \tTotal 1005.91/169.39/687.54 \n","04/19/2023 03:29:51 PM - INFO - [49:15] loss\t101.20 =\tBCE 101.19788 \tLL 0.01304 \tTotal 926.89/139.96/614.16 \n","04/19/2023 03:29:51 PM - INFO - [49:16] loss\t94.86 =\tBCE 94.85691 \tLL 0.01060 \tTotal 757.96/130.24/453.67 \n","04/19/2023 03:29:52 PM - INFO - [49:17] loss\t87.44 =\tBCE 87.43870 \tLL 0.00937 \tTotal 831.66/153.16/499.57 \n","04/19/2023 03:29:52 PM - INFO - [49:18] loss\t84.60 =\tBCE 84.59908 \tLL 0.00775 \tTotal 1102.48/174.64/786.11 \n","04/19/2023 03:29:53 PM - INFO - [49:19] loss\t80.01 =\tBCE 80.01408 \tLL 0.00694 \tTotal 997.19/156.35/678.33 \n","04/19/2023 03:29:53 PM - INFO - EVALUATION prior to epoch [50]...\n","04/19/2023 03:29:53 PM - INFO - [50] loss\t74.16=\tBCE 74.16 \tLL 0.00574 \n","04/19/2023 03:29:54 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/50_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:29:59 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/50_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:30:05 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/50_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/19/2023 03:30:06 PM - INFO - Training epoch 50.\n","04/19/2023 03:30:06 PM - INFO - [50:0] loss\t71.87 =\tBCE 71.86958 \tLL 0.00578 \tTotal 830.41/100.01/410.60 \n","04/19/2023 03:30:07 PM - INFO - [50:1] loss\t71.01 =\tBCE 71.00939 \tLL 0.00505 \tTotal 674.34/98.38/393.43 \n","04/19/2023 03:30:07 PM - INFO - [50:2] loss\t66.39 =\tBCE 66.38985 \tLL 0.00426 \tTotal 1142.48/134.69/824.95 \n","04/19/2023 03:30:08 PM - INFO - [50:3] loss\t67.35 =\tBCE 67.34621 \tLL 0.00393 \tTotal 1126.83/122.53/841.15 \n","04/19/2023 03:30:09 PM - INFO - [50:4] loss\t59.36 =\tBCE 59.35659 \tLL 0.00342 \tTotal 603.80/100.30/377.53 \n","04/19/2023 03:30:09 PM - INFO - [50:5] loss\t56.73 =\tBCE 56.72770 \tLL 0.00309 \tTotal 678.94/99.51/384.25 \n","04/19/2023 03:30:10 PM - INFO - [50:6] loss\t56.44 =\tBCE 56.44032 \tLL 0.00295 \tTotal 906.99/113.90/580.36 \n","04/19/2023 03:30:10 PM - INFO - [50:7] loss\t51.12 =\tBCE 51.11736 \tLL 0.00252 \tTotal 1259.67/110.66/980.48 \n","04/19/2023 03:30:11 PM - INFO - [50:8] loss\t47.81 =\tBCE 47.81015 \tLL 0.00242 \tTotal 395.37/113.58/208.23 \n","04/19/2023 03:30:11 PM - INFO - [50:9] loss\t46.87 =\tBCE 46.86666 \tLL 0.00228 \tTotal 668.15/148.65/362.54 \n","04/19/2023 03:30:12 PM - INFO - [50:10] loss\t47.25 =\tBCE 47.25187 \tLL 0.00227 \tTotal 883.08/151.29/610.09 \n","04/19/2023 03:30:12 PM - INFO - [50:11] loss\t40.36 =\tBCE 40.36245 \tLL 0.00191 \tTotal 583.83/86.57/359.79 \n","04/19/2023 03:30:13 PM - INFO - [50:12] loss\t40.84 =\tBCE 40.83583 \tLL 0.00195 \tTotal 472.02/77.57/236.89 \n","04/19/2023 03:30:13 PM - INFO - [50:13] loss\t37.90 =\tBCE 37.89983 \tLL 0.00181 \tTotal 821.73/131.68/551.35 \n","04/19/2023 03:30:14 PM - INFO - [50:14] loss\t38.25 =\tBCE 38.24506 \tLL 0.00192 \tTotal 665.81/106.11/443.51 \n","04/19/2023 03:30:14 PM - INFO - [50:15] loss\t36.92 =\tBCE 36.92112 \tLL 0.00212 \tTotal 510.35/75.43/350.12 \n","04/19/2023 03:30:15 PM - INFO - [50:16] loss\t34.47 =\tBCE 34.46901 \tLL 0.00211 \tTotal 583.20/52.68/384.81 \n","04/19/2023 03:30:16 PM - INFO - [50:17] loss\t34.33 =\tBCE 34.33084 \tLL 0.00209 \tTotal 1087.51/69.39/875.52 \n","04/19/2023 03:30:16 PM - INFO - [50:18] loss\t31.88 =\tBCE 31.87506 \tLL 0.00196 \tTotal 560.60/91.73/368.39 \n","04/19/2023 03:30:17 PM - INFO - [50:19] loss\t31.51 =\tBCE 31.50768 \tLL 0.00198 \tTotal 673.87/75.03/471.68 \n","04/19/2023 03:30:17 PM - INFO - Training epoch 51.\n","04/19/2023 03:30:17 PM - INFO - [51:0] loss\t30.91 =\tBCE 30.90718 \tLL 0.00205 \tTotal 970.88/74.58/724.67 \n","04/19/2023 03:30:18 PM - INFO - [51:1] loss\t28.79 =\tBCE 28.79393 \tLL 0.00207 \tTotal 466.77/50.78/336.70 \n","04/19/2023 03:30:18 PM - INFO - [51:2] loss\t27.69 =\tBCE 27.68880 \tLL 0.00197 \tTotal 423.11/65.27/287.55 \n","04/19/2023 03:30:19 PM - INFO - [51:3] loss\t27.02 =\tBCE 27.02042 \tLL 0.00198 \tTotal 669.87/80.51/490.32 \n","04/19/2023 03:30:19 PM - INFO - [51:4] loss\t26.34 =\tBCE 26.34422 \tLL 0.00192 \tTotal 446.25/57.15/290.03 \n","04/19/2023 03:30:20 PM - INFO - [51:5] loss\t25.38 =\tBCE 25.38279 \tLL 0.00187 \tTotal 322.18/62.30/219.93 \n","04/19/2023 03:30:20 PM - INFO - [51:6] loss\t24.30 =\tBCE 24.30212 \tLL 0.00173 \tTotal 487.71/72.85/352.19 \n","04/19/2023 03:30:21 PM - INFO - [51:7] loss\t23.56 =\tBCE 23.56188 \tLL 0.00171 \tTotal 349.75/50.66/255.54 \n","04/19/2023 03:30:22 PM - INFO - [51:8] loss\t23.08 =\tBCE 23.07817 \tLL 0.00156 \tTotal 424.72/46.24/312.65 \n","04/19/2023 03:30:22 PM - INFO - [51:9] loss\t22.78 =\tBCE 22.77807 \tLL 0.00156 \tTotal 331.63/51.81/199.76 \n","04/19/2023 03:30:23 PM - INFO - [51:10] loss\t21.98 =\tBCE 21.97844 \tLL 0.00149 \tTotal 363.77/60.35/275.17 \n","04/19/2023 03:30:23 PM - INFO - [51:11] loss\t21.77 =\tBCE 21.76820 \tLL 0.00150 \tTotal 375.15/41.79/279.04 \n","04/19/2023 03:30:24 PM - INFO - [51:12] loss\t20.37 =\tBCE 20.36930 \tLL 0.00136 \tTotal 245.67/56.42/165.93 \n","04/19/2023 03:30:24 PM - INFO - [51:13] loss\t20.38 =\tBCE 20.38300 \tLL 0.00142 \tTotal 250.55/61.72/149.41 \n","04/19/2023 03:30:25 PM - INFO - [51:14] loss\t20.24 =\tBCE 20.23982 \tLL 0.00133 \tTotal 391.34/44.63/272.04 \n","04/19/2023 03:30:25 PM - INFO - [51:15] loss\t19.65 =\tBCE 19.65121 \tLL 0.00136 \tTotal 247.81/35.51/196.73 \n","04/19/2023 03:30:26 PM - INFO - [51:16] loss\t18.85 =\tBCE 18.85318 \tLL 0.00125 \tTotal 215.04/61.95/162.34 \n","04/19/2023 03:30:26 PM - INFO - [51:17] loss\t18.14 =\tBCE 18.14154 \tLL 0.00118 \tTotal 359.34/55.11/268.31 \n","04/19/2023 03:30:27 PM - INFO - [51:18] loss\t17.89 =\tBCE 17.89217 \tLL 0.00118 \tTotal 302.46/46.59/212.04 \n","04/19/2023 03:30:28 PM - INFO - [51:19] loss\t17.59 =\tBCE 17.59168 \tLL 0.00124 \tTotal 245.83/81.98/159.75 \n","04/19/2023 03:30:28 PM - INFO - Training epoch 52.\n","04/19/2023 03:30:28 PM - INFO - [52:0] loss\t17.03 =\tBCE 17.03412 \tLL 0.00122 \tTotal 360.08/76.23/245.71 \n","04/19/2023 03:30:29 PM - INFO - [52:1] loss\t16.76 =\tBCE 16.75819 \tLL 0.00120 \tTotal 225.74/26.22/158.15 \n","04/19/2023 03:30:29 PM - INFO - [52:2] loss\t16.58 =\tBCE 16.57636 \tLL 0.00119 \tTotal 259.27/49.46/173.96 \n","04/19/2023 03:30:30 PM - INFO - [52:3] loss\t16.57 =\tBCE 16.56907 \tLL 0.00120 \tTotal 322.55/60.29/212.71 \n","04/19/2023 03:30:30 PM - INFO - [52:4] loss\t15.86 =\tBCE 15.86476 \tLL 0.00119 \tTotal 247.21/26.85/204.57 \n","04/19/2023 03:30:31 PM - INFO - [52:5] loss\t15.83 =\tBCE 15.83209 \tLL 0.00116 \tTotal 182.59/57.55/108.91 \n","04/19/2023 03:30:31 PM - INFO - [52:6] loss\t15.33 =\tBCE 15.32654 \tLL 0.00115 \tTotal 147.18/52.79/82.97 \n","04/19/2023 03:30:32 PM - INFO - [52:7] loss\t15.16 =\tBCE 15.16251 \tLL 0.00111 \tTotal 172.86/28.88/91.94 \n","04/19/2023 03:30:33 PM - INFO - [52:8] loss\t14.84 =\tBCE 14.84354 \tLL 0.00112 \tTotal 227.28/43.28/156.76 \n","04/19/2023 03:30:33 PM - INFO - [52:9] loss\t14.67 =\tBCE 14.66593 \tLL 0.00108 \tTotal 205.88/44.63/154.95 \n","04/19/2023 03:30:34 PM - INFO - [52:10] loss\t14.40 =\tBCE 14.39701 \tLL 0.00107 \tTotal 289.12/49.38/188.96 \n","04/19/2023 03:30:34 PM - INFO - [52:11] loss\t14.32 =\tBCE 14.32139 \tLL 0.00103 \tTotal 176.44/44.10/82.60 \n","04/19/2023 03:30:35 PM - INFO - [52:12] loss\t14.33 =\tBCE 14.32529 \tLL 0.00103 \tTotal 466.22/67.89/324.58 \n","04/19/2023 03:30:35 PM - INFO - [52:13] loss\t13.72 =\tBCE 13.71573 \tLL 0.00096 \tTotal 174.07/30.15/88.07 \n","04/19/2023 03:30:36 PM - INFO - [52:14] loss\t13.94 =\tBCE 13.94238 \tLL 0.00101 \tTotal 382.65/45.52/299.35 \n","04/19/2023 03:30:36 PM - INFO - [52:15] loss\t13.28 =\tBCE 13.28173 \tLL 0.00093 \tTotal 137.33/34.04/95.15 \n","04/19/2023 03:30:37 PM - INFO - [52:16] loss\t12.87 =\tBCE 12.86852 \tLL 0.00089 \tTotal 146.47/20.28/102.79 \n","04/19/2023 03:30:38 PM - INFO - [52:17] loss\t13.28 =\tBCE 13.27632 \tLL 0.00097 \tTotal 201.94/38.13/124.50 \n","04/19/2023 03:30:38 PM - INFO - [52:18] loss\t13.11 =\tBCE 13.11462 \tLL 0.00099 \tTotal 230.96/46.40/149.43 \n","04/19/2023 03:30:39 PM - INFO - [52:19] loss\t12.64 =\tBCE 12.64062 \tLL 0.00101 \tTotal 147.80/19.73/107.32 \n","04/19/2023 03:30:39 PM - INFO - Training epoch 53.\n","04/19/2023 03:30:39 PM - INFO - [53:0] loss\t12.62 =\tBCE 12.61947 \tLL 0.00097 \tTotal 191.28/37.46/144.78 \n","04/19/2023 03:30:40 PM - INFO - [53:1] loss\t12.28 =\tBCE 12.27643 \tLL 0.00093 \tTotal 308.41/33.81/248.19 \n","04/19/2023 03:30:40 PM - INFO - [53:2] loss\t12.13 =\tBCE 12.13241 \tLL 0.00096 \tTotal 146.35/19.21/108.61 \n","04/19/2023 03:30:41 PM - INFO - [53:3] loss\t12.18 =\tBCE 12.17746 \tLL 0.00096 \tTotal 216.40/35.07/175.68 \n","04/19/2023 03:30:41 PM - INFO - [53:4] loss\t11.83 =\tBCE 11.83342 \tLL 0.00094 \tTotal 142.13/30.81/62.24 \n","04/19/2023 03:30:42 PM - INFO - [53:5] loss\t11.75 =\tBCE 11.75064 \tLL 0.00090 \tTotal 131.44/21.53/94.14 \n","04/19/2023 03:30:42 PM - INFO - [53:6] loss\t11.30 =\tBCE 11.29947 \tLL 0.00086 \tTotal 167.56/23.87/103.45 \n","04/19/2023 03:30:43 PM - INFO - [53:7] loss\t11.50 =\tBCE 11.50213 \tLL 0.00090 \tTotal 217.08/22.24/150.88 \n","04/19/2023 03:30:44 PM - INFO - [53:8] loss\t10.99 =\tBCE 10.98513 \tLL 0.00083 \tTotal 253.85/32.00/193.17 \n","04/19/2023 03:30:44 PM - INFO - [53:9] loss\t11.40 =\tBCE 11.40192 \tLL 0.00098 \tTotal 228.17/30.26/147.54 \n","04/19/2023 03:30:45 PM - INFO - [53:10] loss\t10.93 =\tBCE 10.92597 \tLL 0.00087 \tTotal 235.21/32.30/179.58 \n","04/19/2023 03:30:45 PM - INFO - [53:11] loss\t10.76 =\tBCE 10.75520 \tLL 0.00089 \tTotal 215.46/38.38/140.32 \n","04/19/2023 03:30:46 PM - INFO - [53:12] loss\t10.98 =\tBCE 10.98191 \tLL 0.00087 \tTotal 227.92/32.36/151.00 \n","04/19/2023 03:30:46 PM - INFO - [53:13] loss\t10.54 =\tBCE 10.54321 \tLL 0.00083 \tTotal 196.63/37.04/135.72 \n","04/19/2023 03:30:47 PM - INFO - [53:14] loss\t10.82 =\tBCE 10.81937 \tLL 0.00089 \tTotal 295.57/33.34/230.01 \n","04/19/2023 03:30:47 PM - INFO - [53:15] loss\t10.50 =\tBCE 10.50394 \tLL 0.00082 \tTotal 278.82/62.33/189.05 \n","04/19/2023 03:30:48 PM - INFO - [53:16] loss\t10.27 =\tBCE 10.27049 \tLL 0.00083 \tTotal 124.87/17.61/73.10 \n","04/19/2023 03:30:49 PM - INFO - [53:17] loss\t10.16 =\tBCE 10.16356 \tLL 0.00086 \tTotal 279.88/46.23/196.22 \n","04/19/2023 03:30:49 PM - INFO - [53:18] loss\t10.29 =\tBCE 10.29399 \tLL 0.00086 \tTotal 286.24/34.36/231.02 \n","04/19/2023 03:30:50 PM - INFO - [53:19] loss\t10.19 =\tBCE 10.18654 \tLL 0.00087 \tTotal 160.14/30.38/89.80 \n","04/19/2023 03:30:50 PM - INFO - Training epoch 54.\n","04/19/2023 03:30:50 PM - INFO - [54:0] loss\t10.08 =\tBCE 10.07869 \tLL 0.00085 \tTotal 201.18/35.21/121.53 \n","04/19/2023 03:30:51 PM - INFO - [54:1] loss\t9.43 =\tBCE 9.42981 \tLL 0.00081 \tTotal 190.06/26.23/139.21 \n","04/19/2023 03:30:51 PM - INFO - [54:2] loss\t9.95 =\tBCE 9.94893 \tLL 0.00083 \tTotal 354.47/55.46/262.09 \n","04/19/2023 03:30:52 PM - INFO - [54:3] loss\t9.66 =\tBCE 9.66358 \tLL 0.00085 \tTotal 236.99/46.29/181.90 \n","04/19/2023 03:30:52 PM - INFO - [54:4] loss\t9.67 =\tBCE 9.66895 \tLL 0.00084 \tTotal 309.21/33.05/247.30 \n","04/19/2023 03:30:53 PM - INFO - [54:5] loss\t9.74 =\tBCE 9.73588 \tLL 0.00087 \tTotal 337.82/53.75/238.50 \n","04/19/2023 03:30:53 PM - INFO - [54:6] loss\t9.36 =\tBCE 9.36439 \tLL 0.00082 \tTotal 127.98/18.20/76.96 \n","04/19/2023 03:30:54 PM - INFO - [54:7] loss\t9.34 =\tBCE 9.33989 \tLL 0.00080 \tTotal 123.29/23.49/83.49 \n","04/19/2023 03:30:54 PM - INFO - [54:8] loss\t9.29 =\tBCE 9.28641 \tLL 0.00083 \tTotal 152.42/23.36/103.59 \n","04/19/2023 03:30:55 PM - INFO - [54:9] loss\t9.00 =\tBCE 9.00324 \tLL 0.00080 \tTotal 319.62/50.88/248.14 \n","04/19/2023 03:30:56 PM - INFO - [54:10] loss\t8.97 =\tBCE 8.97303 \tLL 0.00081 \tTotal 179.60/35.59/126.84 \n","04/19/2023 03:30:56 PM - INFO - [54:11] loss\t8.83 =\tBCE 8.82677 \tLL 0.00080 \tTotal 172.51/27.41/99.59 \n","04/19/2023 03:30:57 PM - INFO - [54:12] loss\t9.02 =\tBCE 9.02412 \tLL 0.00078 \tTotal 234.31/38.02/168.84 \n","04/19/2023 03:30:57 PM - INFO - [54:13] loss\t8.50 =\tBCE 8.49953 \tLL 0.00077 \tTotal 154.01/19.47/117.04 \n","04/19/2023 03:30:58 PM - INFO - [54:14] loss\t8.76 =\tBCE 8.75929 \tLL 0.00081 \tTotal 129.85/21.05/59.55 \n","04/19/2023 03:30:58 PM - INFO - [54:15] loss\t8.50 =\tBCE 8.50450 \tLL 0.00083 \tTotal 197.63/23.44/125.89 \n","04/19/2023 03:30:59 PM - INFO - [54:16] loss\t8.59 =\tBCE 8.59361 \tLL 0.00081 \tTotal 204.77/35.46/162.91 \n","04/19/2023 03:30:59 PM - INFO - [54:17] loss\t8.52 =\tBCE 8.52073 \tLL 0.00080 \tTotal 161.51/16.70/79.81 \n","04/19/2023 03:31:00 PM - INFO - [54:18] loss\t8.30 =\tBCE 8.30489 \tLL 0.00079 \tTotal 221.57/21.50/145.86 \n","04/19/2023 03:31:00 PM - INFO - [54:19] loss\t8.51 =\tBCE 8.51021 \tLL 0.00083 \tTotal 162.44/25.60/117.80 \n","04/19/2023 03:31:00 PM - INFO - Training epoch 55.\n","04/19/2023 03:31:01 PM - INFO - [55:0] loss\t8.14 =\tBCE 8.14458 \tLL 0.00077 \tTotal 245.63/30.47/157.40 \n","04/19/2023 03:31:02 PM - INFO - [55:1] loss\t8.34 =\tBCE 8.33788 \tLL 0.00081 \tTotal 257.54/49.14/153.55 \n","04/19/2023 03:31:02 PM - INFO - [55:2] loss\t8.21 =\tBCE 8.21020 \tLL 0.00082 \tTotal 216.95/35.20/162.08 \n","04/19/2023 03:31:03 PM - INFO - [55:3] loss\t8.37 =\tBCE 8.36653 \tLL 0.00081 \tTotal 505.94/95.31/380.12 \n","04/19/2023 03:31:03 PM - INFO - [55:4] loss\t8.14 =\tBCE 8.13834 \tLL 0.00084 \tTotal 443.24/82.14/303.81 \n","04/19/2023 03:31:04 PM - INFO - [55:5] loss\t8.10 =\tBCE 8.09519 \tLL 0.00082 \tTotal 206.88/36.85/169.28 \n","04/19/2023 03:31:04 PM - INFO - [55:6] loss\t8.08 =\tBCE 8.07647 \tLL 0.00084 \tTotal 662.54/110.96/432.79 \n","04/19/2023 03:31:05 PM - INFO - [55:7] loss\t8.27 =\tBCE 8.26957 \tLL 0.00087 \tTotal 474.33/62.21/367.68 \n","04/19/2023 03:31:05 PM - INFO - [55:8] loss\t7.76 =\tBCE 7.76158 \tLL 0.00079 \tTotal 193.65/38.60/125.40 \n","04/19/2023 03:31:06 PM - INFO - [55:9] loss\t7.72 =\tBCE 7.72325 \tLL 0.00080 \tTotal 516.75/66.22/417.62 \n","04/19/2023 03:31:06 PM - INFO - [55:10] loss\t7.74 =\tBCE 7.74224 \tLL 0.00081 \tTotal 187.93/31.80/115.86 \n","04/19/2023 03:31:07 PM - INFO - [55:11] loss\t7.79 =\tBCE 7.78671 \tLL 0.00080 \tTotal 510.60/71.39/383.85 \n","04/19/2023 03:31:07 PM - INFO - [55:12] loss\t7.70 =\tBCE 7.70333 \tLL 0.00081 \tTotal 577.63/80.40/416.64 \n","04/19/2023 03:31:08 PM - INFO - [55:13] loss\t7.38 =\tBCE 7.38206 \tLL 0.00079 \tTotal 150.59/46.84/72.57 \n","04/19/2023 03:31:09 PM - INFO - [55:14] loss\t7.58 =\tBCE 7.57647 \tLL 0.00083 \tTotal 386.28/61.47/262.47 \n","04/19/2023 03:31:09 PM - INFO - [55:15] loss\t7.28 =\tBCE 7.27863 \tLL 0.00081 \tTotal 124.65/59.22/48.37 \n","04/19/2023 03:31:10 PM - INFO - [55:16] loss\t7.31 =\tBCE 7.30617 \tLL 0.00079 \tTotal 378.88/73.46/250.61 \n","04/19/2023 03:31:10 PM - INFO - [55:17] loss\t7.32 =\tBCE 7.32032 \tLL 0.00083 \tTotal 327.92/61.95/239.34 \n","04/19/2023 03:31:11 PM - INFO - [55:18] loss\t7.24 =\tBCE 7.24464 \tLL 0.00082 \tTotal 229.03/48.42/192.03 \n","04/19/2023 03:31:11 PM - INFO - [55:19] loss\t7.45 =\tBCE 7.44938 \tLL 0.00080 \tTotal 505.07/85.90/349.26 \n","04/19/2023 03:31:11 PM - INFO - Training epoch 56.\n","04/19/2023 03:31:12 PM - INFO - [56:0] loss\t7.06 =\tBCE 7.05518 \tLL 0.00079 \tTotal 121.62/22.71/70.67 \n","04/19/2023 03:31:12 PM - INFO - [56:1] loss\t7.38 =\tBCE 7.37881 \tLL 0.00081 \tTotal 550.01/79.06/390.89 \n","04/19/2023 03:31:13 PM - INFO - [56:2] loss\t6.90 =\tBCE 6.90455 \tLL 0.00082 \tTotal 431.34/58.70/344.19 \n","04/19/2023 03:31:13 PM - INFO - [56:3] loss\t6.78 =\tBCE 6.77854 \tLL 0.00077 \tTotal 195.86/32.22/135.82 \n","04/19/2023 03:31:14 PM - INFO - [56:4] loss\t7.05 =\tBCE 7.04589 \tLL 0.00080 \tTotal 427.58/59.70/310.59 \n","04/19/2023 03:31:15 PM - INFO - [56:5] loss\t6.92 =\tBCE 6.92153 \tLL 0.00084 \tTotal 199.09/21.12/117.77 \n","04/19/2023 03:31:15 PM - INFO - [56:6] loss\t6.92 =\tBCE 6.92125 \tLL 0.00082 \tTotal 425.41/58.15/318.88 \n","04/19/2023 03:31:16 PM - INFO - [56:7] loss\t6.82 =\tBCE 6.82096 \tLL 0.00076 \tTotal 253.75/35.96/179.76 \n","04/19/2023 03:31:16 PM - INFO - [56:8] loss\t7.01 =\tBCE 7.00996 \tLL 0.00083 \tTotal 292.71/35.48/214.61 \n","04/19/2023 03:31:17 PM - INFO - [56:9] loss\t6.78 =\tBCE 6.78419 \tLL 0.00081 \tTotal 336.42/59.00/203.71 \n","04/19/2023 03:31:17 PM - INFO - [56:10] loss\t6.66 =\tBCE 6.66341 \tLL 0.00080 \tTotal 221.81/49.74/170.97 \n","04/19/2023 03:31:18 PM - INFO - [56:11] loss\t6.70 =\tBCE 6.70313 \tLL 0.00084 \tTotal 179.41/33.05/105.49 \n","04/19/2023 03:31:18 PM - INFO - [56:12] loss\t6.74 =\tBCE 6.73746 \tLL 0.00090 \tTotal 205.40/30.95/111.09 \n","04/19/2023 03:31:19 PM - INFO - [56:13] loss\t6.81 =\tBCE 6.80505 \tLL 0.00083 \tTotal 242.14/53.49/173.10 \n","04/19/2023 03:31:19 PM - INFO - [56:14] loss\t6.71 =\tBCE 6.71259 \tLL 0.00084 \tTotal 297.48/46.19/193.88 \n","04/19/2023 03:31:20 PM - INFO - [56:15] loss\t6.68 =\tBCE 6.67862 \tLL 0.00084 \tTotal 269.82/43.67/194.61 \n","04/19/2023 03:31:20 PM - INFO - [56:16] loss\t6.46 =\tBCE 6.46380 \tLL 0.00080 \tTotal 178.39/19.44/58.23 \n","04/19/2023 03:31:21 PM - INFO - [56:17] loss\t6.46 =\tBCE 6.46347 \tLL 0.00081 \tTotal 170.17/32.85/90.16 \n","04/19/2023 03:31:22 PM - INFO - [56:18] loss\t6.47 =\tBCE 6.46822 \tLL 0.00082 \tTotal 200.04/28.55/126.90 \n","04/19/2023 03:31:22 PM - INFO - [56:19] loss\t6.27 =\tBCE 6.26859 \tLL 0.00079 \tTotal 273.05/30.70/202.95 \n","04/19/2023 03:31:22 PM - INFO - Training epoch 57.\n","04/19/2023 03:31:23 PM - INFO - [57:0] loss\t6.41 =\tBCE 6.40780 \tLL 0.00082 \tTotal 210.88/27.56/150.94 \n","04/19/2023 03:31:23 PM - INFO - [57:1] loss\t6.21 =\tBCE 6.21244 \tLL 0.00079 \tTotal 359.51/58.10/247.56 \n","04/19/2023 03:31:24 PM - INFO - [57:2] loss\t6.28 =\tBCE 6.27716 \tLL 0.00086 \tTotal 417.14/62.65/317.30 \n","04/19/2023 03:31:24 PM - INFO - [57:3] loss\t6.18 =\tBCE 6.18452 \tLL 0.00080 \tTotal 207.40/21.54/137.64 \n","04/19/2023 03:31:25 PM - INFO - [57:4] loss\t6.45 =\tBCE 6.45127 \tLL 0.00087 \tTotal 467.76/66.97/357.30 \n","04/19/2023 03:31:25 PM - INFO - [57:5] loss\t6.20 =\tBCE 6.20151 \tLL 0.00082 \tTotal 311.64/43.32/224.92 \n","04/19/2023 03:31:26 PM - INFO - [57:6] loss\t6.08 =\tBCE 6.07703 \tLL 0.00083 \tTotal 305.98/39.21/249.93 \n","04/19/2023 03:31:26 PM - INFO - [57:7] loss\t6.05 =\tBCE 6.04552 \tLL 0.00084 \tTotal 341.72/46.92/235.66 \n","04/19/2023 03:31:27 PM - INFO - [57:8] loss\t6.10 =\tBCE 6.09537 \tLL 0.00080 \tTotal 258.22/43.94/189.71 \n","04/19/2023 03:31:27 PM - INFO - [57:9] loss\t6.28 =\tBCE 6.27823 \tLL 0.00087 \tTotal 460.39/58.76/360.72 \n","04/19/2023 03:31:28 PM - INFO - [57:10] loss\t6.11 =\tBCE 6.10826 \tLL 0.00084 \tTotal 230.67/64.32/142.46 \n","04/19/2023 03:31:29 PM - INFO - [57:11] loss\t5.94 =\tBCE 5.93737 \tLL 0.00081 \tTotal 272.84/45.80/185.94 \n","04/19/2023 03:31:29 PM - INFO - [57:12] loss\t6.11 =\tBCE 6.11159 \tLL 0.00086 \tTotal 441.81/86.29/338.26 \n","04/19/2023 03:31:30 PM - INFO - [57:13] loss\t5.92 =\tBCE 5.92315 \tLL 0.00085 \tTotal 457.21/56.09/317.75 \n","04/19/2023 03:31:30 PM - INFO - [57:14] loss\t5.84 =\tBCE 5.83617 \tLL 0.00088 \tTotal 203.30/30.77/112.60 \n","04/19/2023 03:31:31 PM - INFO - [57:15] loss\t6.00 =\tBCE 5.99746 \tLL 0.00089 \tTotal 474.54/66.87/335.99 \n","04/19/2023 03:31:31 PM - INFO - [57:16] loss\t5.86 =\tBCE 5.86393 \tLL 0.00084 \tTotal 383.08/47.14/280.53 \n","04/19/2023 03:31:32 PM - INFO - [57:17] loss\t5.71 =\tBCE 5.71258 \tLL 0.00083 \tTotal 206.77/24.96/145.32 \n","04/19/2023 03:31:32 PM - INFO - [57:18] loss\t5.85 =\tBCE 5.85116 \tLL 0.00087 \tTotal 417.97/45.71/330.17 \n","04/19/2023 03:31:33 PM - INFO - [57:19] loss\t5.82 =\tBCE 5.81901 \tLL 0.00082 \tTotal 457.90/71.25/328.83 \n","04/19/2023 03:31:33 PM - INFO - Training epoch 58.\n","04/19/2023 03:31:33 PM - INFO - [58:0] loss\t5.86 =\tBCE 5.85942 \tLL 0.00088 \tTotal 230.63/36.85/156.71 \n","04/19/2023 03:31:34 PM - INFO - [58:1] loss\t5.80 =\tBCE 5.80366 \tLL 0.00090 \tTotal 430.69/60.92/289.61 \n","04/19/2023 03:31:34 PM - INFO - [58:2] loss\t5.85 =\tBCE 5.84846 \tLL 0.00083 \tTotal 875.97/110.10/685.20 \n","04/19/2023 03:31:35 PM - INFO - [58:3] loss\t5.82 =\tBCE 5.82402 \tLL 0.00083 \tTotal 846.68/114.05/631.25 \n","04/19/2023 03:31:36 PM - INFO - [58:4] loss\t5.59 =\tBCE 5.58930 \tLL 0.00079 \tTotal 284.64/32.91/225.27 \n","04/19/2023 03:31:36 PM - INFO - [58:5] loss\t5.52 =\tBCE 5.52013 \tLL 0.00083 \tTotal 765.35/105.20/560.51 \n","04/19/2023 03:31:37 PM - INFO - [58:6] loss\t5.91 =\tBCE 5.90996 \tLL 0.00086 \tTotal 807.20/121.59/600.16 \n","04/19/2023 03:31:37 PM - INFO - [58:7] loss\t5.77 =\tBCE 5.76960 \tLL 0.00089 \tTotal 252.21/34.95/222.93 \n","04/19/2023 03:31:38 PM - INFO - [58:8] loss\t5.75 =\tBCE 5.74583 \tLL 0.00086 \tTotal 700.10/105.07/524.56 \n","04/19/2023 03:31:38 PM - INFO - [58:9] loss\t5.62 =\tBCE 5.62127 \tLL 0.00087 \tTotal 643.94/95.91/481.56 \n","04/19/2023 03:31:39 PM - INFO - [58:10] loss\t5.64 =\tBCE 5.64087 \tLL 0.00086 \tTotal 345.79/42.17/205.63 \n","04/19/2023 03:31:39 PM - INFO - [58:11] loss\t5.48 =\tBCE 5.47754 \tLL 0.00087 \tTotal 391.18/67.72/270.53 \n","04/19/2023 03:31:40 PM - INFO - [58:12] loss\t5.71 =\tBCE 5.71266 \tLL 0.00086 \tTotal 830.94/105.19/632.39 \n","04/19/2023 03:31:40 PM - INFO - [58:13] loss\t5.31 =\tBCE 5.30681 \tLL 0.00081 \tTotal 455.17/67.74/339.80 \n","04/19/2023 03:31:41 PM - INFO - [58:14] loss\t5.37 =\tBCE 5.36778 \tLL 0.00086 \tTotal 396.79/47.82/285.36 \n","04/19/2023 03:31:41 PM - INFO - [58:15] loss\t5.29 =\tBCE 5.29408 \tLL 0.00082 \tTotal 471.56/76.59/300.39 \n","04/19/2023 03:31:42 PM - INFO - [58:16] loss\t5.09 =\tBCE 5.09271 \tLL 0.00081 \tTotal 189.96/18.82/125.28 \n","04/19/2023 03:31:43 PM - INFO - [58:17] loss\t5.30 =\tBCE 5.29503 \tLL 0.00088 \tTotal 591.21/79.84/428.73 \n","04/19/2023 03:31:43 PM - INFO - [58:18] loss\t5.38 =\tBCE 5.37577 \tLL 0.00081 \tTotal 665.05/91.71/504.70 \n","04/19/2023 03:31:44 PM - INFO - [58:19] loss\t5.21 =\tBCE 5.20825 \tLL 0.00086 \tTotal 268.89/34.88/191.62 \n","Not implemented\n","04/19/2023 03:31:44 PM - INFO - Training epoch 59.\n","04/19/2023 03:31:44 PM - INFO - [59:0] loss\t5.45 =\tBCE 5.45077 \tLL 0.00091 \tTotal 439.92/73.42/317.07 \n","04/19/2023 03:31:45 PM - INFO - [59:1] loss\t5.21 =\tBCE 5.20695 \tLL 0.00082 \tTotal 606.50/90.86/455.74 \n","04/19/2023 03:31:45 PM - INFO - [59:2] loss\t5.13 =\tBCE 5.12769 \tLL 0.00082 \tTotal 276.72/35.47/212.26 \n","04/19/2023 03:31:46 PM - INFO - [59:3] loss\t5.31 =\tBCE 5.30749 \tLL 0.00088 \tTotal 251.89/43.38/153.22 \n","04/19/2023 03:31:46 PM - INFO - [59:4] loss\t5.10 =\tBCE 5.10407 \tLL 0.00086 \tTotal 301.02/39.19/192.68 \n","04/19/2023 03:31:47 PM - INFO - [59:5] loss\t4.96 =\tBCE 4.95745 \tLL 0.00083 \tTotal 334.19/50.97/239.62 \n","04/19/2023 03:31:47 PM - INFO - [59:6] loss\t5.16 =\tBCE 5.15860 \tLL 0.00089 \tTotal 198.21/36.94/131.19 \n","04/19/2023 03:31:48 PM - INFO - [59:7] loss\t4.96 =\tBCE 4.95907 \tLL 0.00080 \tTotal 298.59/52.27/213.45 \n","04/19/2023 03:31:49 PM - INFO - [59:8] loss\t5.09 =\tBCE 5.08558 \tLL 0.00085 \tTotal 322.68/57.86/222.11 \n","04/19/2023 03:31:49 PM - INFO - [59:9] loss\t4.79 =\tBCE 4.79392 \tLL 0.00081 \tTotal 246.73/40.56/173.39 \n","04/19/2023 03:31:50 PM - INFO - [59:10] loss\t4.88 =\tBCE 4.88280 \tLL 0.00082 \tTotal 450.89/68.74/323.04 \n","04/19/2023 03:31:50 PM - INFO - [59:11] loss\t5.01 =\tBCE 5.00942 \tLL 0.00084 \tTotal 454.79/56.30/336.90 \n","04/19/2023 03:31:51 PM - INFO - [59:12] loss\t4.86 =\tBCE 4.85670 \tLL 0.00081 \tTotal 303.05/44.30/199.26 \n","04/19/2023 03:31:51 PM - INFO - [59:13] loss\t4.85 =\tBCE 4.85113 \tLL 0.00083 \tTotal 298.12/42.37/225.04 \n","04/19/2023 03:31:52 PM - INFO - [59:14] loss\t4.98 =\tBCE 4.97803 \tLL 0.00082 \tTotal 615.67/89.00/446.24 \n","04/19/2023 03:31:52 PM - INFO - [59:15] loss\t4.99 =\tBCE 4.99067 \tLL 0.00081 \tTotal 755.48/114.66/551.45 \n","04/19/2023 03:31:53 PM - INFO - [59:16] loss\t5.02 =\tBCE 5.02086 \tLL 0.00092 \tTotal 641.22/88.05/442.44 \n","04/19/2023 03:31:53 PM - INFO - [59:17] loss\t4.85 =\tBCE 4.84929 \tLL 0.00086 \tTotal 206.26/45.28/81.30 \n","04/19/2023 03:31:54 PM - INFO - [59:18] loss\t5.01 =\tBCE 5.00981 \tLL 0.00089 \tTotal 633.10/85.66/464.98 \n","04/19/2023 03:31:54 PM - INFO - [59:19] loss\t4.86 =\tBCE 4.85607 \tLL 0.00084 \tTotal 652.88/91.34/515.16 \n","04/19/2023 03:31:54 PM - INFO - EVALUATION prior to epoch [60]...\n","04/19/2023 03:31:55 PM - INFO - [60] loss\t4.84=\tBCE 4.84 \tLL 0.00087 \n","04/19/2023 03:31:56 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/60_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:32:02 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/60_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:32:06 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/60_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/19/2023 03:32:07 PM - INFO - Training epoch 60.\n","04/19/2023 03:32:07 PM - INFO - [60:0] loss\t4.60 =\tBCE 4.59992 \tLL 0.00083 \tTotal 340.32/40.03/240.51 \n","04/19/2023 03:32:08 PM - INFO - [60:1] loss\t4.77 =\tBCE 4.76762 \tLL 0.00089 \tTotal 216.67/43.59/121.56 \n","04/19/2023 03:32:09 PM - INFO - [60:2] loss\t4.75 =\tBCE 4.75400 \tLL 0.00085 \tTotal 178.81/41.22/107.44 \n","04/19/2023 03:32:09 PM - INFO - [60:3] loss\t4.44 =\tBCE 4.44240 \tLL 0.00085 \tTotal 213.00/25.01/106.48 \n","04/19/2023 03:32:10 PM - INFO - [60:4] loss\t4.63 =\tBCE 4.62985 \tLL 0.00086 \tTotal 247.81/60.13/181.11 \n","04/19/2023 03:32:10 PM - INFO - [60:5] loss\t4.82 =\tBCE 4.82467 \tLL 0.00086 \tTotal 304.22/42.21/199.20 \n","04/19/2023 03:32:11 PM - INFO - [60:6] loss\t4.73 =\tBCE 4.72768 \tLL 0.00091 \tTotal 469.86/84.81/346.40 \n","04/19/2023 03:32:11 PM - INFO - [60:7] loss\t4.82 =\tBCE 4.82163 \tLL 0.00090 \tTotal 523.15/62.01/413.52 \n","04/19/2023 03:32:12 PM - INFO - [60:8] loss\t4.55 =\tBCE 4.55248 \tLL 0.00080 \tTotal 278.45/50.58/196.83 \n","04/19/2023 03:32:12 PM - INFO - [60:9] loss\t4.67 =\tBCE 4.67235 \tLL 0.00085 \tTotal 449.60/65.27/344.23 \n","04/19/2023 03:32:13 PM - INFO - [60:10] loss\t4.55 =\tBCE 4.54578 \tLL 0.00083 \tTotal 640.71/85.32/451.23 \n","04/19/2023 03:32:13 PM - INFO - [60:11] loss\t4.55 =\tBCE 4.55225 \tLL 0.00083 \tTotal 277.22/68.50/164.39 \n","04/19/2023 03:32:14 PM - INFO - [60:12] loss\t4.53 =\tBCE 4.53302 \tLL 0.00085 \tTotal 571.36/73.61/416.81 \n","04/19/2023 03:32:14 PM - INFO - [60:13] loss\t4.95 =\tBCE 4.95033 \tLL 0.00088 \tTotal 961.28/149.71/738.39 \n","04/19/2023 03:32:15 PM - INFO - [60:14] loss\t4.88 =\tBCE 4.87850 \tLL 0.00090 \tTotal 1068.62/158.23/824.59 \n","04/19/2023 03:32:16 PM - INFO - [60:15] loss\t4.79 =\tBCE 4.79008 \tLL 0.00087 \tTotal 710.41/96.90/506.35 \n","04/19/2023 03:32:16 PM - INFO - [60:16] loss\t4.45 =\tBCE 4.44706 \tLL 0.00085 \tTotal 270.05/29.56/129.51 \n","04/19/2023 03:32:17 PM - INFO - [60:17] loss\t4.68 =\tBCE 4.67602 \tLL 0.00092 \tTotal 697.56/102.59/434.64 \n","04/19/2023 03:32:17 PM - INFO - [60:18] loss\t4.79 =\tBCE 4.78578 \tLL 0.00089 \tTotal 820.41/104.37/621.65 \n","04/19/2023 03:32:18 PM - INFO - [60:19] loss\t4.71 =\tBCE 4.71389 \tLL 0.00092 \tTotal 631.45/97.78/430.01 \n","04/19/2023 03:32:18 PM - INFO - Training epoch 61.\n","04/19/2023 03:32:18 PM - INFO - [61:0] loss\t4.37 =\tBCE 4.37048 \tLL 0.00089 \tTotal 248.06/37.13/179.53 \n","04/19/2023 03:32:19 PM - INFO - [61:1] loss\t4.75 =\tBCE 4.75371 \tLL 0.00092 \tTotal 844.75/120.34/604.86 \n","04/19/2023 03:32:19 PM - INFO - [61:2] loss\t4.81 =\tBCE 4.81246 \tLL 0.00089 \tTotal 1007.93/140.04/773.96 \n","04/19/2023 03:32:20 PM - INFO - [61:3] loss\t4.69 =\tBCE 4.68826 \tLL 0.00090 \tTotal 762.58/106.31/542.64 \n","04/19/2023 03:32:20 PM - INFO - [61:4] loss\t4.33 =\tBCE 4.32992 \tLL 0.00087 \tTotal 345.78/45.08/215.24 \n","04/19/2023 03:32:21 PM - INFO - [61:5] loss\t4.58 =\tBCE 4.58340 \tLL 0.00088 \tTotal 798.08/111.98/580.20 \n","04/19/2023 03:32:21 PM - INFO - [61:6] loss\t4.86 =\tBCE 4.85816 \tLL 0.00090 \tTotal 1299.70/161.93/1035.49 \n","04/19/2023 03:32:22 PM - INFO - [61:7] loss\t4.81 =\tBCE 4.81040 \tLL 0.00091 \tTotal 1120.52/140.38/862.35 \n","04/19/2023 03:32:23 PM - INFO - [61:8] loss\t4.69 =\tBCE 4.69369 \tLL 0.00102 \tTotal 553.63/72.87/365.84 \n","04/19/2023 03:32:23 PM - INFO - [61:9] loss\t4.29 =\tBCE 4.28799 \tLL 0.00091 \tTotal 427.77/53.39/250.21 \n","04/19/2023 03:32:24 PM - INFO - [61:10] loss\t4.51 =\tBCE 4.51089 \tLL 0.00087 \tTotal 1062.73/141.72/824.40 \n","04/19/2023 03:32:24 PM - INFO - [61:11] loss\t4.72 =\tBCE 4.71537 \tLL 0.00088 \tTotal 1346.45/178.64/1033.88 \n","04/19/2023 03:32:25 PM - INFO - [61:12] loss\t4.33 =\tBCE 4.32517 \tLL 0.00083 \tTotal 836.12/120.69/640.78 \n","04/19/2023 03:32:25 PM - INFO - [61:13] loss\t4.19 =\tBCE 4.19087 \tLL 0.00090 \tTotal 278.60/25.03/99.59 \n","04/19/2023 03:32:26 PM - INFO - [61:14] loss\t4.45 =\tBCE 4.44982 \tLL 0.00084 \tTotal 814.27/105.45/625.47 \n","04/19/2023 03:32:26 PM - INFO - [61:15] loss\t4.49 =\tBCE 4.49083 \tLL 0.00090 \tTotal 1007.24/129.63/763.22 \n","04/19/2023 03:32:27 PM - INFO - [61:16] loss\t4.20 =\tBCE 4.20464 \tLL 0.00084 \tTotal 678.24/91.33/493.63 \n","04/19/2023 03:32:28 PM - INFO - [61:17] loss\t4.28 =\tBCE 4.28309 \tLL 0.00091 \tTotal 241.74/53.07/150.57 \n","04/19/2023 03:32:28 PM - INFO - [61:18] loss\t4.31 =\tBCE 4.31072 \tLL 0.00091 \tTotal 438.92/53.83/320.75 \n","04/19/2023 03:32:29 PM - INFO - [61:19] loss\t4.00 =\tBCE 4.00133 \tLL 0.00086 \tTotal 526.51/95.69/403.16 \n","04/19/2023 03:32:29 PM - INFO - Training epoch 62.\n","04/19/2023 03:32:29 PM - INFO - [62:0] loss\t4.21 =\tBCE 4.20860 \tLL 0.00091 \tTotal 530.33/65.32/391.05 \n","04/19/2023 03:32:30 PM - INFO - [62:1] loss\t4.10 =\tBCE 4.09866 \tLL 0.00086 \tTotal 227.31/55.24/145.07 \n","04/19/2023 03:32:30 PM - INFO - [62:2] loss\t4.03 =\tBCE 4.02835 \tLL 0.00088 \tTotal 549.24/64.90/416.11 \n","04/19/2023 03:32:31 PM - INFO - [62:3] loss\t4.27 =\tBCE 4.27473 \tLL 0.00090 \tTotal 748.37/101.32/588.49 \n","04/19/2023 03:32:31 PM - INFO - [62:4] loss\t4.17 =\tBCE 4.17115 \tLL 0.00088 \tTotal 452.73/79.70/330.74 \n","04/19/2023 03:32:32 PM - INFO - [62:5] loss\t3.90 =\tBCE 3.90492 \tLL 0.00081 \tTotal 271.51/72.39/113.58 \n","04/19/2023 03:32:32 PM - INFO - [62:6] loss\t3.92 =\tBCE 3.92124 \tLL 0.00089 \tTotal 238.35/43.74/157.45 \n","04/19/2023 03:32:33 PM - INFO - [62:7] loss\t4.04 =\tBCE 4.04098 \tLL 0.00085 \tTotal 303.93/62.81/195.02 \n","04/19/2023 03:32:34 PM - INFO - [62:8] loss\t3.94 =\tBCE 3.93783 \tLL 0.00083 \tTotal 370.75/74.11/226.57 \n","04/19/2023 03:32:34 PM - INFO - [62:9] loss\t4.13 =\tBCE 4.12890 \tLL 0.00089 \tTotal 522.20/79.47/354.99 \n","04/19/2023 03:32:35 PM - INFO - [62:10] loss\t4.26 =\tBCE 4.25834 \tLL 0.00094 \tTotal 559.55/75.04/430.66 \n","04/19/2023 03:32:35 PM - INFO - [62:11] loss\t4.04 =\tBCE 4.03599 \tLL 0.00088 \tTotal 377.40/53.58/281.01 \n","04/19/2023 03:32:36 PM - INFO - [62:12] loss\t3.99 =\tBCE 3.99272 \tLL 0.00087 \tTotal 311.65/46.38/106.36 \n","04/19/2023 03:32:36 PM - INFO - [62:13] loss\t3.83 =\tBCE 3.83264 \tLL 0.00087 \tTotal 280.05/45.42/159.05 \n","04/19/2023 03:32:37 PM - INFO - [62:14] loss\t4.08 =\tBCE 4.07773 \tLL 0.00093 \tTotal 423.46/57.83/212.00 \n","04/19/2023 03:32:37 PM - INFO - [62:15] loss\t4.04 =\tBCE 4.04214 \tLL 0.00092 \tTotal 568.82/75.04/406.21 \n","04/19/2023 03:32:38 PM - INFO - [62:16] loss\t4.03 =\tBCE 4.03333 \tLL 0.00091 \tTotal 481.54/69.81/338.53 \n","04/19/2023 03:32:39 PM - INFO - [62:17] loss\t4.22 =\tBCE 4.21741 \tLL 0.00094 \tTotal 425.88/51.17/190.25 \n","04/19/2023 03:32:39 PM - INFO - [62:18] loss\t3.86 =\tBCE 3.85707 \tLL 0.00084 \tTotal 256.37/38.85/173.42 \n","04/19/2023 03:32:40 PM - INFO - [62:19] loss\t3.88 =\tBCE 3.88186 \tLL 0.00091 \tTotal 500.85/63.22/314.96 \n","04/19/2023 03:32:40 PM - INFO - Training epoch 63.\n","04/19/2023 03:32:40 PM - INFO - [63:0] loss\t3.83 =\tBCE 3.82541 \tLL 0.00089 \tTotal 225.72/31.98/126.16 \n","04/19/2023 03:32:41 PM - INFO - [63:1] loss\t3.88 =\tBCE 3.87524 \tLL 0.00090 \tTotal 312.52/52.10/185.61 \n","04/19/2023 03:32:41 PM - INFO - [63:2] loss\t3.80 =\tBCE 3.79901 \tLL 0.00084 \tTotal 491.97/65.91/346.44 \n","04/19/2023 03:32:42 PM - INFO - [63:3] loss\t3.79 =\tBCE 3.79023 \tLL 0.00087 \tTotal 582.52/76.55/452.30 \n","04/19/2023 03:32:42 PM - INFO - [63:4] loss\t3.78 =\tBCE 3.78037 \tLL 0.00087 \tTotal 369.08/53.42/250.18 \n","04/19/2023 03:32:43 PM - INFO - [63:5] loss\t3.68 =\tBCE 3.68400 \tLL 0.00082 \tTotal 208.17/37.04/127.94 \n","04/19/2023 03:32:43 PM - INFO - [63:6] loss\t3.70 =\tBCE 3.70320 \tLL 0.00083 \tTotal 253.83/31.30/179.73 \n","04/19/2023 03:32:44 PM - INFO - [63:7] loss\t3.78 =\tBCE 3.78180 \tLL 0.00086 \tTotal 346.70/46.33/249.67 \n","04/19/2023 03:32:45 PM - INFO - [63:8] loss\t3.62 =\tBCE 3.61626 \tLL 0.00088 \tTotal 332.68/45.82/233.27 \n","04/19/2023 03:32:45 PM - INFO - [63:9] loss\t3.70 =\tBCE 3.69961 \tLL 0.00087 \tTotal 385.48/36.18/255.17 \n","04/19/2023 03:32:46 PM - INFO - [63:10] loss\t3.66 =\tBCE 3.66459 \tLL 0.00083 \tTotal 328.03/41.69/204.51 \n","04/19/2023 03:32:46 PM - INFO - [63:11] loss\t3.93 =\tBCE 3.92588 \tLL 0.00091 \tTotal 316.98/45.51/243.79 \n","04/19/2023 03:32:47 PM - INFO - [63:12] loss\t3.81 =\tBCE 3.81015 \tLL 0.00087 \tTotal 537.50/69.91/408.76 \n","04/19/2023 03:32:47 PM - INFO - [63:13] loss\t3.85 =\tBCE 3.84689 \tLL 0.00091 \tTotal 633.66/86.12/450.33 \n","04/19/2023 03:32:48 PM - INFO - [63:14] loss\t3.64 =\tBCE 3.64467 \tLL 0.00089 \tTotal 447.97/63.28/323.08 \n","04/19/2023 03:32:48 PM - INFO - [63:15] loss\t3.62 =\tBCE 3.61603 \tLL 0.00089 \tTotal 210.21/38.88/123.25 \n","04/19/2023 03:32:49 PM - INFO - [63:16] loss\t3.74 =\tBCE 3.74110 \tLL 0.00091 \tTotal 421.61/60.40/322.04 \n","04/19/2023 03:32:49 PM - INFO - [63:17] loss\t3.72 =\tBCE 3.72464 \tLL 0.00087 \tTotal 662.30/98.93/495.78 \n","04/19/2023 03:32:50 PM - INFO - [63:18] loss\t3.80 =\tBCE 3.79896 \tLL 0.00091 \tTotal 891.09/117.89/699.87 \n","04/19/2023 03:32:51 PM - INFO - [63:19] loss\t3.84 =\tBCE 3.84455 \tLL 0.00089 \tTotal 1027.85/139.60/806.56 \n","04/19/2023 03:32:51 PM - INFO - Training epoch 64.\n","04/19/2023 03:32:51 PM - INFO - [64:0] loss\t3.76 =\tBCE 3.75685 \tLL 0.00087 \tTotal 934.17/126.53/706.17 \n","04/19/2023 03:32:52 PM - INFO - [64:1] loss\t3.70 =\tBCE 3.69702 \tLL 0.00088 \tTotal 789.75/104.55/590.80 \n","04/19/2023 03:32:52 PM - INFO - [64:2] loss\t3.72 =\tBCE 3.71827 \tLL 0.00091 \tTotal 426.07/62.53/298.91 \n","04/19/2023 03:32:53 PM - INFO - [64:3] loss\t3.52 =\tBCE 3.52270 \tLL 0.00085 \tTotal 318.15/35.81/188.83 \n","04/19/2023 03:32:53 PM - INFO - [64:4] loss\t3.65 =\tBCE 3.65161 \tLL 0.00088 \tTotal 589.66/81.18/452.04 \n","04/19/2023 03:32:54 PM - INFO - [64:5] loss\t3.69 =\tBCE 3.69372 \tLL 0.00091 \tTotal 783.87/96.12/644.31 \n","04/19/2023 03:32:54 PM - INFO - [64:6] loss\t3.51 =\tBCE 3.50542 \tLL 0.00083 \tTotal 662.16/91.45/473.23 \n","04/19/2023 03:32:55 PM - INFO - [64:7] loss\t3.65 =\tBCE 3.65187 \tLL 0.00090 \tTotal 541.83/60.39/389.55 \n","04/19/2023 03:32:56 PM - INFO - [64:8] loss\t3.64 =\tBCE 3.64080 \tLL 0.00095 \tTotal 401.53/41.40/291.56 \n","04/19/2023 03:32:56 PM - INFO - [64:9] loss\t3.43 =\tBCE 3.43025 \tLL 0.00084 \tTotal 267.27/34.77/154.12 \n","04/19/2023 03:32:57 PM - INFO - [64:10] loss\t3.66 =\tBCE 3.65762 \tLL 0.00091 \tTotal 363.43/55.18/250.17 \n","04/19/2023 03:32:57 PM - INFO - [64:11] loss\t3.48 =\tBCE 3.47741 \tLL 0.00081 \tTotal 359.70/48.78/227.65 \n","04/19/2023 03:32:58 PM - INFO - [64:12] loss\t3.52 =\tBCE 3.52152 \tLL 0.00090 \tTotal 351.46/46.90/272.61 \n","04/19/2023 03:32:58 PM - INFO - [64:13] loss\t3.56 =\tBCE 3.55762 \tLL 0.00094 \tTotal 296.37/38.14/227.89 \n","04/19/2023 03:32:59 PM - INFO - [64:14] loss\t3.47 =\tBCE 3.47350 \tLL 0.00093 \tTotal 400.72/57.16/335.56 \n","04/19/2023 03:32:59 PM - INFO - [64:15] loss\t3.39 =\tBCE 3.39161 \tLL 0.00086 \tTotal 691.78/93.07/505.33 \n","04/19/2023 03:33:00 PM - INFO - [64:16] loss\t3.66 =\tBCE 3.66245 \tLL 0.00091 \tTotal 866.07/129.95/658.31 \n","04/19/2023 03:33:00 PM - INFO - [64:17] loss\t3.69 =\tBCE 3.68780 \tLL 0.00087 \tTotal 1113.24/147.10/866.44 \n","04/19/2023 03:33:01 PM - INFO - [64:18] loss\t3.82 =\tBCE 3.82180 \tLL 0.00088 \tTotal 1273.24/175.68/945.97 \n","04/19/2023 03:33:01 PM - INFO - [64:19] loss\t4.27 =\tBCE 4.27053 \tLL 0.00100 \tTotal 1499.28/189.55/1211.07 \n","04/19/2023 03:33:01 PM - INFO - Training epoch 65.\n","04/19/2023 03:33:02 PM - INFO - [65:0] loss\t4.12 =\tBCE 4.11639 \tLL 0.00087 \tTotal 1591.38/216.02/1241.91 \n","04/19/2023 03:33:02 PM - INFO - [65:1] loss\t3.92 =\tBCE 3.91844 \tLL 0.00094 \tTotal 1305.18/182.68/989.65 \n","04/19/2023 03:33:03 PM - INFO - [65:2] loss\t3.62 =\tBCE 3.62006 \tLL 0.00092 \tTotal 778.18/94.14/595.64 \n","04/19/2023 03:33:04 PM - INFO - [65:3] loss\t3.35 =\tBCE 3.35042 \tLL 0.00085 \tTotal 294.09/60.40/187.25 \n","04/19/2023 03:33:04 PM - INFO - [65:4] loss\t3.60 =\tBCE 3.60467 \tLL 0.00094 \tTotal 613.27/81.37/439.75 \n","04/19/2023 03:33:05 PM - INFO - [65:5] loss\t3.48 =\tBCE 3.48486 \tLL 0.00086 \tTotal 830.35/116.15/635.77 \n","04/19/2023 03:33:05 PM - INFO - [65:6] loss\t3.54 =\tBCE 3.54368 \tLL 0.00091 \tTotal 718.95/100.56/533.30 \n","04/19/2023 03:33:06 PM - INFO - [65:7] loss\t3.33 =\tBCE 3.33473 \tLL 0.00084 \tTotal 322.67/40.58/181.62 \n","04/19/2023 03:33:06 PM - INFO - [65:8] loss\t3.53 =\tBCE 3.53202 \tLL 0.00095 \tTotal 409.29/45.26/281.05 \n","04/19/2023 03:33:07 PM - INFO - [65:9] loss\t3.48 =\tBCE 3.48169 \tLL 0.00092 \tTotal 615.11/74.47/437.48 \n","04/19/2023 03:33:07 PM - INFO - [65:10] loss\t3.33 =\tBCE 3.32912 \tLL 0.00091 \tTotal 576.81/71.52/440.85 \n","04/19/2023 03:33:08 PM - INFO - [65:11] loss\t3.42 =\tBCE 3.41825 \tLL 0.00089 \tTotal 371.51/48.78/234.39 \n","04/19/2023 03:33:08 PM - INFO - [65:12] loss\t3.39 =\tBCE 3.39315 \tLL 0.00092 \tTotal 386.70/57.54/294.98 \n","04/19/2023 03:33:09 PM - INFO - [65:13] loss\t3.43 =\tBCE 3.42968 \tLL 0.00093 \tTotal 348.93/54.80/174.95 \n","04/19/2023 03:33:10 PM - INFO - [65:14] loss\t3.37 =\tBCE 3.37333 \tLL 0.00090 \tTotal 397.62/50.20/286.93 \n","04/19/2023 03:33:10 PM - INFO - [65:15] loss\t3.40 =\tBCE 3.39901 \tLL 0.00090 \tTotal 554.60/78.68/352.11 \n","04/19/2023 03:33:11 PM - INFO - [65:16] loss\t3.33 =\tBCE 3.32648 \tLL 0.00087 \tTotal 497.31/96.88/328.13 \n","04/19/2023 03:33:11 PM - INFO - [65:17] loss\t3.40 =\tBCE 3.40234 \tLL 0.00096 \tTotal 754.03/91.44/564.51 \n","04/19/2023 03:33:12 PM - INFO - [65:18] loss\t3.37 =\tBCE 3.37014 \tLL 0.00088 \tTotal 726.97/101.69/577.81 \n","04/19/2023 03:33:12 PM - INFO - [65:19] loss\t3.31 =\tBCE 3.30645 \tLL 0.00088 \tTotal 532.80/108.35/364.06 \n","04/19/2023 03:33:12 PM - INFO - Training epoch 66.\n","04/19/2023 03:33:13 PM - INFO - [66:0] loss\t3.35 =\tBCE 3.34937 \tLL 0.00094 \tTotal 366.19/97.02/273.17 \n","04/19/2023 03:33:13 PM - INFO - [66:1] loss\t3.06 =\tBCE 3.05908 \tLL 0.00082 \tTotal 336.20/80.71/256.54 \n","04/19/2023 03:33:14 PM - INFO - [66:2] loss\t3.14 =\tBCE 3.13626 \tLL 0.00088 \tTotal 237.94/62.27/180.70 \n","04/19/2023 03:33:14 PM - INFO - [66:3] loss\t3.14 =\tBCE 3.13658 \tLL 0.00089 \tTotal 210.42/62.07/129.96 \n","04/19/2023 03:33:15 PM - INFO - [66:4] loss\t3.23 =\tBCE 3.23333 \tLL 0.00088 \tTotal 434.27/58.11/322.58 \n","04/19/2023 03:33:15 PM - INFO - [66:5] loss\t3.31 =\tBCE 3.30598 \tLL 0.00086 \tTotal 716.49/113.85/537.66 \n","04/19/2023 03:33:16 PM - INFO - [66:6] loss\t3.53 =\tBCE 3.52959 \tLL 0.00090 \tTotal 986.56/143.31/770.57 \n","04/19/2023 03:33:17 PM - INFO - [66:7] loss\t3.40 =\tBCE 3.40031 \tLL 0.00088 \tTotal 926.40/117.21/718.13 \n","04/19/2023 03:33:17 PM - INFO - [66:8] loss\t3.29 =\tBCE 3.28772 \tLL 0.00087 \tTotal 655.75/84.77/466.98 \n","04/19/2023 03:33:18 PM - INFO - [66:9] loss\t3.11 =\tBCE 3.10921 \tLL 0.00090 \tTotal 465.71/60.41/364.01 \n","04/19/2023 03:33:18 PM - INFO - [66:10] loss\t3.12 =\tBCE 3.12305 \tLL 0.00085 \tTotal 386.34/44.83/284.22 \n","04/19/2023 03:33:19 PM - INFO - [66:11] loss\t3.21 =\tBCE 3.20886 \tLL 0.00089 \tTotal 413.68/52.98/265.82 \n","04/19/2023 03:33:19 PM - INFO - [66:12] loss\t3.24 =\tBCE 3.23719 \tLL 0.00089 \tTotal 434.86/57.26/258.68 \n","04/19/2023 03:33:20 PM - INFO - [66:13] loss\t3.21 =\tBCE 3.20553 \tLL 0.00088 \tTotal 444.12/66.22/342.47 \n","04/19/2023 03:33:20 PM - INFO - [66:14] loss\t3.02 =\tBCE 3.02178 \tLL 0.00082 \tTotal 243.35/32.18/125.80 \n","04/19/2023 03:33:21 PM - INFO - [66:15] loss\t3.06 =\tBCE 3.05814 \tLL 0.00086 \tTotal 335.49/50.00/231.28 \n","04/19/2023 03:33:21 PM - INFO - [66:16] loss\t3.21 =\tBCE 3.21465 \tLL 0.00092 \tTotal 491.54/71.41/349.39 \n","04/19/2023 03:33:22 PM - INFO - [66:17] loss\t3.10 =\tBCE 3.10184 \tLL 0.00086 \tTotal 513.80/69.73/364.10 \n","04/19/2023 03:33:22 PM - INFO - [66:18] loss\t3.17 =\tBCE 3.17133 \tLL 0.00089 \tTotal 743.00/84.27/596.56 \n","04/19/2023 03:33:23 PM - INFO - [66:19] loss\t3.22 =\tBCE 3.22353 \tLL 0.00088 \tTotal 900.98/112.85/692.55 \n","04/19/2023 03:33:23 PM - INFO - Training epoch 67.\n","04/19/2023 03:33:24 PM - INFO - [67:0] loss\t3.24 =\tBCE 3.24478 \tLL 0.00084 \tTotal 975.19/149.83/713.57 \n","04/19/2023 03:33:24 PM - INFO - [67:1] loss\t3.37 =\tBCE 3.36906 \tLL 0.00092 \tTotal 1102.94/147.94/854.09 \n","04/19/2023 03:33:25 PM - INFO - [67:2] loss\t3.44 =\tBCE 3.43978 \tLL 0.00090 \tTotal 1279.14/158.21/1012.93 \n","04/19/2023 03:33:25 PM - INFO - [67:3] loss\t3.64 =\tBCE 3.64114 \tLL 0.00089 \tTotal 1498.30/195.35/1170.06 \n","04/19/2023 03:33:26 PM - INFO - [67:4] loss\t3.84 =\tBCE 3.84151 \tLL 0.00094 \tTotal 1688.23/236.74/1276.19 \n","04/19/2023 03:33:26 PM - INFO - [67:5] loss\t4.18 =\tBCE 4.17932 \tLL 0.00097 \tTotal 1941.64/285.08/1396.42 \n","04/19/2023 03:33:27 PM - INFO - [67:6] loss\t4.18 =\tBCE 4.18454 \tLL 0.00095 \tTotal 2201.43/288.73/1723.21 \n","04/19/2023 03:33:27 PM - INFO - [67:7] loss\t4.68 =\tBCE 4.67814 \tLL 0.00092 \tTotal 2738.48/350.02/2185.20 \n","04/19/2023 03:33:28 PM - INFO - [67:8] loss\t6.13 =\tBCE 6.12794 \tLL 0.00103 \tTotal 3694.33/481.77/2877.42 \n","04/19/2023 03:33:28 PM - INFO - [67:9] loss\t11.07 =\tBCE 11.07187 \tLL 0.00128 \tTotal 6236.57/807.63/4850.59 \n","04/19/2023 03:33:29 PM - INFO - [67:10] loss\t39.97 =\tBCE 39.97271 \tLL 0.00253 \tTotal 14848.40/1854.64/11580.07 \n","04/19/2023 03:33:30 PM - INFO - [67:11] loss\t617.96 =\tBCE 617.96106 \tLL 0.01137 \tTotal 40204.32/4442.50/31487.05 \n","04/19/2023 03:33:30 PM - INFO - [67:12] loss\t3612.09 =\tBCE 3612.09375 \tLL 0.06162 \tTotal 57608.06/5712.94/43469.03 \n","04/19/2023 03:33:31 PM - INFO - [67:13] loss\t1159.63 =\tBCE 1159.63367 \tLL 0.05313 \tTotal 35692.07/3212.58/24894.26 \n","04/19/2023 03:33:31 PM - INFO - [67:14] loss\t525.73 =\tBCE 525.73480 \tLL 0.07610 \tTotal 20022.74/2408.41/12291.89 \n","04/19/2023 03:33:32 PM - INFO - [67:15] loss\t1167.70 =\tBCE 1167.69580 \tLL 0.09954 \tTotal 40511.09/3830.95/32121.52 \n","04/19/2023 03:33:32 PM - INFO - [67:16] loss\t214.48 =\tBCE 214.48366 \tLL 0.07230 \tTotal 18196.66/2141.40/14231.24 \n","04/19/2023 03:33:33 PM - INFO - [67:17] loss\t286.73 =\tBCE 286.73083 \tLL 0.06912 \tTotal 18982.28/1771.61/14826.93 \n","04/19/2023 03:33:33 PM - INFO - [67:18] loss\t492.68 =\tBCE 492.68234 \tLL 0.04985 \tTotal 25197.68/2708.93/18464.47 \n","04/19/2023 03:33:34 PM - INFO - [67:19] loss\t111.68 =\tBCE 111.67628 \tLL 0.03325 \tTotal 7804.21/455.74/4189.81 \n","04/19/2023 03:33:34 PM - INFO - Training epoch 68.\n","04/19/2023 03:33:35 PM - INFO - [68:0] loss\t227.96 =\tBCE 227.96342 \tLL 0.03058 \tTotal 17646.18/1992.23/12050.37 \n","04/19/2023 03:33:35 PM - INFO - [68:1] loss\t62.92 =\tBCE 62.92256 \tLL 0.01265 \tTotal 3336.63/677.19/1590.68 \n","04/19/2023 03:33:36 PM - INFO - [68:2] loss\t123.43 =\tBCE 123.42764 \tLL 0.01353 \tTotal 11964.01/1397.06/8544.47 \n","04/19/2023 03:33:36 PM - INFO - [68:3] loss\t77.61 =\tBCE 77.61368 \tLL 0.01223 \tTotal 4975.50/598.21/2016.39 \n","04/19/2023 03:33:37 PM - INFO - [68:4] loss\t91.57 =\tBCE 91.57355 \tLL 0.00803 \tTotal 7528.10/857.24/5283.17 \n","04/19/2023 03:33:37 PM - INFO - [68:5] loss\t78.55 =\tBCE 78.54567 \tLL 0.00506 \tTotal 5980.00/861.37/4124.87 \n","04/19/2023 03:33:38 PM - INFO - [68:6] loss\t58.07 =\tBCE 58.06504 \tLL 0.00493 \tTotal 2670.15/294.87/1835.11 \n","04/19/2023 03:33:38 PM - INFO - [68:7] loss\t69.01 =\tBCE 69.00806 \tLL 0.00503 \tTotal 5320.10/415.87/4263.36 \n","04/19/2023 03:33:39 PM - INFO - [68:8] loss\t63.92 =\tBCE 63.91694 \tLL 0.00380 \tTotal 4582.95/443.95/3497.26 \n","04/19/2023 03:33:39 PM - INFO - [68:9] loss\t49.29 =\tBCE 49.29254 \tLL 0.00338 \tTotal 1715.56/268.06/1058.28 \n","04/19/2023 03:33:40 PM - INFO - [68:10] loss\t64.23 =\tBCE 64.23486 \tLL 0.00333 \tTotal 4080.86/281.84/2683.48 \n","04/19/2023 03:33:41 PM - INFO - [68:11] loss\t53.07 =\tBCE 53.06606 \tLL 0.00290 \tTotal 3204.58/248.16/2419.00 \n","04/19/2023 03:33:41 PM - INFO - [68:12] loss\t50.27 =\tBCE 50.26933 \tLL 0.00283 \tTotal 1855.46/222.67/1175.35 \n","04/19/2023 03:33:42 PM - INFO - [68:13] loss\t51.29 =\tBCE 51.28816 \tLL 0.00252 \tTotal 1793.98/295.68/923.43 \n","04/19/2023 03:33:42 PM - INFO - [68:14] loss\t48.41 =\tBCE 48.41177 \tLL 0.00197 \tTotal 1734.33/288.48/1084.67 \n","04/19/2023 03:33:43 PM - INFO - [68:15] loss\t47.93 =\tBCE 47.93273 \tLL 0.00186 \tTotal 1823.12/202.12/1302.94 \n","04/19/2023 03:33:43 PM - INFO - [68:16] loss\t45.90 =\tBCE 45.89845 \tLL 0.00185 \tTotal 1154.34/113.52/709.98 \n","04/19/2023 03:33:44 PM - INFO - [68:17] loss\t50.15 =\tBCE 50.15478 \tLL 0.00200 \tTotal 1560.96/213.09/948.45 \n","04/19/2023 03:33:44 PM - INFO - [68:18] loss\t48.74 =\tBCE 48.73779 \tLL 0.00200 \tTotal 1338.26/255.55/842.03 \n","04/19/2023 03:33:45 PM - INFO - [68:19] loss\t45.93 =\tBCE 45.92689 \tLL 0.00213 \tTotal 1043.98/230.47/709.52 \n","Not implemented\n","04/19/2023 03:33:45 PM - INFO - Training epoch 69.\n","04/19/2023 03:33:45 PM - INFO - [69:0] loss\t44.82 =\tBCE 44.82360 \tLL 0.00230 \tTotal 1181.55/147.10/819.80 \n","04/19/2023 03:33:46 PM - INFO - [69:1] loss\t42.56 =\tBCE 42.56248 \tLL 0.00246 \tTotal 963.22/103.29/534.76 \n","04/19/2023 03:33:46 PM - INFO - [69:2] loss\t43.01 =\tBCE 43.01323 \tLL 0.00277 \tTotal 1121.94/129.10/781.68 \n","04/19/2023 03:33:47 PM - INFO - [69:3] loss\t41.00 =\tBCE 41.00406 \tLL 0.00284 \tTotal 732.87/157.83/500.24 \n","04/19/2023 03:33:48 PM - INFO - [69:4] loss\t41.07 =\tBCE 41.06584 \tLL 0.00279 \tTotal 605.72/141.93/438.88 \n","04/19/2023 03:33:48 PM - INFO - [69:5] loss\t41.12 =\tBCE 41.12215 \tLL 0.00255 \tTotal 976.58/115.53/667.80 \n","04/19/2023 03:33:49 PM - INFO - [69:6] loss\t38.70 =\tBCE 38.69878 \tLL 0.00235 \tTotal 942.59/89.48/558.47 \n","04/19/2023 03:33:49 PM - INFO - [69:7] loss\t37.06 =\tBCE 37.06421 \tLL 0.00214 \tTotal 788.80/91.23/523.63 \n","04/19/2023 03:33:50 PM - INFO - [69:8] loss\t36.54 =\tBCE 36.53803 \tLL 0.00206 \tTotal 359.59/121.28/226.55 \n","04/19/2023 03:33:50 PM - INFO - [69:9] loss\t34.91 =\tBCE 34.90744 \tLL 0.00197 \tTotal 553.76/143.22/354.28 \n","04/19/2023 03:33:51 PM - INFO - [69:10] loss\t36.13 =\tBCE 36.12726 \tLL 0.00185 \tTotal 1003.00/142.66/750.06 \n","04/19/2023 03:33:51 PM - INFO - [69:11] loss\t34.63 =\tBCE 34.63456 \tLL 0.00180 \tTotal 742.05/81.02/525.45 \n","04/19/2023 03:33:52 PM - INFO - [69:12] loss\t31.95 =\tBCE 31.94807 \tLL 0.00155 \tTotal 348.98/60.19/247.60 \n","04/19/2023 03:33:53 PM - INFO - [69:13] loss\t31.15 =\tBCE 31.14661 \tLL 0.00140 \tTotal 714.88/110.00/497.69 \n","04/19/2023 03:33:53 PM - INFO - [69:14] loss\t30.50 =\tBCE 30.50444 \tLL 0.00127 \tTotal 546.06/100.59/349.11 \n","04/19/2023 03:33:54 PM - INFO - [69:15] loss\t29.80 =\tBCE 29.79755 \tLL 0.00128 \tTotal 458.09/81.50/318.23 \n","04/19/2023 03:33:54 PM - INFO - [69:16] loss\t29.02 =\tBCE 29.02406 \tLL 0.00121 \tTotal 362.68/57.90/211.78 \n","04/19/2023 03:33:55 PM - INFO - [69:17] loss\t27.51 =\tBCE 27.51127 \tLL 0.00108 \tTotal 347.72/63.07/223.87 \n","04/19/2023 03:33:55 PM - INFO - [69:18] loss\t27.36 =\tBCE 27.36184 \tLL 0.00106 \tTotal 453.52/96.59/309.68 \n","04/19/2023 03:33:56 PM - INFO - [69:19] loss\t26.26 =\tBCE 26.26126 \tLL 0.00101 \tTotal 389.99/105.81/228.48 \n","04/19/2023 03:33:56 PM - INFO - EVALUATION prior to epoch [70]...\n","04/19/2023 03:33:56 PM - INFO - [70] loss\t25.35=\tBCE 25.35 \tLL 0.00095 \n","04/19/2023 03:33:57 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/70_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:34:02 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/70_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:34:08 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/70_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/19/2023 03:34:09 PM - INFO - Training epoch 70.\n","04/19/2023 03:34:09 PM - INFO - [70:0] loss\t24.84 =\tBCE 24.84466 \tLL 0.00094 \tTotal 356.44/77.08/233.02 \n","04/19/2023 03:34:10 PM - INFO - [70:1] loss\t24.58 =\tBCE 24.58044 \tLL 0.00086 \tTotal 464.00/44.96/367.20 \n","04/19/2023 03:34:10 PM - INFO - [70:2] loss\t24.13 =\tBCE 24.12820 \tLL 0.00085 \tTotal 367.28/45.89/231.77 \n","04/19/2023 03:34:11 PM - INFO - [70:3] loss\t23.41 =\tBCE 23.40830 \tLL 0.00081 \tTotal 347.05/63.76/179.94 \n","04/19/2023 03:34:11 PM - INFO - [70:4] loss\t22.90 =\tBCE 22.90223 \tLL 0.00079 \tTotal 364.06/61.92/179.22 \n","04/19/2023 03:34:12 PM - INFO - [70:5] loss\t21.74 =\tBCE 21.74138 \tLL 0.00079 \tTotal 251.51/44.23/139.42 \n","04/19/2023 03:34:12 PM - INFO - [70:6] loss\t21.52 =\tBCE 21.51991 \tLL 0.00081 \tTotal 400.79/51.90/315.71 \n","04/19/2023 03:34:13 PM - INFO - [70:7] loss\t20.89 =\tBCE 20.89321 \tLL 0.00084 \tTotal 372.16/57.57/225.26 \n","04/19/2023 03:34:14 PM - INFO - [70:8] loss\t20.12 =\tBCE 20.12379 \tLL 0.00087 \tTotal 255.04/57.61/95.18 \n","04/19/2023 03:34:14 PM - INFO - [70:9] loss\t19.82 =\tBCE 19.81552 \tLL 0.00092 \tTotal 284.42/54.23/151.19 \n","04/19/2023 03:34:15 PM - INFO - [70:10] loss\t19.70 =\tBCE 19.70340 \tLL 0.00086 \tTotal 223.20/43.49/148.16 \n","04/19/2023 03:34:15 PM - INFO - [70:11] loss\t19.23 =\tBCE 19.23333 \tLL 0.00089 \tTotal 327.27/41.17/244.19 \n","04/19/2023 03:34:16 PM - INFO - [70:12] loss\t18.81 =\tBCE 18.80679 \tLL 0.00088 \tTotal 282.89/38.05/151.79 \n","04/19/2023 03:34:16 PM - INFO - [70:13] loss\t17.95 =\tBCE 17.94912 \tLL 0.00082 \tTotal 314.07/42.27/124.93 \n","04/19/2023 03:34:17 PM - INFO - [70:14] loss\t17.89 =\tBCE 17.88829 \tLL 0.00083 \tTotal 262.07/41.23/160.63 \n","04/19/2023 03:34:17 PM - INFO - [70:15] loss\t17.21 =\tBCE 17.21255 \tLL 0.00090 \tTotal 190.48/31.92/121.76 \n","04/19/2023 03:34:18 PM - INFO - [70:16] loss\t16.91 =\tBCE 16.90908 \tLL 0.00085 \tTotal 256.84/41.88/116.85 \n","04/19/2023 03:34:18 PM - INFO - [70:17] loss\t16.93 =\tBCE 16.92780 \tLL 0.00087 \tTotal 343.24/50.51/196.87 \n","04/19/2023 03:34:19 PM - INFO - [70:18] loss\t16.27 =\tBCE 16.26976 \tLL 0.00078 \tTotal 200.48/31.77/133.46 \n","04/19/2023 03:34:20 PM - INFO - [70:19] loss\t15.71 =\tBCE 15.71443 \tLL 0.00068 \tTotal 252.46/37.96/165.75 \n","04/19/2023 03:34:20 PM - INFO - Training epoch 71.\n","04/19/2023 03:34:20 PM - INFO - [71:0] loss\t15.39 =\tBCE 15.39351 \tLL 0.00071 \tTotal 226.09/31.52/108.47 \n","04/19/2023 03:34:21 PM - INFO - [71:1] loss\t15.58 =\tBCE 15.57597 \tLL 0.00074 \tTotal 261.28/29.65/127.02 \n","04/19/2023 03:34:21 PM - INFO - [71:2] loss\t14.93 =\tBCE 14.93051 \tLL 0.00069 \tTotal 223.44/30.62/162.15 \n","04/19/2023 03:34:22 PM - INFO - [71:3] loss\t14.67 =\tBCE 14.67029 \tLL 0.00069 \tTotal 222.39/29.61/135.36 \n","04/19/2023 03:34:22 PM - INFO - [71:4] loss\t14.44 =\tBCE 14.44176 \tLL 0.00069 \tTotal 214.49/24.25/127.17 \n","04/19/2023 03:34:23 PM - INFO - [71:5] loss\t13.80 =\tBCE 13.80281 \tLL 0.00069 \tTotal 170.68/28.48/105.67 \n","04/19/2023 03:34:23 PM - INFO - [71:6] loss\t14.19 =\tBCE 14.18523 \tLL 0.00068 \tTotal 139.53/26.75/92.92 \n","04/19/2023 03:34:24 PM - INFO - [71:7] loss\t13.62 =\tBCE 13.62408 \tLL 0.00062 \tTotal 122.31/24.21/80.99 \n","04/19/2023 03:34:24 PM - INFO - [71:8] loss\t13.59 =\tBCE 13.58923 \tLL 0.00065 \tTotal 220.05/31.69/149.37 \n","04/19/2023 03:34:25 PM - INFO - [71:9] loss\t12.75 =\tBCE 12.74531 \tLL 0.00060 \tTotal 152.74/21.72/98.55 \n","04/19/2023 03:34:25 PM - INFO - [71:10] loss\t12.93 =\tBCE 12.93009 \tLL 0.00063 \tTotal 120.45/21.48/84.00 \n","04/19/2023 03:34:26 PM - INFO - [71:11] loss\t12.80 =\tBCE 12.80328 \tLL 0.00065 \tTotal 210.37/32.33/142.90 \n","04/19/2023 03:34:27 PM - INFO - [71:12] loss\t12.30 =\tBCE 12.29754 \tLL 0.00062 \tTotal 101.11/22.84/77.04 \n","04/19/2023 03:34:27 PM - INFO - [71:13] loss\t12.44 =\tBCE 12.43645 \tLL 0.00063 \tTotal 216.84/35.74/150.05 \n","04/19/2023 03:34:28 PM - INFO - [71:14] loss\t12.05 =\tBCE 12.04655 \tLL 0.00061 \tTotal 153.70/27.61/92.59 \n","04/19/2023 03:34:28 PM - INFO - [71:15] loss\t11.95 =\tBCE 11.94946 \tLL 0.00060 \tTotal 184.70/25.26/129.80 \n","04/19/2023 03:34:29 PM - INFO - [71:16] loss\t11.84 =\tBCE 11.84222 \tLL 0.00063 \tTotal 122.51/21.72/68.97 \n","04/19/2023 03:34:29 PM - INFO - [71:17] loss\t11.65 =\tBCE 11.64991 \tLL 0.00060 \tTotal 130.46/21.29/75.41 \n","04/19/2023 03:34:30 PM - INFO - [71:18] loss\t11.02 =\tBCE 11.02371 \tLL 0.00059 \tTotal 127.24/20.01/75.28 \n","04/19/2023 03:34:30 PM - INFO - [71:19] loss\t11.45 =\tBCE 11.44985 \tLL 0.00063 \tTotal 130.16/21.37/68.23 \n","04/19/2023 03:34:30 PM - INFO - Training epoch 72.\n","04/19/2023 03:34:31 PM - INFO - [72:0] loss\t10.89 =\tBCE 10.88926 \tLL 0.00057 \tTotal 99.26/17.81/61.36 \n","04/19/2023 03:34:32 PM - INFO - [72:1] loss\t10.92 =\tBCE 10.92207 \tLL 0.00060 \tTotal 146.01/24.37/102.00 \n","04/19/2023 03:34:32 PM - INFO - [72:2] loss\t10.95 =\tBCE 10.94973 \tLL 0.00065 \tTotal 142.02/19.23/92.49 \n","04/19/2023 03:34:33 PM - INFO - [72:3] loss\t10.66 =\tBCE 10.66045 \tLL 0.00058 \tTotal 207.50/24.32/153.08 \n","04/19/2023 03:34:33 PM - INFO - [72:4] loss\t10.58 =\tBCE 10.57801 \tLL 0.00057 \tTotal 156.17/22.14/92.26 \n","04/19/2023 03:34:34 PM - INFO - [72:5] loss\t10.11 =\tBCE 10.10864 \tLL 0.00054 \tTotal 161.18/23.37/110.06 \n","04/19/2023 03:34:34 PM - INFO - [72:6] loss\t10.44 =\tBCE 10.44387 \tLL 0.00061 \tTotal 97.38/17.65/64.51 \n","04/19/2023 03:34:35 PM - INFO - [72:7] loss\t10.25 =\tBCE 10.24858 \tLL 0.00060 \tTotal 150.27/19.00/109.66 \n","04/19/2023 03:34:35 PM - INFO - [72:8] loss\t9.82 =\tBCE 9.81990 \tLL 0.00058 \tTotal 112.19/18.62/68.23 \n","04/19/2023 03:34:36 PM - INFO - [72:9] loss\t10.28 =\tBCE 10.27562 \tLL 0.00063 \tTotal 96.82/17.73/62.27 \n","04/19/2023 03:34:37 PM - INFO - [72:10] loss\t9.52 =\tBCE 9.51721 \tLL 0.00054 \tTotal 170.61/21.35/95.65 \n","04/19/2023 03:34:37 PM - INFO - [72:11] loss\t9.68 =\tBCE 9.67843 \tLL 0.00056 \tTotal 151.13/19.44/74.74 \n","04/19/2023 03:34:38 PM - INFO - [72:12] loss\t9.67 =\tBCE 9.66721 \tLL 0.00057 \tTotal 87.22/19.16/60.68 \n","04/19/2023 03:34:38 PM - INFO - [72:13] loss\t9.19 =\tBCE 9.18703 \tLL 0.00059 \tTotal 161.07/24.50/106.68 \n","04/19/2023 03:34:39 PM - INFO - [72:14] loss\t9.56 =\tBCE 9.56209 \tLL 0.00059 \tTotal 157.22/22.50/92.56 \n","04/19/2023 03:34:39 PM - INFO - [72:15] loss\t9.05 =\tBCE 9.04727 \tLL 0.00057 \tTotal 126.91/19.99/83.08 \n","04/19/2023 03:34:40 PM - INFO - [72:16] loss\t9.02 =\tBCE 9.01932 \tLL 0.00056 \tTotal 140.62/24.25/95.19 \n","04/19/2023 03:34:40 PM - INFO - [72:17] loss\t9.16 =\tBCE 9.15695 \tLL 0.00058 \tTotal 159.20/24.15/109.40 \n","04/19/2023 03:34:41 PM - INFO - [72:18] loss\t8.99 =\tBCE 8.99468 \tLL 0.00059 \tTotal 161.02/21.03/93.21 \n","04/19/2023 03:34:41 PM - INFO - [72:19] loss\t9.29 =\tBCE 9.28862 \tLL 0.00061 \tTotal 102.36/22.58/63.96 \n","04/19/2023 03:34:41 PM - INFO - Training epoch 73.\n","04/19/2023 03:34:42 PM - INFO - [73:0] loss\t8.86 =\tBCE 8.85949 \tLL 0.00056 \tTotal 132.22/18.03/77.76 \n","04/19/2023 03:34:43 PM - INFO - [73:1] loss\t8.65 =\tBCE 8.64645 \tLL 0.00055 \tTotal 140.63/20.86/96.25 \n","04/19/2023 03:34:43 PM - INFO - [73:2] loss\t8.48 =\tBCE 8.47788 \tLL 0.00054 \tTotal 122.32/16.05/80.93 \n","04/19/2023 03:34:44 PM - INFO - [73:3] loss\t8.73 =\tBCE 8.72710 \tLL 0.00057 \tTotal 139.98/21.87/96.35 \n","04/19/2023 03:34:44 PM - INFO - [73:4] loss\t8.32 =\tBCE 8.31546 \tLL 0.00057 \tTotal 129.45/19.87/79.89 \n","04/19/2023 03:34:45 PM - INFO - [73:5] loss\t8.17 =\tBCE 8.17250 \tLL 0.00054 \tTotal 224.89/34.78/148.50 \n","04/19/2023 03:34:45 PM - INFO - [73:6] loss\t8.23 =\tBCE 8.23180 \tLL 0.00056 \tTotal 93.82/20.23/38.53 \n","04/19/2023 03:34:46 PM - INFO - [73:7] loss\t8.12 =\tBCE 8.11550 \tLL 0.00054 \tTotal 115.02/15.36/76.84 \n","04/19/2023 03:34:46 PM - INFO - [73:8] loss\t8.11 =\tBCE 8.10910 \tLL 0.00055 \tTotal 233.69/33.33/161.30 \n","04/19/2023 03:34:47 PM - INFO - [73:9] loss\t7.91 =\tBCE 7.91089 \tLL 0.00055 \tTotal 118.07/13.03/78.40 \n","04/19/2023 03:34:48 PM - INFO - [73:10] loss\t8.00 =\tBCE 8.00379 \tLL 0.00058 \tTotal 246.75/36.34/187.27 \n","04/19/2023 03:34:48 PM - INFO - [73:11] loss\t7.79 =\tBCE 7.79419 \tLL 0.00056 \tTotal 131.75/18.07/89.94 \n","04/19/2023 03:34:49 PM - INFO - [73:12] loss\t7.80 =\tBCE 7.80195 \tLL 0.00055 \tTotal 236.01/34.52/160.14 \n","04/19/2023 03:34:49 PM - INFO - [73:13] loss\t7.75 =\tBCE 7.75318 \tLL 0.00055 \tTotal 109.13/15.16/70.21 \n","04/19/2023 03:34:50 PM - INFO - [73:14] loss\t7.59 =\tBCE 7.58880 \tLL 0.00058 \tTotal 158.80/25.34/116.60 \n","04/19/2023 03:34:50 PM - INFO - [73:15] loss\t7.67 =\tBCE 7.67314 \tLL 0.00058 \tTotal 198.05/26.08/126.81 \n","04/19/2023 03:34:51 PM - INFO - [73:16] loss\t7.56 =\tBCE 7.55874 \tLL 0.00053 \tTotal 227.95/33.70/160.95 \n","04/19/2023 03:34:51 PM - INFO - [73:17] loss\t7.53 =\tBCE 7.52707 \tLL 0.00055 \tTotal 146.99/18.58/98.46 \n","04/19/2023 03:34:52 PM - INFO - [73:18] loss\t7.52 =\tBCE 7.52403 \tLL 0.00057 \tTotal 170.65/20.96/119.03 \n","04/19/2023 03:34:52 PM - INFO - [73:19] loss\t7.35 =\tBCE 7.35222 \tLL 0.00059 \tTotal 180.16/22.95/130.31 \n","04/19/2023 03:34:52 PM - INFO - Training epoch 74.\n","04/19/2023 03:34:53 PM - INFO - [74:0] loss\t7.37 =\tBCE 7.37011 \tLL 0.00057 \tTotal 156.21/23.83/118.76 \n","04/19/2023 03:34:54 PM - INFO - [74:1] loss\t7.19 =\tBCE 7.19139 \tLL 0.00057 \tTotal 268.45/32.20/187.17 \n","04/19/2023 03:34:54 PM - INFO - [74:2] loss\t7.11 =\tBCE 7.10933 \tLL 0.00057 \tTotal 157.78/23.99/104.59 \n","04/19/2023 03:34:55 PM - INFO - [74:3] loss\t7.13 =\tBCE 7.13288 \tLL 0.00057 \tTotal 291.28/45.09/201.29 \n","04/19/2023 03:34:55 PM - INFO - [74:4] loss\t7.15 =\tBCE 7.14648 \tLL 0.00057 \tTotal 184.03/18.67/126.37 \n","04/19/2023 03:34:56 PM - INFO - [74:5] loss\t6.89 =\tBCE 6.88598 \tLL 0.00055 \tTotal 297.57/37.09/234.44 \n","04/19/2023 03:34:56 PM - INFO - [74:6] loss\t6.99 =\tBCE 6.98617 \tLL 0.00054 \tTotal 90.44/18.76/62.03 \n","04/19/2023 03:34:57 PM - INFO - [74:7] loss\t7.03 =\tBCE 7.03319 \tLL 0.00061 \tTotal 266.49/35.94/206.92 \n","04/19/2023 03:34:57 PM - INFO - [74:8] loss\t6.96 =\tBCE 6.96189 \tLL 0.00059 \tTotal 186.82/21.32/133.95 \n","04/19/2023 03:34:58 PM - INFO - [74:9] loss\t6.65 =\tBCE 6.65252 \tLL 0.00053 \tTotal 263.37/42.21/181.82 \n","04/19/2023 03:34:58 PM - INFO - [74:10] loss\t6.71 =\tBCE 6.70642 \tLL 0.00055 \tTotal 145.58/23.34/88.04 \n","04/19/2023 03:34:59 PM - INFO - [74:11] loss\t6.52 =\tBCE 6.51522 \tLL 0.00056 \tTotal 203.26/26.54/124.39 \n","04/19/2023 03:34:59 PM - INFO - [74:12] loss\t6.70 =\tBCE 6.69510 \tLL 0.00059 \tTotal 256.81/39.18/175.08 \n","04/19/2023 03:35:00 PM - INFO - [74:13] loss\t6.47 =\tBCE 6.46563 \tLL 0.00058 \tTotal 187.05/24.12/120.11 \n","04/19/2023 03:35:01 PM - INFO - [74:14] loss\t6.76 =\tBCE 6.76264 \tLL 0.00060 \tTotal 332.63/40.15/233.38 \n","04/19/2023 03:35:01 PM - INFO - [74:15] loss\t6.38 =\tBCE 6.37553 \tLL 0.00056 \tTotal 164.25/24.19/86.91 \n","04/19/2023 03:35:02 PM - INFO - [74:16] loss\t6.52 =\tBCE 6.51957 \tLL 0.00058 \tTotal 340.54/42.22/248.73 \n","04/19/2023 03:35:02 PM - INFO - [74:17] loss\t6.43 =\tBCE 6.43359 \tLL 0.00056 \tTotal 225.54/29.56/167.40 \n","04/19/2023 03:35:03 PM - INFO - [74:18] loss\t6.39 =\tBCE 6.39149 \tLL 0.00054 \tTotal 203.77/29.56/138.30 \n","04/19/2023 03:35:03 PM - INFO - [74:19] loss\t6.06 =\tBCE 6.06224 \tLL 0.00056 \tTotal 164.62/33.70/100.94 \n","04/19/2023 03:35:03 PM - INFO - Training epoch 75.\n","04/19/2023 03:35:04 PM - INFO - [75:0] loss\t6.01 =\tBCE 6.01037 \tLL 0.00053 \tTotal 142.92/18.36/80.63 \n","04/19/2023 03:35:04 PM - INFO - [75:1] loss\t6.08 =\tBCE 6.08109 \tLL 0.00054 \tTotal 124.10/33.29/70.69 \n","04/19/2023 03:35:05 PM - INFO - [75:2] loss\t6.15 =\tBCE 6.14646 \tLL 0.00056 \tTotal 154.13/23.75/101.64 \n","04/19/2023 03:35:06 PM - INFO - [75:3] loss\t6.15 =\tBCE 6.14954 \tLL 0.00058 \tTotal 179.18/22.14/113.88 \n","04/19/2023 03:35:06 PM - INFO - [75:4] loss\t6.16 =\tBCE 6.15733 \tLL 0.00059 \tTotal 95.59/36.77/63.35 \n","04/19/2023 03:35:07 PM - INFO - [75:5] loss\t6.06 =\tBCE 6.06151 \tLL 0.00058 \tTotal 129.96/29.81/45.10 \n","04/19/2023 03:35:07 PM - INFO - [75:6] loss\t6.25 =\tBCE 6.25041 \tLL 0.00062 \tTotal 152.34/17.56/107.21 \n","04/19/2023 03:35:08 PM - INFO - [75:7] loss\t6.02 =\tBCE 6.02470 \tLL 0.00058 \tTotal 77.24/29.04/42.84 \n","04/19/2023 03:35:08 PM - INFO - [75:8] loss\t5.93 =\tBCE 5.93146 \tLL 0.00057 \tTotal 288.96/44.56/204.25 \n","04/19/2023 03:35:09 PM - INFO - [75:9] loss\t5.97 =\tBCE 5.97286 \tLL 0.00059 \tTotal 105.74/20.13/64.88 \n","04/19/2023 03:35:09 PM - INFO - [75:10] loss\t5.86 =\tBCE 5.86012 \tLL 0.00059 \tTotal 184.44/36.78/106.70 \n","04/19/2023 03:35:10 PM - INFO - [75:11] loss\t5.78 =\tBCE 5.77867 \tLL 0.00057 \tTotal 114.65/28.26/42.80 \n","04/19/2023 03:35:10 PM - INFO - [75:12] loss\t5.90 =\tBCE 5.89804 \tLL 0.00060 \tTotal 191.88/19.95/141.94 \n","04/19/2023 03:35:11 PM - INFO - [75:13] loss\t5.81 =\tBCE 5.80878 \tLL 0.00058 \tTotal 149.55/31.92/51.95 \n","04/19/2023 03:35:11 PM - INFO - [75:14] loss\t5.72 =\tBCE 5.72169 \tLL 0.00058 \tTotal 117.61/25.48/82.50 \n","04/19/2023 03:35:12 PM - INFO - [75:15] loss\t5.51 =\tBCE 5.50699 \tLL 0.00057 \tTotal 103.51/16.71/42.40 \n","04/19/2023 03:35:13 PM - INFO - [75:16] loss\t5.42 =\tBCE 5.42089 \tLL 0.00055 \tTotal 204.74/41.67/141.55 \n","04/19/2023 03:35:13 PM - INFO - [75:17] loss\t5.40 =\tBCE 5.39975 \tLL 0.00058 \tTotal 152.66/28.70/103.80 \n","04/19/2023 03:35:14 PM - INFO - [75:18] loss\t5.65 =\tBCE 5.64643 \tLL 0.00059 \tTotal 210.08/29.43/157.28 \n","04/19/2023 03:35:14 PM - INFO - [75:19] loss\t5.47 =\tBCE 5.47153 \tLL 0.00057 \tTotal 188.03/33.16/110.37 \n","04/19/2023 03:35:14 PM - INFO - Training epoch 76.\n","04/19/2023 03:35:15 PM - INFO - [76:0] loss\t5.44 =\tBCE 5.43933 \tLL 0.00058 \tTotal 292.07/40.38/228.34 \n","04/19/2023 03:35:15 PM - INFO - [76:1] loss\t5.32 =\tBCE 5.32355 \tLL 0.00059 \tTotal 134.25/23.98/85.30 \n","04/19/2023 03:35:16 PM - INFO - [76:2] loss\t5.58 =\tBCE 5.57976 \tLL 0.00064 \tTotal 208.98/34.96/154.37 \n","04/19/2023 03:35:16 PM - INFO - [76:3] loss\t5.39 =\tBCE 5.38827 \tLL 0.00056 \tTotal 120.23/21.57/61.13 \n","04/19/2023 03:35:17 PM - INFO - [76:4] loss\t5.43 =\tBCE 5.43112 \tLL 0.00062 \tTotal 259.97/37.83/191.68 \n","04/19/2023 03:35:17 PM - INFO - [76:5] loss\t5.30 =\tBCE 5.29638 \tLL 0.00060 \tTotal 215.59/28.37/146.47 \n","04/19/2023 03:35:18 PM - INFO - [76:6] loss\t5.27 =\tBCE 5.27313 \tLL 0.00057 \tTotal 210.96/25.08/143.71 \n","04/19/2023 03:35:19 PM - INFO - [76:7] loss\t5.12 =\tBCE 5.11749 \tLL 0.00057 \tTotal 158.92/30.30/115.96 \n","04/19/2023 03:35:19 PM - INFO - [76:8] loss\t5.23 =\tBCE 5.23129 \tLL 0.00058 \tTotal 247.64/33.27/177.51 \n","04/19/2023 03:35:20 PM - INFO - [76:9] loss\t5.11 =\tBCE 5.11142 \tLL 0.00058 \tTotal 226.51/32.79/148.22 \n","04/19/2023 03:35:20 PM - INFO - [76:10] loss\t5.27 =\tBCE 5.26708 \tLL 0.00062 \tTotal 247.07/35.13/185.15 \n","04/19/2023 03:35:21 PM - INFO - [76:11] loss\t5.23 =\tBCE 5.22648 \tLL 0.00060 \tTotal 241.23/33.58/188.93 \n","04/19/2023 03:35:21 PM - INFO - [76:12] loss\t5.16 =\tBCE 5.15849 \tLL 0.00060 \tTotal 187.70/27.52/134.38 \n","04/19/2023 03:35:22 PM - INFO - [76:13] loss\t5.14 =\tBCE 5.13668 \tLL 0.00058 \tTotal 171.82/24.53/116.30 \n","04/19/2023 03:35:22 PM - INFO - [76:14] loss\t5.02 =\tBCE 5.01535 \tLL 0.00058 \tTotal 94.51/15.30/57.50 \n","04/19/2023 03:35:23 PM - INFO - [76:15] loss\t5.09 =\tBCE 5.08782 \tLL 0.00059 \tTotal 173.05/29.28/82.46 \n","04/19/2023 03:35:23 PM - INFO - [76:16] loss\t5.07 =\tBCE 5.06823 \tLL 0.00062 \tTotal 118.89/23.08/77.55 \n","04/19/2023 03:35:24 PM - INFO - [76:17] loss\t4.94 =\tBCE 4.93518 \tLL 0.00057 \tTotal 165.61/18.09/106.13 \n","04/19/2023 03:35:24 PM - INFO - [76:18] loss\t5.19 =\tBCE 5.18803 \tLL 0.00065 \tTotal 142.67/22.83/107.54 \n","04/19/2023 03:35:25 PM - INFO - [76:19] loss\t4.88 =\tBCE 4.88286 \tLL 0.00057 \tTotal 101.04/16.30/47.94 \n","04/19/2023 03:35:25 PM - INFO - Training epoch 77.\n","04/19/2023 03:35:25 PM - INFO - [77:0] loss\t4.74 =\tBCE 4.73567 \tLL 0.00059 \tTotal 93.60/14.97/40.89 \n","04/19/2023 03:35:26 PM - INFO - [77:1] loss\t4.99 =\tBCE 4.98929 \tLL 0.00062 \tTotal 135.92/24.10/80.27 \n","04/19/2023 03:35:27 PM - INFO - [77:2] loss\t4.83 =\tBCE 4.82999 \tLL 0.00058 \tTotal 158.11/27.29/103.45 \n","04/19/2023 03:35:27 PM - INFO - [77:3] loss\t4.86 =\tBCE 4.86463 \tLL 0.00062 \tTotal 284.64/35.70/224.71 \n","04/19/2023 03:35:28 PM - INFO - [77:4] loss\t4.74 =\tBCE 4.74117 \tLL 0.00059 \tTotal 190.12/35.39/125.79 \n","04/19/2023 03:35:28 PM - INFO - [77:5] loss\t4.66 =\tBCE 4.66118 \tLL 0.00061 \tTotal 163.58/28.14/111.39 \n","04/19/2023 03:35:29 PM - INFO - [77:6] loss\t4.75 =\tBCE 4.74755 \tLL 0.00059 \tTotal 171.09/25.32/101.90 \n","04/19/2023 03:35:29 PM - INFO - [77:7] loss\t4.69 =\tBCE 4.69475 \tLL 0.00059 \tTotal 216.94/37.94/158.31 \n","04/19/2023 03:35:30 PM - INFO - [77:8] loss\t4.78 =\tBCE 4.78051 \tLL 0.00060 \tTotal 226.05/28.79/174.92 \n","04/19/2023 03:35:30 PM - INFO - [77:9] loss\t4.80 =\tBCE 4.80400 \tLL 0.00064 \tTotal 187.40/28.95/147.33 \n","04/19/2023 03:35:31 PM - INFO - [77:10] loss\t4.74 =\tBCE 4.73986 \tLL 0.00062 \tTotal 251.54/36.60/180.10 \n","04/19/2023 03:35:31 PM - INFO - [77:11] loss\t4.90 =\tBCE 4.89976 \tLL 0.00064 \tTotal 154.60/26.43/106.65 \n","04/19/2023 03:35:32 PM - INFO - [77:12] loss\t4.62 =\tBCE 4.61721 \tLL 0.00063 \tTotal 271.27/37.50/209.19 \n","04/19/2023 03:35:33 PM - INFO - [77:13] loss\t4.51 =\tBCE 4.51196 \tLL 0.00060 \tTotal 144.59/24.99/104.88 \n","04/19/2023 03:35:33 PM - INFO - [77:14] loss\t4.63 =\tBCE 4.62834 \tLL 0.00064 \tTotal 249.50/31.38/196.86 \n","04/19/2023 03:35:34 PM - INFO - [77:15] loss\t4.72 =\tBCE 4.72276 \tLL 0.00063 \tTotal 209.41/33.23/144.42 \n","04/19/2023 03:35:34 PM - INFO - [77:16] loss\t4.55 =\tBCE 4.55150 \tLL 0.00056 \tTotal 142.00/25.77/89.66 \n","04/19/2023 03:35:35 PM - INFO - [77:17] loss\t4.46 =\tBCE 4.46137 \tLL 0.00059 \tTotal 143.67/20.95/92.68 \n","04/19/2023 03:35:35 PM - INFO - [77:18] loss\t4.50 =\tBCE 4.49620 \tLL 0.00063 \tTotal 206.88/26.40/155.42 \n","04/19/2023 03:35:36 PM - INFO - [77:19] loss\t4.62 =\tBCE 4.61611 \tLL 0.00066 \tTotal 158.27/19.04/122.64 \n","04/19/2023 03:35:36 PM - INFO - Training epoch 78.\n","04/19/2023 03:35:36 PM - INFO - [78:0] loss\t4.42 =\tBCE 4.42023 \tLL 0.00060 \tTotal 173.94/19.12/131.10 \n","04/19/2023 03:35:37 PM - INFO - [78:1] loss\t4.42 =\tBCE 4.42319 \tLL 0.00064 \tTotal 161.65/25.05/102.14 \n","04/19/2023 03:35:37 PM - INFO - [78:2] loss\t4.47 =\tBCE 4.46752 \tLL 0.00061 \tTotal 134.74/20.43/93.64 \n","04/19/2023 03:35:38 PM - INFO - [78:3] loss\t4.39 =\tBCE 4.38557 \tLL 0.00060 \tTotal 136.80/17.99/72.21 \n","04/19/2023 03:35:38 PM - INFO - [78:4] loss\t4.36 =\tBCE 4.36152 \tLL 0.00061 \tTotal 174.24/26.72/94.76 \n","04/19/2023 03:35:39 PM - INFO - [78:5] loss\t4.27 =\tBCE 4.26742 \tLL 0.00060 \tTotal 296.97/42.42/235.24 \n","04/19/2023 03:35:39 PM - INFO - [78:6] loss\t4.33 =\tBCE 4.33429 \tLL 0.00064 \tTotal 190.79/31.01/111.25 \n","04/19/2023 03:35:40 PM - INFO - [78:7] loss\t4.36 =\tBCE 4.36500 \tLL 0.00061 \tTotal 246.24/36.36/169.87 \n","04/19/2023 03:35:41 PM - INFO - [78:8] loss\t4.21 =\tBCE 4.20562 \tLL 0.00061 \tTotal 189.14/33.70/127.33 \n","04/19/2023 03:35:41 PM - INFO - [78:9] loss\t4.29 =\tBCE 4.28925 \tLL 0.00062 \tTotal 187.64/32.95/115.76 \n","04/19/2023 03:35:42 PM - INFO - [78:10] loss\t4.34 =\tBCE 4.33600 \tLL 0.00064 \tTotal 226.49/36.51/184.86 \n","04/19/2023 03:35:42 PM - INFO - [78:11] loss\t4.43 =\tBCE 4.42603 \tLL 0.00062 \tTotal 326.21/48.27/224.19 \n","04/19/2023 03:35:43 PM - INFO - [78:12] loss\t4.29 =\tBCE 4.29389 \tLL 0.00064 \tTotal 110.11/17.36/71.12 \n","04/19/2023 03:35:43 PM - INFO - [78:13] loss\t4.29 =\tBCE 4.28835 \tLL 0.00060 \tTotal 201.73/47.99/124.98 \n","04/19/2023 03:35:44 PM - INFO - [78:14] loss\t4.10 =\tBCE 4.09853 \tLL 0.00060 \tTotal 138.08/29.68/79.62 \n","04/19/2023 03:35:44 PM - INFO - [78:15] loss\t4.35 =\tBCE 4.34692 \tLL 0.00066 \tTotal 122.52/33.33/74.35 \n","04/19/2023 03:35:45 PM - INFO - [78:16] loss\t4.29 =\tBCE 4.29473 \tLL 0.00065 \tTotal 208.51/45.94/134.01 \n","04/19/2023 03:35:45 PM - INFO - [78:17] loss\t4.18 =\tBCE 4.17886 \tLL 0.00064 \tTotal 186.05/24.74/138.65 \n","04/19/2023 03:35:46 PM - INFO - [78:18] loss\t4.14 =\tBCE 4.14104 \tLL 0.00061 \tTotal 267.20/56.14/178.85 \n","04/19/2023 03:35:47 PM - INFO - [78:19] loss\t4.17 =\tBCE 4.17248 \tLL 0.00065 \tTotal 136.78/25.31/77.81 \n","Not implemented\n","04/19/2023 03:35:47 PM - INFO - Training epoch 79.\n","04/19/2023 03:35:47 PM - INFO - [79:0] loss\t4.16 =\tBCE 4.16458 \tLL 0.00065 \tTotal 338.94/59.39/243.38 \n","04/19/2023 03:35:48 PM - INFO - [79:1] loss\t4.09 =\tBCE 4.08876 \tLL 0.00064 \tTotal 175.87/31.34/75.23 \n","04/19/2023 03:35:48 PM - INFO - [79:2] loss\t4.10 =\tBCE 4.09589 \tLL 0.00061 \tTotal 331.92/58.97/215.88 \n","04/19/2023 03:35:49 PM - INFO - [79:3] loss\t3.92 =\tBCE 3.92062 \tLL 0.00060 \tTotal 161.53/32.98/84.95 \n","04/19/2023 03:35:49 PM - INFO - [79:4] loss\t4.04 =\tBCE 4.03936 \tLL 0.00061 \tTotal 362.00/55.52/238.84 \n","04/19/2023 03:35:50 PM - INFO - [79:5] loss\t3.93 =\tBCE 3.93451 \tLL 0.00059 \tTotal 177.77/23.44/122.76 \n","04/19/2023 03:35:50 PM - INFO - [79:6] loss\t3.92 =\tBCE 3.92140 \tLL 0.00060 \tTotal 324.25/41.97/237.77 \n","04/19/2023 03:35:51 PM - INFO - [79:7] loss\t4.15 =\tBCE 4.15402 \tLL 0.00066 \tTotal 257.06/35.12/179.52 \n","04/19/2023 03:35:51 PM - INFO - [79:8] loss\t4.00 =\tBCE 3.99919 \tLL 0.00062 \tTotal 322.61/42.17/249.06 \n","04/19/2023 03:35:52 PM - INFO - [79:9] loss\t4.02 =\tBCE 4.01718 \tLL 0.00065 \tTotal 388.50/51.92/285.96 \n","04/19/2023 03:35:52 PM - INFO - [79:10] loss\t3.86 =\tBCE 3.86001 \tLL 0.00063 \tTotal 174.42/19.51/79.70 \n","04/19/2023 03:35:53 PM - INFO - [79:11] loss\t3.95 =\tBCE 3.94538 \tLL 0.00063 \tTotal 326.71/41.55/235.48 \n","04/19/2023 03:35:54 PM - INFO - [79:12] loss\t3.96 =\tBCE 3.96015 \tLL 0.00065 \tTotal 206.75/28.76/151.04 \n","04/19/2023 03:35:54 PM - INFO - [79:13] loss\t4.24 =\tBCE 4.24333 \tLL 0.00066 \tTotal 449.74/56.77/340.80 \n","04/19/2023 03:35:55 PM - INFO - [79:14] loss\t3.91 =\tBCE 3.91298 \tLL 0.00062 \tTotal 257.82/38.89/179.11 \n","04/19/2023 03:35:55 PM - INFO - [79:15] loss\t3.97 =\tBCE 3.97234 \tLL 0.00064 \tTotal 372.46/51.41/277.32 \n","04/19/2023 03:35:56 PM - INFO - [79:16] loss\t3.91 =\tBCE 3.91275 \tLL 0.00063 \tTotal 299.76/47.46/213.29 \n","04/19/2023 03:35:56 PM - INFO - [79:17] loss\t3.91 =\tBCE 3.91338 \tLL 0.00065 \tTotal 157.68/23.65/101.97 \n","04/19/2023 03:35:57 PM - INFO - [79:18] loss\t3.89 =\tBCE 3.88556 \tLL 0.00064 \tTotal 199.20/39.43/125.88 \n","04/19/2023 03:35:57 PM - INFO - [79:19] loss\t3.85 =\tBCE 3.85492 \tLL 0.00066 \tTotal 217.56/31.83/160.69 \n","04/19/2023 03:35:57 PM - INFO - EVALUATION prior to epoch [80]...\n","04/19/2023 03:35:58 PM - INFO - [80] loss\t3.91=\tBCE 3.91 \tLL 0.00066 \n","04/19/2023 03:35:59 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/80_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:36:04 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/80_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:36:09 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/80_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/19/2023 03:36:10 PM - INFO - Training epoch 80.\n","04/19/2023 03:36:10 PM - INFO - [80:0] loss\t3.75 =\tBCE 3.75493 \tLL 0.00062 \tTotal 212.78/34.99/150.36 \n","04/19/2023 03:36:11 PM - INFO - [80:1] loss\t3.80 =\tBCE 3.80063 \tLL 0.00063 \tTotal 152.41/42.29/82.45 \n","04/19/2023 03:36:11 PM - INFO - [80:2] loss\t3.77 =\tBCE 3.76970 \tLL 0.00066 \tTotal 158.21/24.40/121.05 \n","04/19/2023 03:36:12 PM - INFO - [80:3] loss\t3.79 =\tBCE 3.78584 \tLL 0.00065 \tTotal 241.01/41.30/166.28 \n","04/19/2023 03:36:12 PM - INFO - [80:4] loss\t3.69 =\tBCE 3.69404 \tLL 0.00058 \tTotal 336.93/44.42/266.88 \n","04/19/2023 03:36:13 PM - INFO - [80:5] loss\t3.83 =\tBCE 3.82936 \tLL 0.00066 \tTotal 175.01/27.41/127.09 \n","04/19/2023 03:36:14 PM - INFO - [80:6] loss\t3.85 =\tBCE 3.84521 \tLL 0.00063 \tTotal 461.23/64.71/349.83 \n","04/19/2023 03:36:14 PM - INFO - [80:7] loss\t3.66 =\tBCE 3.66339 \tLL 0.00064 \tTotal 224.18/30.54/167.11 \n","04/19/2023 03:36:15 PM - INFO - [80:8] loss\t3.68 =\tBCE 3.67728 \tLL 0.00063 \tTotal 266.43/44.15/208.33 \n","04/19/2023 03:36:15 PM - INFO - [80:9] loss\t3.74 =\tBCE 3.74233 \tLL 0.00063 \tTotal 410.64/57.58/315.39 \n","04/19/2023 03:36:16 PM - INFO - [80:10] loss\t3.64 =\tBCE 3.64303 \tLL 0.00064 \tTotal 109.74/19.36/86.29 \n","04/19/2023 03:36:16 PM - INFO - [80:11] loss\t3.83 =\tBCE 3.82556 \tLL 0.00068 \tTotal 458.13/74.91/336.82 \n","04/19/2023 03:36:17 PM - INFO - [80:12] loss\t3.73 =\tBCE 3.72817 \tLL 0.00065 \tTotal 289.46/37.34/227.53 \n","04/19/2023 03:36:17 PM - INFO - [80:13] loss\t3.57 =\tBCE 3.57194 \tLL 0.00062 \tTotal 310.96/58.02/195.35 \n","04/19/2023 03:36:18 PM - INFO - [80:14] loss\t3.65 =\tBCE 3.65155 \tLL 0.00063 \tTotal 429.53/53.13/329.54 \n","04/19/2023 03:36:18 PM - INFO - [80:15] loss\t3.60 =\tBCE 3.59889 \tLL 0.00064 \tTotal 331.47/44.91/224.57 \n","04/19/2023 03:36:19 PM - INFO - [80:16] loss\t3.67 =\tBCE 3.67152 \tLL 0.00068 \tTotal 341.71/43.24/249.85 \n","04/19/2023 03:36:20 PM - INFO - [80:17] loss\t3.65 =\tBCE 3.64747 \tLL 0.00067 \tTotal 264.94/37.53/184.59 \n","04/19/2023 03:36:20 PM - INFO - [80:18] loss\t3.75 =\tBCE 3.74774 \tLL 0.00067 \tTotal 254.29/31.29/182.37 \n","04/19/2023 03:36:21 PM - INFO - [80:19] loss\t3.68 =\tBCE 3.67958 \tLL 0.00065 \tTotal 233.99/34.97/154.40 \n","04/19/2023 03:36:21 PM - INFO - Training epoch 81.\n","04/19/2023 03:36:21 PM - INFO - [81:0] loss\t3.68 =\tBCE 3.68043 \tLL 0.00065 \tTotal 278.94/39.44/195.62 \n","04/19/2023 03:36:22 PM - INFO - [81:1] loss\t3.64 =\tBCE 3.64207 \tLL 0.00066 \tTotal 378.97/45.73/302.29 \n","04/19/2023 03:36:22 PM - INFO - [81:2] loss\t3.44 =\tBCE 3.44010 \tLL 0.00065 \tTotal 272.03/38.93/171.35 \n","04/19/2023 03:36:23 PM - INFO - [81:3] loss\t3.56 =\tBCE 3.56190 \tLL 0.00064 \tTotal 433.20/49.41/333.30 \n","04/19/2023 03:36:23 PM - INFO - [81:4] loss\t3.46 =\tBCE 3.46127 \tLL 0.00063 \tTotal 306.55/45.23/188.69 \n","04/19/2023 03:36:24 PM - INFO - [81:5] loss\t3.73 =\tBCE 3.73386 \tLL 0.00070 \tTotal 237.28/23.60/95.96 \n","04/19/2023 03:36:24 PM - INFO - [81:6] loss\t3.47 =\tBCE 3.47170 \tLL 0.00065 \tTotal 184.37/28.81/119.11 \n","04/19/2023 03:36:25 PM - INFO - [81:7] loss\t3.56 =\tBCE 3.56099 \tLL 0.00070 \tTotal 286.90/36.18/206.01 \n","04/19/2023 03:36:25 PM - INFO - [81:8] loss\t3.46 =\tBCE 3.45603 \tLL 0.00069 \tTotal 314.55/38.54/232.68 \n","04/19/2023 03:36:26 PM - INFO - [81:9] loss\t3.38 =\tBCE 3.37996 \tLL 0.00061 \tTotal 159.35/16.87/100.48 \n","04/19/2023 03:36:27 PM - INFO - [81:10] loss\t3.52 =\tBCE 3.51890 \tLL 0.00066 \tTotal 195.98/27.54/142.99 \n","04/19/2023 03:36:27 PM - INFO - [81:11] loss\t3.42 =\tBCE 3.41687 \tLL 0.00062 \tTotal 213.23/21.54/104.78 \n","04/19/2023 03:36:28 PM - INFO - [81:12] loss\t3.50 =\tBCE 3.50189 \tLL 0.00065 \tTotal 146.10/26.57/76.68 \n","04/19/2023 03:36:28 PM - INFO - [81:13] loss\t3.42 =\tBCE 3.42333 \tLL 0.00064 \tTotal 182.08/28.14/114.70 \n","04/19/2023 03:36:29 PM - INFO - [81:14] loss\t3.36 =\tBCE 3.35550 \tLL 0.00065 \tTotal 152.73/23.33/90.44 \n","04/19/2023 03:36:29 PM - INFO - [81:15] loss\t3.50 =\tBCE 3.50170 \tLL 0.00068 \tTotal 238.43/48.77/172.22 \n","04/19/2023 03:36:30 PM - INFO - [81:16] loss\t3.33 =\tBCE 3.33121 \tLL 0.00068 \tTotal 182.02/22.41/90.56 \n","04/19/2023 03:36:30 PM - INFO - [81:17] loss\t3.36 =\tBCE 3.35591 \tLL 0.00065 \tTotal 256.59/42.89/175.40 \n","04/19/2023 03:36:31 PM - INFO - [81:18] loss\t3.34 =\tBCE 3.33685 \tLL 0.00063 \tTotal 284.35/38.55/163.14 \n","04/19/2023 03:36:32 PM - INFO - [81:19] loss\t3.40 =\tBCE 3.39840 \tLL 0.00067 \tTotal 298.90/38.04/222.85 \n","04/19/2023 03:36:32 PM - INFO - Training epoch 82.\n","04/19/2023 03:36:32 PM - INFO - [82:0] loss\t3.30 =\tBCE 3.30054 \tLL 0.00064 \tTotal 148.27/23.62/107.33 \n","04/19/2023 03:36:33 PM - INFO - [82:1] loss\t3.36 =\tBCE 3.36152 \tLL 0.00064 \tTotal 339.30/51.91/223.78 \n","04/19/2023 03:36:33 PM - INFO - [82:2] loss\t3.26 =\tBCE 3.26260 \tLL 0.00063 \tTotal 142.89/19.22/105.65 \n","04/19/2023 03:36:34 PM - INFO - [82:3] loss\t3.32 =\tBCE 3.32133 \tLL 0.00065 \tTotal 283.81/47.97/184.56 \n","04/19/2023 03:36:34 PM - INFO - [82:4] loss\t3.25 =\tBCE 3.24670 \tLL 0.00063 \tTotal 163.12/27.56/103.66 \n","04/19/2023 03:36:35 PM - INFO - [82:5] loss\t3.39 =\tBCE 3.38559 \tLL 0.00068 \tTotal 478.13/67.79/348.75 \n","04/19/2023 03:36:35 PM - INFO - [82:6] loss\t3.21 =\tBCE 3.21346 \tLL 0.00063 \tTotal 328.51/41.36/250.09 \n","04/19/2023 03:36:36 PM - INFO - [82:7] loss\t3.28 =\tBCE 3.28152 \tLL 0.00066 \tTotal 155.24/21.67/119.55 \n","04/19/2023 03:36:36 PM - INFO - [82:8] loss\t3.28 =\tBCE 3.27815 \tLL 0.00068 \tTotal 258.78/34.68/154.17 \n","04/19/2023 03:36:37 PM - INFO - [82:9] loss\t3.35 =\tBCE 3.34686 \tLL 0.00064 \tTotal 258.72/36.17/187.13 \n","04/19/2023 03:36:38 PM - INFO - [82:10] loss\t3.26 =\tBCE 3.25764 \tLL 0.00067 \tTotal 418.67/54.50/303.09 \n","04/19/2023 03:36:38 PM - INFO - [82:11] loss\t3.20 =\tBCE 3.19825 \tLL 0.00063 \tTotal 167.71/22.16/78.86 \n","04/19/2023 03:36:39 PM - INFO - [82:12] loss\t3.35 =\tBCE 3.34928 \tLL 0.00068 \tTotal 459.83/59.00/346.08 \n","04/19/2023 03:36:39 PM - INFO - [82:13] loss\t3.09 =\tBCE 3.09041 \tLL 0.00065 \tTotal 200.03/33.80/127.67 \n","04/19/2023 03:36:40 PM - INFO - [82:14] loss\t3.39 =\tBCE 3.38967 \tLL 0.00072 \tTotal 519.23/67.01/405.39 \n","04/19/2023 03:36:40 PM - INFO - [82:15] loss\t3.28 =\tBCE 3.28227 \tLL 0.00066 \tTotal 567.82/74.62/453.66 \n","04/19/2023 03:36:41 PM - INFO - [82:16] loss\t3.27 =\tBCE 3.26923 \tLL 0.00068 \tTotal 148.60/31.32/79.59 \n","04/19/2023 03:36:41 PM - INFO - [82:17] loss\t3.32 =\tBCE 3.32199 \tLL 0.00070 \tTotal 458.87/62.67/344.56 \n","04/19/2023 03:36:42 PM - INFO - [82:18] loss\t3.32 =\tBCE 3.31652 \tLL 0.00071 \tTotal 228.94/42.32/175.69 \n","04/19/2023 03:36:43 PM - INFO - [82:19] loss\t3.13 =\tBCE 3.13191 \tLL 0.00065 \tTotal 367.04/56.06/240.80 \n","04/19/2023 03:36:43 PM - INFO - Training epoch 83.\n","04/19/2023 03:36:43 PM - INFO - [83:0] loss\t3.16 =\tBCE 3.16192 \tLL 0.00066 \tTotal 340.99/58.34/242.69 \n","04/19/2023 03:36:44 PM - INFO - [83:1] loss\t3.17 =\tBCE 3.17339 \tLL 0.00066 \tTotal 233.45/41.52/140.46 \n","04/19/2023 03:36:44 PM - INFO - [83:2] loss\t3.21 =\tBCE 3.20624 \tLL 0.00067 \tTotal 467.00/69.37/340.68 \n","04/19/2023 03:36:45 PM - INFO - [83:3] loss\t3.10 =\tBCE 3.10124 \tLL 0.00065 \tTotal 345.48/47.55/281.98 \n","04/19/2023 03:36:45 PM - INFO - [83:4] loss\t3.05 =\tBCE 3.05144 \tLL 0.00065 \tTotal 196.88/25.21/132.27 \n","04/19/2023 03:36:46 PM - INFO - [83:5] loss\t3.10 =\tBCE 3.09644 \tLL 0.00064 \tTotal 284.00/42.23/212.09 \n","04/19/2023 03:36:46 PM - INFO - [83:6] loss\t3.13 =\tBCE 3.13492 \tLL 0.00068 \tTotal 191.56/32.85/133.83 \n","04/19/2023 03:36:47 PM - INFO - [83:7] loss\t3.24 =\tBCE 3.23791 \tLL 0.00070 \tTotal 277.80/41.42/154.01 \n","04/19/2023 03:36:47 PM - INFO - [83:8] loss\t3.19 =\tBCE 3.19364 \tLL 0.00069 \tTotal 364.11/44.40/296.75 \n","04/19/2023 03:36:48 PM - INFO - [83:9] loss\t3.08 =\tBCE 3.08067 \tLL 0.00065 \tTotal 274.96/46.45/166.47 \n","04/19/2023 03:36:49 PM - INFO - [83:10] loss\t2.98 =\tBCE 2.98009 \tLL 0.00066 \tTotal 395.37/44.89/282.02 \n","04/19/2023 03:36:49 PM - INFO - [83:11] loss\t3.31 =\tBCE 3.30577 \tLL 0.00071 \tTotal 658.78/92.40/506.55 \n","04/19/2023 03:36:50 PM - INFO - [83:12] loss\t3.09 =\tBCE 3.08869 \tLL 0.00066 \tTotal 289.85/38.85/183.89 \n","04/19/2023 03:36:50 PM - INFO - [83:13] loss\t3.13 =\tBCE 3.13026 \tLL 0.00065 \tTotal 534.39/74.60/408.72 \n","04/19/2023 03:36:51 PM - INFO - [83:14] loss\t3.14 =\tBCE 3.13909 \tLL 0.00068 \tTotal 628.18/87.96/470.68 \n","04/19/2023 03:36:51 PM - INFO - [83:15] loss\t3.04 =\tBCE 3.03610 \tLL 0.00065 \tTotal 181.92/17.03/125.72 \n","04/19/2023 03:36:52 PM - INFO - [83:16] loss\t3.07 =\tBCE 3.06819 \tLL 0.00064 \tTotal 579.36/79.95/426.65 \n","04/19/2023 03:36:52 PM - INFO - [83:17] loss\t3.05 =\tBCE 3.04716 \tLL 0.00067 \tTotal 323.26/44.67/254.86 \n","04/19/2023 03:36:53 PM - INFO - [83:18] loss\t3.03 =\tBCE 3.03215 \tLL 0.00068 \tTotal 244.89/37.11/173.56 \n","04/19/2023 03:36:53 PM - INFO - [83:19] loss\t3.05 =\tBCE 3.04936 \tLL 0.00068 \tTotal 348.05/39.33/275.19 \n","04/19/2023 03:36:53 PM - INFO - Training epoch 84.\n","04/19/2023 03:36:54 PM - INFO - [84:0] loss\t2.97 =\tBCE 2.97199 \tLL 0.00066 \tTotal 188.71/35.14/125.15 \n","04/19/2023 03:36:54 PM - INFO - [84:1] loss\t2.93 =\tBCE 2.92518 \tLL 0.00063 \tTotal 368.34/42.88/284.53 \n","04/19/2023 03:36:55 PM - INFO - [84:2] loss\t3.05 =\tBCE 3.05103 \tLL 0.00069 \tTotal 214.56/29.78/130.12 \n","04/19/2023 03:36:56 PM - INFO - [84:3] loss\t2.97 =\tBCE 2.97362 \tLL 0.00066 \tTotal 191.21/28.93/121.08 \n","04/19/2023 03:36:56 PM - INFO - [84:4] loss\t2.99 =\tBCE 2.98833 \tLL 0.00066 \tTotal 378.47/55.47/266.05 \n","04/19/2023 03:36:57 PM - INFO - [84:5] loss\t2.94 =\tBCE 2.93753 \tLL 0.00067 \tTotal 440.43/54.51/348.83 \n","04/19/2023 03:36:57 PM - INFO - [84:6] loss\t2.95 =\tBCE 2.95125 \tLL 0.00066 \tTotal 160.86/28.85/111.19 \n","04/19/2023 03:36:58 PM - INFO - [84:7] loss\t2.94 =\tBCE 2.94234 \tLL 0.00068 \tTotal 401.62/50.00/301.77 \n","04/19/2023 03:36:58 PM - INFO - [84:8] loss\t2.99 =\tBCE 2.99397 \tLL 0.00068 \tTotal 309.12/41.70/228.55 \n","04/19/2023 03:36:59 PM - INFO - [84:9] loss\t2.89 =\tBCE 2.89316 \tLL 0.00066 \tTotal 248.41/33.93/177.02 \n","04/19/2023 03:36:59 PM - INFO - [84:10] loss\t2.99 =\tBCE 2.98673 \tLL 0.00070 \tTotal 381.90/46.25/274.65 \n","04/19/2023 03:37:00 PM - INFO - [84:11] loss\t2.83 =\tBCE 2.82620 \tLL 0.00063 \tTotal 287.28/44.84/190.78 \n","04/19/2023 03:37:01 PM - INFO - [84:12] loss\t2.97 =\tBCE 2.96624 \tLL 0.00069 \tTotal 239.81/30.51/172.59 \n","04/19/2023 03:37:01 PM - INFO - [84:13] loss\t2.87 =\tBCE 2.87011 \tLL 0.00070 \tTotal 306.17/44.39/219.51 \n","04/19/2023 03:37:02 PM - INFO - [84:14] loss\t2.87 =\tBCE 2.87415 \tLL 0.00064 \tTotal 204.12/19.58/106.80 \n","04/19/2023 03:37:02 PM - INFO - [84:15] loss\t2.93 =\tBCE 2.92990 \tLL 0.00065 \tTotal 355.64/49.58/254.27 \n","04/19/2023 03:37:03 PM - INFO - [84:16] loss\t2.94 =\tBCE 2.93863 \tLL 0.00068 \tTotal 343.86/43.80/250.30 \n","04/19/2023 03:37:03 PM - INFO - [84:17] loss\t2.80 =\tBCE 2.80111 \tLL 0.00068 \tTotal 181.26/21.71/99.32 \n","04/19/2023 03:37:04 PM - INFO - [84:18] loss\t2.78 =\tBCE 2.78165 \tLL 0.00068 \tTotal 215.63/26.35/163.61 \n","04/19/2023 03:37:04 PM - INFO - [84:19] loss\t2.89 =\tBCE 2.88772 \tLL 0.00065 \tTotal 323.49/43.37/240.37 \n","04/19/2023 03:37:04 PM - INFO - Training epoch 85.\n","04/19/2023 03:37:05 PM - INFO - [85:0] loss\t2.81 =\tBCE 2.81198 \tLL 0.00064 \tTotal 267.16/33.78/190.90 \n","04/19/2023 03:37:05 PM - INFO - [85:1] loss\t2.81 =\tBCE 2.81301 \tLL 0.00068 \tTotal 198.68/26.24/93.92 \n","04/19/2023 03:37:06 PM - INFO - [85:2] loss\t2.87 =\tBCE 2.86622 \tLL 0.00067 \tTotal 349.44/40.04/271.61 \n","04/19/2023 03:37:06 PM - INFO - [85:3] loss\t2.85 =\tBCE 2.84657 \tLL 0.00068 \tTotal 273.42/32.65/217.02 \n","04/19/2023 03:37:07 PM - INFO - [85:4] loss\t2.83 =\tBCE 2.82969 \tLL 0.00067 \tTotal 190.14/23.22/128.09 \n","04/19/2023 03:37:07 PM - INFO - [85:5] loss\t2.74 =\tBCE 2.73943 \tLL 0.00065 \tTotal 275.60/41.34/201.09 \n","04/19/2023 03:37:08 PM - INFO - [85:6] loss\t2.77 =\tBCE 2.76678 \tLL 0.00067 \tTotal 314.97/45.40/212.81 \n","04/19/2023 03:37:09 PM - INFO - [85:7] loss\t2.71 =\tBCE 2.70754 \tLL 0.00065 \tTotal 164.01/21.14/85.76 \n","04/19/2023 03:37:09 PM - INFO - [85:8] loss\t2.77 =\tBCE 2.77325 \tLL 0.00066 \tTotal 332.87/44.25/273.54 \n","04/19/2023 03:37:10 PM - INFO - [85:9] loss\t2.78 =\tBCE 2.77516 \tLL 0.00066 \tTotal 337.54/46.51/227.18 \n","04/19/2023 03:37:10 PM - INFO - [85:10] loss\t2.74 =\tBCE 2.74278 \tLL 0.00066 \tTotal 177.96/24.41/121.88 \n","04/19/2023 03:37:11 PM - INFO - [85:11] loss\t2.73 =\tBCE 2.73284 \tLL 0.00067 \tTotal 234.88/29.62/171.30 \n","04/19/2023 03:37:11 PM - INFO - [85:12] loss\t2.80 =\tBCE 2.80093 \tLL 0.00065 \tTotal 158.62/21.91/64.42 \n","04/19/2023 03:37:12 PM - INFO - [85:13] loss\t2.76 =\tBCE 2.75610 \tLL 0.00068 \tTotal 247.51/27.42/167.24 \n","04/19/2023 03:37:12 PM - INFO - [85:14] loss\t2.68 =\tBCE 2.67530 \tLL 0.00067 \tTotal 222.77/30.65/138.70 \n","04/19/2023 03:37:13 PM - INFO - [85:15] loss\t2.72 =\tBCE 2.71564 \tLL 0.00065 \tTotal 181.77/23.77/98.94 \n","04/19/2023 03:37:13 PM - INFO - [85:16] loss\t2.67 =\tBCE 2.66647 \tLL 0.00067 \tTotal 162.46/20.62/114.56 \n","04/19/2023 03:37:14 PM - INFO - [85:17] loss\t2.74 =\tBCE 2.74160 \tLL 0.00067 \tTotal 229.06/28.73/163.50 \n","04/19/2023 03:37:15 PM - INFO - [85:18] loss\t2.70 =\tBCE 2.69645 \tLL 0.00068 \tTotal 279.46/32.80/206.95 \n","04/19/2023 03:37:15 PM - INFO - [85:19] loss\t2.76 =\tBCE 2.76007 \tLL 0.00073 \tTotal 134.01/13.74/92.99 \n","04/19/2023 03:37:15 PM - INFO - Training epoch 86.\n","04/19/2023 03:37:16 PM - INFO - [86:0] loss\t2.70 =\tBCE 2.70094 \tLL 0.00066 \tTotal 242.11/28.21/159.34 \n","04/19/2023 03:37:16 PM - INFO - [86:1] loss\t2.62 =\tBCE 2.61539 \tLL 0.00063 \tTotal 131.47/15.66/101.01 \n","04/19/2023 03:37:17 PM - INFO - [86:2] loss\t2.69 =\tBCE 2.68900 \tLL 0.00069 \tTotal 178.84/23.06/105.06 \n","04/19/2023 03:37:17 PM - INFO - [86:3] loss\t2.62 =\tBCE 2.61865 \tLL 0.00067 \tTotal 196.05/24.66/145.59 \n","04/19/2023 03:37:18 PM - INFO - [86:4] loss\t2.64 =\tBCE 2.63689 \tLL 0.00067 \tTotal 199.81/20.14/137.29 \n","04/19/2023 03:37:18 PM - INFO - [86:5] loss\t2.68 =\tBCE 2.68250 \tLL 0.00064 \tTotal 163.78/26.60/100.39 \n","04/19/2023 03:37:19 PM - INFO - [86:6] loss\t2.64 =\tBCE 2.63595 \tLL 0.00067 \tTotal 86.71/13.39/49.83 \n","04/19/2023 03:37:19 PM - INFO - [86:7] loss\t2.51 =\tBCE 2.51461 \tLL 0.00065 \tTotal 131.30/12.54/84.71 \n","04/19/2023 03:37:20 PM - INFO - [86:8] loss\t2.67 =\tBCE 2.66697 \tLL 0.00068 \tTotal 139.92/33.71/106.09 \n","04/19/2023 03:37:20 PM - INFO - [86:9] loss\t2.62 =\tBCE 2.61966 \tLL 0.00066 \tTotal 155.65/23.82/109.59 \n","04/19/2023 03:37:21 PM - INFO - [86:10] loss\t2.58 =\tBCE 2.57538 \tLL 0.00064 \tTotal 116.46/22.48/76.00 \n","04/19/2023 03:37:21 PM - INFO - [86:11] loss\t2.51 =\tBCE 2.50688 \tLL 0.00066 \tTotal 160.20/23.34/124.39 \n","04/19/2023 03:37:22 PM - INFO - [86:12] loss\t2.63 =\tBCE 2.63289 \tLL 0.00067 \tTotal 167.25/25.34/119.81 \n","04/19/2023 03:37:23 PM - INFO - [86:13] loss\t2.60 =\tBCE 2.60254 \tLL 0.00067 \tTotal 198.61/30.16/161.24 \n","04/19/2023 03:37:23 PM - INFO - [86:14] loss\t2.58 =\tBCE 2.58036 \tLL 0.00066 \tTotal 200.80/24.43/128.29 \n","04/19/2023 03:37:24 PM - INFO - [86:15] loss\t2.63 =\tBCE 2.63372 \tLL 0.00065 \tTotal 171.02/33.44/141.43 \n","04/19/2023 03:37:24 PM - INFO - [86:16] loss\t2.56 =\tBCE 2.56389 \tLL 0.00065 \tTotal 210.91/20.99/122.28 \n","04/19/2023 03:37:25 PM - INFO - [86:17] loss\t2.60 =\tBCE 2.60381 \tLL 0.00066 \tTotal 240.86/33.17/185.56 \n","04/19/2023 03:37:25 PM - INFO - [86:18] loss\t2.66 =\tBCE 2.66027 \tLL 0.00067 \tTotal 336.90/44.67/247.47 \n","04/19/2023 03:37:26 PM - INFO - [86:19] loss\t2.64 =\tBCE 2.64358 \tLL 0.00072 \tTotal 231.20/35.86/179.14 \n","04/19/2023 03:37:26 PM - INFO - Training epoch 87.\n","04/19/2023 03:37:26 PM - INFO - [87:0] loss\t2.68 =\tBCE 2.68003 \tLL 0.00073 \tTotal 220.95/31.61/151.31 \n","04/19/2023 03:37:27 PM - INFO - [87:1] loss\t2.60 =\tBCE 2.59970 \tLL 0.00066 \tTotal 469.38/66.55/379.33 \n","04/19/2023 03:37:28 PM - INFO - [87:2] loss\t2.61 =\tBCE 2.61214 \tLL 0.00067 \tTotal 337.57/43.06/264.42 \n","04/19/2023 03:37:28 PM - INFO - [87:3] loss\t2.65 =\tBCE 2.65312 \tLL 0.00070 \tTotal 167.65/39.37/127.04 \n","04/19/2023 03:37:29 PM - INFO - [87:4] loss\t2.51 =\tBCE 2.51035 \tLL 0.00067 \tTotal 260.76/36.17/199.16 \n","04/19/2023 03:37:29 PM - INFO - [87:5] loss\t2.48 =\tBCE 2.48364 \tLL 0.00064 \tTotal 145.17/37.30/60.32 \n","04/19/2023 03:37:30 PM - INFO - [87:6] loss\t2.55 =\tBCE 2.54745 \tLL 0.00069 \tTotal 340.88/47.58/268.03 \n","04/19/2023 03:37:30 PM - INFO - [87:7] loss\t2.53 =\tBCE 2.53148 \tLL 0.00065 \tTotal 352.26/48.52/256.72 \n","04/19/2023 03:37:31 PM - INFO - [87:8] loss\t2.56 =\tBCE 2.55633 \tLL 0.00069 \tTotal 172.65/26.03/77.21 \n","04/19/2023 03:37:31 PM - INFO - [87:9] loss\t2.51 =\tBCE 2.51131 \tLL 0.00066 \tTotal 502.04/63.66/396.94 \n","04/19/2023 03:37:32 PM - INFO - [87:10] loss\t2.58 =\tBCE 2.58143 \tLL 0.00069 \tTotal 465.20/67.64/355.90 \n","04/19/2023 03:37:32 PM - INFO - [87:11] loss\t2.51 =\tBCE 2.50919 \tLL 0.00068 \tTotal 153.40/21.82/122.62 \n","04/19/2023 03:37:33 PM - INFO - [87:12] loss\t2.57 =\tBCE 2.57012 \tLL 0.00067 \tTotal 640.05/87.88/486.89 \n","04/19/2023 03:37:33 PM - INFO - [87:13] loss\t2.55 =\tBCE 2.54672 \tLL 0.00067 \tTotal 492.84/60.75/393.59 \n","04/19/2023 03:37:34 PM - INFO - [87:14] loss\t2.55 =\tBCE 2.54865 \tLL 0.00067 \tTotal 187.70/38.02/106.86 \n","04/19/2023 03:37:34 PM - INFO - [87:15] loss\t2.48 =\tBCE 2.48443 \tLL 0.00065 \tTotal 489.86/61.34/379.56 \n","04/19/2023 03:37:35 PM - INFO - [87:16] loss\t2.45 =\tBCE 2.44649 \tLL 0.00065 \tTotal 389.99/57.33/299.13 \n","04/19/2023 03:37:36 PM - INFO - [87:17] loss\t2.42 =\tBCE 2.41805 \tLL 0.00068 \tTotal 196.56/25.83/109.50 \n","04/19/2023 03:37:36 PM - INFO - [87:18] loss\t2.44 =\tBCE 2.44480 \tLL 0.00063 \tTotal 497.40/73.57/377.02 \n","04/19/2023 03:37:37 PM - INFO - [87:19] loss\t2.59 =\tBCE 2.58576 \tLL 0.00067 \tTotal 432.45/63.69/340.33 \n","04/19/2023 03:37:37 PM - INFO - Training epoch 88.\n","04/19/2023 03:37:37 PM - INFO - [88:0] loss\t2.45 =\tBCE 2.45202 \tLL 0.00067 \tTotal 168.53/18.55/102.27 \n","04/19/2023 03:37:38 PM - INFO - [88:1] loss\t2.46 =\tBCE 2.46062 \tLL 0.00070 \tTotal 471.41/65.04/366.15 \n","04/19/2023 03:37:38 PM - INFO - [88:2] loss\t2.45 =\tBCE 2.44808 \tLL 0.00067 \tTotal 318.71/41.97/238.59 \n","04/19/2023 03:37:39 PM - INFO - [88:3] loss\t2.41 =\tBCE 2.41180 \tLL 0.00064 \tTotal 273.31/42.46/197.27 \n","04/19/2023 03:37:39 PM - INFO - [88:4] loss\t2.51 =\tBCE 2.51008 \tLL 0.00069 \tTotal 538.39/70.89/425.34 \n","04/19/2023 03:37:40 PM - INFO - [88:5] loss\t2.38 =\tBCE 2.38052 \tLL 0.00065 \tTotal 214.00/21.48/166.44 \n","04/19/2023 03:37:40 PM - INFO - [88:6] loss\t2.53 =\tBCE 2.53019 \tLL 0.00069 \tTotal 490.81/62.17/394.16 \n","04/19/2023 03:37:41 PM - INFO - [88:7] loss\t2.51 =\tBCE 2.50744 \tLL 0.00067 \tTotal 544.55/66.88/407.97 \n","04/19/2023 03:37:42 PM - INFO - [88:8] loss\t2.33 =\tBCE 2.33010 \tLL 0.00065 \tTotal 114.93/25.40/81.80 \n","04/19/2023 03:37:42 PM - INFO - [88:9] loss\t2.41 =\tBCE 2.40501 \tLL 0.00067 \tTotal 437.81/54.03/340.82 \n","04/19/2023 03:37:43 PM - INFO - [88:10] loss\t2.47 =\tBCE 2.47034 \tLL 0.00069 \tTotal 454.35/57.78/345.20 \n","04/19/2023 03:37:43 PM - INFO - [88:11] loss\t2.46 =\tBCE 2.45790 \tLL 0.00070 \tTotal 235.72/35.14/139.47 \n","04/19/2023 03:37:44 PM - INFO - [88:12] loss\t2.40 =\tBCE 2.40012 \tLL 0.00068 \tTotal 280.51/38.22/200.48 \n","04/19/2023 03:37:44 PM - INFO - [88:13] loss\t2.45 =\tBCE 2.44936 \tLL 0.00066 \tTotal 310.14/39.75/240.83 \n","04/19/2023 03:37:45 PM - INFO - [88:14] loss\t2.44 =\tBCE 2.43880 \tLL 0.00069 \tTotal 178.01/33.36/79.96 \n","04/19/2023 03:37:45 PM - INFO - [88:15] loss\t2.42 =\tBCE 2.42390 \tLL 0.00065 \tTotal 315.09/36.63/182.86 \n","04/19/2023 03:37:46 PM - INFO - [88:16] loss\t2.40 =\tBCE 2.40076 \tLL 0.00067 \tTotal 348.51/53.59/232.44 \n","04/19/2023 03:37:46 PM - INFO - [88:17] loss\t2.46 =\tBCE 2.46068 \tLL 0.00071 \tTotal 195.41/42.88/144.25 \n","04/19/2023 03:37:47 PM - INFO - [88:18] loss\t2.31 =\tBCE 2.31455 \tLL 0.00067 \tTotal 246.98/30.77/143.66 \n","04/19/2023 03:37:47 PM - INFO - [88:19] loss\t2.39 =\tBCE 2.39159 \tLL 0.00070 \tTotal 314.51/61.26/231.65 \n","Not implemented\n","04/19/2023 03:37:47 PM - INFO - Training epoch 89.\n","04/19/2023 03:37:48 PM - INFO - [89:0] loss\t2.42 =\tBCE 2.41708 \tLL 0.00067 \tTotal 301.48/30.46/162.40 \n","04/19/2023 03:37:49 PM - INFO - [89:1] loss\t2.32 =\tBCE 2.32331 \tLL 0.00067 \tTotal 195.61/51.22/103.12 \n","04/19/2023 03:37:49 PM - INFO - [89:2] loss\t2.41 =\tBCE 2.41448 \tLL 0.00069 \tTotal 271.78/32.61/165.63 \n","04/19/2023 03:37:50 PM - INFO - [89:3] loss\t2.40 =\tBCE 2.40241 \tLL 0.00069 \tTotal 219.43/38.75/161.81 \n","04/19/2023 03:37:50 PM - INFO - [89:4] loss\t2.29 =\tBCE 2.29023 \tLL 0.00066 \tTotal 364.85/57.83/236.37 \n","04/19/2023 03:37:51 PM - INFO - [89:5] loss\t2.34 =\tBCE 2.33530 \tLL 0.00069 \tTotal 428.53/59.76/340.41 \n","04/19/2023 03:37:51 PM - INFO - [89:6] loss\t2.49 =\tBCE 2.48597 \tLL 0.00069 \tTotal 445.53/83.31/302.04 \n","04/19/2023 03:37:52 PM - INFO - [89:7] loss\t2.38 =\tBCE 2.37975 \tLL 0.00067 \tTotal 163.38/25.33/102.68 \n","04/19/2023 03:37:52 PM - INFO - [89:8] loss\t2.41 =\tBCE 2.40706 \tLL 0.00065 \tTotal 320.35/64.06/183.69 \n","04/19/2023 03:37:53 PM - INFO - [89:9] loss\t2.31 =\tBCE 2.31065 \tLL 0.00068 \tTotal 216.11/34.94/150.52 \n","04/19/2023 03:37:53 PM - INFO - [89:10] loss\t2.30 =\tBCE 2.30053 \tLL 0.00066 \tTotal 278.83/45.95/93.01 \n","04/19/2023 03:37:54 PM - INFO - [89:11] loss\t2.34 =\tBCE 2.33804 \tLL 0.00068 \tTotal 360.00/46.92/279.72 \n","04/19/2023 03:37:55 PM - INFO - [89:12] loss\t2.32 =\tBCE 2.31578 \tLL 0.00066 \tTotal 454.39/63.17/310.41 \n","04/19/2023 03:37:55 PM - INFO - [89:13] loss\t2.27 =\tBCE 2.26602 \tLL 0.00064 \tTotal 203.77/26.82/121.12 \n","04/19/2023 03:37:56 PM - INFO - [89:14] loss\t2.28 =\tBCE 2.28176 \tLL 0.00066 \tTotal 298.56/41.63/144.12 \n","04/19/2023 03:37:56 PM - INFO - [89:15] loss\t2.38 =\tBCE 2.38369 \tLL 0.00071 \tTotal 362.13/41.32/275.53 \n","04/19/2023 03:37:57 PM - INFO - [89:16] loss\t2.35 =\tBCE 2.35158 \tLL 0.00068 \tTotal 187.23/34.59/125.01 \n","04/19/2023 03:37:57 PM - INFO - [89:17] loss\t2.21 =\tBCE 2.20725 \tLL 0.00066 \tTotal 243.36/25.61/189.22 \n","04/19/2023 03:37:58 PM - INFO - [89:18] loss\t2.19 =\tBCE 2.18516 \tLL 0.00065 \tTotal 170.48/40.63/106.45 \n","04/19/2023 03:37:58 PM - INFO - [89:19] loss\t2.32 =\tBCE 2.31877 \tLL 0.00068 \tTotal 270.51/34.63/215.89 \n","04/19/2023 03:37:58 PM - INFO - EVALUATION prior to epoch [90]...\n","04/19/2023 03:37:59 PM - INFO - [90] loss\t2.39=\tBCE 2.39 \tLL 0.00067 \n","04/19/2023 03:38:00 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/90_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:38:04 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/90_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:38:11 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/90_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/19/2023 03:38:11 PM - INFO - Training epoch 90.\n","04/19/2023 03:38:12 PM - INFO - [90:0] loss\t2.30 =\tBCE 2.30067 \tLL 0.00064 \tTotal 569.48/88.12/422.34 \n","04/19/2023 03:38:12 PM - INFO - [90:1] loss\t2.27 =\tBCE 2.26611 \tLL 0.00066 \tTotal 492.96/63.79/391.68 \n","04/19/2023 03:38:13 PM - INFO - [90:2] loss\t2.24 =\tBCE 2.24172 \tLL 0.00066 \tTotal 166.97/17.98/91.39 \n","04/19/2023 03:38:13 PM - INFO - [90:3] loss\t2.24 =\tBCE 2.23592 \tLL 0.00068 \tTotal 321.08/44.91/230.88 \n","04/19/2023 03:38:14 PM - INFO - [90:4] loss\t2.20 =\tBCE 2.19849 \tLL 0.00066 \tTotal 166.41/27.53/111.04 \n","04/19/2023 03:38:14 PM - INFO - [90:5] loss\t2.18 =\tBCE 2.17611 \tLL 0.00067 \tTotal 298.73/42.34/205.69 \n","04/19/2023 03:38:15 PM - INFO - [90:6] loss\t2.33 =\tBCE 2.33225 \tLL 0.00067 \tTotal 366.27/50.38/295.41 \n","04/19/2023 03:38:15 PM - INFO - [90:7] loss\t2.16 =\tBCE 2.15882 \tLL 0.00065 \tTotal 224.70/31.81/156.04 \n","04/19/2023 03:38:16 PM - INFO - [90:8] loss\t2.21 =\tBCE 2.20947 \tLL 0.00065 \tTotal 200.18/41.80/135.30 \n","04/19/2023 03:38:17 PM - INFO - [90:9] loss\t2.18 =\tBCE 2.17636 \tLL 0.00066 \tTotal 277.45/31.99/209.84 \n","04/19/2023 03:38:17 PM - INFO - [90:10] loss\t2.19 =\tBCE 2.19372 \tLL 0.00065 \tTotal 130.87/24.29/87.55 \n","04/19/2023 03:38:18 PM - INFO - [90:11] loss\t2.27 =\tBCE 2.27204 \tLL 0.00068 \tTotal 247.51/28.46/182.98 \n","04/19/2023 03:38:18 PM - INFO - [90:12] loss\t2.26 =\tBCE 2.26230 \tLL 0.00068 \tTotal 320.12/42.16/240.73 \n","04/19/2023 03:38:19 PM - INFO - [90:13] loss\t2.29 =\tBCE 2.28799 \tLL 0.00071 \tTotal 349.41/44.42/283.26 \n","04/19/2023 03:38:19 PM - INFO - [90:14] loss\t2.20 =\tBCE 2.19642 \tLL 0.00068 \tTotal 266.92/22.69/180.24 \n","04/19/2023 03:38:20 PM - INFO - [90:15] loss\t2.20 =\tBCE 2.20078 \tLL 0.00071 \tTotal 253.56/33.91/181.10 \n","04/19/2023 03:38:20 PM - INFO - [90:16] loss\t2.20 =\tBCE 2.20370 \tLL 0.00065 \tTotal 359.52/49.40/258.52 \n","04/19/2023 03:38:21 PM - INFO - [90:17] loss\t2.25 =\tBCE 2.25134 \tLL 0.00071 \tTotal 224.17/30.10/129.33 \n","04/19/2023 03:38:21 PM - INFO - [90:18] loss\t2.18 =\tBCE 2.17808 \tLL 0.00062 \tTotal 491.48/67.93/378.17 \n","04/19/2023 03:38:22 PM - INFO - [90:19] loss\t2.25 =\tBCE 2.25237 \tLL 0.00067 \tTotal 495.79/63.85/379.84 \n","04/19/2023 03:38:22 PM - INFO - Training epoch 91.\n","04/19/2023 03:38:23 PM - INFO - [91:0] loss\t2.25 =\tBCE 2.25100 \tLL 0.00069 \tTotal 196.33/38.33/106.81 \n","04/19/2023 03:38:23 PM - INFO - [91:1] loss\t2.11 =\tBCE 2.11352 \tLL 0.00064 \tTotal 412.94/56.79/308.60 \n","04/19/2023 03:38:24 PM - INFO - [91:2] loss\t2.23 =\tBCE 2.23026 \tLL 0.00067 \tTotal 482.85/69.08/375.29 \n","04/19/2023 03:38:24 PM - INFO - [91:3] loss\t2.07 =\tBCE 2.06625 \tLL 0.00063 \tTotal 124.11/20.20/82.37 \n","04/19/2023 03:38:25 PM - INFO - [91:4] loss\t2.22 =\tBCE 2.21566 \tLL 0.00065 \tTotal 489.04/71.17/359.61 \n","04/19/2023 03:38:25 PM - INFO - [91:5] loss\t2.23 =\tBCE 2.23016 \tLL 0.00066 \tTotal 688.71/101.71/530.22 \n","04/19/2023 03:38:26 PM - INFO - [91:6] loss\t2.22 =\tBCE 2.21626 \tLL 0.00068 \tTotal 459.72/61.54/366.26 \n","04/19/2023 03:38:26 PM - INFO - [91:7] loss\t2.25 =\tBCE 2.24554 \tLL 0.00069 \tTotal 325.43/54.44/256.68 \n","04/19/2023 03:38:27 PM - INFO - [91:8] loss\t2.20 =\tBCE 2.20420 \tLL 0.00068 \tTotal 634.77/85.28/465.95 \n","04/19/2023 03:38:27 PM - INFO - [91:9] loss\t2.15 =\tBCE 2.15189 \tLL 0.00066 \tTotal 286.05/43.67/190.95 \n","04/19/2023 03:38:28 PM - INFO - [91:10] loss\t2.17 =\tBCE 2.17427 \tLL 0.00068 \tTotal 290.48/45.88/180.51 \n","04/19/2023 03:38:28 PM - INFO - [91:11] loss\t2.20 =\tBCE 2.19602 \tLL 0.00070 \tTotal 555.97/60.73/437.96 \n","04/19/2023 03:38:29 PM - INFO - [91:12] loss\t2.27 =\tBCE 2.26947 \tLL 0.00072 \tTotal 499.00/64.12/346.10 \n","04/19/2023 03:38:30 PM - INFO - [91:13] loss\t2.16 =\tBCE 2.16289 \tLL 0.00066 \tTotal 196.71/26.24/108.84 \n","04/19/2023 03:38:30 PM - INFO - [91:14] loss\t2.14 =\tBCE 2.14004 \tLL 0.00066 \tTotal 450.46/69.95/325.10 \n","04/19/2023 03:38:31 PM - INFO - [91:15] loss\t2.23 =\tBCE 2.23116 \tLL 0.00067 \tTotal 644.45/77.63/517.85 \n","04/19/2023 03:38:31 PM - INFO - [91:16] loss\t2.18 =\tBCE 2.17950 \tLL 0.00069 \tTotal 300.47/68.22/193.13 \n","04/19/2023 03:38:32 PM - INFO - [91:17] loss\t2.14 =\tBCE 2.13559 \tLL 0.00066 \tTotal 405.26/50.96/297.73 \n","04/19/2023 03:38:32 PM - INFO - [91:18] loss\t2.26 =\tBCE 2.25983 \tLL 0.00069 \tTotal 589.44/96.02/454.17 \n","04/19/2023 03:38:33 PM - INFO - [91:19] loss\t2.11 =\tBCE 2.10930 \tLL 0.00067 \tTotal 372.92/43.95/251.57 \n","04/19/2023 03:38:33 PM - INFO - Training epoch 92.\n","04/19/2023 03:38:33 PM - INFO - [92:0] loss\t2.07 =\tBCE 2.07162 \tLL 0.00069 \tTotal 308.35/62.40/247.54 \n","04/19/2023 03:38:34 PM - INFO - [92:1] loss\t2.16 =\tBCE 2.15556 \tLL 0.00066 \tTotal 592.94/83.64/434.52 \n","04/19/2023 03:38:34 PM - INFO - [92:2] loss\t2.16 =\tBCE 2.15859 \tLL 0.00070 \tTotal 371.93/63.40/277.98 \n","04/19/2023 03:38:35 PM - INFO - [92:3] loss\t2.10 =\tBCE 2.09880 \tLL 0.00065 \tTotal 272.50/46.26/123.69 \n","04/19/2023 03:38:36 PM - INFO - [92:4] loss\t2.07 =\tBCE 2.06931 \tLL 0.00067 \tTotal 371.81/55.68/271.75 \n","04/19/2023 03:38:36 PM - INFO - [92:5] loss\t2.14 =\tBCE 2.14393 \tLL 0.00070 \tTotal 284.90/38.37/167.43 \n","04/19/2023 03:38:37 PM - INFO - [92:6] loss\t2.13 =\tBCE 2.13359 \tLL 0.00071 \tTotal 390.42/50.57/298.51 \n","04/19/2023 03:38:37 PM - INFO - [92:7] loss\t2.15 =\tBCE 2.14572 \tLL 0.00068 \tTotal 397.76/49.10/305.25 \n","04/19/2023 03:38:38 PM - INFO - [92:8] loss\t2.07 =\tBCE 2.07202 \tLL 0.00069 \tTotal 246.96/45.64/168.85 \n","04/19/2023 03:38:38 PM - INFO - [92:9] loss\t2.09 =\tBCE 2.09426 \tLL 0.00068 \tTotal 341.43/56.50/246.18 \n","04/19/2023 03:38:39 PM - INFO - [92:10] loss\t2.11 =\tBCE 2.11448 \tLL 0.00065 \tTotal 231.72/30.93/168.79 \n","04/19/2023 03:38:40 PM - INFO - [92:11] loss\t2.12 =\tBCE 2.12133 \tLL 0.00068 \tTotal 402.95/59.82/281.16 \n","04/19/2023 03:38:40 PM - INFO - [92:12] loss\t2.08 =\tBCE 2.08481 \tLL 0.00069 \tTotal 197.69/23.10/127.18 \n","04/19/2023 03:38:41 PM - INFO - [92:13] loss\t2.15 =\tBCE 2.14587 \tLL 0.00065 \tTotal 422.01/66.64/299.71 \n","04/19/2023 03:38:41 PM - INFO - [92:14] loss\t2.02 =\tBCE 2.01598 \tLL 0.00066 \tTotal 321.03/36.04/226.16 \n","04/19/2023 03:38:42 PM - INFO - [92:15] loss\t2.04 =\tBCE 2.03563 \tLL 0.00065 \tTotal 344.93/45.49/254.85 \n","04/19/2023 03:38:42 PM - INFO - [92:16] loss\t2.01 =\tBCE 2.00927 \tLL 0.00067 \tTotal 218.12/21.51/64.66 \n","04/19/2023 03:38:43 PM - INFO - [92:17] loss\t2.02 =\tBCE 2.01809 \tLL 0.00064 \tTotal 232.37/38.94/164.15 \n","04/19/2023 03:38:43 PM - INFO - [92:18] loss\t2.01 =\tBCE 2.01127 \tLL 0.00064 \tTotal 130.02/25.11/61.63 \n","04/19/2023 03:38:44 PM - INFO - [92:19] loss\t2.12 =\tBCE 2.12091 \tLL 0.00067 \tTotal 332.35/50.95/243.03 \n","04/19/2023 03:38:44 PM - INFO - Training epoch 93.\n","04/19/2023 03:38:44 PM - INFO - [93:0] loss\t2.05 =\tBCE 2.05173 \tLL 0.00068 \tTotal 436.73/61.46/328.01 \n","04/19/2023 03:38:45 PM - INFO - [93:1] loss\t2.05 =\tBCE 2.04930 \tLL 0.00063 \tTotal 461.10/54.89/365.07 \n","04/19/2023 03:38:46 PM - INFO - [93:2] loss\t1.98 =\tBCE 1.97909 \tLL 0.00065 \tTotal 180.49/20.10/109.64 \n","04/19/2023 03:38:46 PM - INFO - [93:3] loss\t2.12 =\tBCE 2.12051 \tLL 0.00068 \tTotal 580.58/72.47/466.19 \n","04/19/2023 03:38:47 PM - INFO - [93:4] loss\t2.08 =\tBCE 2.07767 \tLL 0.00067 \tTotal 576.79/75.97/449.73 \n","04/19/2023 03:38:47 PM - INFO - [93:5] loss\t1.96 =\tBCE 1.96026 \tLL 0.00067 \tTotal 209.67/35.86/141.05 \n","04/19/2023 03:38:48 PM - INFO - [93:6] loss\t2.03 =\tBCE 2.02799 \tLL 0.00067 \tTotal 435.21/50.10/356.12 \n","04/19/2023 03:38:48 PM - INFO - [93:7] loss\t2.02 =\tBCE 2.02010 \tLL 0.00065 \tTotal 460.14/61.46/357.65 \n","04/19/2023 03:38:49 PM - INFO - [93:8] loss\t1.87 =\tBCE 1.86576 \tLL 0.00061 \tTotal 193.39/25.89/96.16 \n","04/19/2023 03:38:49 PM - INFO - [93:9] loss\t2.04 =\tBCE 2.04128 \tLL 0.00066 \tTotal 455.52/62.65/345.71 \n","04/19/2023 03:38:50 PM - INFO - [93:10] loss\t2.11 =\tBCE 2.10573 \tLL 0.00070 \tTotal 701.69/94.44/555.66 \n","04/19/2023 03:38:50 PM - INFO - [93:11] loss\t1.96 =\tBCE 1.96415 \tLL 0.00068 \tTotal 396.87/49.45/299.47 \n","04/19/2023 03:38:51 PM - INFO - [93:12] loss\t2.00 =\tBCE 1.99507 \tLL 0.00065 \tTotal 289.56/47.70/228.14 \n","04/19/2023 03:38:52 PM - INFO - [93:13] loss\t2.04 =\tBCE 2.04087 \tLL 0.00067 \tTotal 548.59/77.60/417.96 \n","04/19/2023 03:38:52 PM - INFO - [93:14] loss\t1.99 =\tBCE 1.99001 \tLL 0.00066 \tTotal 272.91/39.25/211.99 \n","04/19/2023 03:38:53 PM - INFO - [93:15] loss\t2.06 =\tBCE 2.06188 \tLL 0.00072 \tTotal 462.11/62.08/359.59 \n","04/19/2023 03:38:53 PM - INFO - [93:16] loss\t2.06 =\tBCE 2.06401 \tLL 0.00067 \tTotal 566.13/70.71/458.29 \n","04/19/2023 03:38:54 PM - INFO - [93:17] loss\t1.95 =\tBCE 1.95382 \tLL 0.00066 \tTotal 163.03/29.43/109.57 \n","04/19/2023 03:38:54 PM - INFO - [93:18] loss\t2.00 =\tBCE 2.00346 \tLL 0.00067 \tTotal 281.00/34.95/218.99 \n","04/19/2023 03:38:55 PM - INFO - [93:19] loss\t1.92 =\tBCE 1.92480 \tLL 0.00064 \tTotal 227.22/29.19/151.54 \n","04/19/2023 03:38:55 PM - INFO - Training epoch 94.\n","04/19/2023 03:38:55 PM - INFO - [94:0] loss\t1.90 =\tBCE 1.89771 \tLL 0.00067 \tTotal 187.19/25.30/123.42 \n","04/19/2023 03:38:56 PM - INFO - [94:1] loss\t1.93 =\tBCE 1.93171 \tLL 0.00064 \tTotal 164.19/23.91/111.21 \n","04/19/2023 03:38:56 PM - INFO - [94:2] loss\t1.96 =\tBCE 1.96024 \tLL 0.00067 \tTotal 158.11/31.29/82.19 \n","04/19/2023 03:38:57 PM - INFO - [94:3] loss\t1.97 =\tBCE 1.97147 \tLL 0.00068 \tTotal 189.83/25.41/128.35 \n","04/19/2023 03:38:58 PM - INFO - [94:4] loss\t1.92 =\tBCE 1.92346 \tLL 0.00064 \tTotal 235.03/36.83/170.09 \n","04/19/2023 03:38:58 PM - INFO - [94:5] loss\t2.03 =\tBCE 2.02946 \tLL 0.00066 \tTotal 239.56/33.41/157.40 \n","04/19/2023 03:38:59 PM - INFO - [94:6] loss\t1.88 =\tBCE 1.88113 \tLL 0.00067 \tTotal 281.77/32.08/226.81 \n","04/19/2023 03:38:59 PM - INFO - [94:7] loss\t1.88 =\tBCE 1.87986 \tLL 0.00064 \tTotal 212.57/27.10/173.12 \n","04/19/2023 03:39:00 PM - INFO - [94:8] loss\t1.85 =\tBCE 1.85132 \tLL 0.00066 \tTotal 208.14/30.77/160.58 \n","04/19/2023 03:39:00 PM - INFO - [94:9] loss\t1.85 =\tBCE 1.85250 \tLL 0.00063 \tTotal 142.21/30.63/88.36 \n","04/19/2023 03:39:01 PM - INFO - [94:10] loss\t1.86 =\tBCE 1.85505 \tLL 0.00064 \tTotal 149.07/20.33/87.95 \n","04/19/2023 03:39:01 PM - INFO - [94:11] loss\t1.90 =\tBCE 1.90406 \tLL 0.00069 \tTotal 215.72/28.95/158.91 \n","04/19/2023 03:39:02 PM - INFO - [94:12] loss\t1.88 =\tBCE 1.88308 \tLL 0.00067 \tTotal 144.08/16.09/98.41 \n","04/19/2023 03:39:02 PM - INFO - [94:13] loss\t1.92 =\tBCE 1.92106 \tLL 0.00070 \tTotal 186.85/19.06/128.81 \n","04/19/2023 03:39:03 PM - INFO - [94:14] loss\t1.87 =\tBCE 1.86658 \tLL 0.00067 \tTotal 128.88/19.17/87.69 \n","04/19/2023 03:39:03 PM - INFO - [94:15] loss\t1.92 =\tBCE 1.91706 \tLL 0.00066 \tTotal 269.10/26.89/208.70 \n","04/19/2023 03:39:04 PM - INFO - [94:16] loss\t1.96 =\tBCE 1.96172 \tLL 0.00068 \tTotal 465.86/64.12/364.42 \n","04/19/2023 03:39:05 PM - INFO - [94:17] loss\t1.94 =\tBCE 1.94226 \tLL 0.00062 \tTotal 540.15/75.63/428.50 \n","04/19/2023 03:39:05 PM - INFO - [94:18] loss\t1.98 =\tBCE 1.97794 \tLL 0.00067 \tTotal 375.20/47.82/279.92 \n","04/19/2023 03:39:06 PM - INFO - [94:19] loss\t1.89 =\tBCE 1.89142 \tLL 0.00065 \tTotal 121.52/17.05/101.51 \n","04/19/2023 03:39:06 PM - INFO - Training epoch 95.\n","04/19/2023 03:39:06 PM - INFO - [95:0] loss\t1.96 =\tBCE 1.95562 \tLL 0.00070 \tTotal 398.82/56.72/269.86 \n","04/19/2023 03:39:07 PM - INFO - [95:1] loss\t1.90 =\tBCE 1.89591 \tLL 0.00066 \tTotal 416.63/58.09/332.87 \n","04/19/2023 03:39:07 PM - INFO - [95:2] loss\t1.81 =\tBCE 1.80759 \tLL 0.00063 \tTotal 187.34/28.61/128.62 \n","04/19/2023 03:39:08 PM - INFO - [95:3] loss\t1.85 =\tBCE 1.85491 \tLL 0.00066 \tTotal 314.78/39.20/241.49 \n","04/19/2023 03:39:08 PM - INFO - [95:4] loss\t1.92 =\tBCE 1.91700 \tLL 0.00068 \tTotal 398.13/54.41/307.08 \n","04/19/2023 03:39:09 PM - INFO - [95:5] loss\t1.91 =\tBCE 1.90919 \tLL 0.00068 \tTotal 301.61/34.32/235.25 \n","04/19/2023 03:39:10 PM - INFO - [95:6] loss\t1.92 =\tBCE 1.92007 \tLL 0.00067 \tTotal 347.86/44.65/271.17 \n","04/19/2023 03:39:10 PM - INFO - [95:7] loss\t2.00 =\tBCE 2.00065 \tLL 0.00067 \tTotal 528.90/69.20/403.22 \n","04/19/2023 03:39:11 PM - INFO - [95:8] loss\t1.88 =\tBCE 1.87749 \tLL 0.00067 \tTotal 287.15/36.43/208.69 \n","04/19/2023 03:39:11 PM - INFO - [95:9] loss\t1.91 =\tBCE 1.90923 \tLL 0.00067 \tTotal 269.68/39.26/209.21 \n","04/19/2023 03:39:12 PM - INFO - [95:10] loss\t1.87 =\tBCE 1.87196 \tLL 0.00067 \tTotal 403.62/50.35/314.62 \n","04/19/2023 03:39:12 PM - INFO - [95:11] loss\t1.85 =\tBCE 1.85140 \tLL 0.00065 \tTotal 250.27/38.79/171.38 \n","04/19/2023 03:39:13 PM - INFO - [95:12] loss\t1.82 =\tBCE 1.81962 \tLL 0.00068 \tTotal 218.94/41.72/133.20 \n","04/19/2023 03:39:13 PM - INFO - [95:13] loss\t1.88 =\tBCE 1.88095 \tLL 0.00066 \tTotal 456.54/54.91/346.10 \n","04/19/2023 03:39:14 PM - INFO - [95:14] loss\t1.90 =\tBCE 1.89607 \tLL 0.00064 \tTotal 478.81/60.23/407.99 \n","04/19/2023 03:39:14 PM - INFO - [95:15] loss\t1.75 =\tBCE 1.75356 \tLL 0.00063 \tTotal 237.03/31.86/147.31 \n","04/19/2023 03:39:15 PM - INFO - [95:16] loss\t1.92 =\tBCE 1.92382 \tLL 0.00067 \tTotal 343.16/44.69/276.16 \n","04/19/2023 03:39:15 PM - INFO - [95:17] loss\t1.85 =\tBCE 1.84521 \tLL 0.00069 \tTotal 546.92/71.20/417.22 \n","04/19/2023 03:39:16 PM - INFO - [95:18] loss\t1.87 =\tBCE 1.87409 \tLL 0.00067 \tTotal 299.52/32.67/222.32 \n","04/19/2023 03:39:16 PM - INFO - [95:19] loss\t1.97 =\tBCE 1.96959 \tLL 0.00072 \tTotal 454.54/48.47/397.51 \n","04/19/2023 03:39:16 PM - INFO - Training epoch 96.\n","04/19/2023 03:39:17 PM - INFO - [96:0] loss\t1.93 =\tBCE 1.92889 \tLL 0.00065 \tTotal 657.23/83.42/513.15 \n","04/19/2023 03:39:18 PM - INFO - [96:1] loss\t1.86 =\tBCE 1.86312 \tLL 0.00067 \tTotal 421.06/54.80/331.73 \n","04/19/2023 03:39:18 PM - INFO - [96:2] loss\t1.85 =\tBCE 1.84767 \tLL 0.00066 \tTotal 357.33/47.85/243.89 \n","04/19/2023 03:39:19 PM - INFO - [96:3] loss\t2.07 =\tBCE 2.06744 \tLL 0.00068 \tTotal 876.34/107.75/714.77 \n","04/19/2023 03:39:19 PM - INFO - [96:4] loss\t1.94 =\tBCE 1.94331 \tLL 0.00065 \tTotal 928.73/116.82/749.88 \n","04/19/2023 03:39:20 PM - INFO - [96:5] loss\t1.99 =\tBCE 1.98874 \tLL 0.00068 \tTotal 611.66/88.93/466.86 \n","04/19/2023 03:39:20 PM - INFO - [96:6] loss\t1.88 =\tBCE 1.87993 \tLL 0.00071 \tTotal 309.49/37.96/230.78 \n","04/19/2023 03:39:21 PM - INFO - [96:7] loss\t2.03 =\tBCE 2.02950 \tLL 0.00069 \tTotal 812.87/110.20/645.54 \n","04/19/2023 03:39:21 PM - INFO - [96:8] loss\t2.07 =\tBCE 2.07354 \tLL 0.00071 \tTotal 876.51/121.00/658.93 \n","04/19/2023 03:39:22 PM - INFO - [96:9] loss\t1.82 =\tBCE 1.82425 \tLL 0.00066 \tTotal 514.33/61.71/398.08 \n","04/19/2023 03:39:22 PM - INFO - [96:10] loss\t1.79 =\tBCE 1.79369 \tLL 0.00066 \tTotal 330.52/45.54/221.31 \n","04/19/2023 03:39:23 PM - INFO - [96:11] loss\t2.05 =\tBCE 2.05240 \tLL 0.00069 \tTotal 880.51/102.77/736.06 \n","04/19/2023 03:39:24 PM - INFO - [96:12] loss\t1.95 =\tBCE 1.95344 \tLL 0.00067 \tTotal 925.44/119.93/714.60 \n","04/19/2023 03:39:24 PM - INFO - [96:13] loss\t1.87 =\tBCE 1.86925 \tLL 0.00070 \tTotal 371.27/55.03/276.13 \n","04/19/2023 03:39:25 PM - INFO - [96:14] loss\t1.90 =\tBCE 1.90286 \tLL 0.00066 \tTotal 632.66/83.25/491.76 \n","04/19/2023 03:39:25 PM - INFO - [96:15] loss\t2.18 =\tBCE 2.17911 \tLL 0.00074 \tTotal 1213.13/150.98/975.63 \n","04/19/2023 03:39:26 PM - INFO - [96:16] loss\t2.34 =\tBCE 2.33828 \tLL 0.00072 \tTotal 1311.91/177.93/1010.91 \n","04/19/2023 03:39:26 PM - INFO - [96:17] loss\t2.00 =\tBCE 1.99649 \tLL 0.00066 \tTotal 972.12/124.97/769.24 \n","04/19/2023 03:39:27 PM - INFO - [96:18] loss\t1.86 =\tBCE 1.86407 \tLL 0.00064 \tTotal 380.89/58.04/256.78 \n","04/19/2023 03:39:27 PM - INFO - [96:19] loss\t1.89 =\tBCE 1.88922 \tLL 0.00067 \tTotal 574.35/78.44/465.00 \n","04/19/2023 03:39:27 PM - INFO - Training epoch 97.\n","04/19/2023 03:39:28 PM - INFO - [97:0] loss\t1.98 =\tBCE 1.97735 \tLL 0.00069 \tTotal 767.98/107.08/593.22 \n","04/19/2023 03:39:28 PM - INFO - [97:1] loss\t1.79 =\tBCE 1.78577 \tLL 0.00068 \tTotal 396.11/56.57/327.98 \n","04/19/2023 03:39:29 PM - INFO - [97:2] loss\t1.82 =\tBCE 1.81651 \tLL 0.00066 \tTotal 376.03/58.01/299.44 \n","04/19/2023 03:39:29 PM - INFO - [97:3] loss\t1.88 =\tBCE 1.87628 \tLL 0.00070 \tTotal 495.56/66.08/389.08 \n","04/19/2023 03:39:30 PM - INFO - [97:4] loss\t1.83 =\tBCE 1.82702 \tLL 0.00066 \tTotal 379.50/59.75/263.12 \n","04/19/2023 03:39:31 PM - INFO - [97:5] loss\t1.85 =\tBCE 1.85075 \tLL 0.00068 \tTotal 388.92/57.10/262.27 \n","04/19/2023 03:39:31 PM - INFO - [97:6] loss\t1.75 =\tBCE 1.75456 \tLL 0.00065 \tTotal 441.18/54.17/343.72 \n","04/19/2023 03:39:32 PM - INFO - [97:7] loss\t1.79 =\tBCE 1.79481 \tLL 0.00068 \tTotal 510.93/72.93/392.76 \n","04/19/2023 03:39:32 PM - INFO - [97:8] loss\t1.75 =\tBCE 1.75469 \tLL 0.00065 \tTotal 260.03/31.85/181.59 \n","04/19/2023 03:39:33 PM - INFO - [97:9] loss\t1.79 =\tBCE 1.78815 \tLL 0.00064 \tTotal 314.40/49.15/220.67 \n","04/19/2023 03:39:33 PM - INFO - [97:10] loss\t1.76 =\tBCE 1.76034 \tLL 0.00067 \tTotal 452.65/62.87/350.74 \n","04/19/2023 03:39:34 PM - INFO - [97:11] loss\t1.80 =\tBCE 1.80119 \tLL 0.00068 \tTotal 416.21/50.61/310.13 \n","04/19/2023 03:39:34 PM - INFO - [97:12] loss\t1.74 =\tBCE 1.73891 \tLL 0.00067 \tTotal 154.24/35.73/99.67 \n","04/19/2023 03:39:35 PM - INFO - [97:13] loss\t1.70 =\tBCE 1.69888 \tLL 0.00063 \tTotal 341.28/40.92/266.45 \n","04/19/2023 03:39:35 PM - INFO - [97:14] loss\t1.76 =\tBCE 1.76295 \tLL 0.00065 \tTotal 374.53/51.19/301.35 \n","04/19/2023 03:39:36 PM - INFO - [97:15] loss\t1.73 =\tBCE 1.72824 \tLL 0.00067 \tTotal 177.60/25.87/110.22 \n","04/19/2023 03:39:37 PM - INFO - [97:16] loss\t1.76 =\tBCE 1.76177 \tLL 0.00065 \tTotal 255.37/48.50/189.35 \n","04/19/2023 03:39:37 PM - INFO - [97:17] loss\t1.77 =\tBCE 1.76559 \tLL 0.00066 \tTotal 378.80/53.62/286.79 \n","04/19/2023 03:39:38 PM - INFO - [97:18] loss\t1.81 =\tBCE 1.80646 \tLL 0.00065 \tTotal 466.83/60.49/350.40 \n","04/19/2023 03:39:38 PM - INFO - [97:19] loss\t1.74 =\tBCE 1.74059 \tLL 0.00064 \tTotal 320.49/46.02/249.08 \n","04/19/2023 03:39:38 PM - INFO - Training epoch 98.\n","04/19/2023 03:39:39 PM - INFO - [98:0] loss\t1.66 =\tBCE 1.65876 \tLL 0.00063 \tTotal 244.25/32.24/178.17 \n","04/19/2023 03:39:39 PM - INFO - [98:1] loss\t1.73 =\tBCE 1.72636 \tLL 0.00066 \tTotal 455.38/62.41/355.44 \n","04/19/2023 03:39:40 PM - INFO - [98:2] loss\t1.74 =\tBCE 1.74258 \tLL 0.00067 \tTotal 229.98/30.88/143.24 \n","04/19/2023 03:39:40 PM - INFO - [98:3] loss\t1.76 =\tBCE 1.75504 \tLL 0.00066 \tTotal 445.17/59.27/340.57 \n","04/19/2023 03:39:41 PM - INFO - [98:4] loss\t1.86 =\tBCE 1.86148 \tLL 0.00069 \tTotal 784.04/96.19/626.47 \n","04/19/2023 03:39:41 PM - INFO - [98:5] loss\t1.90 =\tBCE 1.90194 \tLL 0.00067 \tTotal 822.49/107.40/656.27 \n","04/19/2023 03:39:42 PM - INFO - [98:6] loss\t1.81 =\tBCE 1.81259 \tLL 0.00068 \tTotal 511.37/68.30/402.34 \n","04/19/2023 03:39:42 PM - INFO - [98:7] loss\t1.65 =\tBCE 1.64997 \tLL 0.00067 \tTotal 165.01/23.82/112.39 \n","04/19/2023 03:39:43 PM - INFO - [98:8] loss\t1.85 =\tBCE 1.85465 \tLL 0.00067 \tTotal 798.27/100.69/646.97 \n","04/19/2023 03:39:43 PM - INFO - [98:9] loss\t1.93 =\tBCE 1.93465 \tLL 0.00065 \tTotal 1042.21/134.09/818.40 \n","04/19/2023 03:39:44 PM - INFO - [98:10] loss\t1.79 =\tBCE 1.79156 \tLL 0.00065 \tTotal 741.76/87.00/588.73 \n","04/19/2023 03:39:45 PM - INFO - [98:11] loss\t1.65 =\tBCE 1.65375 \tLL 0.00068 \tTotal 191.67/21.29/102.49 \n","04/19/2023 03:39:45 PM - INFO - [98:12] loss\t1.84 =\tBCE 1.84019 \tLL 0.00067 \tTotal 781.71/89.82/640.08 \n","04/19/2023 03:39:46 PM - INFO - [98:13] loss\t1.88 =\tBCE 1.88304 \tLL 0.00065 \tTotal 791.63/110.37/597.81 \n","04/19/2023 03:39:46 PM - INFO - [98:14] loss\t1.74 =\tBCE 1.73614 \tLL 0.00066 \tTotal 317.77/39.72/243.41 \n","04/19/2023 03:39:47 PM - INFO - [98:15] loss\t1.76 =\tBCE 1.76152 \tLL 0.00064 \tTotal 591.40/78.29/461.35 \n","04/19/2023 03:39:47 PM - INFO - [98:16] loss\t2.01 =\tBCE 2.01051 \tLL 0.00069 \tTotal 953.90/122.27/766.69 \n","04/19/2023 03:39:48 PM - INFO - [98:17] loss\t1.76 =\tBCE 1.76286 \tLL 0.00067 \tTotal 605.82/80.07/437.53 \n","04/19/2023 03:39:48 PM - INFO - [98:18] loss\t1.75 =\tBCE 1.75226 \tLL 0.00066 \tTotal 305.84/44.47/194.74 \n","04/19/2023 03:39:49 PM - INFO - [98:19] loss\t1.88 =\tBCE 1.87662 \tLL 0.00067 \tTotal 718.05/97.64/524.74 \n","Not implemented\n","04/19/2023 03:39:49 PM - INFO - Training epoch 99.\n","04/19/2023 03:39:49 PM - INFO - [99:0] loss\t1.83 =\tBCE 1.82538 \tLL 0.00070 \tTotal 778.13/101.33/615.53 \n","04/19/2023 03:39:50 PM - INFO - [99:1] loss\t1.72 =\tBCE 1.72385 \tLL 0.00070 \tTotal 367.93/39.45/265.91 \n","04/19/2023 03:39:51 PM - INFO - [99:2] loss\t1.66 =\tBCE 1.66005 \tLL 0.00061 \tTotal 440.11/54.61/349.90 \n","04/19/2023 03:39:51 PM - INFO - [99:3] loss\t1.72 =\tBCE 1.72069 \tLL 0.00064 \tTotal 709.30/84.66/551.01 \n","04/19/2023 03:39:52 PM - INFO - [99:4] loss\t1.71 =\tBCE 1.70844 \tLL 0.00066 \tTotal 415.07/68.99/279.23 \n","04/19/2023 03:39:52 PM - INFO - [99:5] loss\t1.80 =\tBCE 1.80162 \tLL 0.00067 \tTotal 453.97/57.49/328.48 \n","04/19/2023 03:39:53 PM - INFO - [99:6] loss\t1.73 =\tBCE 1.73332 \tLL 0.00067 \tTotal 615.80/84.31/489.87 \n","04/19/2023 03:39:53 PM - INFO - [99:7] loss\t1.69 =\tBCE 1.69076 \tLL 0.00064 \tTotal 441.42/64.11/313.88 \n","04/19/2023 03:39:54 PM - INFO - [99:8] loss\t1.75 =\tBCE 1.75150 \tLL 0.00068 \tTotal 461.15/63.75/371.10 \n","04/19/2023 03:39:54 PM - INFO - [99:9] loss\t1.78 =\tBCE 1.78356 \tLL 0.00064 \tTotal 880.13/116.43/697.37 \n","04/19/2023 03:39:55 PM - INFO - [99:10] loss\t1.83 =\tBCE 1.82670 \tLL 0.00067 \tTotal 790.06/115.10/614.41 \n","04/19/2023 03:39:55 PM - INFO - [99:11] loss\t1.71 =\tBCE 1.70761 \tLL 0.00071 \tTotal 279.68/38.58/182.74 \n","04/19/2023 03:39:56 PM - INFO - [99:12] loss\t1.68 =\tBCE 1.67873 \tLL 0.00065 \tTotal 448.06/66.09/339.85 \n","04/19/2023 03:39:56 PM - INFO - [99:13] loss\t1.81 =\tBCE 1.80936 \tLL 0.00069 \tTotal 485.01/62.87/372.15 \n","04/19/2023 03:39:57 PM - INFO - [99:14] loss\t1.66 =\tBCE 1.66363 \tLL 0.00065 \tTotal 267.32/36.14/199.55 \n","04/19/2023 03:39:58 PM - INFO - [99:15] loss\t1.80 =\tBCE 1.80298 \tLL 0.00066 \tTotal 668.16/82.53/545.33 \n","04/19/2023 03:39:58 PM - INFO - [99:16] loss\t1.79 =\tBCE 1.78808 \tLL 0.00069 \tTotal 782.34/96.53/581.47 \n","04/19/2023 03:39:59 PM - INFO - [99:17] loss\t1.75 =\tBCE 1.74785 \tLL 0.00069 \tTotal 530.67/71.84/424.97 \n","04/19/2023 03:39:59 PM - INFO - [99:18] loss\t1.56 =\tBCE 1.55778 \tLL 0.00062 \tTotal 161.10/21.99/100.05 \n","04/19/2023 03:40:00 PM - INFO - [99:19] loss\t1.77 =\tBCE 1.77234 \tLL 0.00067 \tTotal 539.69/86.88/423.20 \n","04/19/2023 03:40:00 PM - INFO - EVALUATION prior to epoch [100]...\n","04/19/2023 03:40:00 PM - INFO - [100] loss\t1.82=\tBCE 1.82 \tLL 0.00067 \n","04/19/2023 03:40:02 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/100_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:40:07 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/100_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/19/2023 03:40:12 PM - INFO - Figure saved ./out/run_2023-04-19_15-19-26/figures/100_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/19/2023 03:40:12 PM - INFO - Training epoch 100.\n","04/19/2023 03:40:13 PM - INFO - [100:0] loss\t1.73 =\tBCE 1.72884 \tLL 0.00065 \tTotal 645.51/88.86/491.12 \n","04/19/2023 03:40:14 PM - INFO - [100:1] loss\t1.70 =\tBCE 1.70171 \tLL 0.00068 \tTotal 549.00/70.54/443.84 \n","04/19/2023 03:40:14 PM - INFO - [100:2] loss\t1.65 =\tBCE 1.64906 \tLL 0.00069 \tTotal 267.93/41.43/184.16 \n","04/19/2023 03:40:15 PM - INFO - [100:3] loss\t1.66 =\tBCE 1.66038 \tLL 0.00065 \tTotal 512.70/72.26/414.75 \n","04/19/2023 03:40:15 PM - INFO - [100:4] loss\t1.73 =\tBCE 1.72598 \tLL 0.00069 \tTotal 450.81/60.37/343.82 \n","04/19/2023 03:40:16 PM - INFO - [100:5] loss\t1.55 =\tBCE 1.54595 \tLL 0.00065 \tTotal 175.53/34.63/108.67 \n","04/19/2023 03:40:16 PM - INFO - [100:6] loss\t1.61 =\tBCE 1.61402 \tLL 0.00063 \tTotal 407.62/61.49/327.14 \n","04/19/2023 03:40:17 PM - INFO - [100:7] loss\t1.67 =\tBCE 1.66703 \tLL 0.00066 \tTotal 385.28/54.26/296.56 \n","04/19/2023 03:40:17 PM - INFO - [100:8] loss\t1.60 =\tBCE 1.59695 \tLL 0.00064 \tTotal 263.59/48.82/193.75 \n","04/19/2023 03:40:18 PM - INFO - [100:9] loss\t1.61 =\tBCE 1.61290 \tLL 0.00066 \tTotal 277.86/33.83/205.41 \n","04/19/2023 03:40:18 PM - INFO - [100:10] loss\t1.54 =\tBCE 1.53573 \tLL 0.00063 \tTotal 328.02/46.41/269.78 \n","04/19/2023 03:40:19 PM - INFO - [100:11] loss\t1.64 =\tBCE 1.64092 \tLL 0.00063 \tTotal 349.54/55.13/198.23 \n","04/19/2023 03:40:20 PM - INFO - [100:12] loss\t1.55 =\tBCE 1.55129 \tLL 0.00062 \tTotal 227.17/27.00/167.21 \n","04/19/2023 03:40:20 PM - INFO - [100:13] loss\t1.57 =\tBCE 1.57318 \tLL 0.00063 \tTotal 201.93/24.96/129.53 \n","04/19/2023 03:40:21 PM - INFO - [100:14] loss\t1.59 =\tBCE 1.59134 \tLL 0.00063 \tTotal 205.04/23.44/142.98 \n","04/19/2023 03:40:21 PM - INFO - [100:15] loss\t1.63 =\tBCE 1.62757 \tLL 0.00064 \tTotal 401.63/53.74/311.04 \n","04/19/2023 03:40:22 PM - INFO - [100:16] loss\t1.68 =\tBCE 1.68133 \tLL 0.00068 \tTotal 578.37/69.60/445.53 \n","04/19/2023 03:40:22 PM - INFO - [100:17] loss\t1.67 =\tBCE 1.66842 \tLL 0.00065 \tTotal 469.87/59.32/378.82 \n","04/19/2023 03:40:23 PM - INFO - [100:18] loss\t1.58 =\tBCE 1.57675 \tLL 0.00066 \tTotal 196.42/29.86/99.02 \n","04/19/2023 03:40:23 PM - INFO - [100:19] loss\t1.69 =\tBCE 1.68986 \tLL 0.00069 \tTotal 548.53/74.37/441.13 \n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/bce_loss █▆▆▂▂▁▃▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train/ll_loss ▄▁█▃▂▂▅▁▄▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/total_loss █▆▆▂▂▁▃▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:     val/bce_loss █▁▂▂▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:        val/epoch ▁▂▂▃▄▅▅▆▇▇█\n","\u001b[34m\u001b[1mwandb\u001b[0m:      val/ll_loss ▁▂█▃▁▂▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   val/total_loss █▁▂▂▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/bce_loss 1.68986\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train/epoch 100\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train/ll_loss 0.00069\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/total_loss 1.68986\n","\u001b[34m\u001b[1mwandb\u001b[0m:     val/bce_loss 1.81507\n","\u001b[34m\u001b[1mwandb\u001b[0m:        val/epoch 100\n","\u001b[34m\u001b[1mwandb\u001b[0m:      val/ll_loss 0.00067\n","\u001b[34m\u001b[1mwandb\u001b[0m:   val/total_loss 1.81507\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mexpert-shadow-9\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/simonecaldarella/homomorphism-autoencoder/runs/969ss2ye\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 33 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230419_151940-969ss2ye/logs\u001b[0m\n"]}],"source":["%cd /content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/\n","!python3 train_block_mlp_repr.py --dataset=dsprites --data_root=/content/drive/MyDrive/Advanced_Machine_Learning/dsprites-dataset --cyclic_trans --fixed_in_intervention=0,1,2,3 --fixed_in_sampling=0,1,2,3 --fixed_values=0,1,5,14 --distrib=uniform --displacement_range=-10,10 --n_steps=2 --rotate_actions=45 --num_train=10000 --batch_size=500 --epochs=101 --log_wandb --lr=0.001 --toggle_training_every=2,2 --shuffle=1 --use_adam --use_cuda --conv_channels=64,64,64,64 --kernel_sizes=6,4,4,4 --strides=2,2,1,1 --lin_channels=1024 --net_act=relu --dims=2,2 --group_hidden_units=128,128 --reconstruct_first --exponential_map --latent_loss --latent_loss_weight=400 --val_epoch=10 --num_val=500 --plot_epoch=10 --plot_manifold_latent=[0,1] --plot_manifold --plot_reconstruction --plot_pca --plot_vary_latents=[4,5]"]},{"cell_type":"markdown","source":["### Recombination to Element"],"metadata":{"id":"8PGgEdaQVZQO"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/\n","!python3 train_block_mlp_repr.py --combinatorial_indices=/content/drive/MyDrive/Advanced_Machine_Learning/remove_from_train_shape_equal_1__scale_equal_5__orientation_equal_14__posX_equal_15__posY_greater_equal_15.json --dataset=dsprites --data_root=/content/drive/MyDrive/Advanced_Machine_Learning/dsprites-dataset --cyclic_trans --fixed_in_intervention=0,1,2,3 --fixed_in_sampling=0,1,2,3 --fixed_values=0,1,5,14 --distrib=uniform --displacement_range=-10,10 --n_steps=2 --rotate_actions=45 --num_train=10000 --batch_size=500 --epochs=101 --log_wandb --lr=0.001 --toggle_training_every=2,2 --shuffle=1 --use_adam --use_cuda --conv_channels=64,64,64,64 --kernel_sizes=6,4,4,4 --strides=2,2,1,1 --lin_channels=1024 --net_act=relu --dims=2,2 --group_hidden_units=128,128 --reconstruct_first_only --exponential_map --latent_loss --latent_loss_weight=400 --val_epoch=10 --num_val=500 --plot_epoch=10 --plot_manifold_latent=[0,1] --plot_manifold --plot_reconstruction --plot_pca --plot_vary_latents=[4,5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TEc5f5qxVb5Q","executionInfo":{"status":"ok","timestamp":1682182092060,"user_tz":-120,"elapsed":1185980,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"outputId":"9b9faf4e-c1ea-4f29-fb24-0be78f22975f"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism\n","Created output folder ./out/run_2023-04-22_16-28-30.\n","04/22/2023 04:28:30 PM - INFO - Using cuda : True\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.0\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/wandb/run-20230422_162838-3ey46wbr\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mskilled-snowflake-19\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/simonecaldarella/homomorphism-autoencoder\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/simonecaldarella/homomorphism-autoencoder/runs/3ey46wbr\u001b[0m\n","04/22/2023 04:28:42 PM - INFO - ### Training ###\n","04/22/2023 04:28:44 PM - INFO - EVALUATION prior to epoch [0]...\n","04/22/2023 04:28:44 PM - INFO - [0] loss\t2897.71=\tBCE 2897.71 \tLL 0.00042 \n","04/22/2023 04:28:45 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/0_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:28:52 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/0_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:28:57 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/0_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 04:28:57 PM - INFO - Training epoch 0.\n","04/22/2023 04:28:58 PM - INFO - [0:0] loss\t2897.60 =\tBCE 2897.59790 \tLL 0.00051 \tTotal 2204.11/2204.06/3.22 \n","04/22/2023 04:28:59 PM - INFO - [0:1] loss\t2872.66 =\tBCE 2872.65552 \tLL 0.03179 \tTotal 2179.21/2150.14/194.17 \n","04/22/2023 04:28:59 PM - INFO - [0:2] loss\t2784.17 =\tBCE 2784.16724 \tLL 0.00007 \tTotal 2134.31/2134.29/0.46 \n","04/22/2023 04:29:00 PM - INFO - [0:3] loss\t2606.87 =\tBCE 2606.87061 \tLL 0.00006 \tTotal 2179.34/2179.12/0.40 \n","04/22/2023 04:29:00 PM - INFO - [0:4] loss\t2388.85 =\tBCE 2388.84912 \tLL 0.00023 \tTotal 1673.32/1673.08/5.41 \n","04/22/2023 04:29:01 PM - INFO - [0:5] loss\t2455.75 =\tBCE 2455.74731 \tLL 0.00083 \tTotal 2072.50/2060.84/22.20 \n","04/22/2023 04:29:01 PM - INFO - [0:6] loss\t2352.83 =\tBCE 2352.83350 \tLL 0.00008 \tTotal 1905.72/1903.30/1.53 \n","04/22/2023 04:29:02 PM - INFO - [0:7] loss\t2172.13 =\tBCE 2172.12549 \tLL 0.00006 \tTotal 1210.41/1210.29/0.44 \n","04/22/2023 04:29:02 PM - INFO - [0:8] loss\t2088.22 =\tBCE 2088.21753 \tLL 0.00007 \tTotal 1392.53/1392.42/0.58 \n","04/22/2023 04:29:03 PM - INFO - [0:9] loss\t2026.09 =\tBCE 2026.09229 \tLL 0.00007 \tTotal 1709.22/1709.02/0.59 \n","04/22/2023 04:29:03 PM - INFO - [0:10] loss\t1916.53 =\tBCE 1916.52673 \tLL 0.00008 \tTotal 1631.41/1631.20/0.61 \n","04/22/2023 04:29:04 PM - INFO - [0:11] loss\t1787.50 =\tBCE 1787.50171 \tLL 0.00008 \tTotal 1130.98/1130.81/0.65 \n","04/22/2023 04:29:04 PM - INFO - [0:12] loss\t1697.01 =\tBCE 1697.01392 \tLL 0.00010 \tTotal 955.99/955.93/0.75 \n","04/22/2023 04:29:05 PM - INFO - [0:13] loss\t1633.03 =\tBCE 1633.03210 \tLL 0.00018 \tTotal 1298.16/1298.13/1.23 \n","04/22/2023 04:29:06 PM - INFO - [0:14] loss\t1520.04 =\tBCE 1520.04163 \tLL 0.00037 \tTotal 1166.44/1166.43/2.40 \n","04/22/2023 04:29:06 PM - INFO - [0:15] loss\t1391.94 =\tBCE 1391.94470 \tLL 0.00063 \tTotal 766.07/765.98/4.14 \n","04/22/2023 04:29:07 PM - INFO - [0:16] loss\t1295.82 =\tBCE 1295.82007 \tLL 0.00141 \tTotal 667.55/666.37/8.66 \n","04/22/2023 04:29:07 PM - INFO - [0:17] loss\t1214.22 =\tBCE 1214.21655 \tLL 0.00364 \tTotal 735.45/730.33/20.46 \n","04/22/2023 04:29:08 PM - INFO - [0:18] loss\t1138.42 =\tBCE 1138.42480 \tLL 0.00945 \tTotal 596.12/573.75/55.85 \n","04/22/2023 04:29:08 PM - INFO - Training epoch 1.\n","04/22/2023 04:29:08 PM - INFO - [1:0] loss\t1066.39 =\tBCE 1066.39441 \tLL 0.02390 \tTotal 455.73/407.10/185.36 \n","04/22/2023 04:29:09 PM - INFO - [1:1] loss\t1031.00 =\tBCE 1030.99597 \tLL 0.02641 \tTotal 1059.12/792.22/288.90 \n","04/22/2023 04:29:09 PM - INFO - [1:2] loss\t971.56 =\tBCE 971.55511 \tLL 0.01386 \tTotal 385.41/270.12/241.83 \n","04/22/2023 04:29:10 PM - INFO - [1:3] loss\t963.53 =\tBCE 963.53326 \tLL 0.01359 \tTotal 561.93/406.84/309.63 \n","04/22/2023 04:29:10 PM - INFO - [1:4] loss\t945.96 =\tBCE 945.96155 \tLL 0.01032 \tTotal 577.81/470.47/221.59 \n","04/22/2023 04:29:11 PM - INFO - [1:5] loss\t927.15 =\tBCE 927.15417 \tLL 0.00915 \tTotal 400.55/350.75/99.77 \n","04/22/2023 04:29:11 PM - INFO - [1:6] loss\t925.04 =\tBCE 925.03961 \tLL 0.01357 \tTotal 403.37/248.19/176.10 \n","04/22/2023 04:29:12 PM - INFO - [1:7] loss\t921.37 =\tBCE 921.37286 \tLL 0.01424 \tTotal 569.30/363.47/195.66 \n","04/22/2023 04:29:12 PM - INFO - [1:8] loss\t907.69 =\tBCE 907.68774 \tLL 0.01161 \tTotal 383.40/298.65/127.65 \n","04/22/2023 04:29:13 PM - INFO - [1:9] loss\t899.84 =\tBCE 899.83575 \tLL 0.00846 \tTotal 262.02/227.33/118.36 \n","04/22/2023 04:29:13 PM - INFO - [1:10] loss\t903.95 =\tBCE 903.95441 \tLL 0.00623 \tTotal 254.16/240.91/52.64 \n","04/22/2023 04:29:14 PM - INFO - [1:11] loss\t891.42 =\tBCE 891.41833 \tLL 0.00454 \tTotal 270.47/256.74/26.71 \n","04/22/2023 04:29:14 PM - INFO - [1:12] loss\t873.01 =\tBCE 873.01300 \tLL 0.00375 \tTotal 232.50/219.40/23.24 \n","04/22/2023 04:29:15 PM - INFO - [1:13] loss\t880.21 =\tBCE 880.21088 \tLL 0.00362 \tTotal 171.22/165.15/30.31 \n","04/22/2023 04:29:16 PM - INFO - [1:14] loss\t857.34 =\tBCE 857.33783 \tLL 0.00338 \tTotal 193.19/185.08/24.86 \n","04/22/2023 04:29:16 PM - INFO - [1:15] loss\t868.04 =\tBCE 868.03815 \tLL 0.00384 \tTotal 217.92/215.61/23.52 \n","04/22/2023 04:29:17 PM - INFO - [1:16] loss\t854.62 =\tBCE 854.61963 \tLL 0.00393 \tTotal 194.42/191.32/20.06 \n","04/22/2023 04:29:17 PM - INFO - [1:17] loss\t848.55 =\tBCE 848.54810 \tLL 0.00465 \tTotal 160.74/152.71/23.10 \n","04/22/2023 04:29:18 PM - INFO - [1:18] loss\t839.34 =\tBCE 839.34436 \tLL 0.00586 \tTotal 148.04/130.59/35.28 \n","04/22/2023 04:29:18 PM - INFO - Training epoch 2.\n","04/22/2023 04:29:18 PM - INFO - [2:0] loss\t839.93 =\tBCE 839.93213 \tLL 0.00733 \tTotal 149.43/128.55/35.67 \n","04/22/2023 04:29:19 PM - INFO - [2:1] loss\t830.71 =\tBCE 830.71173 \tLL 0.00941 \tTotal 139.34/112.65/34.35 \n","04/22/2023 04:29:19 PM - INFO - [2:2] loss\t839.18 =\tBCE 839.17780 \tLL 0.01339 \tTotal 128.72/120.05/31.88 \n","04/22/2023 04:29:20 PM - INFO - [2:3] loss\t823.73 =\tBCE 823.72607 \tLL 0.01926 \tTotal 147.02/120.26/53.82 \n","04/22/2023 04:29:21 PM - INFO - [2:4] loss\t820.63 =\tBCE 820.63202 \tLL 0.02518 \tTotal 176.99/144.31/16.92 \n","04/22/2023 04:29:21 PM - INFO - [2:5] loss\t823.71 =\tBCE 823.71167 \tLL 0.02761 \tTotal 143.06/111.03/38.78 \n","04/22/2023 04:29:22 PM - INFO - [2:6] loss\t814.41 =\tBCE 814.40765 \tLL 0.02322 \tTotal 139.13/118.18/27.13 \n","04/22/2023 04:29:22 PM - INFO - [2:7] loss\t809.38 =\tBCE 809.37720 \tLL 0.02360 \tTotal 202.86/150.07/28.79 \n","04/22/2023 04:29:23 PM - INFO - [2:8] loss\t801.83 =\tBCE 801.82831 \tLL 0.03042 \tTotal 122.03/110.96/35.79 \n","04/22/2023 04:29:23 PM - INFO - [2:9] loss\t805.43 =\tBCE 805.42798 \tLL 0.04052 \tTotal 297.83/142.38/78.34 \n","04/22/2023 04:29:24 PM - INFO - [2:10] loss\t794.27 =\tBCE 794.27258 \tLL 0.03392 \tTotal 114.29/95.63/39.51 \n","04/22/2023 04:29:24 PM - INFO - [2:11] loss\t785.44 =\tBCE 785.44165 \tLL 0.03219 \tTotal 301.22/142.66/98.85 \n","04/22/2023 04:29:25 PM - INFO - [2:12] loss\t785.93 =\tBCE 785.92792 \tLL 0.03819 \tTotal 107.25/93.78/33.33 \n","04/22/2023 04:29:25 PM - INFO - [2:13] loss\t781.94 =\tBCE 781.93860 \tLL 0.04778 \tTotal 266.57/125.60/72.80 \n","04/22/2023 04:29:26 PM - INFO - [2:14] loss\t770.38 =\tBCE 770.38110 \tLL 0.04637 \tTotal 124.27/100.08/40.77 \n","04/22/2023 04:29:26 PM - INFO - [2:15] loss\t755.71 =\tBCE 755.71472 \tLL 0.04582 \tTotal 246.34/118.11/31.41 \n","04/22/2023 04:29:27 PM - INFO - [2:16] loss\t759.60 =\tBCE 759.59912 \tLL 0.06242 \tTotal 196.29/133.60/37.56 \n","04/22/2023 04:29:27 PM - INFO - [2:17] loss\t749.22 =\tBCE 749.21539 \tLL 0.07044 \tTotal 151.10/122.77/28.62 \n","04/22/2023 04:29:28 PM - INFO - [2:18] loss\t735.43 =\tBCE 735.42578 \tLL 0.07328 \tTotal 217.96/140.33/68.44 \n","04/22/2023 04:29:28 PM - INFO - Training epoch 3.\n","04/22/2023 04:29:28 PM - INFO - [3:0] loss\t729.37 =\tBCE 729.36652 \tLL 0.09079 \tTotal 223.46/146.18/42.58 \n","04/22/2023 04:29:29 PM - INFO - [3:1] loss\t711.95 =\tBCE 711.94592 \tLL 0.08574 \tTotal 176.34/134.92/49.27 \n","04/22/2023 04:29:30 PM - INFO - [3:2] loss\t695.32 =\tBCE 695.31604 \tLL 0.08483 \tTotal 244.62/148.53/11.26 \n","04/22/2023 04:29:30 PM - INFO - [3:3] loss\t682.86 =\tBCE 682.86047 \tLL 0.09344 \tTotal 324.99/152.47/37.15 \n","04/22/2023 04:29:31 PM - INFO - [3:4] loss\t677.13 =\tBCE 677.13489 \tLL 0.08522 \tTotal 246.31/161.41/24.75 \n","04/22/2023 04:29:31 PM - INFO - [3:5] loss\t662.65 =\tBCE 662.65479 \tLL 0.08363 \tTotal 211.39/155.94/29.02 \n","04/22/2023 04:29:32 PM - INFO - [3:6] loss\t645.29 =\tBCE 645.28796 \tLL 0.10175 \tTotal 325.95/164.37/73.66 \n","04/22/2023 04:29:32 PM - INFO - [3:7] loss\t629.74 =\tBCE 629.73981 \tLL 0.09403 \tTotal 222.89/166.51/31.41 \n","04/22/2023 04:29:33 PM - INFO - [3:8] loss\t611.80 =\tBCE 611.79865 \tLL 0.08411 \tTotal 316.99/166.10/63.99 \n","04/22/2023 04:29:33 PM - INFO - [3:9] loss\t606.71 =\tBCE 606.70966 \tLL 0.09015 \tTotal 497.24/194.54/41.16 \n","04/22/2023 04:29:34 PM - INFO - [3:10] loss\t589.34 =\tBCE 589.34198 \tLL 0.08492 \tTotal 507.36/198.68/15.70 \n","04/22/2023 04:29:34 PM - INFO - [3:11] loss\t562.83 =\tBCE 562.83466 \tLL 0.08431 \tTotal 665.13/207.02/75.13 \n","04/22/2023 04:29:35 PM - INFO - [3:12] loss\t558.60 =\tBCE 558.59601 \tLL 0.11711 \tTotal 1019.21/245.50/25.99 \n","04/22/2023 04:29:36 PM - INFO - [3:13] loss\t552.78 =\tBCE 552.77710 \tLL 0.08418 \tTotal 830.40/225.45/62.30 \n","04/22/2023 04:29:36 PM - INFO - [3:14] loss\t526.15 =\tBCE 526.14661 \tLL 0.08572 \tTotal 658.65/199.08/61.97 \n","04/22/2023 04:29:37 PM - INFO - [3:15] loss\t513.30 =\tBCE 513.29706 \tLL 0.09049 \tTotal 582.27/195.00/44.29 \n","04/22/2023 04:29:37 PM - INFO - [3:16] loss\t502.12 =\tBCE 502.12183 \tLL 0.08497 \tTotal 311.00/202.67/34.17 \n","04/22/2023 04:29:38 PM - INFO - [3:17] loss\t488.65 =\tBCE 488.64569 \tLL 0.08270 \tTotal 814.52/248.16/27.03 \n","04/22/2023 04:29:38 PM - INFO - [3:18] loss\t476.24 =\tBCE 476.23550 \tLL 0.09224 \tTotal 891.15/220.68/24.59 \n","04/22/2023 04:29:38 PM - INFO - Training epoch 4.\n","04/22/2023 04:29:39 PM - INFO - [4:0] loss\t459.76 =\tBCE 459.76242 \tLL 0.08391 \tTotal 489.99/199.62/56.96 \n","04/22/2023 04:29:39 PM - INFO - [4:1] loss\t449.11 =\tBCE 449.11130 \tLL 0.06826 \tTotal 978.24/284.41/23.42 \n","04/22/2023 04:29:40 PM - INFO - [4:2] loss\t439.97 =\tBCE 439.97241 \tLL 0.09238 \tTotal 1100.45/229.27/50.14 \n","04/22/2023 04:29:40 PM - INFO - [4:3] loss\t428.07 =\tBCE 428.06503 \tLL 0.07334 \tTotal 1516.32/274.42/18.03 \n","04/22/2023 04:29:41 PM - INFO - [4:4] loss\t428.11 =\tBCE 428.11160 \tLL 0.07606 \tTotal 2125.33/304.34/51.99 \n","04/22/2023 04:29:41 PM - INFO - [4:5] loss\t407.76 =\tBCE 407.75671 \tLL 0.07077 \tTotal 658.94/216.60/45.05 \n","04/22/2023 04:29:42 PM - INFO - [4:6] loss\t400.33 =\tBCE 400.32977 \tLL 0.06389 \tTotal 1510.85/277.59/26.92 \n","04/22/2023 04:29:42 PM - INFO - [4:7] loss\t393.10 =\tBCE 393.10059 \tLL 0.06167 \tTotal 1851.02/316.96/33.14 \n","04/22/2023 04:29:43 PM - INFO - [4:8] loss\t383.75 =\tBCE 383.74728 \tLL 0.04712 \tTotal 2761.74/577.00/35.05 \n","04/22/2023 04:29:43 PM - INFO - [4:9] loss\t387.27 =\tBCE 387.27063 \tLL 0.08090 \tTotal 1548.12/539.90/75.29 \n","04/22/2023 04:29:44 PM - INFO - [4:10] loss\t383.76 =\tBCE 383.75659 \tLL 0.08318 \tTotal 1704.05/467.64/100.61 \n","04/22/2023 04:29:44 PM - INFO - [4:11] loss\t343.24 =\tBCE 343.24072 \tLL 0.06534 \tTotal 1674.09/404.55/48.42 \n","04/22/2023 04:29:45 PM - INFO - [4:12] loss\t368.46 =\tBCE 368.45584 \tLL 0.06243 \tTotal 4636.84/1066.91/80.94 \n","04/22/2023 04:29:46 PM - INFO - [4:13] loss\t326.66 =\tBCE 326.65762 \tLL 0.09657 \tTotal 1669.44/604.12/53.08 \n","04/22/2023 04:29:46 PM - INFO - [4:14] loss\t339.48 =\tBCE 339.48096 \tLL 0.10713 \tTotal 3131.53/597.39/67.76 \n","04/22/2023 04:29:47 PM - INFO - [4:15] loss\t282.07 =\tBCE 282.07199 \tLL 0.09297 \tTotal 2431.30/428.75/47.93 \n","04/22/2023 04:29:47 PM - INFO - [4:16] loss\t303.24 =\tBCE 303.23877 \tLL 0.06931 \tTotal 5637.50/1437.44/39.69 \n","04/22/2023 04:29:48 PM - INFO - [4:17] loss\t307.77 =\tBCE 307.76767 \tLL 0.10162 \tTotal 4464.87/1325.57/107.01 \n","04/22/2023 04:29:48 PM - INFO - [4:18] loss\t265.60 =\tBCE 265.60327 \tLL 0.09195 \tTotal 4255.79/742.88/119.64 \n","04/22/2023 04:29:48 PM - INFO - Training epoch 5.\n","04/22/2023 04:29:49 PM - INFO - [5:0] loss\t261.50 =\tBCE 261.49631 \tLL 0.08217 \tTotal 4880.98/1352.41/19.51 \n","04/22/2023 04:29:49 PM - INFO - [5:1] loss\t254.37 =\tBCE 254.36848 \tLL 0.09784 \tTotal 6613.61/855.87/184.34 \n","04/22/2023 04:29:50 PM - INFO - [5:2] loss\t246.52 =\tBCE 246.52119 \tLL 0.08362 \tTotal 5202.24/751.64/15.65 \n","04/22/2023 04:29:50 PM - INFO - [5:3] loss\t226.44 =\tBCE 226.43559 \tLL 0.08172 \tTotal 4702.92/634.74/117.57 \n","04/22/2023 04:29:51 PM - INFO - [5:4] loss\t224.52 =\tBCE 224.52339 \tLL 0.08315 \tTotal 5868.47/795.96/87.38 \n","04/22/2023 04:29:51 PM - INFO - [5:5] loss\t205.51 =\tBCE 205.51497 \tLL 0.06772 \tTotal 3918.41/1382.84/36.08 \n","04/22/2023 04:29:52 PM - INFO - [5:6] loss\t202.79 =\tBCE 202.79143 \tLL 0.08251 \tTotal 3852.47/1413.94/85.99 \n","04/22/2023 04:29:52 PM - INFO - [5:7] loss\t189.64 =\tBCE 189.63904 \tLL 0.07265 \tTotal 3985.20/511.26/57.53 \n","04/22/2023 04:29:53 PM - INFO - [5:8] loss\t172.80 =\tBCE 172.80157 \tLL 0.07244 \tTotal 3353.47/735.40/13.00 \n","04/22/2023 04:29:53 PM - INFO - [5:9] loss\t180.89 =\tBCE 180.89420 \tLL 0.08461 \tTotal 4754.83/978.02/83.47 \n","04/22/2023 04:29:54 PM - INFO - [5:10] loss\t182.80 =\tBCE 182.79765 \tLL 0.07038 \tTotal 5803.42/1548.33/87.95 \n","04/22/2023 04:29:54 PM - INFO - [5:11] loss\t171.77 =\tBCE 171.77170 \tLL 0.08099 \tTotal 4652.86/1278.13/22.56 \n","04/22/2023 04:29:55 PM - INFO - [5:12] loss\t152.99 =\tBCE 152.99014 \tLL 0.06822 \tTotal 4076.65/875.07/64.01 \n","04/22/2023 04:29:56 PM - INFO - [5:13] loss\t147.72 =\tBCE 147.71585 \tLL 0.07259 \tTotal 2822.97/602.25/67.17 \n","04/22/2023 04:29:56 PM - INFO - [5:14] loss\t134.58 =\tBCE 134.58075 \tLL 0.07180 \tTotal 2349.60/531.13/14.20 \n","04/22/2023 04:29:57 PM - INFO - [5:15] loss\t156.60 =\tBCE 156.59660 \tLL 0.06884 \tTotal 4148.68/1404.96/67.91 \n","04/22/2023 04:29:57 PM - INFO - [5:16] loss\t136.15 =\tBCE 136.15146 \tLL 0.07521 \tTotal 3208.36/1274.90/53.99 \n","04/22/2023 04:29:58 PM - INFO - [5:17] loss\t154.04 =\tBCE 154.03824 \tLL 0.06455 \tTotal 6780.46/1383.15/15.83 \n","04/22/2023 04:29:58 PM - INFO - [5:18] loss\t150.30 =\tBCE 150.29915 \tLL 0.07714 \tTotal 4860.92/1706.50/60.24 \n","04/22/2023 04:29:58 PM - INFO - Training epoch 6.\n","04/22/2023 04:29:59 PM - INFO - [6:0] loss\t140.84 =\tBCE 140.84149 \tLL 0.06948 \tTotal 3925.41/1735.80/21.91 \n","04/22/2023 04:29:59 PM - INFO - [6:1] loss\t126.01 =\tBCE 126.00652 \tLL 0.07433 \tTotal 3716.74/627.53/24.27 \n","04/22/2023 04:30:00 PM - INFO - [6:2] loss\t116.18 =\tBCE 116.18346 \tLL 0.07186 \tTotal 2378.83/625.74/18.70 \n","04/22/2023 04:30:00 PM - INFO - [6:3] loss\t133.41 =\tBCE 133.41003 \tLL 0.06321 \tTotal 5471.38/1417.13/34.65 \n","04/22/2023 04:30:01 PM - INFO - [6:4] loss\t144.94 =\tBCE 144.94220 \tLL 0.07407 \tTotal 5288.21/2028.46/24.23 \n","04/22/2023 04:30:01 PM - INFO - [6:5] loss\t135.52 =\tBCE 135.51822 \tLL 0.06467 \tTotal 6041.06/1746.67/4.73 \n","04/22/2023 04:30:02 PM - INFO - [6:6] loss\t123.83 =\tBCE 123.82890 \tLL 0.07069 \tTotal 5535.37/949.97/18.70 \n","04/22/2023 04:30:03 PM - INFO - [6:7] loss\t100.79 =\tBCE 100.78825 \tLL 0.06539 \tTotal 1985.89/283.72/53.48 \n","04/22/2023 04:30:03 PM - INFO - [6:8] loss\t117.70 =\tBCE 117.70191 \tLL 0.06112 \tTotal 6021.59/1059.50/15.35 \n","04/22/2023 04:30:04 PM - INFO - [6:9] loss\t120.08 =\tBCE 120.07839 \tLL 0.06909 \tTotal 5401.88/1486.26/13.16 \n","04/22/2023 04:30:04 PM - INFO - [6:10] loss\t117.79 =\tBCE 117.78798 \tLL 0.06191 \tTotal 4037.97/1492.11/67.48 \n","04/22/2023 04:30:05 PM - INFO - [6:11] loss\t101.25 =\tBCE 101.25284 \tLL 0.06337 \tTotal 3103.00/728.27/20.49 \n","04/22/2023 04:30:05 PM - INFO - [6:12] loss\t97.82 =\tBCE 97.82005 \tLL 0.06327 \tTotal 2009.21/557.99/13.17 \n","04/22/2023 04:30:06 PM - INFO - [6:13] loss\t103.08 =\tBCE 103.08461 \tLL 0.05699 \tTotal 4254.12/1277.08/36.56 \n","04/22/2023 04:30:06 PM - INFO - [6:14] loss\t108.11 =\tBCE 108.11047 \tLL 0.06401 \tTotal 4260.15/1258.13/24.36 \n","04/22/2023 04:30:07 PM - INFO - [6:15] loss\t99.52 =\tBCE 99.52097 \tLL 0.05632 \tTotal 3685.03/1068.67/17.65 \n","04/22/2023 04:30:07 PM - INFO - [6:16] loss\t94.18 =\tBCE 94.18362 \tLL 0.05947 \tTotal 3131.23/656.49/28.05 \n","04/22/2023 04:30:08 PM - INFO - [6:17] loss\t85.23 =\tBCE 85.22794 \tLL 0.05766 \tTotal 1791.85/290.93/18.02 \n","04/22/2023 04:30:08 PM - INFO - [6:18] loss\t90.59 =\tBCE 90.58505 \tLL 0.05522 \tTotal 2907.50/680.43/29.94 \n","04/22/2023 04:30:08 PM - INFO - Training epoch 7.\n","04/22/2023 04:30:09 PM - INFO - [7:0] loss\t94.89 =\tBCE 94.88976 \tLL 0.05905 \tTotal 4521.97/910.56/14.19 \n","04/22/2023 04:30:09 PM - INFO - [7:1] loss\t94.38 =\tBCE 94.37694 \tLL 0.05016 \tTotal 4826.44/1539.95/7.06 \n","04/22/2023 04:30:10 PM - INFO - [7:2] loss\t122.65 =\tBCE 122.64887 \tLL 0.05918 \tTotal 5755.28/2493.17/23.18 \n","04/22/2023 04:30:10 PM - INFO - [7:3] loss\t132.61 =\tBCE 132.61168 \tLL 0.04931 \tTotal 8519.46/2942.56/6.88 \n","04/22/2023 04:30:11 PM - INFO - [7:4] loss\t161.90 =\tBCE 161.90022 \tLL 0.06452 \tTotal 8731.47/2905.67/34.14 \n","04/22/2023 04:30:12 PM - INFO - [7:5] loss\t87.27 =\tBCE 87.27052 \tLL 0.05755 \tTotal 3821.75/1078.79/32.02 \n","04/22/2023 04:30:12 PM - INFO - [7:6] loss\t108.15 =\tBCE 108.15401 \tLL 0.05646 \tTotal 5494.69/1956.29/11.13 \n","04/22/2023 04:30:13 PM - INFO - [7:7] loss\t138.16 =\tBCE 138.16331 \tLL 0.06881 \tTotal 6510.76/2617.76/47.96 \n","04/22/2023 04:30:13 PM - INFO - [7:8] loss\t86.26 =\tBCE 86.25663 \tLL 0.06119 \tTotal 2708.53/365.72/25.04 \n","04/22/2023 04:30:14 PM - INFO - [7:9] loss\t131.56 =\tBCE 131.56142 \tLL 0.05657 \tTotal 6538.81/2684.91/28.93 \n","04/22/2023 04:30:14 PM - INFO - [7:10] loss\t114.53 =\tBCE 114.53016 \tLL 0.06933 \tTotal 4856.46/1740.16/53.46 \n","04/22/2023 04:30:15 PM - INFO - [7:11] loss\t101.93 =\tBCE 101.93403 \tLL 0.06756 \tTotal 3887.43/1546.81/23.59 \n","04/22/2023 04:30:15 PM - INFO - [7:12] loss\t113.71 =\tBCE 113.70525 \tLL 0.05686 \tTotal 5530.88/2189.50/54.25 \n","04/22/2023 04:30:16 PM - INFO - [7:13] loss\t88.00 =\tBCE 87.99994 \tLL 0.06383 \tTotal 3605.77/707.06/49.74 \n","04/22/2023 04:30:16 PM - INFO - [7:14] loss\t108.54 =\tBCE 108.53872 \tLL 0.06766 \tTotal 4393.80/1724.00/11.61 \n","04/22/2023 04:30:17 PM - INFO - [7:15] loss\t82.36 =\tBCE 82.36410 \tLL 0.06343 \tTotal 2818.78/384.25/64.11 \n","04/22/2023 04:30:17 PM - INFO - [7:16] loss\t106.46 =\tBCE 106.45522 \tLL 0.05659 \tTotal 5072.26/1678.06/74.26 \n","04/22/2023 04:30:18 PM - INFO - [7:17] loss\t80.06 =\tBCE 80.06487 \tLL 0.06095 \tTotal 1996.73/339.03/28.92 \n","04/22/2023 04:30:18 PM - INFO - [7:18] loss\t98.09 =\tBCE 98.08978 \tLL 0.06134 \tTotal 4671.88/1244.50/81.66 \n","04/22/2023 04:30:18 PM - INFO - Training epoch 8.\n","04/22/2023 04:30:19 PM - INFO - [8:0] loss\t75.88 =\tBCE 75.88231 \tLL 0.05498 \tTotal 1313.01/385.89/49.63 \n","04/22/2023 04:30:20 PM - INFO - [8:1] loss\t93.96 =\tBCE 93.96357 \tLL 0.05283 \tTotal 4831.22/1149.64/40.77 \n","04/22/2023 04:30:20 PM - INFO - [8:2] loss\t78.22 =\tBCE 78.21935 \tLL 0.05415 \tTotal 2538.31/637.79/8.77 \n","04/22/2023 04:30:21 PM - INFO - [8:3] loss\t84.45 =\tBCE 84.44952 \tLL 0.05608 \tTotal 3377.63/830.67/74.18 \n","04/22/2023 04:30:21 PM - INFO - [8:4] loss\t81.41 =\tBCE 81.40524 \tLL 0.05101 \tTotal 2873.27/853.28/61.66 \n","04/22/2023 04:30:22 PM - INFO - [8:5] loss\t73.48 =\tBCE 73.48103 \tLL 0.04778 \tTotal 2266.30/642.59/7.39 \n","04/22/2023 04:30:22 PM - INFO - [8:6] loss\t80.04 =\tBCE 80.04058 \tLL 0.05116 \tTotal 2848.77/953.07/38.10 \n","04/22/2023 04:30:23 PM - INFO - [8:7] loss\t71.19 =\tBCE 71.18556 \tLL 0.05071 \tTotal 1440.46/379.57/93.90 \n","04/22/2023 04:30:23 PM - INFO - [8:8] loss\t78.97 =\tBCE 78.97282 \tLL 0.04615 \tTotal 3115.94/1171.06/18.13 \n","04/22/2023 04:30:24 PM - INFO - [8:9] loss\t69.89 =\tBCE 69.88906 \tLL 0.04844 \tTotal 1160.49/355.45/28.16 \n","04/22/2023 04:30:24 PM - INFO - [8:10] loss\t74.75 =\tBCE 74.75426 \tLL 0.04929 \tTotal 2248.59/802.46/65.67 \n","04/22/2023 04:30:25 PM - INFO - [8:11] loss\t68.71 =\tBCE 68.70779 \tLL 0.04438 \tTotal 1981.80/760.20/44.66 \n","04/22/2023 04:30:25 PM - INFO - [8:12] loss\t65.63 =\tBCE 65.62799 \tLL 0.04425 \tTotal 1359.38/330.69/14.63 \n","04/22/2023 04:30:26 PM - INFO - [8:13] loss\t67.83 =\tBCE 67.82953 \tLL 0.04494 \tTotal 2386.83/776.33/54.71 \n","04/22/2023 04:30:26 PM - INFO - [8:14] loss\t64.48 =\tBCE 64.47872 \tLL 0.04426 \tTotal 1565.77/296.83/69.04 \n","04/22/2023 04:30:27 PM - INFO - [8:15] loss\t66.24 =\tBCE 66.24002 \tLL 0.04395 \tTotal 2575.43/499.15/22.10 \n","04/22/2023 04:30:27 PM - INFO - [8:16] loss\t66.57 =\tBCE 66.56515 \tLL 0.04460 \tTotal 2770.31/569.36/27.61 \n","04/22/2023 04:30:28 PM - INFO - [8:17] loss\t59.75 =\tBCE 59.75102 \tLL 0.04245 \tTotal 575.51/136.55/47.53 \n","04/22/2023 04:30:28 PM - INFO - [8:18] loss\t63.79 =\tBCE 63.78915 \tLL 0.04053 \tTotal 2714.57/446.03/40.26 \n","Not implemented\n","04/22/2023 04:30:29 PM - INFO - Training epoch 9.\n","04/22/2023 04:30:29 PM - INFO - [9:0] loss\t61.87 =\tBCE 61.86551 \tLL 0.04203 \tTotal 3011.25/425.36/18.81 \n","04/22/2023 04:30:30 PM - INFO - [9:1] loss\t59.32 =\tBCE 59.31881 \tLL 0.04200 \tTotal 1741.69/232.99/37.00 \n","04/22/2023 04:30:30 PM - INFO - [9:2] loss\t62.48 =\tBCE 62.47745 \tLL 0.03965 \tTotal 2467.68/757.08/29.82 \n","04/22/2023 04:30:31 PM - INFO - [9:3] loss\t65.69 =\tBCE 65.69326 \tLL 0.04199 \tTotal 2972.04/1175.68/40.92 \n","04/22/2023 04:30:31 PM - INFO - [9:4] loss\t66.29 =\tBCE 66.28815 \tLL 0.03844 \tTotal 4344.12/1298.16/8.42 \n","04/22/2023 04:30:32 PM - INFO - [9:5] loss\t85.89 =\tBCE 85.88910 \tLL 0.04275 \tTotal 8028.84/1512.03/31.34 \n","04/22/2023 04:30:32 PM - INFO - [9:6] loss\t115.97 =\tBCE 115.97346 \tLL 0.03868 \tTotal 13258.79/2195.64/31.26 \n","04/22/2023 04:30:33 PM - INFO - [9:7] loss\t182.36 =\tBCE 182.35876 \tLL 0.04645 \tTotal 15056.78/3056.91/33.18 \n","04/22/2023 04:30:33 PM - INFO - [9:8] loss\t96.78 =\tBCE 96.78133 \tLL 0.04175 \tTotal 9147.32/2192.95/18.75 \n","04/22/2023 04:30:34 PM - INFO - [9:9] loss\t59.33 =\tBCE 59.33214 \tLL 0.04451 \tTotal 2476.06/344.81/43.37 \n","04/22/2023 04:30:34 PM - INFO - [9:10] loss\t91.41 =\tBCE 91.40839 \tLL 0.04574 \tTotal 8755.80/1375.22/9.23 \n","04/22/2023 04:30:35 PM - INFO - [9:11] loss\t83.24 =\tBCE 83.23605 \tLL 0.04048 \tTotal 8229.87/1541.56/9.93 \n","04/22/2023 04:30:35 PM - INFO - [9:12] loss\t65.56 =\tBCE 65.55672 \tLL 0.04696 \tTotal 3729.76/951.07/7.25 \n","04/22/2023 04:30:36 PM - INFO - [9:13] loss\t67.45 =\tBCE 67.44690 \tLL 0.04574 \tTotal 5688.65/656.38/23.32 \n","04/22/2023 04:30:36 PM - INFO - [9:14] loss\t73.51 =\tBCE 73.50558 \tLL 0.04409 \tTotal 6641.23/1036.02/17.83 \n","04/22/2023 04:30:37 PM - INFO - [9:15] loss\t62.80 =\tBCE 62.80294 \tLL 0.04605 \tTotal 2711.10/886.85/14.72 \n","04/22/2023 04:30:37 PM - INFO - [9:16] loss\t68.04 =\tBCE 68.03559 \tLL 0.04361 \tTotal 5665.96/669.57/10.86 \n","04/22/2023 04:30:38 PM - INFO - [9:17] loss\t67.56 =\tBCE 67.56414 \tLL 0.04400 \tTotal 5245.53/800.10/27.12 \n","04/22/2023 04:30:38 PM - INFO - [9:18] loss\t60.91 =\tBCE 60.91167 \tLL 0.04603 \tTotal 2592.67/561.27/15.30 \n","04/22/2023 04:30:39 PM - INFO - EVALUATION prior to epoch [10]...\n","04/22/2023 04:30:39 PM - INFO - [10] loss\t58.32=\tBCE 58.32 \tLL 0.04396 \n","04/22/2023 04:30:40 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/10_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:30:46 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/10_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:30:51 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/10_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 04:30:51 PM - INFO - Training epoch 10.\n","04/22/2023 04:30:52 PM - INFO - [10:0] loss\t65.54 =\tBCE 65.53838 \tLL 0.04501 \tTotal 5083.40/572.61/18.65 \n","04/22/2023 04:30:53 PM - INFO - [10:1] loss\t63.95 =\tBCE 63.95038 \tLL 0.04344 \tTotal 4440.40/673.82/17.76 \n","04/22/2023 04:30:53 PM - INFO - [10:2] loss\t56.82 =\tBCE 56.81842 \tLL 0.04257 \tTotal 2882.92/407.78/17.48 \n","04/22/2023 04:30:54 PM - INFO - [10:3] loss\t61.60 =\tBCE 61.60423 \tLL 0.04222 \tTotal 4213.96/519.12/12.47 \n","04/22/2023 04:30:54 PM - INFO - [10:4] loss\t57.29 =\tBCE 57.29295 \tLL 0.04149 \tTotal 3112.46/391.58/12.96 \n","04/22/2023 04:30:55 PM - INFO - [10:5] loss\t58.12 =\tBCE 58.12055 \tLL 0.04077 \tTotal 2988.10/552.31/15.62 \n","04/22/2023 04:30:55 PM - INFO - [10:6] loss\t56.23 =\tBCE 56.23210 \tLL 0.04065 \tTotal 3398.19/421.95/28.77 \n","04/22/2023 04:30:56 PM - INFO - [10:7] loss\t56.14 =\tBCE 56.13692 \tLL 0.03985 \tTotal 2620.58/424.55/16.34 \n","04/22/2023 04:30:56 PM - INFO - [10:8] loss\t53.55 =\tBCE 53.54685 \tLL 0.03766 \tTotal 3127.91/488.97/6.57 \n","04/22/2023 04:30:57 PM - INFO - [10:9] loss\t55.47 =\tBCE 55.47030 \tLL 0.04059 \tTotal 3346.32/424.50/14.31 \n","04/22/2023 04:30:57 PM - INFO - [10:10] loss\t52.79 =\tBCE 52.78756 \tLL 0.03887 \tTotal 2348.94/312.91/24.21 \n","04/22/2023 04:30:58 PM - INFO - [10:11] loss\t54.71 =\tBCE 54.70737 \tLL 0.03776 \tTotal 3236.09/399.65/27.07 \n","04/22/2023 04:30:58 PM - INFO - [10:12] loss\t52.13 =\tBCE 52.12890 \tLL 0.03824 \tTotal 2621.00/402.51/9.79 \n","04/22/2023 04:30:59 PM - INFO - [10:13] loss\t53.02 =\tBCE 53.01868 \tLL 0.03672 \tTotal 2217.56/439.53/10.61 \n","04/22/2023 04:30:59 PM - INFO - [10:14] loss\t52.95 =\tBCE 52.95086 \tLL 0.03710 \tTotal 2677.12/409.86/20.71 \n","04/22/2023 04:31:00 PM - INFO - [10:15] loss\t50.51 =\tBCE 50.51424 \tLL 0.03637 \tTotal 2453.53/342.05/37.65 \n","04/22/2023 04:31:00 PM - INFO - [10:16] loss\t51.34 =\tBCE 51.33581 \tLL 0.03627 \tTotal 2751.84/391.24/13.42 \n","04/22/2023 04:31:01 PM - INFO - [10:17] loss\t52.38 =\tBCE 52.37563 \tLL 0.03567 \tTotal 2968.97/736.08/16.54 \n","04/22/2023 04:31:01 PM - INFO - [10:18] loss\t56.75 =\tBCE 56.75350 \tLL 0.03773 \tTotal 3115.43/1182.21/42.35 \n","04/22/2023 04:31:01 PM - INFO - Training epoch 11.\n","04/22/2023 04:31:02 PM - INFO - [11:0] loss\t65.58 =\tBCE 65.58318 \tLL 0.03283 \tTotal 6111.38/1914.96/19.89 \n","04/22/2023 04:31:02 PM - INFO - [11:1] loss\t125.90 =\tBCE 125.89870 \tLL 0.03946 \tTotal 9956.94/3405.69/20.51 \n","04/22/2023 04:31:03 PM - INFO - [11:2] loss\t187.62 =\tBCE 187.61716 \tLL 0.03243 \tTotal 17285.69/5249.86/21.23 \n","04/22/2023 04:31:03 PM - INFO - [11:3] loss\t357.42 =\tBCE 357.41934 \tLL 0.05107 \tTotal 15295.55/6278.83/39.74 \n","04/22/2023 04:31:04 PM - INFO - [11:4] loss\t69.19 =\tBCE 69.19106 \tLL 0.04867 \tTotal 2599.28/440.02/15.13 \n","04/22/2023 04:31:04 PM - INFO - [11:5] loss\t316.20 =\tBCE 316.20212 \tLL 0.04639 \tTotal 15968.33/6296.13/25.42 \n","04/22/2023 04:31:05 PM - INFO - [11:6] loss\t129.50 =\tBCE 129.50352 \tLL 0.06201 \tTotal 8330.30/2012.80/13.63 \n","04/22/2023 04:31:06 PM - INFO - [11:7] loss\t227.36 =\tBCE 227.35675 \tLL 0.06644 \tTotal 8595.13/4033.32/74.96 \n","04/22/2023 04:31:06 PM - INFO - [11:8] loss\t85.88 =\tBCE 85.88118 \tLL 0.06694 \tTotal 4544.18/577.74/15.99 \n","04/22/2023 04:31:07 PM - INFO - [11:9] loss\t186.87 =\tBCE 186.86731 \tLL 0.06331 \tTotal 7805.40/3488.63/45.58 \n","04/22/2023 04:31:07 PM - INFO - [11:10] loss\t112.53 =\tBCE 112.52715 \tLL 0.06492 \tTotal 3817.85/2051.47/53.57 \n","04/22/2023 04:31:08 PM - INFO - [11:11] loss\t99.53 =\tBCE 99.53474 \tLL 0.06687 \tTotal 4415.60/1292.71/26.66 \n","04/22/2023 04:31:08 PM - INFO - [11:12] loss\t146.18 =\tBCE 146.18069 \tLL 0.06437 \tTotal 4976.36/2434.69/36.22 \n","04/22/2023 04:31:09 PM - INFO - [11:13] loss\t90.80 =\tBCE 90.80312 \tLL 0.05956 \tTotal 2124.03/1110.52/22.73 \n","04/22/2023 04:31:09 PM - INFO - [11:14] loss\t96.83 =\tBCE 96.82765 \tLL 0.05639 \tTotal 3760.22/1028.92/16.80 \n","04/22/2023 04:31:10 PM - INFO - [11:15] loss\t123.84 =\tBCE 123.84042 \tLL 0.05413 \tTotal 4308.84/1827.63/20.02 \n","04/22/2023 04:31:10 PM - INFO - [11:16] loss\t84.96 =\tBCE 84.95586 \tLL 0.05746 \tTotal 1802.19/860.49/45.85 \n","04/22/2023 04:31:11 PM - INFO - [11:17] loss\t87.00 =\tBCE 87.00266 \tLL 0.05866 \tTotal 2958.62/646.84/13.23 \n","04/22/2023 04:31:11 PM - INFO - [11:18] loss\t102.91 =\tBCE 102.91055 \tLL 0.05947 \tTotal 2662.84/1311.25/37.31 \n","04/22/2023 04:31:11 PM - INFO - Training epoch 12.\n","04/22/2023 04:31:12 PM - INFO - [12:0] loss\t90.85 =\tBCE 90.84793 \tLL 0.05620 \tTotal 1606.57/918.09/36.84 \n","04/22/2023 04:31:12 PM - INFO - [12:1] loss\t80.69 =\tBCE 80.69055 \tLL 0.05207 \tTotal 2261.89/279.44/28.32 \n","04/22/2023 04:31:13 PM - INFO - [12:2] loss\t89.08 =\tBCE 89.08104 \tLL 0.05122 \tTotal 2198.80/978.80/26.28 \n","04/22/2023 04:31:13 PM - INFO - [12:3] loss\t85.92 =\tBCE 85.91788 \tLL 0.05183 \tTotal 1697.47/976.07/41.43 \n","04/22/2023 04:31:14 PM - INFO - [12:4] loss\t79.12 =\tBCE 79.11703 \tLL 0.05192 \tTotal 1893.26/350.13/10.89 \n","04/22/2023 04:31:15 PM - INFO - [12:5] loss\t79.49 =\tBCE 79.49255 \tLL 0.05170 \tTotal 1425.47/516.72/10.55 \n","04/22/2023 04:31:15 PM - INFO - [12:6] loss\t81.85 =\tBCE 81.85037 \tLL 0.04834 \tTotal 1653.59/806.56/9.24 \n","04/22/2023 04:31:16 PM - INFO - [12:7] loss\t74.17 =\tBCE 74.17175 \tLL 0.04444 \tTotal 1623.05/444.64/22.34 \n","04/22/2023 04:31:16 PM - INFO - [12:8] loss\t71.69 =\tBCE 71.69327 \tLL 0.04362 \tTotal 1280.06/307.68/19.30 \n","04/22/2023 04:31:17 PM - INFO - [12:9] loss\t77.20 =\tBCE 77.20444 \tLL 0.04289 \tTotal 1785.51/674.38/5.69 \n","04/22/2023 04:31:17 PM - INFO - [12:10] loss\t73.17 =\tBCE 73.17021 \tLL 0.04300 \tTotal 1532.19/531.85/21.20 \n","04/22/2023 04:31:18 PM - INFO - [12:11] loss\t68.40 =\tBCE 68.40499 \tLL 0.04355 \tTotal 993.71/139.63/19.57 \n","04/22/2023 04:31:18 PM - INFO - [12:12] loss\t72.53 =\tBCE 72.53450 \tLL 0.04383 \tTotal 1340.38/472.14/15.82 \n","04/22/2023 04:31:19 PM - INFO - [12:13] loss\t71.77 =\tBCE 71.77130 \tLL 0.04264 \tTotal 1468.28/469.11/19.11 \n","04/22/2023 04:31:19 PM - INFO - [12:14] loss\t65.03 =\tBCE 65.03157 \tLL 0.04026 \tTotal 874.43/130.78/14.89 \n","04/22/2023 04:31:20 PM - INFO - [12:15] loss\t66.41 =\tBCE 66.40880 \tLL 0.03827 \tTotal 1087.10/426.61/20.71 \n","04/22/2023 04:31:20 PM - INFO - [12:16] loss\t68.36 =\tBCE 68.36161 \tLL 0.03798 \tTotal 1666.99/502.17/13.38 \n","04/22/2023 04:31:21 PM - INFO - [12:17] loss\t62.82 =\tBCE 62.82359 \tLL 0.03810 \tTotal 657.84/119.09/9.40 \n","04/22/2023 04:31:21 PM - INFO - [12:18] loss\t64.04 =\tBCE 64.03905 \tLL 0.03888 \tTotal 986.43/387.51/11.77 \n","04/22/2023 04:31:21 PM - INFO - Training epoch 13.\n","04/22/2023 04:31:22 PM - INFO - [13:0] loss\t65.58 =\tBCE 65.57617 \tLL 0.03861 \tTotal 1448.36/401.99/25.21 \n","04/22/2023 04:31:23 PM - INFO - [13:1] loss\t59.65 =\tBCE 59.65197 \tLL 0.03790 \tTotal 551.11/94.21/19.73 \n","04/22/2023 04:31:23 PM - INFO - [13:2] loss\t61.18 =\tBCE 61.17909 \tLL 0.03719 \tTotal 1103.78/433.00/9.02 \n","04/22/2023 04:31:24 PM - INFO - [13:3] loss\t59.28 =\tBCE 59.27737 \tLL 0.03697 \tTotal 1361.65/312.69/14.59 \n","04/22/2023 04:31:24 PM - INFO - [13:4] loss\t56.16 =\tBCE 56.16445 \tLL 0.03691 \tTotal 466.92/143.24/28.72 \n","04/22/2023 04:31:25 PM - INFO - [13:5] loss\t56.22 =\tBCE 56.22165 \tLL 0.03594 \tTotal 1264.95/361.84/7.89 \n","04/22/2023 04:31:25 PM - INFO - [13:6] loss\t55.79 =\tBCE 55.79117 \tLL 0.03681 \tTotal 931.36/155.21/17.89 \n","04/22/2023 04:31:26 PM - INFO - [13:7] loss\t53.23 =\tBCE 53.22599 \tLL 0.03524 \tTotal 591.78/306.90/26.48 \n","04/22/2023 04:31:26 PM - INFO - [13:8] loss\t55.34 =\tBCE 55.33628 \tLL 0.03624 \tTotal 1225.43/360.21/16.97 \n","04/22/2023 04:31:27 PM - INFO - [13:9] loss\t52.92 =\tBCE 52.92273 \tLL 0.03619 \tTotal 427.93/126.43/4.89 \n","04/22/2023 04:31:27 PM - INFO - [13:10] loss\t53.51 =\tBCE 53.51283 \tLL 0.03392 \tTotal 1143.47/326.86/9.39 \n","04/22/2023 04:31:28 PM - INFO - [13:11] loss\t50.30 =\tBCE 50.30478 \tLL 0.03435 \tTotal 725.61/164.19/4.79 \n","04/22/2023 04:31:28 PM - INFO - [13:12] loss\t51.12 =\tBCE 51.12482 \tLL 0.03427 \tTotal 719.48/302.55/26.25 \n","04/22/2023 04:31:29 PM - INFO - [13:13] loss\t50.10 =\tBCE 50.09520 \tLL 0.03450 \tTotal 920.15/268.43/7.28 \n","04/22/2023 04:31:30 PM - INFO - [13:14] loss\t48.88 =\tBCE 48.87854 \tLL 0.03338 \tTotal 351.98/118.02/4.92 \n","04/22/2023 04:31:30 PM - INFO - [13:15] loss\t49.28 =\tBCE 49.27916 \tLL 0.03465 \tTotal 1124.51/300.83/23.83 \n","04/22/2023 04:31:31 PM - INFO - [13:16] loss\t48.23 =\tBCE 48.22826 \tLL 0.03334 \tTotal 356.46/68.37/8.77 \n","04/22/2023 04:31:31 PM - INFO - [13:17] loss\t48.48 =\tBCE 48.48304 \tLL 0.03298 \tTotal 1130.73/294.75/15.16 \n","04/22/2023 04:31:32 PM - INFO - [13:18] loss\t46.96 =\tBCE 46.95530 \tLL 0.03309 \tTotal 443.33/105.07/6.12 \n","04/22/2023 04:31:32 PM - INFO - Training epoch 14.\n","04/22/2023 04:31:32 PM - INFO - [14:0] loss\t46.21 =\tBCE 46.20694 \tLL 0.03261 \tTotal 1011.42/247.60/10.76 \n","04/22/2023 04:31:33 PM - INFO - [14:1] loss\t46.01 =\tBCE 46.00834 \tLL 0.03280 \tTotal 604.36/121.21/10.96 \n","04/22/2023 04:31:33 PM - INFO - [14:2] loss\t46.05 =\tBCE 46.05356 \tLL 0.03286 \tTotal 678.84/247.53/17.98 \n","04/22/2023 04:31:34 PM - INFO - [14:3] loss\t44.93 =\tBCE 44.92838 \tLL 0.03246 \tTotal 526.91/103.79/5.73 \n","04/22/2023 04:31:34 PM - INFO - [14:4] loss\t44.15 =\tBCE 44.14944 \tLL 0.03226 \tTotal 659.16/172.57/6.94 \n","04/22/2023 04:31:35 PM - INFO - [14:5] loss\t43.52 =\tBCE 43.52327 \tLL 0.03168 \tTotal 632.52/88.02/17.78 \n","04/22/2023 04:31:35 PM - INFO - [14:6] loss\t42.43 =\tBCE 42.42870 \tLL 0.03136 \tTotal 494.72/178.32/24.86 \n","04/22/2023 04:31:36 PM - INFO - [14:7] loss\t42.66 =\tBCE 42.65618 \tLL 0.03204 \tTotal 739.65/96.74/12.92 \n","04/22/2023 04:31:36 PM - INFO - [14:8] loss\t42.75 =\tBCE 42.75095 \tLL 0.03144 \tTotal 779.21/141.75/16.06 \n","04/22/2023 04:31:37 PM - INFO - [14:9] loss\t42.32 =\tBCE 42.32310 \tLL 0.03175 \tTotal 656.14/77.29/27.41 \n","04/22/2023 04:31:37 PM - INFO - [14:10] loss\t41.57 =\tBCE 41.56999 \tLL 0.03102 \tTotal 512.00/135.27/8.48 \n","04/22/2023 04:31:38 PM - INFO - [14:11] loss\t40.59 =\tBCE 40.59267 \tLL 0.03027 \tTotal 801.59/96.24/18.09 \n","04/22/2023 04:31:39 PM - INFO - [14:12] loss\t41.44 =\tBCE 41.44042 \tLL 0.03061 \tTotal 489.50/122.09/11.60 \n","04/22/2023 04:31:39 PM - INFO - [14:13] loss\t40.88 =\tBCE 40.88110 \tLL 0.03068 \tTotal 604.49/89.12/26.24 \n","04/22/2023 04:31:40 PM - INFO - [14:14] loss\t39.69 =\tBCE 39.68647 \tLL 0.03044 \tTotal 445.49/83.58/20.73 \n","04/22/2023 04:31:40 PM - INFO - [14:15] loss\t39.72 =\tBCE 39.72362 \tLL 0.03049 \tTotal 472.52/85.16/5.18 \n","04/22/2023 04:31:41 PM - INFO - [14:16] loss\t39.35 =\tBCE 39.34657 \tLL 0.02962 \tTotal 530.17/80.67/14.19 \n","04/22/2023 04:31:41 PM - INFO - [14:17] loss\t39.19 =\tBCE 39.18612 \tLL 0.02966 \tTotal 338.14/62.65/21.07 \n","04/22/2023 04:31:42 PM - INFO - [14:18] loss\t39.32 =\tBCE 39.32192 \tLL 0.02995 \tTotal 627.40/76.94/11.89 \n","04/22/2023 04:31:42 PM - INFO - Training epoch 15.\n","04/22/2023 04:31:42 PM - INFO - [15:0] loss\t37.76 =\tBCE 37.75942 \tLL 0.02943 \tTotal 507.02/72.84/14.68 \n","04/22/2023 04:31:43 PM - INFO - [15:1] loss\t37.90 =\tBCE 37.90337 \tLL 0.02958 \tTotal 886.53/142.19/23.32 \n","04/22/2023 04:31:43 PM - INFO - [15:2] loss\t37.43 =\tBCE 37.43174 \tLL 0.02891 \tTotal 854.08/161.13/14.40 \n","04/22/2023 04:31:44 PM - INFO - [15:3] loss\t38.24 =\tBCE 38.23790 \tLL 0.02921 \tTotal 1083.84/176.16/8.24 \n","04/22/2023 04:31:44 PM - INFO - [15:4] loss\t38.41 =\tBCE 38.40755 \tLL 0.02890 \tTotal 1488.65/204.50/14.03 \n","04/22/2023 04:31:45 PM - INFO - [15:5] loss\t37.20 =\tBCE 37.19619 \tLL 0.02806 \tTotal 1879.68/282.49/3.50 \n","04/22/2023 04:31:45 PM - INFO - [15:6] loss\t37.97 =\tBCE 37.97409 \tLL 0.02822 \tTotal 2326.55/416.09/12.89 \n","04/22/2023 04:31:46 PM - INFO - [15:7] loss\t39.99 =\tBCE 39.99011 \tLL 0.02737 \tTotal 3323.92/677.66/6.57 \n","04/22/2023 04:31:47 PM - INFO - [15:8] loss\t46.42 =\tBCE 46.42138 \tLL 0.02925 \tTotal 5405.50/1014.53/8.08 \n","04/22/2023 04:31:47 PM - INFO - [15:9] loss\t65.90 =\tBCE 65.90284 \tLL 0.02758 \tTotal 10257.68/1723.13/7.94 \n","04/22/2023 04:31:48 PM - INFO - [15:10] loss\t147.24 =\tBCE 147.24248 \tLL 0.03215 \tTotal 17798.31/2958.36/12.16 \n","04/22/2023 04:31:48 PM - INFO - [15:11] loss\t217.09 =\tBCE 217.08525 \tLL 0.02805 \tTotal 26459.57/3798.50/10.28 \n","04/22/2023 04:31:49 PM - INFO - [15:12] loss\t262.85 =\tBCE 262.85068 \tLL 0.03513 \tTotal 23809.94/3570.26/16.99 \n","04/22/2023 04:31:49 PM - INFO - [15:13] loss\t60.71 =\tBCE 60.70893 \tLL 0.03527 \tTotal 5288.32/701.27/16.62 \n","04/22/2023 04:31:50 PM - INFO - [15:14] loss\t209.59 =\tBCE 209.58560 \tLL 0.03123 \tTotal 22090.85/3995.35/6.65 \n","04/22/2023 04:31:50 PM - INFO - [15:15] loss\t221.57 =\tBCE 221.56581 \tLL 0.03955 \tTotal 21545.66/2833.71/31.22 \n","04/22/2023 04:31:51 PM - INFO - [15:16] loss\t114.16 =\tBCE 114.16283 \tLL 0.04175 \tTotal 7338.31/2508.48/13.10 \n","04/22/2023 04:31:51 PM - INFO - [15:17] loss\t173.54 =\tBCE 173.54425 \tLL 0.03884 \tTotal 18655.62/2472.72/17.95 \n","04/22/2023 04:31:52 PM - INFO - [15:18] loss\t112.32 =\tBCE 112.31792 \tLL 0.03778 \tTotal 8850.59/2492.36/19.46 \n","04/22/2023 04:31:52 PM - INFO - Training epoch 16.\n","04/22/2023 04:31:52 PM - INFO - [16:0] loss\t102.35 =\tBCE 102.35106 \tLL 0.04220 \tTotal 10981.39/1418.38/10.87 \n","04/22/2023 04:31:53 PM - INFO - [16:1] loss\t118.12 =\tBCE 118.12387 \tLL 0.04407 \tTotal 7075.07/2409.60/13.70 \n","04/22/2023 04:31:53 PM - INFO - [16:2] loss\t78.43 =\tBCE 78.43160 \tLL 0.04253 \tTotal 7840.30/903.31/28.05 \n","04/22/2023 04:31:54 PM - INFO - [16:3] loss\t103.31 =\tBCE 103.31184 \tLL 0.04008 \tTotal 6624.64/2182.72/31.53 \n","04/22/2023 04:31:54 PM - INFO - [16:4] loss\t77.85 =\tBCE 77.84517 \tLL 0.04257 \tTotal 5658.81/1275.42/7.94 \n","04/22/2023 04:31:55 PM - INFO - [16:5] loss\t72.97 =\tBCE 72.97460 \tLL 0.04698 \tTotal 4066.37/1199.64/18.74 \n","04/22/2023 04:31:55 PM - INFO - [16:6] loss\t89.37 =\tBCE 89.36717 \tLL 0.04715 \tTotal 5179.00/1611.81/21.09 \n","04/22/2023 04:31:56 PM - INFO - [16:7] loss\t60.19 =\tBCE 60.19094 \tLL 0.04557 \tTotal 3721.05/415.88/9.62 \n","04/22/2023 04:31:57 PM - INFO - [16:8] loss\t75.77 =\tBCE 75.77238 \tLL 0.04325 \tTotal 4006.72/1298.83/10.88 \n","04/22/2023 04:31:57 PM - INFO - [16:9] loss\t68.95 =\tBCE 68.94968 \tLL 0.04377 \tTotal 3373.56/991.47/11.95 \n","04/22/2023 04:31:58 PM - INFO - [16:10] loss\t56.80 =\tBCE 56.80053 \tLL 0.04476 \tTotal 2671.00/375.15/25.81 \n","04/22/2023 04:31:58 PM - INFO - [16:11] loss\t67.99 =\tBCE 67.98962 \tLL 0.04572 \tTotal 2915.07/901.42/11.07 \n","04/22/2023 04:31:59 PM - INFO - [16:12] loss\t62.35 =\tBCE 62.35282 \tLL 0.04364 \tTotal 3304.95/692.89/11.69 \n","04/22/2023 04:31:59 PM - INFO - [16:13] loss\t54.02 =\tBCE 54.01750 \tLL 0.04253 \tTotal 1571.46/316.20/10.80 \n","04/22/2023 04:32:00 PM - INFO - [16:14] loss\t65.99 =\tBCE 65.99047 \tLL 0.04099 \tTotal 3543.65/827.29/17.40 \n","04/22/2023 04:32:00 PM - INFO - [16:15] loss\t58.04 =\tBCE 58.04193 \tLL 0.04230 \tTotal 2116.15/482.21/6.77 \n","04/22/2023 04:32:01 PM - INFO - [16:16] loss\t54.43 =\tBCE 54.42824 \tLL 0.04275 \tTotal 1689.53/320.15/7.35 \n","04/22/2023 04:32:01 PM - INFO - [16:17] loss\t58.99 =\tBCE 58.99248 \tLL 0.04187 \tTotal 2673.67/609.17/18.24 \n","04/22/2023 04:32:02 PM - INFO - [16:18] loss\t53.27 =\tBCE 53.27319 \tLL 0.04057 \tTotal 1529.77/379.26/7.35 \n","04/22/2023 04:32:02 PM - INFO - Training epoch 17.\n","04/22/2023 04:32:02 PM - INFO - [17:0] loss\t52.32 =\tBCE 52.32090 \tLL 0.03782 \tTotal 1770.49/309.36/8.24 \n","04/22/2023 04:32:03 PM - INFO - [17:1] loss\t56.50 =\tBCE 56.50430 \tLL 0.03654 \tTotal 2422.55/592.37/12.61 \n","04/22/2023 04:32:03 PM - INFO - [17:2] loss\t51.49 =\tBCE 51.48662 \tLL 0.03755 \tTotal 1048.93/297.42/16.91 \n","04/22/2023 04:32:04 PM - INFO - [17:3] loss\t51.80 =\tBCE 51.79589 \tLL 0.03784 \tTotal 1937.38/313.30/12.04 \n","04/22/2023 04:32:04 PM - INFO - [17:4] loss\t53.79 =\tBCE 53.79324 \tLL 0.03822 \tTotal 1870.41/454.54/16.58 \n","04/22/2023 04:32:05 PM - INFO - [17:5] loss\t48.33 =\tBCE 48.33290 \tLL 0.03540 \tTotal 711.19/190.56/18.43 \n","04/22/2023 04:32:05 PM - INFO - [17:6] loss\t51.91 =\tBCE 51.91219 \tLL 0.03609 \tTotal 2248.05/369.32/12.93 \n","04/22/2023 04:32:06 PM - INFO - [17:7] loss\t49.34 =\tBCE 49.34377 \tLL 0.03485 \tTotal 1164.76/427.76/9.83 \n","04/22/2023 04:32:06 PM - INFO - [17:8] loss\t47.83 =\tBCE 47.82542 \tLL 0.03523 \tTotal 1348.65/149.31/6.52 \n","04/22/2023 04:32:07 PM - INFO - [17:9] loss\t50.79 =\tBCE 50.78869 \tLL 0.03540 \tTotal 1611.36/371.82/9.85 \n","04/22/2023 04:32:08 PM - INFO - [17:10] loss\t46.85 =\tBCE 46.84962 \tLL 0.03401 \tTotal 919.71/298.22/3.71 \n","04/22/2023 04:32:08 PM - INFO - [17:11] loss\t45.62 =\tBCE 45.61675 \tLL 0.03213 \tTotal 1323.89/209.52/13.67 \n","04/22/2023 04:32:09 PM - INFO - [17:12] loss\t46.80 =\tBCE 46.80422 \tLL 0.03342 \tTotal 1247.53/421.91/10.53 \n","04/22/2023 04:32:09 PM - INFO - [17:13] loss\t44.36 =\tBCE 44.36409 \tLL 0.03271 \tTotal 773.13/139.55/8.66 \n","04/22/2023 04:32:10 PM - INFO - [17:14] loss\t45.60 =\tBCE 45.59665 \tLL 0.03299 \tTotal 1156.24/311.40/3.95 \n","04/22/2023 04:32:10 PM - INFO - [17:15] loss\t45.54 =\tBCE 45.54159 \tLL 0.03282 \tTotal 710.03/246.21/4.24 \n","04/22/2023 04:32:11 PM - INFO - [17:16] loss\t44.30 =\tBCE 44.30409 \tLL 0.03144 \tTotal 924.45/175.11/5.76 \n","04/22/2023 04:32:11 PM - INFO - [17:17] loss\t44.33 =\tBCE 44.33235 \tLL 0.03191 \tTotal 1074.90/307.19/5.75 \n","04/22/2023 04:32:12 PM - INFO - [17:18] loss\t42.48 =\tBCE 42.48416 \tLL 0.03171 \tTotal 404.31/72.84/3.71 \n","04/22/2023 04:32:12 PM - INFO - Training epoch 18.\n","04/22/2023 04:32:12 PM - INFO - [18:0] loss\t43.17 =\tBCE 43.16614 \tLL 0.03128 \tTotal 1099.64/246.99/8.50 \n","04/22/2023 04:32:13 PM - INFO - [18:1] loss\t41.76 =\tBCE 41.75971 \tLL 0.03055 \tTotal 395.29/109.72/4.36 \n","04/22/2023 04:32:13 PM - INFO - [18:2] loss\t41.76 =\tBCE 41.76149 \tLL 0.03004 \tTotal 950.01/201.20/3.41 \n","04/22/2023 04:32:14 PM - INFO - [18:3] loss\t42.08 =\tBCE 42.07583 \tLL 0.03026 \tTotal 756.02/172.03/10.78 \n","04/22/2023 04:32:14 PM - INFO - [18:4] loss\t40.41 =\tBCE 40.41428 \tLL 0.03020 \tTotal 658.79/115.07/7.12 \n","04/22/2023 04:32:15 PM - INFO - [18:5] loss\t39.16 =\tBCE 39.16123 \tLL 0.02958 \tTotal 900.29/178.86/3.24 \n","04/22/2023 04:32:15 PM - INFO - [18:6] loss\t40.58 =\tBCE 40.57885 \tLL 0.02994 \tTotal 496.13/94.29/5.40 \n","04/22/2023 04:32:16 PM - INFO - [18:7] loss\t39.18 =\tBCE 39.18099 \tLL 0.02833 \tTotal 924.98/215.29/5.55 \n","04/22/2023 04:32:17 PM - INFO - [18:8] loss\t40.02 =\tBCE 40.01534 \tLL 0.02968 \tTotal 681.05/98.58/7.83 \n","04/22/2023 04:32:17 PM - INFO - [18:9] loss\t39.99 =\tBCE 39.98949 \tLL 0.03077 \tTotal 906.60/166.25/9.92 \n","04/22/2023 04:32:18 PM - INFO - [18:10] loss\t38.62 =\tBCE 38.62383 \tLL 0.02906 \tTotal 721.77/97.35/11.78 \n","04/22/2023 04:32:18 PM - INFO - [18:11] loss\t38.51 =\tBCE 38.51046 \tLL 0.02889 \tTotal 835.26/130.38/6.32 \n","04/22/2023 04:32:19 PM - INFO - [18:12] loss\t38.08 =\tBCE 38.07592 \tLL 0.02881 \tTotal 718.25/97.47/5.78 \n","04/22/2023 04:32:19 PM - INFO - [18:13] loss\t38.08 =\tBCE 38.08151 \tLL 0.02882 \tTotal 837.80/101.91/7.53 \n","04/22/2023 04:32:20 PM - INFO - [18:14] loss\t37.51 =\tBCE 37.51337 \tLL 0.02822 \tTotal 666.54/100.15/4.24 \n","04/22/2023 04:32:20 PM - INFO - [18:15] loss\t37.09 =\tBCE 37.08841 \tLL 0.02907 \tTotal 789.56/98.73/5.25 \n","04/22/2023 04:32:21 PM - INFO - [18:16] loss\t36.42 =\tBCE 36.42083 \tLL 0.02747 \tTotal 765.01/119.07/8.78 \n","04/22/2023 04:32:21 PM - INFO - [18:17] loss\t35.92 =\tBCE 35.92036 \tLL 0.02793 \tTotal 773.38/104.22/8.78 \n","04/22/2023 04:32:22 PM - INFO - [18:18] loss\t36.30 =\tBCE 36.30464 \tLL 0.02831 \tTotal 719.27/121.40/6.03 \n","Not implemented\n","04/22/2023 04:32:22 PM - INFO - Training epoch 19.\n","04/22/2023 04:32:22 PM - INFO - [19:0] loss\t35.89 =\tBCE 35.89030 \tLL 0.02698 \tTotal 734.47/138.01/8.47 \n","04/22/2023 04:32:23 PM - INFO - [19:1] loss\t35.75 =\tBCE 35.75054 \tLL 0.02770 \tTotal 596.76/125.88/13.42 \n","04/22/2023 04:32:23 PM - INFO - [19:2] loss\t34.95 =\tBCE 34.94680 \tLL 0.02722 \tTotal 617.73/163.27/5.26 \n","04/22/2023 04:32:24 PM - INFO - [19:3] loss\t34.51 =\tBCE 34.50989 \tLL 0.02648 \tTotal 454.68/82.27/4.16 \n","04/22/2023 04:32:24 PM - INFO - [19:4] loss\t35.28 =\tBCE 35.27993 \tLL 0.02748 \tTotal 580.61/219.88/6.86 \n","04/22/2023 04:32:25 PM - INFO - [19:5] loss\t34.31 =\tBCE 34.31222 \tLL 0.02671 \tTotal 507.10/76.23/9.88 \n","04/22/2023 04:32:25 PM - INFO - [19:6] loss\t34.60 =\tBCE 34.60463 \tLL 0.02716 \tTotal 639.99/160.46/6.60 \n","04/22/2023 04:32:26 PM - INFO - [19:7] loss\t33.27 =\tBCE 33.27067 \tLL 0.02632 \tTotal 357.67/113.20/7.04 \n","04/22/2023 04:32:26 PM - INFO - [19:8] loss\t34.51 =\tBCE 34.51005 \tLL 0.02674 \tTotal 742.60/123.65/4.66 \n","04/22/2023 04:32:27 PM - INFO - [19:9] loss\t33.90 =\tBCE 33.89626 \tLL 0.02737 \tTotal 387.09/97.08/10.43 \n","04/22/2023 04:32:28 PM - INFO - [19:10] loss\t33.72 =\tBCE 33.71939 \tLL 0.02630 \tTotal 674.45/91.51/4.96 \n","04/22/2023 04:32:28 PM - INFO - [19:11] loss\t33.65 =\tBCE 33.64892 \tLL 0.02709 \tTotal 516.97/108.97/8.18 \n","04/22/2023 04:32:29 PM - INFO - [19:12] loss\t33.60 =\tBCE 33.59867 \tLL 0.02625 \tTotal 516.29/70.23/5.03 \n","04/22/2023 04:32:29 PM - INFO - [19:13] loss\t33.75 =\tBCE 33.74579 \tLL 0.02658 \tTotal 663.71/107.81/3.09 \n","04/22/2023 04:32:30 PM - INFO - [19:14] loss\t31.92 =\tBCE 31.91556 \tLL 0.02546 \tTotal 227.68/50.27/7.59 \n","04/22/2023 04:32:30 PM - INFO - [19:15] loss\t32.37 =\tBCE 32.37132 \tLL 0.02573 \tTotal 751.56/98.08/11.81 \n","04/22/2023 04:32:31 PM - INFO - [19:16] loss\t31.84 =\tBCE 31.83758 \tLL 0.02559 \tTotal 402.42/65.46/9.37 \n","04/22/2023 04:32:31 PM - INFO - [19:17] loss\t31.65 =\tBCE 31.64897 \tLL 0.02509 \tTotal 516.17/83.50/9.05 \n","04/22/2023 04:32:32 PM - INFO - [19:18] loss\t31.82 =\tBCE 31.82136 \tLL 0.02548 \tTotal 541.60/66.17/5.23 \n","04/22/2023 04:32:32 PM - INFO - EVALUATION prior to epoch [20]...\n","04/22/2023 04:32:32 PM - INFO - [20] loss\t27.45=\tBCE 27.45 \tLL 0.02438 \n","04/22/2023 04:32:33 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/20_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:32:38 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/20_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:32:44 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/20_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 04:32:45 PM - INFO - Training epoch 20.\n","04/22/2023 04:32:45 PM - INFO - [20:0] loss\t31.61 =\tBCE 31.61272 \tLL 0.02555 \tTotal 301.67/110.21/7.78 \n","04/22/2023 04:32:46 PM - INFO - [20:1] loss\t31.37 =\tBCE 31.37388 \tLL 0.02535 \tTotal 666.73/88.86/10.14 \n","04/22/2023 04:32:46 PM - INFO - [20:2] loss\t31.60 =\tBCE 31.60490 \tLL 0.02517 \tTotal 456.95/92.97/6.17 \n","04/22/2023 04:32:47 PM - INFO - [20:3] loss\t31.38 =\tBCE 31.38245 \tLL 0.02505 \tTotal 469.91/115.17/4.33 \n","04/22/2023 04:32:47 PM - INFO - [20:4] loss\t30.71 =\tBCE 30.70905 \tLL 0.02512 \tTotal 592.26/98.40/9.52 \n","04/22/2023 04:32:48 PM - INFO - [20:5] loss\t30.84 =\tBCE 30.83732 \tLL 0.02529 \tTotal 278.12/50.99/5.79 \n","04/22/2023 04:32:48 PM - INFO - [20:6] loss\t30.79 =\tBCE 30.78985 \tLL 0.02482 \tTotal 722.50/102.32/8.70 \n","04/22/2023 04:32:49 PM - INFO - [20:7] loss\t31.04 =\tBCE 31.03717 \tLL 0.02447 \tTotal 674.83/115.93/3.43 \n","04/22/2023 04:32:49 PM - INFO - [20:8] loss\t30.23 =\tBCE 30.22530 \tLL 0.02410 \tTotal 688.52/122.98/3.79 \n","04/22/2023 04:32:50 PM - INFO - [20:9] loss\t29.52 =\tBCE 29.52475 \tLL 0.02401 \tTotal 801.21/84.55/2.48 \n","04/22/2023 04:32:50 PM - INFO - [20:10] loss\t29.81 =\tBCE 29.80692 \tLL 0.02406 \tTotal 316.52/67.59/6.79 \n","04/22/2023 04:32:51 PM - INFO - [20:11] loss\t29.71 =\tBCE 29.70584 \tLL 0.02411 \tTotal 584.65/104.12/10.96 \n","04/22/2023 04:32:51 PM - INFO - [20:12] loss\t29.54 =\tBCE 29.54480 \tLL 0.02452 \tTotal 935.90/150.92/2.95 \n","04/22/2023 04:32:52 PM - INFO - [20:13] loss\t30.13 =\tBCE 30.12601 \tLL 0.02483 \tTotal 1137.69/195.14/5.50 \n","04/22/2023 04:32:53 PM - INFO - [20:14] loss\t29.32 =\tBCE 29.31911 \tLL 0.02393 \tTotal 873.59/160.38/9.33 \n","04/22/2023 04:32:53 PM - INFO - [20:15] loss\t28.74 =\tBCE 28.74480 \tLL 0.02358 \tTotal 478.32/150.43/2.47 \n","04/22/2023 04:32:54 PM - INFO - [20:16] loss\t29.30 =\tBCE 29.29925 \tLL 0.02395 \tTotal 582.28/166.63/3.13 \n","04/22/2023 04:32:54 PM - INFO - [20:17] loss\t28.97 =\tBCE 28.96542 \tLL 0.02428 \tTotal 758.54/147.60/2.68 \n","04/22/2023 04:32:55 PM - INFO - [20:18] loss\t28.64 =\tBCE 28.64044 \tLL 0.02308 \tTotal 880.72/120.34/8.71 \n","04/22/2023 04:32:55 PM - INFO - Training epoch 21.\n","04/22/2023 04:32:55 PM - INFO - [21:0] loss\t28.61 =\tBCE 28.61499 \tLL 0.02354 \tTotal 1137.46/161.85/5.46 \n","04/22/2023 04:32:56 PM - INFO - [21:1] loss\t28.98 =\tBCE 28.98341 \tLL 0.02418 \tTotal 1242.94/250.78/12.31 \n","04/22/2023 04:32:56 PM - INFO - [21:2] loss\t28.88 =\tBCE 28.88121 \tLL 0.02269 \tTotal 1537.93/425.26/10.26 \n","04/22/2023 04:32:57 PM - INFO - [21:3] loss\t30.27 =\tBCE 30.26786 \tLL 0.02428 \tTotal 2036.96/643.90/8.80 \n","04/22/2023 04:32:57 PM - INFO - [21:4] loss\t32.45 =\tBCE 32.45200 \tLL 0.02272 \tTotal 2882.04/873.11/4.18 \n","04/22/2023 04:32:58 PM - INFO - [21:5] loss\t37.05 =\tBCE 37.04546 \tLL 0.02438 \tTotal 3734.40/1186.64/20.16 \n","04/22/2023 04:32:58 PM - INFO - [21:6] loss\t42.12 =\tBCE 42.12246 \tLL 0.02275 \tTotal 5664.73/1548.37/12.51 \n","04/22/2023 04:32:59 PM - INFO - [21:7] loss\t63.74 =\tBCE 63.74152 \tLL 0.02508 \tTotal 8486.09/2276.27/6.38 \n","04/22/2023 04:33:00 PM - INFO - [21:8] loss\t98.84 =\tBCE 98.83872 \tLL 0.02284 \tTotal 14537.96/3489.18/11.77 \n","04/22/2023 04:33:00 PM - INFO - [21:9] loss\t232.02 =\tBCE 232.02121 \tLL 0.02953 \tTotal 17576.69/5025.65/22.66 \n","04/22/2023 04:33:01 PM - INFO - [21:10] loss\t110.18 =\tBCE 110.17680 \tLL 0.02623 \tTotal 12711.05/3499.04/13.46 \n","04/22/2023 04:33:01 PM - INFO - [21:11] loss\t40.14 =\tBCE 40.14168 \tLL 0.02768 \tTotal 3148.94/569.90/10.32 \n","04/22/2023 04:33:02 PM - INFO - [21:12] loss\t83.18 =\tBCE 83.17814 \tLL 0.03154 \tTotal 7520.56/2411.59/22.24 \n","04/22/2023 04:33:02 PM - INFO - [21:13] loss\t51.10 =\tBCE 51.10229 \tLL 0.03062 \tTotal 6529.81/1257.48/3.26 \n","04/22/2023 04:33:03 PM - INFO - [21:14] loss\t55.50 =\tBCE 55.49985 \tLL 0.03086 \tTotal 5576.83/1746.48/4.37 \n","04/22/2023 04:33:03 PM - INFO - [21:15] loss\t51.00 =\tBCE 51.00084 \tLL 0.03265 \tTotal 3290.61/1550.83/6.53 \n","04/22/2023 04:33:04 PM - INFO - [21:16] loss\t44.20 =\tBCE 44.19592 \tLL 0.03238 \tTotal 4525.51/1000.70/9.07 \n","04/22/2023 04:33:04 PM - INFO - [21:17] loss\t56.47 =\tBCE 56.47134 \tLL 0.02997 \tTotal 4530.53/1694.04/9.84 \n","04/22/2023 04:33:05 PM - INFO - [21:18] loss\t35.29 =\tBCE 35.28727 \tLL 0.03247 \tTotal 1388.69/166.02/7.34 \n","04/22/2023 04:33:05 PM - INFO - Training epoch 22.\n","04/22/2023 04:33:05 PM - INFO - [22:0] loss\t51.58 =\tBCE 51.57738 \tLL 0.03519 \tTotal 3379.07/1385.18/8.41 \n","04/22/2023 04:33:06 PM - INFO - [22:1] loss\t35.46 =\tBCE 35.45805 \tLL 0.03316 \tTotal 1804.71/260.68/14.88 \n","04/22/2023 04:33:06 PM - INFO - [22:2] loss\t48.52 =\tBCE 48.51748 \tLL 0.03307 \tTotal 2944.51/1329.48/10.02 \n","04/22/2023 04:33:07 PM - INFO - [22:3] loss\t36.73 =\tBCE 36.72982 \tLL 0.03462 \tTotal 1760.07/309.03/3.91 \n","04/22/2023 04:33:07 PM - INFO - [22:4] loss\t43.68 =\tBCE 43.68114 \tLL 0.03511 \tTotal 2587.52/1050.80/18.95 \n","04/22/2023 04:33:08 PM - INFO - [22:5] loss\t36.72 =\tBCE 36.72248 \tLL 0.03526 \tTotal 1614.72/286.18/10.53 \n","04/22/2023 04:33:09 PM - INFO - [22:6] loss\t41.94 =\tBCE 41.93546 \tLL 0.03442 \tTotal 2647.23/972.34/9.51 \n","04/22/2023 04:33:09 PM - INFO - [22:7] loss\t34.70 =\tBCE 34.69957 \tLL 0.03422 \tTotal 1195.27/205.19/2.15 \n","04/22/2023 04:33:10 PM - INFO - [22:8] loss\t40.57 =\tBCE 40.57423 \tLL 0.03473 \tTotal 2511.49/860.96/12.72 \n","04/22/2023 04:33:10 PM - INFO - [22:9] loss\t34.29 =\tBCE 34.29304 \tLL 0.03426 \tTotal 1010.10/122.21/9.91 \n","04/22/2023 04:33:11 PM - INFO - [22:10] loss\t38.70 =\tBCE 38.70331 \tLL 0.03209 \tTotal 2342.65/778.23/7.60 \n","04/22/2023 04:33:11 PM - INFO - [22:11] loss\t32.57 =\tBCE 32.56821 \tLL 0.03223 \tTotal 682.02/96.52/11.71 \n","04/22/2023 04:33:12 PM - INFO - [22:12] loss\t37.24 =\tBCE 37.24369 \tLL 0.03201 \tTotal 2135.69/731.81/20.69 \n","04/22/2023 04:33:12 PM - INFO - [22:13] loss\t33.00 =\tBCE 32.99812 \tLL 0.03189 \tTotal 1242.40/129.84/5.80 \n","04/22/2023 04:33:13 PM - INFO - [22:14] loss\t34.95 =\tBCE 34.95202 \tLL 0.03066 \tTotal 1489.17/622.34/13.42 \n","04/22/2023 04:33:13 PM - INFO - [22:15] loss\t32.40 =\tBCE 32.39568 \tLL 0.03085 \tTotal 1335.23/180.79/15.89 \n","04/22/2023 04:33:14 PM - INFO - [22:16] loss\t34.47 =\tBCE 34.47500 \tLL 0.03025 \tTotal 1446.15/544.34/21.58 \n","04/22/2023 04:33:15 PM - INFO - [22:17] loss\t31.62 =\tBCE 31.61759 \tLL 0.02921 \tTotal 694.61/122.34/5.16 \n","04/22/2023 04:33:15 PM - INFO - [22:18] loss\t32.85 =\tBCE 32.84582 \tLL 0.02793 \tTotal 1735.68/525.12/23.53 \n","04/22/2023 04:33:15 PM - INFO - Training epoch 23.\n","04/22/2023 04:33:16 PM - INFO - [23:0] loss\t31.11 =\tBCE 31.11203 \tLL 0.02890 \tTotal 854.47/111.09/19.92 \n","04/22/2023 04:33:16 PM - INFO - [23:1] loss\t32.02 =\tBCE 32.02261 \tLL 0.02891 \tTotal 1128.56/417.98/10.26 \n","04/22/2023 04:33:17 PM - INFO - [23:2] loss\t30.93 =\tBCE 30.92977 \tLL 0.02856 \tTotal 939.05/170.95/6.78 \n","04/22/2023 04:33:17 PM - INFO - [23:3] loss\t31.51 =\tBCE 31.51485 \tLL 0.02722 \tTotal 1172.33/383.38/23.17 \n","04/22/2023 04:33:18 PM - INFO - [23:4] loss\t30.17 =\tBCE 30.17221 \tLL 0.02749 \tTotal 925.39/197.14/24.46 \n","04/22/2023 04:33:18 PM - INFO - [23:5] loss\t30.99 =\tBCE 30.99454 \tLL 0.02731 \tTotal 1162.08/292.79/6.34 \n","04/22/2023 04:33:19 PM - INFO - [23:6] loss\t29.35 =\tBCE 29.35316 \tLL 0.02596 \tTotal 854.19/255.55/13.29 \n","04/22/2023 04:33:19 PM - INFO - [23:7] loss\t29.30 =\tBCE 29.30039 \tLL 0.02550 \tTotal 935.16/248.11/18.97 \n","04/22/2023 04:33:20 PM - INFO - [23:8] loss\t30.27 =\tBCE 30.27209 \tLL 0.02620 \tTotal 1155.26/331.08/24.64 \n","04/22/2023 04:33:20 PM - INFO - [23:9] loss\t29.11 =\tBCE 29.11406 \tLL 0.02567 \tTotal 479.13/119.22/4.79 \n","04/22/2023 04:33:21 PM - INFO - [23:10] loss\t29.29 =\tBCE 29.29211 \tLL 0.02517 \tTotal 993.09/315.04/18.76 \n","04/22/2023 04:33:21 PM - INFO - [23:11] loss\t28.68 =\tBCE 28.67729 \tLL 0.02520 \tTotal 833.47/129.14/6.92 \n","04/22/2023 04:33:22 PM - INFO - [23:12] loss\t28.49 =\tBCE 28.49375 \tLL 0.02449 \tTotal 774.76/262.72/18.28 \n","04/22/2023 04:33:23 PM - INFO - [23:13] loss\t28.57 =\tBCE 28.56731 \tLL 0.02417 \tTotal 667.22/111.73/12.00 \n","04/22/2023 04:33:23 PM - INFO - [23:14] loss\t27.78 =\tBCE 27.77638 \tLL 0.02391 \tTotal 716.11/191.21/6.49 \n","04/22/2023 04:33:24 PM - INFO - [23:15] loss\t28.83 =\tBCE 28.82507 \tLL 0.02535 \tTotal 916.72/165.73/22.68 \n","04/22/2023 04:33:24 PM - INFO - [23:16] loss\t28.06 =\tBCE 28.05988 \tLL 0.02508 \tTotal 461.27/99.70/16.45 \n","04/22/2023 04:33:25 PM - INFO - [23:17] loss\t28.34 =\tBCE 28.34359 \tLL 0.02373 \tTotal 827.69/191.04/4.91 \n","04/22/2023 04:33:25 PM - INFO - [23:18] loss\t28.08 =\tBCE 28.08430 \tLL 0.02408 \tTotal 1048.68/126.51/15.57 \n","04/22/2023 04:33:25 PM - INFO - Training epoch 24.\n","04/22/2023 04:33:26 PM - INFO - [24:0] loss\t27.44 =\tBCE 27.44122 \tLL 0.02311 \tTotal 739.05/124.82/20.46 \n","04/22/2023 04:33:26 PM - INFO - [24:1] loss\t27.47 =\tBCE 27.47489 \tLL 0.02356 \tTotal 595.83/157.45/2.80 \n","04/22/2023 04:33:27 PM - INFO - [24:2] loss\t27.13 =\tBCE 27.12933 \tLL 0.02286 \tTotal 1151.50/115.55/2.32 \n","04/22/2023 04:33:27 PM - INFO - [24:3] loss\t27.06 =\tBCE 27.05758 \tLL 0.02264 \tTotal 908.90/135.98/2.19 \n","04/22/2023 04:33:28 PM - INFO - [24:4] loss\t26.65 =\tBCE 26.64627 \tLL 0.02255 \tTotal 665.44/93.54/13.09 \n","04/22/2023 04:33:28 PM - INFO - [24:5] loss\t26.57 =\tBCE 26.57449 \tLL 0.02225 \tTotal 483.15/104.40/10.63 \n","04/22/2023 04:33:29 PM - INFO - [24:6] loss\t26.67 =\tBCE 26.66675 \tLL 0.02282 \tTotal 497.93/92.65/7.44 \n","04/22/2023 04:33:29 PM - INFO - [24:7] loss\t26.18 =\tBCE 26.18494 \tLL 0.02229 \tTotal 687.63/96.96/8.49 \n","04/22/2023 04:33:30 PM - INFO - [24:8] loss\t25.80 =\tBCE 25.80309 \tLL 0.02182 \tTotal 694.89/95.33/18.28 \n","04/22/2023 04:33:30 PM - INFO - [24:9] loss\t26.24 =\tBCE 26.24488 \tLL 0.02315 \tTotal 926.46/100.66/5.37 \n","04/22/2023 04:33:31 PM - INFO - [24:10] loss\t25.98 =\tBCE 25.97702 \tLL 0.02229 \tTotal 895.38/112.23/19.72 \n","04/22/2023 04:33:32 PM - INFO - [24:11] loss\t25.94 =\tBCE 25.94141 \tLL 0.02204 \tTotal 830.12/130.63/13.56 \n","04/22/2023 04:33:32 PM - INFO - [24:12] loss\t25.43 =\tBCE 25.43029 \tLL 0.02140 \tTotal 830.03/123.86/13.33 \n","04/22/2023 04:33:33 PM - INFO - [24:13] loss\t26.36 =\tBCE 26.36326 \tLL 0.02249 \tTotal 1058.82/124.79/24.64 \n","04/22/2023 04:33:33 PM - INFO - [24:14] loss\t25.57 =\tBCE 25.56525 \tLL 0.02107 \tTotal 1213.37/155.12/9.64 \n","04/22/2023 04:33:34 PM - INFO - [24:15] loss\t25.54 =\tBCE 25.54001 \tLL 0.02143 \tTotal 1379.30/197.74/4.18 \n","04/22/2023 04:33:34 PM - INFO - [24:16] loss\t25.76 =\tBCE 25.76270 \tLL 0.02118 \tTotal 1400.98/269.64/14.94 \n","04/22/2023 04:33:35 PM - INFO - [24:17] loss\t25.71 =\tBCE 25.71477 \tLL 0.02149 \tTotal 1406.29/297.03/11.34 \n","04/22/2023 04:33:35 PM - INFO - [24:18] loss\t25.81 =\tBCE 25.81146 \tLL 0.02128 \tTotal 1493.56/337.42/4.47 \n","04/22/2023 04:33:35 PM - INFO - Training epoch 25.\n","04/22/2023 04:33:36 PM - INFO - [25:0] loss\t25.51 =\tBCE 25.51086 \tLL 0.02076 \tTotal 1674.33/366.13/4.23 \n","04/22/2023 04:33:36 PM - INFO - [25:1] loss\t26.22 =\tBCE 26.21830 \tLL 0.02102 \tTotal 2070.36/385.82/9.76 \n","04/22/2023 04:33:37 PM - INFO - [25:2] loss\t26.45 =\tBCE 26.45214 \tLL 0.02119 \tTotal 2817.72/448.57/18.51 \n","04/22/2023 04:33:37 PM - INFO - [25:3] loss\t28.69 =\tBCE 28.69076 \tLL 0.02058 \tTotal 3978.73/621.67/6.98 \n","04/22/2023 04:33:38 PM - INFO - [25:4] loss\t34.38 =\tBCE 34.38182 \tLL 0.02136 \tTotal 5514.32/907.19/6.68 \n","04/22/2023 04:33:38 PM - INFO - [25:5] loss\t44.28 =\tBCE 44.27908 \tLL 0.01963 \tTotal 8554.03/1472.51/11.67 \n","04/22/2023 04:33:39 PM - INFO - [25:6] loss\t87.50 =\tBCE 87.50487 \tLL 0.02237 \tTotal 12864.34/2445.96/13.13 \n","04/22/2023 04:33:40 PM - INFO - [25:7] loss\t125.12 =\tBCE 125.12487 \tLL 0.02116 \tTotal 18851.64/3400.12/2.95 \n","04/22/2023 04:33:40 PM - INFO - [25:8] loss\t211.41 =\tBCE 211.41217 \tLL 0.02605 \tTotal 20466.00/3734.57/8.72 \n","04/22/2023 04:33:41 PM - INFO - [25:9] loss\t67.93 =\tBCE 67.92707 \tLL 0.02405 \tTotal 11560.88/1503.64/11.34 \n","04/22/2023 04:33:41 PM - INFO - [25:10] loss\t76.26 =\tBCE 76.26225 \tLL 0.02363 \tTotal 9040.26/2882.59/6.37 \n","04/22/2023 04:33:42 PM - INFO - [25:11] loss\t141.74 =\tBCE 141.74313 \tLL 0.02790 \tTotal 14178.28/3335.66/6.53 \n","04/22/2023 04:33:42 PM - INFO - [25:12] loss\t45.61 =\tBCE 45.60532 \tLL 0.02682 \tTotal 6976.50/994.22/9.29 \n","04/22/2023 04:33:43 PM - INFO - [25:13] loss\t120.09 =\tBCE 120.09399 \tLL 0.02538 \tTotal 11312.20/3661.84/16.50 \n","04/22/2023 04:33:43 PM - INFO - [25:14] loss\t67.01 =\tBCE 67.00515 \tLL 0.02950 \tTotal 8004.78/1653.99/25.99 \n","04/22/2023 04:33:44 PM - INFO - [25:15] loss\t77.26 =\tBCE 77.25771 \tLL 0.03072 \tTotal 6737.16/2328.15/7.75 \n","04/22/2023 04:33:44 PM - INFO - [25:16] loss\t62.63 =\tBCE 62.63310 \tLL 0.02940 \tTotal 6895.98/1757.53/12.05 \n","04/22/2023 04:33:45 PM - INFO - [25:17] loss\t57.65 =\tBCE 57.64555 \tLL 0.02913 \tTotal 4980.20/1840.94/15.16 \n","04/22/2023 04:33:45 PM - INFO - [25:18] loss\t56.85 =\tBCE 56.84981 \tLL 0.03026 \tTotal 5442.81/1496.27/10.76 \n","04/22/2023 04:33:45 PM - INFO - Training epoch 26.\n","04/22/2023 04:33:46 PM - INFO - [26:0] loss\t56.02 =\tBCE 56.02343 \tLL 0.03074 \tTotal 4310.81/1735.89/16.59 \n","04/22/2023 04:33:46 PM - INFO - [26:1] loss\t46.22 =\tBCE 46.21566 \tLL 0.03125 \tTotal 4220.47/1169.56/19.71 \n","04/22/2023 04:33:47 PM - INFO - [26:2] loss\t57.01 =\tBCE 57.00845 \tLL 0.03025 \tTotal 4448.56/1781.29/11.08 \n","04/22/2023 04:33:47 PM - INFO - [26:3] loss\t39.45 =\tBCE 39.45329 \tLL 0.03162 \tTotal 2335.96/886.91/10.11 \n","04/22/2023 04:33:48 PM - INFO - [26:4] loss\t57.56 =\tBCE 57.55770 \tLL 0.03182 \tTotal 4113.27/1664.54/27.06 \n","04/22/2023 04:33:48 PM - INFO - [26:5] loss\t34.63 =\tBCE 34.63322 \tLL 0.03239 \tTotal 1532.75/457.19/4.96 \n","04/22/2023 04:33:49 PM - INFO - [26:6] loss\t53.89 =\tBCE 53.89376 \tLL 0.03228 \tTotal 4030.44/1486.43/28.52 \n","04/22/2023 04:33:49 PM - INFO - [26:7] loss\t36.29 =\tBCE 36.28643 \tLL 0.03336 \tTotal 2267.19/285.18/19.90 \n","04/22/2023 04:33:50 PM - INFO - [26:8] loss\t44.29 =\tBCE 44.29170 \tLL 0.03213 \tTotal 3106.08/1033.37/10.01 \n","04/22/2023 04:33:51 PM - INFO - [26:9] loss\t39.52 =\tBCE 39.51931 \tLL 0.03264 \tTotal 3425.92/588.02/16.38 \n","04/22/2023 04:33:51 PM - INFO - [26:10] loss\t37.10 =\tBCE 37.09865 \tLL 0.03192 \tTotal 2103.65/569.75/7.77 \n","04/22/2023 04:33:52 PM - INFO - [26:11] loss\t42.32 =\tBCE 42.32138 \tLL 0.03052 \tTotal 3890.24/802.03/8.24 \n","04/22/2023 04:33:52 PM - INFO - [26:12] loss\t33.62 =\tBCE 33.62264 \tLL 0.03177 \tTotal 1520.96/187.86/11.79 \n","04/22/2023 04:33:53 PM - INFO - [26:13] loss\t41.98 =\tBCE 41.97869 \tLL 0.03165 \tTotal 3411.97/751.69/14.35 \n","04/22/2023 04:33:53 PM - INFO - [26:14] loss\t33.88 =\tBCE 33.88212 \tLL 0.03052 \tTotal 1509.70/390.01/8.47 \n","04/22/2023 04:33:54 PM - INFO - [26:15] loss\t37.36 =\tBCE 37.35850 \tLL 0.02929 \tTotal 2590.37/583.10/6.19 \n","04/22/2023 04:33:54 PM - INFO - [26:16] loss\t35.55 =\tBCE 35.55421 \tLL 0.02968 \tTotal 1766.29/648.93/13.96 \n","04/22/2023 04:33:55 PM - INFO - [26:17] loss\t32.23 =\tBCE 32.22693 \tLL 0.02925 \tTotal 1449.66/282.55/6.54 \n","04/22/2023 04:33:55 PM - INFO - [26:18] loss\t36.12 =\tBCE 36.11829 \tLL 0.02877 \tTotal 1845.78/694.49/6.62 \n","04/22/2023 04:33:55 PM - INFO - Training epoch 27.\n","04/22/2023 04:33:56 PM - INFO - [27:0] loss\t31.07 =\tBCE 31.06829 \tLL 0.02782 \tTotal 1095.10/122.76/3.71 \n","04/22/2023 04:33:56 PM - INFO - [27:1] loss\t34.65 =\tBCE 34.65311 \tLL 0.02725 \tTotal 1618.70/631.40/7.40 \n","04/22/2023 04:33:57 PM - INFO - [27:2] loss\t31.65 =\tBCE 31.65065 \tLL 0.02827 \tTotal 1468.53/266.12/16.28 \n","04/22/2023 04:33:57 PM - INFO - [27:3] loss\t32.17 =\tBCE 32.16985 \tLL 0.02804 \tTotal 946.89/417.15/11.72 \n","04/22/2023 04:33:58 PM - INFO - [27:4] loss\t32.19 =\tBCE 32.18656 \tLL 0.02663 \tTotal 1849.13/397.72/4.87 \n","04/22/2023 04:33:58 PM - INFO - [27:5] loss\t30.28 =\tBCE 30.28452 \tLL 0.02606 \tTotal 1001.28/201.17/9.62 \n","04/22/2023 04:33:59 PM - INFO - [27:6] loss\t31.73 =\tBCE 31.72515 \tLL 0.02547 \tTotal 1616.63/447.53/14.06 \n","04/22/2023 04:33:59 PM - INFO - [27:7] loss\t30.10 =\tBCE 30.09801 \tLL 0.02651 \tTotal 1079.61/104.77/7.14 \n","04/22/2023 04:34:00 PM - INFO - [27:8] loss\t30.67 =\tBCE 30.66678 \tLL 0.02618 \tTotal 1294.18/370.52/9.34 \n","04/22/2023 04:34:00 PM - INFO - [27:9] loss\t29.79 =\tBCE 29.78755 \tLL 0.02582 \tTotal 1155.73/220.49/10.94 \n","04/22/2023 04:34:01 PM - INFO - [27:10] loss\t29.91 =\tBCE 29.91192 \tLL 0.02523 \tTotal 862.28/298.31/9.24 \n","04/22/2023 04:34:02 PM - INFO - [27:11] loss\t29.63 =\tBCE 29.62995 \tLL 0.02480 \tTotal 1170.03/282.88/8.08 \n","04/22/2023 04:34:02 PM - INFO - [27:12] loss\t29.34 =\tBCE 29.34048 \tLL 0.02545 \tTotal 721.21/190.84/6.15 \n","04/22/2023 04:34:03 PM - INFO - [27:13] loss\t28.99 =\tBCE 28.99399 \tLL 0.02425 \tTotal 1089.70/282.60/5.34 \n","04/22/2023 04:34:03 PM - INFO - [27:14] loss\t28.42 =\tBCE 28.42492 \tLL 0.02435 \tTotal 618.03/106.65/12.97 \n","04/22/2023 04:34:04 PM - INFO - [27:15] loss\t29.19 =\tBCE 29.18703 \tLL 0.02364 \tTotal 1194.69/258.49/5.58 \n","04/22/2023 04:34:04 PM - INFO - [27:16] loss\t27.31 =\tBCE 27.31462 \tLL 0.02380 \tTotal 586.27/82.20/7.80 \n","04/22/2023 04:34:05 PM - INFO - [27:17] loss\t29.37 =\tBCE 29.37462 \tLL 0.02445 \tTotal 1157.01/205.96/18.45 \n","04/22/2023 04:34:05 PM - INFO - [27:18] loss\t27.22 =\tBCE 27.22071 \tLL 0.02305 \tTotal 477.44/105.55/10.70 \n","04/22/2023 04:34:05 PM - INFO - Training epoch 28.\n","04/22/2023 04:34:06 PM - INFO - [28:0] loss\t28.32 =\tBCE 28.32192 \tLL 0.02365 \tTotal 1150.83/203.63/6.81 \n","04/22/2023 04:34:06 PM - INFO - [28:1] loss\t27.35 =\tBCE 27.35188 \tLL 0.02342 \tTotal 306.61/150.98/13.25 \n","04/22/2023 04:34:07 PM - INFO - [28:2] loss\t27.60 =\tBCE 27.59534 \tLL 0.02332 \tTotal 830.77/186.43/9.65 \n","04/22/2023 04:34:07 PM - INFO - [28:3] loss\t26.70 =\tBCE 26.70048 \tLL 0.02268 \tTotal 398.09/153.64/4.78 \n","04/22/2023 04:34:08 PM - INFO - [28:4] loss\t26.59 =\tBCE 26.59132 \tLL 0.02269 \tTotal 573.43/206.05/2.10 \n","04/22/2023 04:34:08 PM - INFO - [28:5] loss\t26.36 =\tBCE 26.35561 \tLL 0.02215 \tTotal 384.20/137.79/11.22 \n","04/22/2023 04:34:09 PM - INFO - [28:6] loss\t26.01 =\tBCE 26.00609 \tLL 0.02190 \tTotal 537.32/207.49/14.66 \n","04/22/2023 04:34:09 PM - INFO - [28:7] loss\t26.48 =\tBCE 26.48335 \tLL 0.02273 \tTotal 492.03/93.62/10.11 \n","04/22/2023 04:34:10 PM - INFO - [28:8] loss\t25.80 =\tBCE 25.79974 \tLL 0.02154 \tTotal 576.95/200.93/16.44 \n","04/22/2023 04:34:11 PM - INFO - [28:9] loss\t26.15 =\tBCE 26.15474 \tLL 0.02212 \tTotal 599.91/76.04/7.66 \n","04/22/2023 04:34:11 PM - INFO - [28:10] loss\t25.59 =\tBCE 25.58564 \tLL 0.02142 \tTotal 817.17/129.61/7.59 \n","04/22/2023 04:34:12 PM - INFO - [28:11] loss\t25.29 =\tBCE 25.29012 \tLL 0.02082 \tTotal 427.65/52.50/10.26 \n","04/22/2023 04:34:12 PM - INFO - [28:12] loss\t25.57 =\tBCE 25.56965 \tLL 0.02135 \tTotal 498.76/119.76/7.43 \n","04/22/2023 04:34:13 PM - INFO - [28:13] loss\t25.28 =\tBCE 25.28132 \tLL 0.02102 \tTotal 488.77/55.67/4.87 \n","04/22/2023 04:34:13 PM - INFO - [28:14] loss\t25.27 =\tBCE 25.27425 \tLL 0.02121 \tTotal 604.16/95.82/6.00 \n","04/22/2023 04:34:14 PM - INFO - [28:15] loss\t25.59 =\tBCE 25.59478 \tLL 0.02165 \tTotal 446.16/53.68/3.45 \n","04/22/2023 04:34:14 PM - INFO - [28:16] loss\t24.50 =\tBCE 24.49950 \tLL 0.02067 \tTotal 585.29/140.31/6.04 \n","04/22/2023 04:34:15 PM - INFO - [28:17] loss\t24.46 =\tBCE 24.46042 \tLL 0.02083 \tTotal 440.66/82.63/8.01 \n","04/22/2023 04:34:15 PM - INFO - [28:18] loss\t24.67 =\tBCE 24.67214 \tLL 0.02096 \tTotal 692.12/99.47/8.04 \n","Not implemented\n","04/22/2023 04:34:15 PM - INFO - Training epoch 29.\n","04/22/2023 04:34:16 PM - INFO - [29:0] loss\t24.86 =\tBCE 24.85662 \tLL 0.02077 \tTotal 596.65/82.81/10.87 \n","04/22/2023 04:34:16 PM - INFO - [29:1] loss\t24.47 =\tBCE 24.46883 \tLL 0.02070 \tTotal 641.50/79.07/2.62 \n","04/22/2023 04:34:17 PM - INFO - [29:2] loss\t24.58 =\tBCE 24.57518 \tLL 0.02135 \tTotal 436.75/67.14/6.77 \n","04/22/2023 04:34:17 PM - INFO - [29:3] loss\t24.11 =\tBCE 24.11308 \tLL 0.02097 \tTotal 688.33/74.16/10.79 \n","04/22/2023 04:34:18 PM - INFO - [29:4] loss\t24.37 =\tBCE 24.37095 \tLL 0.02033 \tTotal 900.70/91.18/2.61 \n","04/22/2023 04:34:18 PM - INFO - [29:5] loss\t24.10 =\tBCE 24.09630 \tLL 0.01998 \tTotal 536.31/89.17/11.10 \n","04/22/2023 04:34:19 PM - INFO - [29:6] loss\t23.84 =\tBCE 23.84023 \tLL 0.02046 \tTotal 510.03/69.16/5.70 \n","04/22/2023 04:34:19 PM - INFO - [29:7] loss\t23.58 =\tBCE 23.57964 \tLL 0.01964 \tTotal 586.85/78.44/7.98 \n","04/22/2023 04:34:20 PM - INFO - [29:8] loss\t23.56 =\tBCE 23.56073 \tLL 0.01954 \tTotal 558.87/119.66/5.52 \n","04/22/2023 04:34:21 PM - INFO - [29:9] loss\t23.61 =\tBCE 23.61269 \tLL 0.02023 \tTotal 720.72/89.03/4.94 \n","04/22/2023 04:34:21 PM - INFO - [29:10] loss\t23.43 =\tBCE 23.42710 \tLL 0.01997 \tTotal 683.44/90.91/14.99 \n","04/22/2023 04:34:22 PM - INFO - [29:11] loss\t23.40 =\tBCE 23.39862 \tLL 0.01929 \tTotal 445.91/105.54/7.96 \n","04/22/2023 04:34:22 PM - INFO - [29:12] loss\t22.77 =\tBCE 22.77174 \tLL 0.01930 \tTotal 526.91/81.72/4.62 \n","04/22/2023 04:34:23 PM - INFO - [29:13] loss\t23.04 =\tBCE 23.03569 \tLL 0.01922 \tTotal 1116.00/137.06/8.95 \n","04/22/2023 04:34:23 PM - INFO - [29:14] loss\t23.48 =\tBCE 23.47542 \tLL 0.01967 \tTotal 1420.47/186.65/6.32 \n","04/22/2023 04:34:24 PM - INFO - [29:15] loss\t23.18 =\tBCE 23.18083 \tLL 0.01883 \tTotal 1403.11/279.79/2.05 \n","04/22/2023 04:34:24 PM - INFO - [29:16] loss\t23.81 =\tBCE 23.81321 \tLL 0.01978 \tTotal 1515.07/352.98/2.80 \n","04/22/2023 04:34:25 PM - INFO - [29:17] loss\t23.79 =\tBCE 23.78673 \tLL 0.01886 \tTotal 2050.32/379.95/8.73 \n","04/22/2023 04:34:25 PM - INFO - [29:18] loss\t24.66 =\tBCE 24.66244 \tLL 0.01869 \tTotal 3060.87/440.69/8.87 \n","04/22/2023 04:34:25 PM - INFO - EVALUATION prior to epoch [30]...\n","04/22/2023 04:34:25 PM - INFO - [30] loss\t23.01=\tBCE 23.01 \tLL 0.01834 \n","04/22/2023 04:34:27 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/30_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:34:31 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/30_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:34:38 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/30_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 04:34:38 PM - INFO - Training epoch 30.\n","04/22/2023 04:34:39 PM - INFO - [30:0] loss\t27.48 =\tBCE 27.48480 \tLL 0.01908 \tTotal 4450.13/584.84/3.20 \n","04/22/2023 04:34:39 PM - INFO - [30:1] loss\t33.37 =\tBCE 33.37141 \tLL 0.01937 \tTotal 6566.87/868.61/2.03 \n","04/22/2023 04:34:40 PM - INFO - [30:2] loss\t48.09 =\tBCE 48.09399 \tLL 0.01893 \tTotal 10573.62/1320.07/2.16 \n","04/22/2023 04:34:40 PM - INFO - [30:3] loss\t90.00 =\tBCE 90.00051 \tLL 0.02033 \tTotal 16807.28/2097.14/1.73 \n","04/22/2023 04:34:41 PM - INFO - [30:4] loss\t186.99 =\tBCE 186.98932 \tLL 0.01834 \tTotal 26033.03/3396.10/4.11 \n","04/22/2023 04:34:41 PM - INFO - [30:5] loss\t331.64 =\tBCE 331.64029 \tLL 0.02194 \tTotal 32951.65/4281.10/11.19 \n","04/22/2023 04:34:42 PM - INFO - [30:6] loss\t169.26 =\tBCE 169.26224 \tLL 0.02025 \tTotal 25012.86/2635.07/6.45 \n","04/22/2023 04:34:42 PM - INFO - [30:7] loss\t71.93 =\tBCE 71.93133 \tLL 0.02055 \tTotal 12875.29/1714.34/7.63 \n","04/22/2023 04:34:43 PM - INFO - [30:8] loss\t195.12 =\tBCE 195.12355 \tLL 0.02537 \tTotal 21834.19/2515.24/10.41 \n","04/22/2023 04:34:43 PM - INFO - [30:9] loss\t52.74 =\tBCE 52.74384 \tLL 0.02350 \tTotal 7762.70/1066.84/7.76 \n","04/22/2023 04:34:44 PM - INFO - [30:10] loss\t146.55 =\tBCE 146.54779 \tLL 0.02149 \tTotal 17907.52/2458.56/10.87 \n","04/22/2023 04:34:44 PM - INFO - [30:11] loss\t94.70 =\tBCE 94.69548 \tLL 0.02500 \tTotal 13195.96/1502.85/2.23 \n","04/22/2023 04:34:45 PM - INFO - [30:12] loss\t96.07 =\tBCE 96.06882 \tLL 0.02747 \tTotal 12933.16/1468.60/9.44 \n","04/22/2023 04:34:45 PM - INFO - [30:13] loss\t71.35 =\tBCE 71.34937 \tLL 0.02626 \tTotal 9103.60/969.36/9.53 \n","04/22/2023 04:34:46 PM - INFO - [30:14] loss\t90.19 =\tBCE 90.18777 \tLL 0.02630 \tTotal 11490.19/1370.04/9.68 \n","04/22/2023 04:34:47 PM - INFO - [30:15] loss\t61.04 =\tBCE 61.04097 \tLL 0.02667 \tTotal 8145.52/850.57/8.03 \n","04/22/2023 04:34:47 PM - INFO - [30:16] loss\t65.21 =\tBCE 65.21062 \tLL 0.02785 \tTotal 8970.57/1032.88/11.79 \n","04/22/2023 04:34:48 PM - INFO - [30:17] loss\t58.96 =\tBCE 58.96033 \tLL 0.02942 \tTotal 7442.70/899.32/6.42 \n","04/22/2023 04:34:48 PM - INFO - [30:18] loss\t47.58 =\tBCE 47.57771 \tLL 0.02672 \tTotal 5299.87/590.79/3.43 \n","04/22/2023 04:34:48 PM - INFO - Training epoch 31.\n","04/22/2023 04:34:49 PM - INFO - [31:0] loss\t56.13 =\tBCE 56.12982 \tLL 0.02676 \tTotal 6751.82/1019.34/12.73 \n","04/22/2023 04:34:49 PM - INFO - [31:1] loss\t42.72 =\tBCE 42.72440 \tLL 0.02755 \tTotal 4007.78/401.97/15.05 \n","04/22/2023 04:34:50 PM - INFO - [31:2] loss\t52.95 =\tBCE 52.94667 \tLL 0.02908 \tTotal 4816.88/884.37/9.36 \n","04/22/2023 04:34:50 PM - INFO - [31:3] loss\t39.92 =\tBCE 39.92073 \tLL 0.02794 \tTotal 2627.06/530.57/11.71 \n","04/22/2023 04:34:51 PM - INFO - [31:4] loss\t46.79 =\tBCE 46.78994 \tLL 0.02721 \tTotal 4148.41/618.68/16.37 \n","04/22/2023 04:34:51 PM - INFO - [31:5] loss\t40.50 =\tBCE 40.49566 \tLL 0.02728 \tTotal 3068.92/700.29/5.82 \n","04/22/2023 04:34:52 PM - INFO - [31:6] loss\t38.78 =\tBCE 38.77801 \tLL 0.02717 \tTotal 2815.63/297.93/8.03 \n","04/22/2023 04:34:52 PM - INFO - [31:7] loss\t42.12 =\tBCE 42.11679 \tLL 0.02856 \tTotal 3376.60/621.33/6.21 \n","04/22/2023 04:34:53 PM - INFO - [31:8] loss\t36.75 =\tBCE 36.74619 \tLL 0.02722 \tTotal 1860.73/432.04/11.48 \n","04/22/2023 04:34:53 PM - INFO - [31:9] loss\t40.52 =\tBCE 40.51736 \tLL 0.02718 \tTotal 3216.30/413.74/9.89 \n","04/22/2023 04:34:54 PM - INFO - [31:10] loss\t38.47 =\tBCE 38.46818 \tLL 0.02783 \tTotal 1705.14/613.35/15.56 \n","04/22/2023 04:34:54 PM - INFO - [31:11] loss\t35.92 =\tBCE 35.91625 \tLL 0.02764 \tTotal 2186.73/276.95/12.08 \n","04/22/2023 04:34:55 PM - INFO - [31:12] loss\t37.23 =\tBCE 37.22517 \tLL 0.02740 \tTotal 2018.01/487.29/2.94 \n","04/22/2023 04:34:56 PM - INFO - [31:13] loss\t37.13 =\tBCE 37.12556 \tLL 0.02562 \tTotal 1902.49/466.85/8.92 \n","04/22/2023 04:34:56 PM - INFO - [31:14] loss\t34.84 =\tBCE 34.84216 \tLL 0.02553 \tTotal 1837.63/285.07/8.98 \n","04/22/2023 04:34:57 PM - INFO - [31:15] loss\t35.76 =\tBCE 35.76145 \tLL 0.02588 \tTotal 1531.58/472.46/3.87 \n","04/22/2023 04:34:57 PM - INFO - [31:16] loss\t34.75 =\tBCE 34.75031 \tLL 0.02541 \tTotal 1728.40/271.08/7.04 \n","04/22/2023 04:34:58 PM - INFO - [31:17] loss\t34.24 =\tBCE 34.23896 \tLL 0.02607 \tTotal 983.09/304.73/8.15 \n","04/22/2023 04:34:58 PM - INFO - [31:18] loss\t35.13 =\tBCE 35.13466 \tLL 0.02429 \tTotal 1854.74/367.62/4.73 \n","04/22/2023 04:34:58 PM - INFO - Training epoch 32.\n","04/22/2023 04:34:59 PM - INFO - [32:0] loss\t32.77 =\tBCE 32.76595 \tLL 0.02426 \tTotal 1390.65/159.89/4.18 \n","04/22/2023 04:34:59 PM - INFO - [32:1] loss\t31.90 =\tBCE 31.89878 \tLL 0.02439 \tTotal 1124.64/331.28/10.18 \n","04/22/2023 04:35:00 PM - INFO - [32:2] loss\t33.28 =\tBCE 33.28496 \tLL 0.02513 \tTotal 1779.09/257.88/9.51 \n","04/22/2023 04:35:00 PM - INFO - [32:3] loss\t31.20 =\tBCE 31.19630 \tLL 0.02429 \tTotal 522.09/131.84/5.00 \n","04/22/2023 04:35:01 PM - INFO - [32:4] loss\t32.81 =\tBCE 32.80794 \tLL 0.02427 \tTotal 1533.93/254.50/3.17 \n","04/22/2023 04:35:01 PM - INFO - [32:5] loss\t30.74 =\tBCE 30.74386 \tLL 0.02352 \tTotal 892.99/130.40/7.19 \n","04/22/2023 04:35:02 PM - INFO - [32:6] loss\t31.75 =\tBCE 31.74852 \tLL 0.02420 \tTotal 1436.50/195.11/8.64 \n","04/22/2023 04:35:02 PM - INFO - [32:7] loss\t30.91 =\tBCE 30.91034 \tLL 0.02383 \tTotal 978.68/171.44/3.79 \n","04/22/2023 04:35:03 PM - INFO - [32:8] loss\t30.73 =\tBCE 30.73077 \tLL 0.02359 \tTotal 1224.21/139.52/5.69 \n","04/22/2023 04:35:04 PM - INFO - [32:9] loss\t29.97 =\tBCE 29.96722 \tLL 0.02329 \tTotal 898.14/141.15/3.76 \n","04/22/2023 04:35:04 PM - INFO - [32:10] loss\t29.99 =\tBCE 29.99066 \tLL 0.02321 \tTotal 1113.46/145.17/2.99 \n","04/22/2023 04:35:05 PM - INFO - [32:11] loss\t29.03 =\tBCE 29.02694 \tLL 0.02281 \tTotal 1042.97/140.24/1.76 \n","04/22/2023 04:35:05 PM - INFO - [32:12] loss\t29.43 =\tBCE 29.42790 \tLL 0.02261 \tTotal 975.17/138.07/11.51 \n","04/22/2023 04:35:06 PM - INFO - [32:13] loss\t29.56 =\tBCE 29.55738 \tLL 0.02294 \tTotal 1306.65/139.34/8.83 \n","04/22/2023 04:35:06 PM - INFO - [32:14] loss\t28.46 =\tBCE 28.45780 \tLL 0.02251 \tTotal 623.01/97.62/3.42 \n","04/22/2023 04:35:07 PM - INFO - [32:15] loss\t28.30 =\tBCE 28.29952 \tLL 0.02239 \tTotal 1180.67/133.86/9.15 \n","04/22/2023 04:35:07 PM - INFO - [32:16] loss\t28.30 =\tBCE 28.30009 \tLL 0.02204 \tTotal 503.93/74.40/2.12 \n","04/22/2023 04:35:08 PM - INFO - [32:17] loss\t28.15 =\tBCE 28.15000 \tLL 0.02202 \tTotal 1143.44/124.94/6.06 \n","04/22/2023 04:35:08 PM - INFO - [32:18] loss\t28.30 =\tBCE 28.29717 \tLL 0.02221 \tTotal 500.27/75.65/10.65 \n","04/22/2023 04:35:08 PM - INFO - Training epoch 33.\n","04/22/2023 04:35:09 PM - INFO - [33:0] loss\t28.39 =\tBCE 28.39197 \tLL 0.02215 \tTotal 1001.84/112.17/4.49 \n","04/22/2023 04:35:09 PM - INFO - [33:1] loss\t27.11 =\tBCE 27.10934 \tLL 0.02204 \tTotal 439.08/74.64/3.24 \n","04/22/2023 04:35:10 PM - INFO - [33:2] loss\t27.40 =\tBCE 27.40236 \tLL 0.02174 \tTotal 925.74/110.02/2.28 \n","04/22/2023 04:35:11 PM - INFO - [33:3] loss\t27.08 =\tBCE 27.08419 \tLL 0.02161 \tTotal 742.30/100.27/6.14 \n","04/22/2023 04:35:11 PM - INFO - [33:4] loss\t27.17 =\tBCE 27.17046 \tLL 0.02160 \tTotal 480.45/69.35/2.41 \n","04/22/2023 04:35:12 PM - INFO - [33:5] loss\t26.70 =\tBCE 26.70290 \tLL 0.02158 \tTotal 826.63/106.48/2.18 \n","04/22/2023 04:35:12 PM - INFO - [33:6] loss\t26.02 =\tBCE 26.01654 \tLL 0.02002 \tTotal 383.43/89.58/1.65 \n","04/22/2023 04:35:13 PM - INFO - [33:7] loss\t26.48 =\tBCE 26.48189 \tLL 0.02084 \tTotal 757.14/113.05/4.09 \n","04/22/2023 04:35:13 PM - INFO - [33:8] loss\t26.25 =\tBCE 26.24784 \tLL 0.02135 \tTotal 472.86/92.00/8.19 \n","04/22/2023 04:35:14 PM - INFO - [33:9] loss\t26.54 =\tBCE 26.53743 \tLL 0.02151 \tTotal 459.44/94.40/2.74 \n","04/22/2023 04:35:14 PM - INFO - [33:10] loss\t25.60 =\tBCE 25.60425 \tLL 0.02083 \tTotal 626.56/118.38/5.88 \n","04/22/2023 04:35:15 PM - INFO - [33:11] loss\t25.22 =\tBCE 25.22138 \tLL 0.01998 \tTotal 223.64/72.83/4.34 \n","04/22/2023 04:35:15 PM - INFO - [33:12] loss\t25.42 =\tBCE 25.41974 \tLL 0.02011 \tTotal 664.08/121.17/2.50 \n","04/22/2023 04:35:16 PM - INFO - [33:13] loss\t24.87 =\tBCE 24.87175 \tLL 0.02022 \tTotal 331.90/113.21/7.80 \n","04/22/2023 04:35:16 PM - INFO - [33:14] loss\t25.46 =\tBCE 25.46104 \tLL 0.02082 \tTotal 499.26/93.85/6.98 \n","04/22/2023 04:35:17 PM - INFO - [33:15] loss\t25.56 =\tBCE 25.55888 \tLL 0.02117 \tTotal 579.87/110.06/1.33 \n","04/22/2023 04:35:17 PM - INFO - [33:16] loss\t25.15 =\tBCE 25.15201 \tLL 0.02060 \tTotal 356.02/56.08/6.66 \n","04/22/2023 04:35:18 PM - INFO - [33:17] loss\t24.34 =\tBCE 24.34197 \tLL 0.02019 \tTotal 264.24/88.45/5.34 \n","04/22/2023 04:35:19 PM - INFO - [33:18] loss\t24.30 =\tBCE 24.29749 \tLL 0.01949 \tTotal 417.11/58.68/5.54 \n","04/22/2023 04:35:19 PM - INFO - Training epoch 34.\n","04/22/2023 04:35:19 PM - INFO - [34:0] loss\t24.67 =\tBCE 24.66655 \tLL 0.02017 \tTotal 324.77/65.13/4.30 \n","04/22/2023 04:35:20 PM - INFO - [34:1] loss\t23.94 =\tBCE 23.94239 \tLL 0.01981 \tTotal 338.21/39.34/6.95 \n","04/22/2023 04:35:20 PM - INFO - [34:2] loss\t24.08 =\tBCE 24.08300 \tLL 0.01964 \tTotal 457.34/65.13/5.25 \n","04/22/2023 04:35:21 PM - INFO - [34:3] loss\t24.04 =\tBCE 24.03710 \tLL 0.01944 \tTotal 196.34/48.61/6.47 \n","04/22/2023 04:35:21 PM - INFO - [34:4] loss\t23.81 =\tBCE 23.80643 \tLL 0.01979 \tTotal 365.91/86.23/5.28 \n","04/22/2023 04:35:22 PM - INFO - [34:5] loss\t23.55 =\tBCE 23.54535 \tLL 0.01932 \tTotal 175.33/29.23/4.82 \n","04/22/2023 04:35:22 PM - INFO - [34:6] loss\t23.75 =\tBCE 23.74879 \tLL 0.01889 \tTotal 270.30/97.09/7.87 \n","04/22/2023 04:35:23 PM - INFO - [34:7] loss\t23.58 =\tBCE 23.58032 \tLL 0.01955 \tTotal 351.51/47.26/5.59 \n","04/22/2023 04:35:23 PM - INFO - [34:8] loss\t23.76 =\tBCE 23.75589 \tLL 0.01981 \tTotal 230.27/75.03/3.79 \n","04/22/2023 04:35:24 PM - INFO - [34:9] loss\t23.36 =\tBCE 23.36116 \tLL 0.01924 \tTotal 317.29/91.45/2.60 \n","04/22/2023 04:35:24 PM - INFO - [34:10] loss\t23.32 =\tBCE 23.32164 \tLL 0.01962 \tTotal 353.89/55.89/3.26 \n","04/22/2023 04:35:25 PM - INFO - [34:11] loss\t22.94 =\tBCE 22.94311 \tLL 0.01942 \tTotal 214.29/85.71/3.67 \n","04/22/2023 04:35:25 PM - INFO - [34:12] loss\t23.03 =\tBCE 23.02653 \tLL 0.01928 \tTotal 333.26/45.18/6.44 \n","04/22/2023 04:35:26 PM - INFO - [34:13] loss\t22.33 =\tBCE 22.33320 \tLL 0.01883 \tTotal 504.23/97.37/3.70 \n","04/22/2023 04:35:26 PM - INFO - [34:14] loss\t23.07 =\tBCE 23.07193 \tLL 0.01965 \tTotal 464.49/93.42/4.40 \n","04/22/2023 04:35:27 PM - INFO - [34:15] loss\t22.61 =\tBCE 22.61041 \tLL 0.01893 \tTotal 263.04/39.33/4.78 \n","04/22/2023 04:35:27 PM - INFO - [34:16] loss\t22.47 =\tBCE 22.46512 \tLL 0.01907 \tTotal 484.75/101.55/2.58 \n","04/22/2023 04:35:28 PM - INFO - [34:17] loss\t22.94 =\tBCE 22.94363 \tLL 0.01926 \tTotal 474.27/92.11/3.24 \n","04/22/2023 04:35:29 PM - INFO - [34:18] loss\t22.58 =\tBCE 22.57850 \tLL 0.01935 \tTotal 221.12/32.11/5.01 \n","04/22/2023 04:35:29 PM - INFO - Training epoch 35.\n","04/22/2023 04:35:29 PM - INFO - [35:0] loss\t22.40 =\tBCE 22.40412 \tLL 0.01885 \tTotal 455.45/93.67/3.05 \n","04/22/2023 04:35:30 PM - INFO - [35:1] loss\t21.96 =\tBCE 21.95754 \tLL 0.01849 \tTotal 583.99/96.18/5.28 \n","04/22/2023 04:35:30 PM - INFO - [35:2] loss\t21.65 =\tBCE 21.65323 \tLL 0.01821 \tTotal 273.39/45.32/7.43 \n","04/22/2023 04:35:31 PM - INFO - [35:3] loss\t22.06 =\tBCE 22.06146 \tLL 0.01872 \tTotal 341.16/83.40/6.11 \n","04/22/2023 04:35:31 PM - INFO - [35:4] loss\t22.11 =\tBCE 22.11044 \tLL 0.01874 \tTotal 613.26/101.82/4.73 \n","04/22/2023 04:35:32 PM - INFO - [35:5] loss\t21.89 =\tBCE 21.88663 \tLL 0.01817 \tTotal 719.00/82.17/5.34 \n","04/22/2023 04:35:32 PM - INFO - [35:6] loss\t21.95 =\tBCE 21.95485 \tLL 0.01828 \tTotal 368.30/71.88/2.76 \n","04/22/2023 04:35:33 PM - INFO - [35:7] loss\t22.00 =\tBCE 21.99942 \tLL 0.01875 \tTotal 546.53/59.71/8.65 \n","04/22/2023 04:35:33 PM - INFO - [35:8] loss\t21.57 =\tBCE 21.57344 \tLL 0.01833 \tTotal 974.45/112.27/10.04 \n","04/22/2023 04:35:34 PM - INFO - [35:9] loss\t21.29 =\tBCE 21.29063 \tLL 0.01769 \tTotal 673.59/98.08/2.72 \n","04/22/2023 04:35:34 PM - INFO - [35:10] loss\t21.43 =\tBCE 21.42717 \tLL 0.01825 \tTotal 127.47/39.00/7.11 \n","04/22/2023 04:35:35 PM - INFO - [35:11] loss\t21.71 =\tBCE 21.71136 \tLL 0.01835 \tTotal 597.88/106.35/9.93 \n","04/22/2023 04:35:35 PM - INFO - [35:12] loss\t21.47 =\tBCE 21.46723 \tLL 0.01848 \tTotal 705.72/99.19/4.55 \n","04/22/2023 04:35:36 PM - INFO - [35:13] loss\t20.95 =\tBCE 20.95088 \tLL 0.01837 \tTotal 344.99/54.28/6.92 \n","04/22/2023 04:35:37 PM - INFO - [35:14] loss\t21.10 =\tBCE 21.10222 \tLL 0.01810 \tTotal 519.52/128.73/4.42 \n","04/22/2023 04:35:37 PM - INFO - [35:15] loss\t21.21 =\tBCE 21.20892 \tLL 0.01792 \tTotal 845.84/129.67/5.43 \n","04/22/2023 04:35:38 PM - INFO - [35:16] loss\t21.34 =\tBCE 21.34083 \tLL 0.01788 \tTotal 764.11/97.51/8.09 \n","04/22/2023 04:35:38 PM - INFO - [35:17] loss\t20.60 =\tBCE 20.60384 \tLL 0.01778 \tTotal 544.48/116.02/8.34 \n","04/22/2023 04:35:39 PM - INFO - [35:18] loss\t21.01 =\tBCE 21.01459 \tLL 0.01772 \tTotal 536.92/118.26/3.73 \n","04/22/2023 04:35:39 PM - INFO - Training epoch 36.\n","04/22/2023 04:35:39 PM - INFO - [36:0] loss\t20.99 =\tBCE 20.98917 \tLL 0.01770 \tTotal 438.78/65.33/5.82 \n","04/22/2023 04:35:40 PM - INFO - [36:1] loss\t20.24 =\tBCE 20.23654 \tLL 0.01739 \tTotal 406.42/48.33/8.97 \n","04/22/2023 04:35:40 PM - INFO - [36:2] loss\t20.62 =\tBCE 20.61699 \tLL 0.01755 \tTotal 537.05/109.35/5.70 \n","04/22/2023 04:35:41 PM - INFO - [36:3] loss\t20.62 =\tBCE 20.62207 \tLL 0.01736 \tTotal 598.81/138.48/11.97 \n","04/22/2023 04:35:41 PM - INFO - [36:4] loss\t20.35 =\tBCE 20.34795 \tLL 0.01765 \tTotal 396.31/106.73/2.61 \n","04/22/2023 04:35:42 PM - INFO - [36:5] loss\t20.67 =\tBCE 20.67463 \tLL 0.01766 \tTotal 172.50/33.76/5.28 \n","04/22/2023 04:35:42 PM - INFO - [36:6] loss\t20.09 =\tBCE 20.08734 \tLL 0.01689 \tTotal 363.20/68.81/1.63 \n","04/22/2023 04:35:43 PM - INFO - [36:7] loss\t20.21 =\tBCE 20.21286 \tLL 0.01767 \tTotal 488.02/96.29/13.58 \n","04/22/2023 04:35:43 PM - INFO - [36:8] loss\t20.50 =\tBCE 20.49553 \tLL 0.01821 \tTotal 463.80/65.07/3.81 \n","04/22/2023 04:35:44 PM - INFO - [36:9] loss\t19.52 =\tBCE 19.51625 \tLL 0.01685 \tTotal 250.18/37.81/4.38 \n","04/22/2023 04:35:44 PM - INFO - [36:10] loss\t20.16 =\tBCE 20.15624 \tLL 0.01761 \tTotal 300.95/47.57/9.60 \n","04/22/2023 04:35:45 PM - INFO - [36:11] loss\t19.98 =\tBCE 19.97649 \tLL 0.01729 \tTotal 518.15/68.81/4.61 \n","04/22/2023 04:35:45 PM - INFO - [36:12] loss\t19.70 =\tBCE 19.70456 \tLL 0.01692 \tTotal 320.18/70.37/4.65 \n","04/22/2023 04:35:46 PM - INFO - [36:13] loss\t19.35 =\tBCE 19.35408 \tLL 0.01712 \tTotal 316.99/61.66/3.65 \n","04/22/2023 04:35:47 PM - INFO - [36:14] loss\t19.71 =\tBCE 19.70669 \tLL 0.01708 \tTotal 337.91/45.30/3.03 \n","04/22/2023 04:35:47 PM - INFO - [36:15] loss\t19.60 =\tBCE 19.60055 \tLL 0.01692 \tTotal 324.04/103.07/5.85 \n","04/22/2023 04:35:48 PM - INFO - [36:16] loss\t20.09 =\tBCE 20.08971 \tLL 0.01733 \tTotal 499.32/169.73/4.55 \n","04/22/2023 04:35:48 PM - INFO - [36:17] loss\t19.77 =\tBCE 19.76593 \tLL 0.01749 \tTotal 546.66/207.53/8.86 \n","04/22/2023 04:35:49 PM - INFO - [36:18] loss\t19.98 =\tBCE 19.98163 \tLL 0.01718 \tTotal 881.38/193.16/5.02 \n","04/22/2023 04:35:49 PM - INFO - Training epoch 37.\n","04/22/2023 04:35:49 PM - INFO - [37:0] loss\t19.54 =\tBCE 19.54100 \tLL 0.01667 \tTotal 1486.18/206.12/6.06 \n","04/22/2023 04:35:50 PM - INFO - [37:1] loss\t20.11 =\tBCE 20.11428 \tLL 0.01628 \tTotal 2192.17/286.44/11.44 \n","04/22/2023 04:35:50 PM - INFO - [37:2] loss\t21.21 =\tBCE 21.20790 \tLL 0.01679 \tTotal 3116.28/439.76/7.65 \n","04/22/2023 04:35:51 PM - INFO - [37:3] loss\t24.12 =\tBCE 24.11525 \tLL 0.01730 \tTotal 4423.46/601.74/2.69 \n","04/22/2023 04:35:51 PM - INFO - [37:4] loss\t27.68 =\tBCE 27.67920 \tLL 0.01697 \tTotal 6014.19/830.49/5.18 \n","04/22/2023 04:35:52 PM - INFO - [37:5] loss\t35.91 =\tBCE 35.91484 \tLL 0.01702 \tTotal 8233.55/1243.51/1.46 \n","04/22/2023 04:35:52 PM - INFO - [37:6] loss\t56.47 =\tBCE 56.47250 \tLL 0.01622 \tTotal 12731.35/2012.57/10.25 \n","04/22/2023 04:35:53 PM - INFO - [37:7] loss\t133.09 =\tBCE 133.09082 \tLL 0.01853 \tTotal 19751.44/3295.21/4.69 \n","04/22/2023 04:35:53 PM - INFO - [37:8] loss\t245.31 =\tBCE 245.30850 \tLL 0.01615 \tTotal 32781.25/5081.52/5.61 \n","04/22/2023 04:35:54 PM - INFO - [37:9] loss\t748.55 =\tBCE 748.54614 \tLL 0.02240 \tTotal 36088.53/5607.07/12.63 \n","04/22/2023 04:35:54 PM - INFO - [37:10] loss\t98.31 =\tBCE 98.30661 \tLL 0.02209 \tTotal 15852.42/1878.31/4.93 \n","04/22/2023 04:35:55 PM - INFO - [37:11] loss\t277.21 =\tBCE 277.21234 \tLL 0.02018 \tTotal 21393.82/5886.48/13.42 \n","04/22/2023 04:35:55 PM - INFO - [37:12] loss\t274.97 =\tBCE 274.96823 \tLL 0.02521 \tTotal 24083.48/3713.99/8.71 \n","04/22/2023 04:35:56 PM - INFO - [37:13] loss\t189.89 =\tBCE 189.89307 \tLL 0.03031 \tTotal 9545.80/3899.80/5.90 \n","04/22/2023 04:35:56 PM - INFO - [37:14] loss\t181.49 =\tBCE 181.49136 \tLL 0.03217 \tTotal 18822.19/3238.70/10.52 \n","04/22/2023 04:35:57 PM - INFO - [37:15] loss\t232.75 =\tBCE 232.74872 \tLL 0.02733 \tTotal 21509.62/3834.01/4.55 \n","04/22/2023 04:35:57 PM - INFO - [37:16] loss\t165.95 =\tBCE 165.95471 \tLL 0.02935 \tTotal 14993.07/2367.04/6.13 \n","04/22/2023 04:35:58 PM - INFO - [37:17] loss\t134.05 =\tBCE 134.04636 \tLL 0.03298 \tTotal 9056.80/2871.89/5.32 \n","04/22/2023 04:35:59 PM - INFO - [37:18] loss\t151.51 =\tBCE 151.50655 \tLL 0.03818 \tTotal 16302.60/1515.70/10.47 \n","04/22/2023 04:35:59 PM - INFO - Training epoch 38.\n","04/22/2023 04:35:59 PM - INFO - [38:0] loss\t83.44 =\tBCE 83.43883 \tLL 0.03625 \tTotal 7112.99/1662.21/5.35 \n","04/22/2023 04:36:00 PM - INFO - [38:1] loss\t125.56 =\tBCE 125.55927 \tLL 0.03292 \tTotal 12814.86/1236.21/4.59 \n","04/22/2023 04:36:00 PM - INFO - [38:2] loss\t97.63 =\tBCE 97.62897 \tLL 0.03187 \tTotal 7400.86/927.65/10.98 \n","04/22/2023 04:36:01 PM - INFO - [38:3] loss\t91.98 =\tBCE 91.98437 \tLL 0.03235 \tTotal 7209.83/1090.20/8.93 \n","04/22/2023 04:36:01 PM - INFO - [38:4] loss\t82.16 =\tBCE 82.15905 \tLL 0.03524 \tTotal 7488.21/692.16/8.08 \n","04/22/2023 04:36:02 PM - INFO - [38:5] loss\t80.49 =\tBCE 80.49253 \tLL 0.03588 \tTotal 7061.30/822.51/6.33 \n","04/22/2023 04:36:02 PM - INFO - [38:6] loss\t74.29 =\tBCE 74.29373 \tLL 0.03544 \tTotal 4872.68/644.28/5.15 \n","04/22/2023 04:36:03 PM - INFO - [38:7] loss\t81.75 =\tBCE 81.74815 \tLL 0.03308 \tTotal 6747.98/637.62/9.98 \n","04/22/2023 04:36:03 PM - INFO - [38:8] loss\t68.40 =\tBCE 68.39584 \tLL 0.03071 \tTotal 5600.55/587.76/6.10 \n","04/22/2023 04:36:04 PM - INFO - [38:9] loss\t57.93 =\tBCE 57.92794 \tLL 0.03113 \tTotal 2169.43/430.10/13.97 \n","04/22/2023 04:36:04 PM - INFO - [38:10] loss\t69.96 =\tBCE 69.96321 \tLL 0.03242 \tTotal 5341.72/515.09/10.11 \n","04/22/2023 04:36:05 PM - INFO - [38:11] loss\t62.52 =\tBCE 62.51949 \tLL 0.03279 \tTotal 4720.62/486.35/11.10 \n","04/22/2023 04:36:05 PM - INFO - [38:12] loss\t49.67 =\tBCE 49.66721 \tLL 0.03283 \tTotal 1791.69/382.26/8.99 \n","04/22/2023 04:36:06 PM - INFO - [38:13] loss\t58.90 =\tBCE 58.90013 \tLL 0.03175 \tTotal 4137.39/461.42/8.34 \n","04/22/2023 04:36:06 PM - INFO - [38:14] loss\t60.58 =\tBCE 60.58106 \tLL 0.03123 \tTotal 3252.38/349.97/11.91 \n","04/22/2023 04:36:07 PM - INFO - [38:15] loss\t51.04 =\tBCE 51.03872 \tLL 0.02970 \tTotal 1788.82/357.72/6.25 \n","04/22/2023 04:36:08 PM - INFO - [38:16] loss\t50.14 =\tBCE 50.13956 \tLL 0.02927 \tTotal 2063.32/333.83/4.32 \n","04/22/2023 04:36:08 PM - INFO - [38:17] loss\t51.08 =\tBCE 51.07855 \tLL 0.02871 \tTotal 2123.49/305.97/8.44 \n","04/22/2023 04:36:09 PM - INFO - [38:18] loss\t50.82 =\tBCE 50.81851 \tLL 0.02855 \tTotal 2070.41/316.47/7.88 \n","Not implemented\n","04/22/2023 04:36:09 PM - INFO - Training epoch 39.\n","04/22/2023 04:36:09 PM - INFO - [39:0] loss\t46.74 =\tBCE 46.74340 \tLL 0.02833 \tTotal 1351.66/231.57/5.26 \n","04/22/2023 04:36:10 PM - INFO - [39:1] loss\t46.30 =\tBCE 46.30046 \tLL 0.02844 \tTotal 1293.57/183.92/2.81 \n","04/22/2023 04:36:10 PM - INFO - [39:2] loss\t50.75 =\tBCE 50.74632 \tLL 0.02783 \tTotal 1989.24/287.97/9.30 \n","04/22/2023 04:36:11 PM - INFO - [39:3] loss\t47.21 =\tBCE 47.21104 \tLL 0.02779 \tTotal 1473.70/211.37/3.58 \n","04/22/2023 04:36:11 PM - INFO - [39:4] loss\t44.70 =\tBCE 44.70277 \tLL 0.02643 \tTotal 887.97/117.16/7.67 \n","04/22/2023 04:36:12 PM - INFO - [39:5] loss\t45.04 =\tBCE 45.04104 \tLL 0.02658 \tTotal 1774.89/215.69/10.15 \n","04/22/2023 04:36:12 PM - INFO - [39:6] loss\t45.20 =\tBCE 45.19891 \tLL 0.02626 \tTotal 1523.67/187.07/4.62 \n","04/22/2023 04:36:13 PM - INFO - [39:7] loss\t44.54 =\tBCE 44.53793 \tLL 0.02641 \tTotal 1203.02/159.03/10.14 \n","04/22/2023 04:36:13 PM - INFO - [39:8] loss\t42.92 =\tBCE 42.92226 \tLL 0.02522 \tTotal 1335.92/160.41/3.17 \n","04/22/2023 04:36:14 PM - INFO - [39:9] loss\t42.90 =\tBCE 42.89927 \tLL 0.02601 \tTotal 1288.04/139.45/9.33 \n","04/22/2023 04:36:14 PM - INFO - [39:10] loss\t43.90 =\tBCE 43.90479 \tLL 0.02604 \tTotal 1424.30/187.21/10.60 \n","04/22/2023 04:36:15 PM - INFO - [39:11] loss\t42.45 =\tBCE 42.44666 \tLL 0.02607 \tTotal 1106.05/150.62/4.99 \n","04/22/2023 04:36:15 PM - INFO - [39:12] loss\t41.65 =\tBCE 41.64772 \tLL 0.02549 \tTotal 814.12/105.64/4.66 \n","04/22/2023 04:36:16 PM - INFO - [39:13] loss\t41.37 =\tBCE 41.36843 \tLL 0.02563 \tTotal 1369.47/171.84/8.17 \n","04/22/2023 04:36:17 PM - INFO - [39:14] loss\t39.95 =\tBCE 39.95100 \tLL 0.02464 \tTotal 1059.90/141.80/9.80 \n","04/22/2023 04:36:17 PM - INFO - [39:15] loss\t39.20 =\tBCE 39.20398 \tLL 0.02535 \tTotal 632.70/99.53/5.36 \n","04/22/2023 04:36:18 PM - INFO - [39:16] loss\t39.09 =\tBCE 39.08517 \tLL 0.02485 \tTotal 1162.99/140.99/4.67 \n","04/22/2023 04:36:18 PM - INFO - [39:17] loss\t38.89 =\tBCE 38.89282 \tLL 0.02499 \tTotal 988.11/109.05/6.19 \n","04/22/2023 04:36:19 PM - INFO - [39:18] loss\t38.64 =\tBCE 38.64442 \tLL 0.02527 \tTotal 631.87/102.35/7.39 \n","04/22/2023 04:36:19 PM - INFO - EVALUATION prior to epoch [40]...\n","04/22/2023 04:36:19 PM - INFO - [40] loss\t34.02=\tBCE 34.02 \tLL 0.02370 \n","04/22/2023 04:36:20 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/40_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:36:25 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/40_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:36:31 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/40_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 04:36:32 PM - INFO - Training epoch 40.\n","04/22/2023 04:36:32 PM - INFO - [40:0] loss\t37.38 =\tBCE 37.37853 \tLL 0.02483 \tTotal 787.35/105.38/8.02 \n","04/22/2023 04:36:33 PM - INFO - [40:1] loss\t37.37 =\tBCE 37.36985 \tLL 0.02527 \tTotal 773.55/96.30/3.26 \n","04/22/2023 04:36:33 PM - INFO - [40:2] loss\t36.43 =\tBCE 36.42740 \tLL 0.02446 \tTotal 652.00/91.65/11.64 \n","04/22/2023 04:36:34 PM - INFO - [40:3] loss\t36.47 =\tBCE 36.46703 \tLL 0.02476 \tTotal 483.40/76.17/6.77 \n","04/22/2023 04:36:34 PM - INFO - [40:4] loss\t35.57 =\tBCE 35.56804 \tLL 0.02431 \tTotal 736.14/91.05/2.69 \n","04/22/2023 04:36:35 PM - INFO - [40:5] loss\t34.87 =\tBCE 34.86982 \tLL 0.02432 \tTotal 672.12/88.75/4.23 \n","04/22/2023 04:36:35 PM - INFO - [40:6] loss\t34.20 =\tBCE 34.20456 \tLL 0.02420 \tTotal 266.91/56.16/3.00 \n","04/22/2023 04:36:36 PM - INFO - [40:7] loss\t34.36 =\tBCE 34.35617 \tLL 0.02417 \tTotal 562.87/97.23/3.56 \n","04/22/2023 04:36:36 PM - INFO - [40:8] loss\t34.61 =\tBCE 34.61458 \tLL 0.02548 \tTotal 573.78/79.46/5.20 \n","04/22/2023 04:36:37 PM - INFO - [40:9] loss\t33.67 =\tBCE 33.66968 \tLL 0.02441 \tTotal 359.90/57.89/9.88 \n","04/22/2023 04:36:37 PM - INFO - [40:10] loss\t33.02 =\tBCE 33.02148 \tLL 0.02363 \tTotal 477.40/82.63/6.07 \n","04/22/2023 04:36:38 PM - INFO - [40:11] loss\t32.27 =\tBCE 32.26691 \tLL 0.02329 \tTotal 523.80/61.34/2.71 \n","04/22/2023 04:36:39 PM - INFO - [40:12] loss\t32.17 =\tBCE 32.17223 \tLL 0.02328 \tTotal 535.60/81.99/18.90 \n","04/22/2023 04:36:39 PM - INFO - [40:13] loss\t32.08 =\tBCE 32.07571 \tLL 0.02392 \tTotal 241.64/52.47/10.36 \n","04/22/2023 04:36:40 PM - INFO - [40:14] loss\t31.75 =\tBCE 31.75458 \tLL 0.02304 \tTotal 609.11/75.36/4.27 \n","04/22/2023 04:36:40 PM - INFO - [40:15] loss\t31.15 =\tBCE 31.14625 \tLL 0.02293 \tTotal 362.54/55.40/7.67 \n","04/22/2023 04:36:41 PM - INFO - [40:16] loss\t30.95 =\tBCE 30.94955 \tLL 0.02253 \tTotal 332.79/46.98/8.23 \n","04/22/2023 04:36:41 PM - INFO - [40:17] loss\t31.24 =\tBCE 31.23820 \tLL 0.02299 \tTotal 577.46/71.94/7.43 \n","04/22/2023 04:36:42 PM - INFO - [40:18] loss\t30.59 =\tBCE 30.58858 \tLL 0.02294 \tTotal 293.51/48.20/6.53 \n","04/22/2023 04:36:42 PM - INFO - Training epoch 41.\n","04/22/2023 04:36:42 PM - INFO - [41:0] loss\t30.84 =\tBCE 30.83573 \tLL 0.02292 \tTotal 470.66/63.83/4.23 \n","04/22/2023 04:36:43 PM - INFO - [41:1] loss\t30.27 =\tBCE 30.27486 \tLL 0.02355 \tTotal 340.94/50.69/13.46 \n","04/22/2023 04:36:43 PM - INFO - [41:2] loss\t29.80 =\tBCE 29.80375 \tLL 0.02290 \tTotal 425.12/62.88/8.28 \n","04/22/2023 04:36:44 PM - INFO - [41:3] loss\t29.02 =\tBCE 29.01858 \tLL 0.02277 \tTotal 249.80/44.20/7.53 \n","04/22/2023 04:36:44 PM - INFO - [41:4] loss\t28.90 =\tBCE 28.89502 \tLL 0.02222 \tTotal 448.27/58.86/5.80 \n","04/22/2023 04:36:45 PM - INFO - [41:5] loss\t28.57 =\tBCE 28.56771 \tLL 0.02196 \tTotal 311.80/47.68/8.46 \n","04/22/2023 04:36:45 PM - INFO - [41:6] loss\t28.82 =\tBCE 28.81701 \tLL 0.02266 \tTotal 257.27/46.99/9.71 \n","04/22/2023 04:36:46 PM - INFO - [41:7] loss\t28.14 =\tBCE 28.14347 \tLL 0.02175 \tTotal 303.12/47.40/9.43 \n","04/22/2023 04:36:47 PM - INFO - [41:8] loss\t28.71 =\tBCE 28.71344 \tLL 0.02240 \tTotal 145.38/38.62/2.69 \n","04/22/2023 04:36:47 PM - INFO - [41:9] loss\t28.27 =\tBCE 28.26785 \tLL 0.02208 \tTotal 261.42/44.47/10.26 \n","04/22/2023 04:36:48 PM - INFO - [41:10] loss\t27.77 =\tBCE 27.76783 \tLL 0.02180 \tTotal 210.85/35.77/12.25 \n","04/22/2023 04:36:48 PM - INFO - [41:11] loss\t28.03 =\tBCE 28.02736 \tLL 0.02178 \tTotal 236.86/46.37/9.90 \n","04/22/2023 04:36:49 PM - INFO - [41:12] loss\t28.09 =\tBCE 28.08570 \tLL 0.02237 \tTotal 172.00/42.66/3.08 \n","04/22/2023 04:36:49 PM - INFO - [41:13] loss\t27.49 =\tBCE 27.48712 \tLL 0.02193 \tTotal 293.08/40.94/8.48 \n","04/22/2023 04:36:50 PM - INFO - [41:14] loss\t26.80 =\tBCE 26.79577 \tLL 0.02149 \tTotal 186.04/38.50/5.96 \n","04/22/2023 04:36:50 PM - INFO - [41:15] loss\t26.69 =\tBCE 26.68971 \tLL 0.02127 \tTotal 198.53/31.97/7.11 \n","04/22/2023 04:36:51 PM - INFO - [41:16] loss\t26.57 =\tBCE 26.57078 \tLL 0.02149 \tTotal 254.71/55.45/5.05 \n","04/22/2023 04:36:51 PM - INFO - [41:17] loss\t27.06 =\tBCE 27.05688 \tLL 0.02206 \tTotal 122.35/30.03/7.24 \n","04/22/2023 04:36:52 PM - INFO - [41:18] loss\t26.24 =\tBCE 26.23801 \tLL 0.02099 \tTotal 229.89/46.97/3.00 \n","04/22/2023 04:36:52 PM - INFO - Training epoch 42.\n","04/22/2023 04:36:52 PM - INFO - [42:0] loss\t25.82 =\tBCE 25.82099 \tLL 0.02083 \tTotal 161.65/31.74/10.19 \n","04/22/2023 04:36:53 PM - INFO - [42:1] loss\t26.30 =\tBCE 26.30156 \tLL 0.02106 \tTotal 140.89/37.56/4.15 \n","04/22/2023 04:36:53 PM - INFO - [42:2] loss\t25.80 =\tBCE 25.80171 \tLL 0.02129 \tTotal 215.95/42.60/4.85 \n","04/22/2023 04:36:54 PM - INFO - [42:3] loss\t25.99 =\tBCE 25.98899 \tLL 0.02110 \tTotal 197.43/36.89/7.01 \n","04/22/2023 04:36:54 PM - INFO - [42:4] loss\t25.44 =\tBCE 25.44130 \tLL 0.02061 \tTotal 207.30/42.27/7.87 \n","04/22/2023 04:36:55 PM - INFO - [42:5] loss\t25.41 =\tBCE 25.41220 \tLL 0.02051 \tTotal 195.96/34.93/7.30 \n","04/22/2023 04:36:56 PM - INFO - [42:6] loss\t25.41 =\tBCE 25.41047 \tLL 0.02106 \tTotal 179.30/42.26/4.73 \n","04/22/2023 04:36:56 PM - INFO - [42:7] loss\t24.55 =\tBCE 24.55246 \tLL 0.01982 \tTotal 152.80/34.41/13.66 \n","04/22/2023 04:36:57 PM - INFO - [42:8] loss\t25.14 =\tBCE 25.14275 \tLL 0.02066 \tTotal 205.36/42.59/10.06 \n","04/22/2023 04:36:57 PM - INFO - [42:9] loss\t24.81 =\tBCE 24.81268 \tLL 0.02036 \tTotal 159.95/29.34/4.72 \n","04/22/2023 04:36:58 PM - INFO - [42:10] loss\t24.80 =\tBCE 24.79849 \tLL 0.02047 \tTotal 140.99/30.44/4.87 \n","04/22/2023 04:36:58 PM - INFO - [42:11] loss\t24.41 =\tBCE 24.41080 \tLL 0.02023 \tTotal 107.96/28.80/3.31 \n","04/22/2023 04:36:59 PM - INFO - [42:12] loss\t24.47 =\tBCE 24.47474 \tLL 0.02023 \tTotal 233.36/37.16/6.03 \n","04/22/2023 04:36:59 PM - INFO - [42:13] loss\t24.13 =\tBCE 24.13347 \tLL 0.01973 \tTotal 222.95/44.63/9.82 \n","04/22/2023 04:37:00 PM - INFO - [42:14] loss\t24.24 =\tBCE 24.24339 \tLL 0.01987 \tTotal 156.42/29.70/7.66 \n","04/22/2023 04:37:00 PM - INFO - [42:15] loss\t23.76 =\tBCE 23.76465 \tLL 0.02005 \tTotal 191.15/31.06/9.87 \n","04/22/2023 04:37:01 PM - INFO - [42:16] loss\t23.55 =\tBCE 23.55090 \tLL 0.01967 \tTotal 99.41/30.43/6.51 \n","04/22/2023 04:37:02 PM - INFO - [42:17] loss\t24.03 =\tBCE 24.03425 \tLL 0.02014 \tTotal 120.36/36.56/13.69 \n","04/22/2023 04:37:02 PM - INFO - [42:18] loss\t23.71 =\tBCE 23.70916 \tLL 0.02008 \tTotal 160.82/30.88/5.96 \n","04/22/2023 04:37:02 PM - INFO - Training epoch 43.\n","04/22/2023 04:37:03 PM - INFO - [43:0] loss\t23.75 =\tBCE 23.75482 \tLL 0.02009 \tTotal 110.29/34.31/3.39 \n","04/22/2023 04:37:03 PM - INFO - [43:1] loss\t23.19 =\tBCE 23.19245 \tLL 0.01932 \tTotal 211.60/46.96/12.23 \n","04/22/2023 04:37:04 PM - INFO - [43:2] loss\t23.60 =\tBCE 23.59611 \tLL 0.01979 \tTotal 188.67/32.33/9.35 \n","04/22/2023 04:37:04 PM - INFO - [43:3] loss\t22.89 =\tBCE 22.88558 \tLL 0.01934 \tTotal 131.18/25.56/4.72 \n","04/22/2023 04:37:05 PM - INFO - [43:4] loss\t23.25 =\tBCE 23.24648 \tLL 0.01958 \tTotal 159.72/34.65/4.82 \n","04/22/2023 04:37:05 PM - INFO - [43:5] loss\t22.95 =\tBCE 22.95012 \tLL 0.01928 \tTotal 108.81/25.70/3.38 \n","04/22/2023 04:37:06 PM - INFO - [43:6] loss\t22.55 =\tBCE 22.54669 \tLL 0.01907 \tTotal 224.64/39.83/2.95 \n","04/22/2023 04:37:06 PM - INFO - [43:7] loss\t22.63 =\tBCE 22.62526 \tLL 0.01879 \tTotal 83.54/27.07/6.41 \n","04/22/2023 04:37:07 PM - INFO - [43:8] loss\t22.99 =\tBCE 22.98658 \tLL 0.01930 \tTotal 187.36/38.51/9.30 \n","04/22/2023 04:37:07 PM - INFO - [43:9] loss\t22.43 =\tBCE 22.43067 \tLL 0.01864 \tTotal 122.57/29.83/2.34 \n","04/22/2023 04:37:08 PM - INFO - [43:10] loss\t22.06 =\tBCE 22.05575 \tLL 0.01842 \tTotal 147.83/32.94/4.63 \n","04/22/2023 04:37:09 PM - INFO - [43:11] loss\t22.31 =\tBCE 22.30982 \tLL 0.01862 \tTotal 189.52/44.32/4.44 \n","04/22/2023 04:37:09 PM - INFO - [43:12] loss\t21.86 =\tBCE 21.86243 \tLL 0.01839 \tTotal 153.99/34.61/7.89 \n","04/22/2023 04:37:10 PM - INFO - [43:13] loss\t21.61 =\tBCE 21.60522 \tLL 0.01832 \tTotal 130.18/35.23/3.16 \n","04/22/2023 04:37:10 PM - INFO - [43:14] loss\t22.04 =\tBCE 22.04272 \tLL 0.01904 \tTotal 137.16/33.66/2.22 \n","04/22/2023 04:37:11 PM - INFO - [43:15] loss\t22.10 =\tBCE 22.09534 \tLL 0.01888 \tTotal 185.26/36.50/2.46 \n","04/22/2023 04:37:11 PM - INFO - [43:16] loss\t21.93 =\tBCE 21.92830 \tLL 0.01875 \tTotal 115.24/23.29/6.07 \n","04/22/2023 04:37:12 PM - INFO - [43:17] loss\t21.65 =\tBCE 21.64901 \tLL 0.01848 \tTotal 275.79/33.58/4.46 \n","04/22/2023 04:37:12 PM - INFO - [43:18] loss\t21.79 =\tBCE 21.79174 \tLL 0.01865 \tTotal 157.97/34.44/3.61 \n","04/22/2023 04:37:12 PM - INFO - Training epoch 44.\n","04/22/2023 04:37:13 PM - INFO - [44:0] loss\t21.44 =\tBCE 21.43572 \tLL 0.01813 \tTotal 369.40/59.20/3.83 \n","04/22/2023 04:37:13 PM - INFO - [44:1] loss\t20.87 =\tBCE 20.86713 \tLL 0.01746 \tTotal 381.35/84.78/7.85 \n","04/22/2023 04:37:14 PM - INFO - [44:2] loss\t21.36 =\tBCE 21.36380 \tLL 0.01829 \tTotal 335.38/57.04/3.61 \n","04/22/2023 04:37:14 PM - INFO - [44:3] loss\t21.37 =\tBCE 21.36527 \tLL 0.01816 \tTotal 296.06/39.89/4.57 \n","04/22/2023 04:37:15 PM - INFO - [44:4] loss\t22.09 =\tBCE 22.09410 \tLL 0.01907 \tTotal 274.31/64.38/4.26 \n","04/22/2023 04:37:15 PM - INFO - [44:5] loss\t21.52 =\tBCE 21.52341 \tLL 0.01850 \tTotal 350.52/44.16/7.19 \n","04/22/2023 04:37:16 PM - INFO - [44:6] loss\t21.13 =\tBCE 21.12996 \tLL 0.01807 \tTotal 446.30/64.38/3.35 \n","04/22/2023 04:37:17 PM - INFO - [44:7] loss\t20.92 =\tBCE 20.92226 \tLL 0.01777 \tTotal 430.38/90.80/2.09 \n","04/22/2023 04:37:17 PM - INFO - [44:8] loss\t20.74 =\tBCE 20.74340 \tLL 0.01800 \tTotal 306.70/61.19/4.27 \n","04/22/2023 04:37:18 PM - INFO - [44:9] loss\t20.58 =\tBCE 20.58100 \tLL 0.01754 \tTotal 156.23/27.91/6.87 \n","04/22/2023 04:37:18 PM - INFO - [44:10] loss\t20.36 =\tBCE 20.35656 \tLL 0.01758 \tTotal 262.35/49.03/5.60 \n","04/22/2023 04:37:19 PM - INFO - [44:11] loss\t20.66 =\tBCE 20.65905 \tLL 0.01790 \tTotal 208.92/28.51/5.81 \n","04/22/2023 04:37:19 PM - INFO - [44:12] loss\t20.17 =\tBCE 20.16537 \tLL 0.01725 \tTotal 313.30/47.14/4.55 \n","04/22/2023 04:37:20 PM - INFO - [44:13] loss\t20.57 =\tBCE 20.57124 \tLL 0.01752 \tTotal 434.42/59.77/5.45 \n","04/22/2023 04:37:20 PM - INFO - [44:14] loss\t20.63 =\tBCE 20.62652 \tLL 0.01783 \tTotal 352.90/43.45/1.29 \n","04/22/2023 04:37:21 PM - INFO - [44:15] loss\t20.37 =\tBCE 20.37180 \tLL 0.01745 \tTotal 221.40/43.13/3.51 \n","04/22/2023 04:37:21 PM - INFO - [44:16] loss\t20.19 =\tBCE 20.18527 \tLL 0.01741 \tTotal 157.00/36.13/2.78 \n","04/22/2023 04:37:22 PM - INFO - [44:17] loss\t20.27 =\tBCE 20.27238 \tLL 0.01775 \tTotal 316.65/60.30/3.17 \n","04/22/2023 04:37:22 PM - INFO - [44:18] loss\t19.78 =\tBCE 19.78304 \tLL 0.01705 \tTotal 215.31/36.95/1.78 \n","04/22/2023 04:37:22 PM - INFO - Training epoch 45.\n","04/22/2023 04:37:23 PM - INFO - [45:0] loss\t20.27 =\tBCE 20.26906 \tLL 0.01761 \tTotal 165.17/45.82/6.15 \n","04/22/2023 04:37:23 PM - INFO - [45:1] loss\t19.88 =\tBCE 19.87956 \tLL 0.01716 \tTotal 272.44/44.26/5.23 \n","04/22/2023 04:37:24 PM - INFO - [45:2] loss\t19.87 =\tBCE 19.87420 \tLL 0.01690 \tTotal 195.11/30.38/5.33 \n","04/22/2023 04:37:24 PM - INFO - [45:3] loss\t19.93 =\tBCE 19.92862 \tLL 0.01723 \tTotal 164.78/32.97/3.17 \n","04/22/2023 04:37:25 PM - INFO - [45:4] loss\t19.73 =\tBCE 19.73391 \tLL 0.01731 \tTotal 199.39/39.28/14.13 \n","04/22/2023 04:37:25 PM - INFO - [45:5] loss\t19.03 =\tBCE 19.03436 \tLL 0.01625 \tTotal 275.05/43.12/9.41 \n","04/22/2023 04:37:26 PM - INFO - [45:6] loss\t19.66 =\tBCE 19.66349 \tLL 0.01735 \tTotal 307.82/42.66/3.68 \n","04/22/2023 04:37:27 PM - INFO - [45:7] loss\t19.54 =\tBCE 19.54184 \tLL 0.01696 \tTotal 367.38/49.76/6.96 \n","04/22/2023 04:37:27 PM - INFO - [45:8] loss\t19.63 =\tBCE 19.62696 \tLL 0.01672 \tTotal 412.03/92.05/15.12 \n","04/22/2023 04:37:28 PM - INFO - [45:9] loss\t19.19 =\tBCE 19.18633 \tLL 0.01635 \tTotal 367.22/108.27/9.89 \n","04/22/2023 04:37:28 PM - INFO - [45:10] loss\t19.48 =\tBCE 19.48126 \tLL 0.01696 \tTotal 302.73/67.26/3.95 \n","04/22/2023 04:37:29 PM - INFO - [45:11] loss\t19.54 =\tBCE 19.53654 \tLL 0.01704 \tTotal 232.54/59.08/8.66 \n","04/22/2023 04:37:29 PM - INFO - [45:12] loss\t19.45 =\tBCE 19.45393 \tLL 0.01705 \tTotal 415.83/89.47/13.57 \n","04/22/2023 04:37:30 PM - INFO - [45:13] loss\t18.84 =\tBCE 18.83683 \tLL 0.01639 \tTotal 348.70/65.27/10.17 \n","04/22/2023 04:37:30 PM - INFO - [45:14] loss\t18.78 =\tBCE 18.78008 \tLL 0.01656 \tTotal 446.46/55.34/4.94 \n","04/22/2023 04:37:31 PM - INFO - [45:15] loss\t19.46 =\tBCE 19.45746 \tLL 0.01690 \tTotal 719.24/91.49/5.23 \n","04/22/2023 04:37:31 PM - INFO - [45:16] loss\t19.41 =\tBCE 19.40714 \tLL 0.01725 \tTotal 750.45/84.94/8.29 \n","04/22/2023 04:37:32 PM - INFO - [45:17] loss\t18.75 =\tBCE 18.75123 \tLL 0.01633 \tTotal 516.93/59.62/10.19 \n","04/22/2023 04:37:32 PM - INFO - [45:18] loss\t18.44 =\tBCE 18.44464 \tLL 0.01566 \tTotal 269.92/56.93/9.29 \n","04/22/2023 04:37:32 PM - INFO - Training epoch 46.\n","04/22/2023 04:37:33 PM - INFO - [46:0] loss\t18.92 =\tBCE 18.92066 \tLL 0.01638 \tTotal 364.84/57.56/2.08 \n","04/22/2023 04:37:33 PM - INFO - [46:1] loss\t18.98 =\tBCE 18.98218 \tLL 0.01643 \tTotal 620.13/84.79/4.95 \n","04/22/2023 04:37:34 PM - INFO - [46:2] loss\t18.74 =\tBCE 18.73870 \tLL 0.01634 \tTotal 722.66/88.94/10.29 \n","04/22/2023 04:37:34 PM - INFO - [46:3] loss\t19.04 =\tBCE 19.03848 \tLL 0.01658 \tTotal 634.33/80.15/9.63 \n","04/22/2023 04:37:35 PM - INFO - [46:4] loss\t18.63 =\tBCE 18.63454 \tLL 0.01609 \tTotal 476.32/85.73/9.55 \n","04/22/2023 04:37:36 PM - INFO - [46:5] loss\t18.39 =\tBCE 18.39364 \tLL 0.01625 \tTotal 238.35/96.46/2.60 \n","04/22/2023 04:37:36 PM - INFO - [46:6] loss\t18.69 =\tBCE 18.69194 \tLL 0.01635 \tTotal 246.26/52.85/10.91 \n","04/22/2023 04:37:37 PM - INFO - [46:7] loss\t18.52 =\tBCE 18.51871 \tLL 0.01633 \tTotal 200.61/37.75/8.46 \n","04/22/2023 04:37:37 PM - INFO - [46:8] loss\t18.09 =\tBCE 18.08596 \tLL 0.01595 \tTotal 273.43/70.07/9.67 \n","04/22/2023 04:37:38 PM - INFO - [46:9] loss\t17.95 =\tBCE 17.94741 \tLL 0.01558 \tTotal 425.97/70.60/4.79 \n","04/22/2023 04:37:38 PM - INFO - [46:10] loss\t18.02 =\tBCE 18.02441 \tLL 0.01590 \tTotal 295.34/59.19/4.43 \n","04/22/2023 04:37:39 PM - INFO - [46:11] loss\t18.38 =\tBCE 18.38272 \tLL 0.01568 \tTotal 185.31/29.33/11.30 \n","04/22/2023 04:37:39 PM - INFO - [46:12] loss\t18.15 =\tBCE 18.15208 \tLL 0.01609 \tTotal 317.22/71.63/11.56 \n","04/22/2023 04:37:40 PM - INFO - [46:13] loss\t18.21 =\tBCE 18.20913 \tLL 0.01590 \tTotal 572.36/136.47/3.71 \n","04/22/2023 04:37:40 PM - INFO - [46:14] loss\t17.81 =\tBCE 17.81103 \tLL 0.01542 \tTotal 650.75/140.22/3.57 \n","04/22/2023 04:37:41 PM - INFO - [46:15] loss\t17.65 =\tBCE 17.65232 \tLL 0.01544 \tTotal 582.73/109.71/9.16 \n","04/22/2023 04:37:41 PM - INFO - [46:16] loss\t17.72 =\tBCE 17.72476 \tLL 0.01574 \tTotal 438.20/67.03/8.85 \n","04/22/2023 04:37:42 PM - INFO - [46:17] loss\t17.81 =\tBCE 17.81010 \tLL 0.01559 \tTotal 716.56/88.67/5.04 \n","04/22/2023 04:37:42 PM - INFO - [46:18] loss\t18.02 =\tBCE 18.02268 \tLL 0.01572 \tTotal 1139.05/125.66/4.46 \n","04/22/2023 04:37:42 PM - INFO - Training epoch 47.\n","04/22/2023 04:37:43 PM - INFO - [47:0] loss\t18.26 =\tBCE 18.26469 \tLL 0.01551 \tTotal 1378.88/150.14/8.20 \n","04/22/2023 04:37:43 PM - INFO - [47:1] loss\t17.99 =\tBCE 17.99118 \tLL 0.01548 \tTotal 1212.60/160.22/2.85 \n","04/22/2023 04:37:44 PM - INFO - [47:2] loss\t17.89 =\tBCE 17.89030 \tLL 0.01554 \tTotal 984.26/202.78/8.20 \n","04/22/2023 04:37:44 PM - INFO - [47:3] loss\t17.77 =\tBCE 17.77179 \tLL 0.01536 \tTotal 1043.66/226.26/2.67 \n","04/22/2023 04:37:45 PM - INFO - [47:4] loss\t18.13 =\tBCE 18.13069 \tLL 0.01566 \tTotal 1215.01/224.48/2.73 \n","04/22/2023 04:37:46 PM - INFO - [47:5] loss\t18.02 =\tBCE 18.01592 \tLL 0.01543 \tTotal 1159.49/214.07/5.82 \n","04/22/2023 04:37:46 PM - INFO - [47:6] loss\t17.46 =\tBCE 17.45523 \tLL 0.01502 \tTotal 892.62/187.87/5.14 \n","04/22/2023 04:37:47 PM - INFO - [47:7] loss\t17.27 =\tBCE 17.27123 \tLL 0.01504 \tTotal 559.42/128.14/7.36 \n","04/22/2023 04:37:47 PM - INFO - [47:8] loss\t17.43 =\tBCE 17.42647 \tLL 0.01559 \tTotal 299.19/71.71/2.56 \n","04/22/2023 04:37:48 PM - INFO - [47:9] loss\t17.17 =\tBCE 17.16717 \tLL 0.01541 \tTotal 223.07/38.28/10.76 \n","04/22/2023 04:37:48 PM - INFO - [47:10] loss\t17.90 =\tBCE 17.89606 \tLL 0.01606 \tTotal 415.41/86.35/8.64 \n","04/22/2023 04:37:49 PM - INFO - [47:11] loss\t17.02 =\tBCE 17.02223 \tLL 0.01503 \tTotal 722.19/124.54/1.48 \n","04/22/2023 04:37:49 PM - INFO - [47:12] loss\t17.30 =\tBCE 17.30400 \tLL 0.01502 \tTotal 981.35/174.67/4.18 \n","04/22/2023 04:37:50 PM - INFO - [47:13] loss\t17.52 =\tBCE 17.52007 \tLL 0.01504 \tTotal 1292.51/259.66/6.61 \n","04/22/2023 04:37:50 PM - INFO - [47:14] loss\t18.38 =\tBCE 18.37603 \tLL 0.01565 \tTotal 1762.63/351.99/5.02 \n","04/22/2023 04:37:51 PM - INFO - [47:15] loss\t19.08 =\tBCE 19.07528 \tLL 0.01521 \tTotal 2508.38/473.02/2.26 \n","04/22/2023 04:37:51 PM - INFO - [47:16] loss\t20.84 =\tBCE 20.83606 \tLL 0.01514 \tTotal 3769.63/651.73/5.02 \n","04/22/2023 04:37:52 PM - INFO - [47:17] loss\t24.00 =\tBCE 23.99972 \tLL 0.01496 \tTotal 5353.45/886.37/2.76 \n","04/22/2023 04:37:52 PM - INFO - [47:18] loss\t31.78 =\tBCE 31.78365 \tLL 0.01537 \tTotal 7105.05/1231.75/1.98 \n","04/22/2023 04:37:52 PM - INFO - Training epoch 48.\n","04/22/2023 04:37:53 PM - INFO - [48:0] loss\t40.85 =\tBCE 40.85484 \tLL 0.01473 \tTotal 9910.92/1760.69/2.24 \n","04/22/2023 04:37:53 PM - INFO - [48:1] loss\t72.84 =\tBCE 72.84029 \tLL 0.01608 \tTotal 13407.80/2659.25/6.36 \n","04/22/2023 04:37:54 PM - INFO - [48:2] loss\t109.00 =\tBCE 109.00012 \tLL 0.01539 \tTotal 17960.78/3621.17/1.35 \n","04/22/2023 04:37:54 PM - INFO - [48:3] loss\t173.60 =\tBCE 173.59891 \tLL 0.01763 \tTotal 20406.10/4125.76/3.72 \n","04/22/2023 04:37:55 PM - INFO - [48:4] loss\t92.54 =\tBCE 92.53949 \tLL 0.01757 \tTotal 17178.96/2715.26/4.50 \n","04/22/2023 04:37:55 PM - INFO - [48:5] loss\t38.43 =\tBCE 38.43243 \tLL 0.01774 \tTotal 6872.67/927.27/6.30 \n","04/22/2023 04:37:56 PM - INFO - [48:6] loss\t42.38 =\tBCE 42.38433 \tLL 0.01840 \tTotal 6093.37/1585.79/2.06 \n","04/22/2023 04:37:57 PM - INFO - [48:7] loss\t56.05 =\tBCE 56.05016 \tLL 0.01866 \tTotal 10213.62/1494.24/7.03 \n","04/22/2023 04:37:57 PM - INFO - [48:8] loss\t39.44 =\tBCE 39.44472 \tLL 0.01844 \tTotal 6532.04/904.45/4.21 \n","04/22/2023 04:37:58 PM - INFO - [48:9] loss\t32.41 =\tBCE 32.41492 \tLL 0.01843 \tTotal 4361.26/948.28/5.42 \n","04/22/2023 04:37:58 PM - INFO - [48:10] loss\t47.57 =\tBCE 47.57000 \tLL 0.01903 \tTotal 9282.25/1095.44/4.07 \n","04/22/2023 04:37:59 PM - INFO - [48:11] loss\t29.60 =\tBCE 29.60064 \tLL 0.01899 \tTotal 5380.63/584.14/2.33 \n","04/22/2023 04:37:59 PM - INFO - [48:12] loss\t32.49 =\tBCE 32.49039 \tLL 0.01937 \tTotal 4520.69/627.37/3.63 \n","04/22/2023 04:38:00 PM - INFO - [48:13] loss\t31.46 =\tBCE 31.45979 \tLL 0.01962 \tTotal 6191.32/623.21/7.57 \n","04/22/2023 04:38:00 PM - INFO - [48:14] loss\t25.45 =\tBCE 25.44549 \tLL 0.01947 \tTotal 3340.01/375.24/2.99 \n","04/22/2023 04:38:01 PM - INFO - [48:15] loss\t31.62 =\tBCE 31.62365 \tLL 0.01958 \tTotal 5065.19/565.29/3.67 \n","04/22/2023 04:38:01 PM - INFO - [48:16] loss\t26.41 =\tBCE 26.41119 \tLL 0.01954 \tTotal 3790.49/440.10/3.38 \n","04/22/2023 04:38:02 PM - INFO - [48:17] loss\t27.72 =\tBCE 27.72414 \tLL 0.02035 \tTotal 3614.66/461.18/8.50 \n","04/22/2023 04:38:02 PM - INFO - [48:18] loss\t24.63 =\tBCE 24.62928 \tLL 0.02011 \tTotal 2861.63/370.63/5.47 \n","Not implemented\n","04/22/2023 04:38:02 PM - INFO - Training epoch 49.\n","04/22/2023 04:38:03 PM - INFO - [49:0] loss\t28.34 =\tBCE 28.33944 \tLL 0.01952 \tTotal 4403.34/484.66/5.21 \n","04/22/2023 04:38:03 PM - INFO - [49:1] loss\t24.24 =\tBCE 24.23512 \tLL 0.01946 \tTotal 2684.70/340.94/7.07 \n","04/22/2023 04:38:04 PM - INFO - [49:2] loss\t23.20 =\tBCE 23.20079 \tLL 0.01969 \tTotal 2873.00/317.05/7.54 \n","04/22/2023 04:38:04 PM - INFO - [49:3] loss\t27.12 =\tBCE 27.12276 \tLL 0.02042 \tTotal 3662.10/441.04/8.35 \n","04/22/2023 04:38:05 PM - INFO - [49:4] loss\t21.11 =\tBCE 21.10973 \tLL 0.01945 \tTotal 1217.39/182.87/9.15 \n","04/22/2023 04:38:05 PM - INFO - [49:5] loss\t26.43 =\tBCE 26.42754 \tLL 0.01953 \tTotal 3786.68/466.76/3.62 \n","04/22/2023 04:38:06 PM - INFO - [49:6] loss\t22.64 =\tBCE 22.63583 \tLL 0.01949 \tTotal 2453.44/275.96/2.96 \n","04/22/2023 04:38:07 PM - INFO - [49:7] loss\t23.85 =\tBCE 23.85248 \tLL 0.01964 \tTotal 2565.37/333.46/11.77 \n","04/22/2023 04:38:07 PM - INFO - [49:8] loss\t22.45 =\tBCE 22.44839 \tLL 0.01964 \tTotal 2223.39/278.00/6.28 \n","04/22/2023 04:38:08 PM - INFO - [49:9] loss\t21.89 =\tBCE 21.88750 \tLL 0.01931 \tTotal 2030.44/245.55/10.09 \n","04/22/2023 04:38:08 PM - INFO - [49:10] loss\t22.42 =\tBCE 22.41994 \tLL 0.01820 \tTotal 1805.10/253.29/3.18 \n","04/22/2023 04:38:09 PM - INFO - [49:11] loss\t21.27 =\tBCE 21.27136 \tLL 0.01905 \tTotal 2268.07/256.25/17.05 \n","04/22/2023 04:38:09 PM - INFO - [49:12] loss\t21.62 =\tBCE 21.61703 \tLL 0.01865 \tTotal 1808.87/226.01/7.51 \n","04/22/2023 04:38:10 PM - INFO - [49:13] loss\t20.61 =\tBCE 20.61404 \tLL 0.01821 \tTotal 1587.36/186.06/4.65 \n","04/22/2023 04:38:10 PM - INFO - [49:14] loss\t21.12 =\tBCE 21.12394 \tLL 0.01764 \tTotal 2266.42/243.65/5.42 \n","04/22/2023 04:38:11 PM - INFO - [49:15] loss\t20.33 =\tBCE 20.33298 \tLL 0.01904 \tTotal 1026.65/127.81/5.94 \n","04/22/2023 04:38:11 PM - INFO - [49:16] loss\t20.21 =\tBCE 20.20683 \tLL 0.01821 \tTotal 1879.34/207.18/7.85 \n","04/22/2023 04:38:12 PM - INFO - [49:17] loss\t20.52 =\tBCE 20.52425 \tLL 0.01868 \tTotal 1278.49/155.16/5.53 \n","04/22/2023 04:38:12 PM - INFO - [49:18] loss\t20.28 =\tBCE 20.27813 \tLL 0.01807 \tTotal 1736.90/202.42/2.16 \n","04/22/2023 04:38:12 PM - INFO - EVALUATION prior to epoch [50]...\n","04/22/2023 04:38:12 PM - INFO - [50] loss\t16.22=\tBCE 16.22 \tLL 0.01673 \n","04/22/2023 04:38:14 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/50_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:38:18 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/50_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:38:23 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/50_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 04:38:24 PM - INFO - Training epoch 50.\n","04/22/2023 04:38:25 PM - INFO - [50:0] loss\t20.16 =\tBCE 20.16185 \tLL 0.01812 \tTotal 1693.47/213.07/5.39 \n","04/22/2023 04:38:25 PM - INFO - [50:1] loss\t19.39 =\tBCE 19.39395 \tLL 0.01825 \tTotal 985.62/142.28/3.87 \n","04/22/2023 04:38:26 PM - INFO - [50:2] loss\t19.26 =\tBCE 19.26144 \tLL 0.01728 \tTotal 1177.49/158.83/5.62 \n","04/22/2023 04:38:26 PM - INFO - [50:3] loss\t19.23 =\tBCE 19.22697 \tLL 0.01738 \tTotal 1206.10/161.60/2.68 \n","04/22/2023 04:38:27 PM - INFO - [50:4] loss\t18.79 =\tBCE 18.79097 \tLL 0.01717 \tTotal 985.58/129.68/2.03 \n","04/22/2023 04:38:27 PM - INFO - [50:5] loss\t19.04 =\tBCE 19.04298 \tLL 0.01768 \tTotal 756.74/127.79/5.40 \n","04/22/2023 04:38:28 PM - INFO - [50:6] loss\t19.03 =\tBCE 19.02802 \tLL 0.01691 \tTotal 1176.10/153.82/2.03 \n","04/22/2023 04:38:28 PM - INFO - [50:7] loss\t18.70 =\tBCE 18.70263 \tLL 0.01746 \tTotal 694.16/119.02/2.04 \n","04/22/2023 04:38:29 PM - INFO - [50:8] loss\t18.63 =\tBCE 18.62743 \tLL 0.01736 \tTotal 843.71/100.83/4.75 \n","04/22/2023 04:38:29 PM - INFO - [50:9] loss\t18.83 =\tBCE 18.82877 \tLL 0.01773 \tTotal 966.98/127.91/2.04 \n","04/22/2023 04:38:30 PM - INFO - [50:10] loss\t18.27 =\tBCE 18.26579 \tLL 0.01720 \tTotal 540.48/72.61/8.19 \n","04/22/2023 04:38:30 PM - INFO - [50:11] loss\t18.35 =\tBCE 18.34626 \tLL 0.01699 \tTotal 1069.71/155.80/2.42 \n","04/22/2023 04:38:31 PM - INFO - [50:12] loss\t18.45 =\tBCE 18.44839 \tLL 0.01705 \tTotal 914.21/143.30/6.57 \n","04/22/2023 04:38:32 PM - INFO - [50:13] loss\t18.41 =\tBCE 18.40696 \tLL 0.01727 \tTotal 809.67/132.62/1.39 \n","04/22/2023 04:38:32 PM - INFO - [50:14] loss\t18.01 =\tBCE 18.01053 \tLL 0.01633 \tTotal 1026.91/132.32/4.85 \n","04/22/2023 04:38:33 PM - INFO - [50:15] loss\t17.76 =\tBCE 17.76324 \tLL 0.01657 \tTotal 713.83/103.95/1.69 \n","04/22/2023 04:38:33 PM - INFO - [50:16] loss\t18.23 =\tBCE 18.22567 \tLL 0.01662 \tTotal 1034.72/135.36/1.83 \n","04/22/2023 04:38:34 PM - INFO - [50:17] loss\t17.87 =\tBCE 17.86649 \tLL 0.01646 \tTotal 363.62/112.59/2.48 \n","04/22/2023 04:38:34 PM - INFO - [50:18] loss\t17.72 =\tBCE 17.72175 \tLL 0.01629 \tTotal 917.68/114.72/6.66 \n","04/22/2023 04:38:34 PM - INFO - Training epoch 51.\n","04/22/2023 04:38:35 PM - INFO - [51:0] loss\t17.80 =\tBCE 17.80267 \tLL 0.01637 \tTotal 758.60/148.13/4.79 \n","04/22/2023 04:38:35 PM - INFO - [51:1] loss\t17.80 =\tBCE 17.79696 \tLL 0.01612 \tTotal 314.65/81.57/9.55 \n","04/22/2023 04:38:36 PM - INFO - [51:2] loss\t17.56 =\tBCE 17.56066 \tLL 0.01596 \tTotal 863.21/123.48/4.71 \n","04/22/2023 04:38:36 PM - INFO - [51:3] loss\t16.99 =\tBCE 16.99357 \tLL 0.01549 \tTotal 544.61/107.20/2.63 \n","04/22/2023 04:38:37 PM - INFO - [51:4] loss\t17.40 =\tBCE 17.39897 \tLL 0.01595 \tTotal 571.73/82.46/3.07 \n","04/22/2023 04:38:37 PM - INFO - [51:5] loss\t17.14 =\tBCE 17.14270 \tLL 0.01584 \tTotal 623.58/101.06/4.79 \n","04/22/2023 04:38:38 PM - INFO - [51:6] loss\t16.95 =\tBCE 16.94774 \tLL 0.01579 \tTotal 402.71/64.83/6.92 \n","04/22/2023 04:38:38 PM - INFO - [51:7] loss\t17.55 =\tBCE 17.54862 \tLL 0.01632 \tTotal 579.61/75.89/2.59 \n","04/22/2023 04:38:39 PM - INFO - [51:8] loss\t17.26 =\tBCE 17.26471 \tLL 0.01610 \tTotal 313.69/82.45/3.23 \n","04/22/2023 04:38:39 PM - INFO - [51:9] loss\t16.88 =\tBCE 16.87933 \tLL 0.01561 \tTotal 448.30/72.81/2.69 \n","04/22/2023 04:38:40 PM - INFO - [51:10] loss\t16.93 =\tBCE 16.92780 \tLL 0.01586 \tTotal 510.55/84.53/3.00 \n","04/22/2023 04:38:41 PM - INFO - [51:11] loss\t16.70 =\tBCE 16.69938 \tLL 0.01534 \tTotal 302.96/87.60/5.41 \n","04/22/2023 04:38:41 PM - INFO - [51:12] loss\t16.75 =\tBCE 16.74613 \tLL 0.01573 \tTotal 463.80/55.32/2.51 \n","04/22/2023 04:38:42 PM - INFO - [51:13] loss\t16.80 =\tBCE 16.79910 \tLL 0.01540 \tTotal 381.07/64.47/4.91 \n","04/22/2023 04:38:42 PM - INFO - [51:14] loss\t16.82 =\tBCE 16.82196 \tLL 0.01538 \tTotal 268.24/49.24/2.70 \n","04/22/2023 04:38:43 PM - INFO - [51:15] loss\t16.94 =\tBCE 16.93550 \tLL 0.01555 \tTotal 371.67/52.70/4.86 \n","04/22/2023 04:38:43 PM - INFO - [51:16] loss\t16.99 =\tBCE 16.98770 \tLL 0.01566 \tTotal 446.08/54.76/8.46 \n","04/22/2023 04:38:44 PM - INFO - [51:17] loss\t16.98 =\tBCE 16.97772 \tLL 0.01580 \tTotal 481.22/75.48/3.32 \n","04/22/2023 04:38:44 PM - INFO - [51:18] loss\t16.57 =\tBCE 16.57072 \tLL 0.01515 \tTotal 442.88/59.51/3.01 \n","04/22/2023 04:38:44 PM - INFO - Training epoch 52.\n","04/22/2023 04:38:45 PM - INFO - [52:0] loss\t16.09 =\tBCE 16.08509 \tLL 0.01507 \tTotal 311.59/39.27/4.67 \n","04/22/2023 04:38:45 PM - INFO - [52:1] loss\t16.58 =\tBCE 16.57593 \tLL 0.01495 \tTotal 236.90/49.24/6.62 \n","04/22/2023 04:38:46 PM - INFO - [52:2] loss\t16.83 =\tBCE 16.82857 \tLL 0.01554 \tTotal 297.35/41.40/4.46 \n","04/22/2023 04:38:46 PM - INFO - [52:3] loss\t16.41 =\tBCE 16.41444 \tLL 0.01523 \tTotal 298.90/40.43/1.72 \n","04/22/2023 04:38:47 PM - INFO - [52:4] loss\t16.28 =\tBCE 16.28420 \tLL 0.01513 \tTotal 210.88/28.04/4.65 \n","04/22/2023 04:38:47 PM - INFO - [52:5] loss\t16.15 =\tBCE 16.14948 \tLL 0.01469 \tTotal 556.09/62.25/9.34 \n","04/22/2023 04:38:48 PM - INFO - [52:6] loss\t16.56 =\tBCE 16.55615 \tLL 0.01556 \tTotal 854.76/90.76/2.93 \n","04/22/2023 04:38:49 PM - INFO - [52:7] loss\t16.26 =\tBCE 16.26413 \tLL 0.01479 \tTotal 855.45/96.61/6.04 \n","04/22/2023 04:38:49 PM - INFO - [52:8] loss\t16.11 =\tBCE 16.10796 \tLL 0.01475 \tTotal 547.82/59.73/3.14 \n","04/22/2023 04:38:50 PM - INFO - [52:9] loss\t16.31 =\tBCE 16.31264 \tLL 0.01501 \tTotal 107.79/23.40/3.40 \n","04/22/2023 04:38:50 PM - INFO - [52:10] loss\t15.78 =\tBCE 15.77918 \tLL 0.01441 \tTotal 416.78/51.21/4.32 \n","04/22/2023 04:38:51 PM - INFO - [52:11] loss\t15.87 =\tBCE 15.87262 \tLL 0.01467 \tTotal 529.33/60.31/1.58 \n","04/22/2023 04:38:51 PM - INFO - [52:12] loss\t15.92 =\tBCE 15.91623 \tLL 0.01460 \tTotal 434.91/60.28/3.64 \n","04/22/2023 04:38:52 PM - INFO - [52:13] loss\t15.87 =\tBCE 15.87469 \tLL 0.01441 \tTotal 187.95/67.28/3.82 \n","04/22/2023 04:38:52 PM - INFO - [52:14] loss\t16.33 =\tBCE 16.33153 \tLL 0.01514 \tTotal 526.71/58.17/3.12 \n","04/22/2023 04:38:53 PM - INFO - [52:15] loss\t15.90 =\tBCE 15.90368 \tLL 0.01451 \tTotal 798.56/87.83/4.74 \n","04/22/2023 04:38:53 PM - INFO - [52:16] loss\t15.86 =\tBCE 15.86015 \tLL 0.01448 \tTotal 835.96/92.37/7.24 \n","04/22/2023 04:38:54 PM - INFO - [52:17] loss\t15.88 =\tBCE 15.87712 \tLL 0.01439 \tTotal 599.81/63.51/2.53 \n","04/22/2023 04:38:55 PM - INFO - [52:18] loss\t15.69 =\tBCE 15.69102 \tLL 0.01430 \tTotal 162.22/32.76/6.24 \n","04/22/2023 04:38:55 PM - INFO - Training epoch 53.\n","04/22/2023 04:38:55 PM - INFO - [53:0] loss\t15.96 =\tBCE 15.95635 \tLL 0.01481 \tTotal 537.70/60.73/4.51 \n","04/22/2023 04:38:56 PM - INFO - [53:1] loss\t15.82 =\tBCE 15.81812 \tLL 0.01461 \tTotal 832.42/94.17/2.30 \n","04/22/2023 04:38:56 PM - INFO - [53:2] loss\t15.94 =\tBCE 15.94460 \tLL 0.01415 \tTotal 949.67/114.49/2.63 \n","04/22/2023 04:38:57 PM - INFO - [53:3] loss\t15.66 =\tBCE 15.66149 \tLL 0.01438 \tTotal 966.34/106.38/1.23 \n","04/22/2023 04:38:57 PM - INFO - [53:4] loss\t15.35 =\tBCE 15.35069 \tLL 0.01417 \tTotal 828.86/95.19/6.66 \n","04/22/2023 04:38:58 PM - INFO - [53:5] loss\t15.78 =\tBCE 15.78378 \tLL 0.01451 \tTotal 533.24/68.79/3.19 \n","04/22/2023 04:38:58 PM - INFO - [53:6] loss\t15.60 =\tBCE 15.59938 \tLL 0.01481 \tTotal 136.18/27.12/2.20 \n","04/22/2023 04:38:59 PM - INFO - [53:7] loss\t15.51 =\tBCE 15.50942 \tLL 0.01434 \tTotal 553.67/75.19/3.72 \n","04/22/2023 04:38:59 PM - INFO - [53:8] loss\t15.58 =\tBCE 15.57660 \tLL 0.01427 \tTotal 751.25/98.00/2.51 \n","04/22/2023 04:39:00 PM - INFO - [53:9] loss\t15.15 =\tBCE 15.14918 \tLL 0.01374 \tTotal 711.79/92.52/5.62 \n","04/22/2023 04:39:00 PM - INFO - [53:10] loss\t15.30 =\tBCE 15.29535 \tLL 0.01394 \tTotal 604.71/106.46/4.35 \n","04/22/2023 04:39:01 PM - INFO - [53:11] loss\t15.54 =\tBCE 15.53942 \tLL 0.01408 \tTotal 628.70/132.64/2.60 \n","04/22/2023 04:39:01 PM - INFO - [53:12] loss\t15.25 =\tBCE 15.24697 \tLL 0.01374 \tTotal 551.54/112.91/1.37 \n","04/22/2023 04:39:02 PM - INFO - [53:13] loss\t15.35 =\tBCE 15.35452 \tLL 0.01413 \tTotal 215.93/52.76/3.30 \n","04/22/2023 04:39:02 PM - INFO - [53:14] loss\t15.20 =\tBCE 15.20473 \tLL 0.01383 \tTotal 468.02/62.13/3.71 \n","04/22/2023 04:39:03 PM - INFO - [53:15] loss\t14.94 =\tBCE 14.94346 \tLL 0.01375 \tTotal 611.89/116.54/3.70 \n","04/22/2023 04:39:04 PM - INFO - [53:16] loss\t15.37 =\tBCE 15.36853 \tLL 0.01391 \tTotal 676.88/131.78/4.04 \n","04/22/2023 04:39:04 PM - INFO - [53:17] loss\t15.33 =\tBCE 15.32712 \tLL 0.01428 \tTotal 721.15/96.60/3.06 \n","04/22/2023 04:39:05 PM - INFO - [53:18] loss\t15.14 =\tBCE 15.14402 \tLL 0.01359 \tTotal 616.09/65.65/5.99 \n","04/22/2023 04:39:05 PM - INFO - Training epoch 54.\n","04/22/2023 04:39:05 PM - INFO - [54:0] loss\t14.87 =\tBCE 14.87440 \tLL 0.01340 \tTotal 481.41/76.99/1.78 \n","04/22/2023 04:39:06 PM - INFO - [54:1] loss\t14.83 =\tBCE 14.82534 \tLL 0.01340 \tTotal 388.78/57.53/2.61 \n","04/22/2023 04:39:06 PM - INFO - [54:2] loss\t14.78 =\tBCE 14.77856 \tLL 0.01347 \tTotal 278.33/45.82/7.92 \n","04/22/2023 04:39:07 PM - INFO - [54:3] loss\t14.74 =\tBCE 14.73843 \tLL 0.01369 \tTotal 493.76/51.50/5.61 \n","04/22/2023 04:39:07 PM - INFO - [54:4] loss\t14.86 =\tBCE 14.85679 \tLL 0.01402 \tTotal 634.41/73.15/5.48 \n","04/22/2023 04:39:08 PM - INFO - [54:5] loss\t14.76 =\tBCE 14.75809 \tLL 0.01363 \tTotal 857.33/101.57/3.28 \n","04/22/2023 04:39:08 PM - INFO - [54:6] loss\t15.19 =\tBCE 15.18862 \tLL 0.01380 \tTotal 1024.17/120.71/7.31 \n","04/22/2023 04:39:09 PM - INFO - [54:7] loss\t15.27 =\tBCE 15.26939 \tLL 0.01397 \tTotal 1030.72/124.04/1.91 \n","04/22/2023 04:39:09 PM - INFO - [54:8] loss\t15.34 =\tBCE 15.33543 \tLL 0.01420 \tTotal 1188.87/128.03/2.00 \n","04/22/2023 04:39:10 PM - INFO - [54:9] loss\t14.95 =\tBCE 14.95035 \tLL 0.01356 \tTotal 1240.53/144.09/4.74 \n","04/22/2023 04:39:10 PM - INFO - [54:10] loss\t15.18 =\tBCE 15.17520 \tLL 0.01380 \tTotal 1108.76/123.38/5.26 \n","04/22/2023 04:39:11 PM - INFO - [54:11] loss\t14.91 =\tBCE 14.91292 \tLL 0.01392 \tTotal 826.71/84.26/2.27 \n","04/22/2023 04:39:12 PM - INFO - [54:12] loss\t14.39 =\tBCE 14.38548 \tLL 0.01303 \tTotal 483.30/71.76/1.86 \n","04/22/2023 04:39:12 PM - INFO - [54:13] loss\t14.92 =\tBCE 14.91640 \tLL 0.01391 \tTotal 701.79/122.63/3.71 \n","04/22/2023 04:39:13 PM - INFO - [54:14] loss\t14.77 =\tBCE 14.77378 \tLL 0.01341 \tTotal 1020.15/172.57/3.71 \n","04/22/2023 04:39:13 PM - INFO - [54:15] loss\t15.06 =\tBCE 15.05575 \tLL 0.01342 \tTotal 1236.62/251.63/4.17 \n","04/22/2023 04:39:14 PM - INFO - [54:16] loss\t15.56 =\tBCE 15.55731 \tLL 0.01356 \tTotal 1405.68/391.94/1.89 \n","04/22/2023 04:39:14 PM - INFO - [54:17] loss\t16.40 =\tBCE 16.40188 \tLL 0.01402 \tTotal 1809.74/535.49/2.47 \n","04/22/2023 04:39:15 PM - INFO - [54:18] loss\t17.28 =\tBCE 17.28435 \tLL 0.01324 \tTotal 2322.63/684.84/5.64 \n","04/22/2023 04:39:15 PM - INFO - Training epoch 55.\n","04/22/2023 04:39:15 PM - INFO - [55:0] loss\t19.36 =\tBCE 19.35850 \tLL 0.01388 \tTotal 2656.22/859.52/6.16 \n","04/22/2023 04:39:16 PM - INFO - [55:1] loss\t20.87 =\tBCE 20.87500 \tLL 0.01298 \tTotal 3646.63/1076.72/2.56 \n","04/22/2023 04:39:16 PM - INFO - [55:2] loss\t28.51 =\tBCE 28.50689 \tLL 0.01442 \tTotal 5255.90/1466.83/2.35 \n","04/22/2023 04:39:17 PM - INFO - [55:3] loss\t42.17 =\tBCE 42.17157 \tLL 0.01318 \tTotal 9822.22/2244.12/5.14 \n","04/22/2023 04:39:17 PM - INFO - [55:4] loss\t122.93 =\tBCE 122.92563 \tLL 0.01532 \tTotal 17179.89/3590.85/4.95 \n","04/22/2023 04:39:18 PM - INFO - [55:5] loss\t206.98 =\tBCE 206.98230 \tLL 0.01350 \tTotal 30282.10/5228.53/5.79 \n","04/22/2023 04:39:18 PM - INFO - [55:6] loss\t970.04 =\tBCE 970.03973 \tLL 0.01856 \tTotal 38814.78/5110.09/4.21 \n","04/22/2023 04:39:19 PM - INFO - [55:7] loss\t281.29 =\tBCE 281.29123 \tLL 0.01963 \tTotal 29954.09/3583.95/5.90 \n","04/22/2023 04:39:19 PM - INFO - [55:8] loss\t317.13 =\tBCE 317.12637 \tLL 0.01859 \tTotal 21722.27/6678.34/10.25 \n","04/22/2023 04:39:20 PM - INFO - [55:9] loss\t168.96 =\tBCE 168.96442 \tLL 0.02004 \tTotal 14873.54/3828.13/4.88 \n","04/22/2023 04:39:21 PM - INFO - [55:10] loss\t146.88 =\tBCE 146.88071 \tLL 0.02236 \tTotal 14087.82/3284.97/9.04 \n","04/22/2023 04:39:21 PM - INFO - [55:11] loss\t190.50 =\tBCE 190.49939 \tLL 0.02261 \tTotal 16282.02/4299.95/4.83 \n","04/22/2023 04:39:22 PM - INFO - [55:12] loss\t96.82 =\tBCE 96.82326 \tLL 0.02035 \tTotal 13418.59/1520.38/5.30 \n","04/22/2023 04:39:22 PM - INFO - [55:13] loss\t125.40 =\tBCE 125.39664 \tLL 0.02189 \tTotal 11180.17/2720.87/3.14 \n","04/22/2023 04:39:23 PM - INFO - [55:14] loss\t122.46 =\tBCE 122.46245 \tLL 0.02406 \tTotal 16008.91/1595.59/4.94 \n","04/22/2023 04:39:23 PM - INFO - [55:15] loss\t56.52 =\tBCE 56.51962 \tLL 0.02346 \tTotal 6545.68/1134.72/5.94 \n","04/22/2023 04:39:24 PM - INFO - [55:16] loss\t135.35 =\tBCE 135.35393 \tLL 0.02175 \tTotal 16411.77/1820.41/4.43 \n","04/22/2023 04:39:24 PM - INFO - [55:17] loss\t48.46 =\tBCE 48.46250 \tLL 0.02424 \tTotal 6460.87/627.19/5.21 \n","04/22/2023 04:39:25 PM - INFO - [55:18] loss\t91.61 =\tBCE 91.61134 \tLL 0.02509 \tTotal 11559.27/1267.87/8.21 \n","04/22/2023 04:39:25 PM - INFO - Training epoch 56.\n","04/22/2023 04:39:25 PM - INFO - [56:0] loss\t73.95 =\tBCE 73.94533 \tLL 0.02635 \tTotal 8415.87/1125.43/8.09 \n","04/22/2023 04:39:26 PM - INFO - [56:1] loss\t46.47 =\tBCE 46.46667 \tLL 0.02484 \tTotal 5173.22/546.06/9.62 \n","04/22/2023 04:39:26 PM - INFO - [56:2] loss\t85.37 =\tBCE 85.36942 \tLL 0.02477 \tTotal 9306.27/1390.90/5.43 \n","04/22/2023 04:39:27 PM - INFO - [56:3] loss\t40.16 =\tBCE 40.15662 \tLL 0.02536 \tTotal 3191.00/634.94/7.55 \n","04/22/2023 04:39:27 PM - INFO - [56:4] loss\t52.35 =\tBCE 52.35083 \tLL 0.02746 \tTotal 6262.94/653.16/8.78 \n","04/22/2023 04:39:28 PM - INFO - [56:5] loss\t56.58 =\tBCE 56.57656 \tLL 0.02690 \tTotal 5191.10/866.86/7.65 \n","04/22/2023 04:39:28 PM - INFO - [56:6] loss\t48.53 =\tBCE 48.53193 \tLL 0.02683 \tTotal 4991.79/600.23/2.31 \n","04/22/2023 04:39:29 PM - INFO - [56:7] loss\t40.32 =\tBCE 40.32322 \tLL 0.02688 \tTotal 3562.33/357.80/12.53 \n","04/22/2023 04:39:29 PM - INFO - [56:8] loss\t50.62 =\tBCE 50.61824 \tLL 0.02684 \tTotal 4917.12/703.91/7.03 \n","04/22/2023 04:39:30 PM - INFO - [56:9] loss\t43.45 =\tBCE 43.44811 \tLL 0.02719 \tTotal 3732.82/544.38/8.00 \n","04/22/2023 04:39:30 PM - INFO - [56:10] loss\t36.35 =\tBCE 36.35498 \tLL 0.02649 \tTotal 2350.84/284.67/13.65 \n","04/22/2023 04:39:31 PM - INFO - [56:11] loss\t46.21 =\tBCE 46.20868 \tLL 0.02543 \tTotal 3990.60/667.67/3.85 \n","04/22/2023 04:39:32 PM - INFO - [56:12] loss\t39.13 =\tBCE 39.12906 \tLL 0.02518 \tTotal 2194.03/546.38/6.44 \n","04/22/2023 04:39:32 PM - INFO - [56:13] loss\t33.58 =\tBCE 33.57742 \tLL 0.02499 \tTotal 2345.41/237.43/13.36 \n","04/22/2023 04:39:33 PM - INFO - [56:14] loss\t38.22 =\tBCE 38.21715 \tLL 0.02494 \tTotal 2419.44/541.64/5.95 \n","04/22/2023 04:39:33 PM - INFO - [56:15] loss\t39.61 =\tBCE 39.60883 \tLL 0.02485 \tTotal 2404.76/589.83/5.61 \n","04/22/2023 04:39:34 PM - INFO - [56:16] loss\t32.40 =\tBCE 32.39524 \tLL 0.02420 \tTotal 1265.35/152.34/9.43 \n","04/22/2023 04:39:34 PM - INFO - [56:17] loss\t34.67 =\tBCE 34.66698 \tLL 0.02409 \tTotal 1662.09/448.41/5.35 \n","04/22/2023 04:39:35 PM - INFO - [56:18] loss\t36.12 =\tBCE 36.11691 \tLL 0.02357 \tTotal 1977.30/502.65/2.86 \n","04/22/2023 04:39:35 PM - INFO - Training epoch 57.\n","04/22/2023 04:39:35 PM - INFO - [57:0] loss\t32.42 =\tBCE 32.41545 \tLL 0.02371 \tTotal 1667.49/184.06/5.03 \n","04/22/2023 04:39:36 PM - INFO - [57:1] loss\t32.03 =\tBCE 32.03421 \tLL 0.02322 \tTotal 1353.18/327.97/9.18 \n","04/22/2023 04:39:36 PM - INFO - [57:2] loss\t33.45 =\tBCE 33.45253 \tLL 0.02267 \tTotal 1727.96/368.13/4.25 \n","04/22/2023 04:39:37 PM - INFO - [57:3] loss\t32.55 =\tBCE 32.54621 \tLL 0.02259 \tTotal 2016.64/233.42/2.93 \n","04/22/2023 04:39:37 PM - INFO - [57:4] loss\t29.11 =\tBCE 29.10973 \tLL 0.02181 \tTotal 750.24/183.15/5.95 \n","04/22/2023 04:39:38 PM - INFO - [57:5] loss\t30.62 =\tBCE 30.61524 \tLL 0.02227 \tTotal 1460.18/228.59/8.83 \n","04/22/2023 04:39:38 PM - INFO - [57:6] loss\t31.68 =\tBCE 31.68220 \tLL 0.02303 \tTotal 1746.05/207.71/3.51 \n","04/22/2023 04:39:39 PM - INFO - [57:7] loss\t29.81 =\tBCE 29.80908 \tLL 0.02216 \tTotal 996.92/110.74/6.19 \n","04/22/2023 04:39:39 PM - INFO - [57:8] loss\t29.24 =\tBCE 29.24195 \tLL 0.02189 \tTotal 1130.46/129.83/7.08 \n","04/22/2023 04:39:40 PM - INFO - [57:9] loss\t29.89 =\tBCE 29.88624 \tLL 0.02142 \tTotal 1533.94/183.63/6.23 \n","04/22/2023 04:39:41 PM - INFO - [57:10] loss\t29.40 =\tBCE 29.40425 \tLL 0.02224 \tTotal 1029.23/136.63/2.60 \n","04/22/2023 04:39:41 PM - INFO - [57:11] loss\t28.24 =\tBCE 28.23617 \tLL 0.02191 \tTotal 743.57/108.42/3.12 \n","04/22/2023 04:39:42 PM - INFO - [57:12] loss\t28.41 =\tBCE 28.40535 \tLL 0.02118 \tTotal 1164.22/133.86/9.24 \n","04/22/2023 04:39:42 PM - INFO - [57:13] loss\t28.36 =\tBCE 28.36313 \tLL 0.02127 \tTotal 1026.54/190.60/3.15 \n","04/22/2023 04:39:43 PM - INFO - [57:14] loss\t27.46 =\tBCE 27.46389 \tLL 0.02062 \tTotal 620.80/126.25/4.41 \n","04/22/2023 04:39:43 PM - INFO - [57:15] loss\t28.24 =\tBCE 28.23835 \tLL 0.02102 \tTotal 1079.11/143.35/11.40 \n","04/22/2023 04:39:44 PM - INFO - [57:16] loss\t27.49 =\tBCE 27.49458 \tLL 0.02111 \tTotal 920.45/184.88/9.13 \n","04/22/2023 04:39:44 PM - INFO - [57:17] loss\t26.45 =\tBCE 26.45050 \tLL 0.02004 \tTotal 582.55/98.57/1.99 \n","04/22/2023 04:39:45 PM - INFO - [57:18] loss\t26.37 =\tBCE 26.37451 \tLL 0.02006 \tTotal 809.30/112.48/3.60 \n","04/22/2023 04:39:45 PM - INFO - Training epoch 58.\n","04/22/2023 04:39:45 PM - INFO - [58:0] loss\t26.96 =\tBCE 26.96318 \tLL 0.02003 \tTotal 782.86/162.61/5.01 \n","04/22/2023 04:39:46 PM - INFO - [58:1] loss\t26.34 =\tBCE 26.34237 \tLL 0.02015 \tTotal 655.50/112.47/8.83 \n","04/22/2023 04:39:46 PM - INFO - [58:2] loss\t25.71 =\tBCE 25.70980 \tLL 0.01989 \tTotal 649.04/109.48/2.41 \n","04/22/2023 04:39:47 PM - INFO - [58:3] loss\t25.77 =\tBCE 25.77271 \tLL 0.01973 \tTotal 678.14/112.86/2.33 \n","04/22/2023 04:39:47 PM - INFO - [58:4] loss\t25.22 =\tBCE 25.21965 \tLL 0.01958 \tTotal 780.53/107.22/6.67 \n","04/22/2023 04:39:48 PM - INFO - [58:5] loss\t25.05 =\tBCE 25.04899 \tLL 0.01977 \tTotal 332.25/53.62/6.66 \n","04/22/2023 04:39:48 PM - INFO - [58:6] loss\t24.85 =\tBCE 24.84973 \tLL 0.01896 \tTotal 583.82/96.93/3.28 \n","04/22/2023 04:39:49 PM - INFO - [58:7] loss\t25.63 =\tBCE 25.63086 \tLL 0.02005 \tTotal 496.58/101.71/5.49 \n","04/22/2023 04:39:49 PM - INFO - [58:8] loss\t24.95 =\tBCE 24.95171 \tLL 0.01971 \tTotal 366.23/71.92/2.02 \n","04/22/2023 04:39:50 PM - INFO - [58:9] loss\t24.74 =\tBCE 24.73782 \tLL 0.02002 \tTotal 305.77/82.75/4.60 \n","04/22/2023 04:39:50 PM - INFO - [58:10] loss\t24.45 =\tBCE 24.45250 \tLL 0.01923 \tTotal 415.12/112.58/5.20 \n","04/22/2023 04:39:51 PM - INFO - [58:11] loss\t24.34 =\tBCE 24.34486 \tLL 0.01967 \tTotal 421.75/63.08/4.49 \n","04/22/2023 04:39:52 PM - INFO - [58:12] loss\t23.86 =\tBCE 23.86124 \tLL 0.01900 \tTotal 225.02/88.75/6.40 \n","04/22/2023 04:39:52 PM - INFO - [58:13] loss\t24.12 =\tBCE 24.11890 \tLL 0.01914 \tTotal 402.78/94.85/4.73 \n","04/22/2023 04:39:53 PM - INFO - [58:14] loss\t23.63 =\tBCE 23.63004 \tLL 0.01913 \tTotal 293.15/58.87/2.82 \n","04/22/2023 04:39:53 PM - INFO - [58:15] loss\t23.72 =\tBCE 23.72379 \tLL 0.01914 \tTotal 282.15/89.36/2.35 \n","04/22/2023 04:39:54 PM - INFO - [58:16] loss\t23.06 =\tBCE 23.05794 \tLL 0.01902 \tTotal 323.07/59.19/3.76 \n","04/22/2023 04:39:54 PM - INFO - [58:17] loss\t23.14 =\tBCE 23.14398 \tLL 0.01851 \tTotal 350.99/65.93/4.88 \n","04/22/2023 04:39:55 PM - INFO - [58:18] loss\t23.36 =\tBCE 23.36276 \tLL 0.01939 \tTotal 138.43/55.85/2.98 \n","Not implemented\n","04/22/2023 04:39:55 PM - INFO - Training epoch 59.\n","04/22/2023 04:39:55 PM - INFO - [59:0] loss\t23.08 =\tBCE 23.08037 \tLL 0.01846 \tTotal 380.10/59.51/5.68 \n","04/22/2023 04:39:56 PM - INFO - [59:1] loss\t22.81 =\tBCE 22.81373 \tLL 0.01878 \tTotal 262.16/68.44/5.30 \n","04/22/2023 04:39:56 PM - INFO - [59:2] loss\t22.87 =\tBCE 22.87017 \tLL 0.01882 \tTotal 249.43/44.70/3.49 \n","04/22/2023 04:39:57 PM - INFO - [59:3] loss\t22.33 =\tBCE 22.33145 \tLL 0.01815 \tTotal 353.32/54.89/2.96 \n","04/22/2023 04:39:57 PM - INFO - [59:4] loss\t22.63 =\tBCE 22.63012 \tLL 0.01888 \tTotal 388.68/46.76/2.34 \n","04/22/2023 04:39:58 PM - INFO - [59:5] loss\t22.30 =\tBCE 22.30224 \tLL 0.01827 \tTotal 256.81/45.15/2.98 \n","04/22/2023 04:39:58 PM - INFO - [59:6] loss\t21.87 =\tBCE 21.86542 \tLL 0.01842 \tTotal 379.88/48.63/2.07 \n","04/22/2023 04:39:59 PM - INFO - [59:7] loss\t22.18 =\tBCE 22.17775 \tLL 0.01820 \tTotal 261.98/36.55/3.34 \n","04/22/2023 04:39:59 PM - INFO - [59:8] loss\t21.46 =\tBCE 21.46477 \tLL 0.01776 \tTotal 204.52/30.42/3.56 \n","04/22/2023 04:40:00 PM - INFO - [59:9] loss\t21.66 =\tBCE 21.65998 \tLL 0.01800 \tTotal 331.35/43.58/2.31 \n","04/22/2023 04:40:00 PM - INFO - [59:10] loss\t21.60 =\tBCE 21.59623 \tLL 0.01753 \tTotal 176.77/32.48/7.74 \n","04/22/2023 04:40:01 PM - INFO - [59:11] loss\t21.77 =\tBCE 21.76538 \tLL 0.01823 \tTotal 234.27/37.17/5.70 \n","04/22/2023 04:40:02 PM - INFO - [59:12] loss\t21.49 =\tBCE 21.49129 \tLL 0.01779 \tTotal 251.96/41.58/7.05 \n","04/22/2023 04:40:02 PM - INFO - [59:13] loss\t20.96 =\tBCE 20.95763 \tLL 0.01763 \tTotal 170.64/36.44/5.91 \n","04/22/2023 04:40:03 PM - INFO - [59:14] loss\t21.08 =\tBCE 21.07698 \tLL 0.01785 \tTotal 228.83/31.56/3.24 \n","04/22/2023 04:40:03 PM - INFO - [59:15] loss\t21.17 =\tBCE 21.17105 \tLL 0.01747 \tTotal 284.93/43.61/7.18 \n","04/22/2023 04:40:04 PM - INFO - [59:16] loss\t20.94 =\tBCE 20.93965 \tLL 0.01728 \tTotal 201.56/39.28/8.06 \n","04/22/2023 04:40:04 PM - INFO - [59:17] loss\t20.44 =\tBCE 20.43941 \tLL 0.01665 \tTotal 247.97/39.03/4.20 \n","04/22/2023 04:40:05 PM - INFO - [59:18] loss\t20.55 =\tBCE 20.55097 \tLL 0.01717 \tTotal 212.07/38.52/6.77 \n","04/22/2023 04:40:05 PM - INFO - EVALUATION prior to epoch [60]...\n","04/22/2023 04:40:05 PM - INFO - [60] loss\t18.52=\tBCE 18.52 \tLL 0.01612 \n","04/22/2023 04:40:07 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/60_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:40:12 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/60_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:40:16 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/60_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 04:40:17 PM - INFO - Training epoch 60.\n","04/22/2023 04:40:18 PM - INFO - [60:0] loss\t20.73 =\tBCE 20.72821 \tLL 0.01712 \tTotal 304.94/43.79/2.58 \n","04/22/2023 04:40:18 PM - INFO - [60:1] loss\t20.63 =\tBCE 20.62506 \tLL 0.01710 \tTotal 285.24/42.62/7.41 \n","04/22/2023 04:40:19 PM - INFO - [60:2] loss\t19.97 =\tBCE 19.97355 \tLL 0.01704 \tTotal 191.72/34.96/5.27 \n","04/22/2023 04:40:19 PM - INFO - [60:3] loss\t19.96 =\tBCE 19.95502 \tLL 0.01672 \tTotal 304.06/35.57/3.67 \n","04/22/2023 04:40:20 PM - INFO - [60:4] loss\t20.49 =\tBCE 20.48603 \tLL 0.01743 \tTotal 64.42/21.82/8.13 \n","04/22/2023 04:40:20 PM - INFO - [60:5] loss\t20.13 =\tBCE 20.13023 \tLL 0.01759 \tTotal 275.81/37.30/2.22 \n","04/22/2023 04:40:21 PM - INFO - [60:6] loss\t19.90 =\tBCE 19.89508 \tLL 0.01715 \tTotal 166.85/30.31/4.90 \n","04/22/2023 04:40:21 PM - INFO - [60:7] loss\t19.70 =\tBCE 19.70267 \tLL 0.01660 \tTotal 348.66/40.30/8.35 \n","04/22/2023 04:40:22 PM - INFO - [60:8] loss\t20.10 =\tBCE 20.09612 \tLL 0.01709 \tTotal 288.22/37.34/2.54 \n","04/22/2023 04:40:22 PM - INFO - [60:9] loss\t19.41 =\tBCE 19.40934 \tLL 0.01653 \tTotal 141.82/30.93/5.11 \n","04/22/2023 04:40:23 PM - INFO - [60:10] loss\t19.60 =\tBCE 19.60013 \tLL 0.01637 \tTotal 265.02/35.05/7.35 \n","04/22/2023 04:40:23 PM - INFO - [60:11] loss\t19.39 =\tBCE 19.38824 \tLL 0.01694 \tTotal 145.35/35.46/10.11 \n","04/22/2023 04:40:24 PM - INFO - [60:12] loss\t19.52 =\tBCE 19.51589 \tLL 0.01655 \tTotal 240.41/37.52/6.07 \n","04/22/2023 04:40:24 PM - INFO - [60:13] loss\t19.71 =\tBCE 19.70800 \tLL 0.01667 \tTotal 218.63/42.21/6.85 \n","04/22/2023 04:40:25 PM - INFO - [60:14] loss\t19.11 =\tBCE 19.10575 \tLL 0.01604 \tTotal 265.45/37.67/4.83 \n","04/22/2023 04:40:25 PM - INFO - [60:15] loss\t19.10 =\tBCE 19.09974 \tLL 0.01647 \tTotal 178.30/38.30/5.23 \n","04/22/2023 04:40:26 PM - INFO - [60:16] loss\t19.03 =\tBCE 19.02851 \tLL 0.01675 \tTotal 204.12/29.58/3.90 \n","04/22/2023 04:40:27 PM - INFO - [60:17] loss\t18.92 =\tBCE 18.92080 \tLL 0.01650 \tTotal 265.72/38.74/2.72 \n","04/22/2023 04:40:27 PM - INFO - [60:18] loss\t18.93 =\tBCE 18.92957 \tLL 0.01610 \tTotal 167.36/30.22/4.12 \n","04/22/2023 04:40:27 PM - INFO - Training epoch 61.\n","04/22/2023 04:40:28 PM - INFO - [61:0] loss\t18.84 =\tBCE 18.83575 \tLL 0.01623 \tTotal 231.35/33.38/2.90 \n","04/22/2023 04:40:28 PM - INFO - [61:1] loss\t18.63 =\tBCE 18.62661 \tLL 0.01624 \tTotal 112.33/26.32/10.91 \n","04/22/2023 04:40:29 PM - INFO - [61:2] loss\t18.69 =\tBCE 18.69220 \tLL 0.01653 \tTotal 173.43/35.20/7.63 \n","04/22/2023 04:40:29 PM - INFO - [61:3] loss\t18.57 =\tBCE 18.56992 \tLL 0.01584 \tTotal 156.92/29.90/4.73 \n","04/22/2023 04:40:30 PM - INFO - [61:4] loss\t18.10 =\tBCE 18.10313 \tLL 0.01537 \tTotal 78.28/32.71/9.62 \n","04/22/2023 04:40:30 PM - INFO - [61:5] loss\t18.25 =\tBCE 18.24593 \tLL 0.01569 \tTotal 159.40/25.74/10.92 \n","04/22/2023 04:40:31 PM - INFO - [61:6] loss\t18.28 =\tBCE 18.28072 \tLL 0.01561 \tTotal 176.21/33.73/4.66 \n","04/22/2023 04:40:31 PM - INFO - [61:7] loss\t18.48 =\tBCE 18.48122 \tLL 0.01602 \tTotal 162.80/26.08/3.56 \n","04/22/2023 04:40:32 PM - INFO - [61:8] loss\t18.26 =\tBCE 18.26252 \tLL 0.01583 \tTotal 153.46/46.96/10.46 \n","04/22/2023 04:40:32 PM - INFO - [61:9] loss\t18.23 =\tBCE 18.23154 \tLL 0.01570 \tTotal 143.37/42.20/5.65 \n","04/22/2023 04:40:33 PM - INFO - [61:10] loss\t18.24 =\tBCE 18.24213 \tLL 0.01606 \tTotal 198.81/29.84/4.42 \n","04/22/2023 04:40:33 PM - INFO - [61:11] loss\t17.77 =\tBCE 17.77333 \tLL 0.01534 \tTotal 190.85/40.30/4.24 \n","04/22/2023 04:40:34 PM - INFO - [61:12] loss\t17.85 =\tBCE 17.85219 \tLL 0.01558 \tTotal 110.30/28.17/6.15 \n","04/22/2023 04:40:35 PM - INFO - [61:13] loss\t18.11 =\tBCE 18.11402 \tLL 0.01604 \tTotal 242.95/33.49/6.91 \n","04/22/2023 04:40:35 PM - INFO - [61:14] loss\t17.99 =\tBCE 17.98965 \tLL 0.01587 \tTotal 227.13/43.59/4.25 \n","04/22/2023 04:40:36 PM - INFO - [61:15] loss\t17.64 =\tBCE 17.63557 \tLL 0.01542 \tTotal 122.70/37.07/4.13 \n","04/22/2023 04:40:36 PM - INFO - [61:16] loss\t17.78 =\tBCE 17.78206 \tLL 0.01600 \tTotal 172.30/35.86/3.91 \n","04/22/2023 04:40:37 PM - INFO - [61:17] loss\t17.58 =\tBCE 17.57867 \tLL 0.01527 \tTotal 157.09/54.24/1.47 \n","04/22/2023 04:40:37 PM - INFO - [61:18] loss\t17.53 =\tBCE 17.52691 \tLL 0.01542 \tTotal 153.86/26.80/6.51 \n","04/22/2023 04:40:37 PM - INFO - Training epoch 62.\n","04/22/2023 04:40:38 PM - INFO - [62:0] loss\t17.08 =\tBCE 17.08342 \tLL 0.01476 \tTotal 136.04/48.89/2.18 \n","04/22/2023 04:40:38 PM - INFO - [62:1] loss\t17.42 =\tBCE 17.41960 \tLL 0.01529 \tTotal 156.28/27.55/1.88 \n","04/22/2023 04:40:39 PM - INFO - [62:2] loss\t17.52 =\tBCE 17.51982 \tLL 0.01539 \tTotal 162.98/43.78/5.58 \n","04/22/2023 04:40:39 PM - INFO - [62:3] loss\t17.49 =\tBCE 17.49078 \tLL 0.01566 \tTotal 155.76/34.43/2.08 \n","04/22/2023 04:40:40 PM - INFO - [62:4] loss\t17.38 =\tBCE 17.38308 \tLL 0.01552 \tTotal 185.55/44.76/0.98 \n","04/22/2023 04:40:40 PM - INFO - [62:5] loss\t17.12 =\tBCE 17.12264 \tLL 0.01485 \tTotal 112.68/25.15/1.49 \n","04/22/2023 04:40:41 PM - INFO - [62:6] loss\t16.98 =\tBCE 16.97744 \tLL 0.01496 \tTotal 202.94/56.20/3.94 \n","04/22/2023 04:40:41 PM - INFO - [62:7] loss\t16.99 =\tBCE 16.99269 \tLL 0.01483 \tTotal 145.21/24.91/3.15 \n","04/22/2023 04:40:42 PM - INFO - [62:8] loss\t16.92 =\tBCE 16.91597 \tLL 0.01491 \tTotal 164.16/54.51/4.08 \n","04/22/2023 04:40:43 PM - INFO - [62:9] loss\t17.16 =\tBCE 17.15655 \tLL 0.01529 \tTotal 165.17/33.00/3.40 \n","04/22/2023 04:40:43 PM - INFO - [62:10] loss\t16.81 =\tBCE 16.80978 \tLL 0.01462 \tTotal 214.69/54.31/3.18 \n","04/22/2023 04:40:44 PM - INFO - [62:11] loss\t16.78 =\tBCE 16.77819 \tLL 0.01487 \tTotal 194.97/26.88/2.66 \n","04/22/2023 04:40:44 PM - INFO - [62:12] loss\t16.76 =\tBCE 16.75895 \tLL 0.01490 \tTotal 162.69/37.35/7.15 \n","04/22/2023 04:40:45 PM - INFO - [62:13] loss\t16.84 =\tBCE 16.84321 \tLL 0.01533 \tTotal 138.07/22.10/3.61 \n","04/22/2023 04:40:45 PM - INFO - [62:14] loss\t16.44 =\tBCE 16.43711 \tLL 0.01455 \tTotal 199.66/35.01/5.12 \n","04/22/2023 04:40:46 PM - INFO - [62:15] loss\t16.44 =\tBCE 16.43698 \tLL 0.01473 \tTotal 193.18/39.24/4.84 \n","04/22/2023 04:40:46 PM - INFO - [62:16] loss\t16.70 =\tBCE 16.70451 \tLL 0.01487 \tTotal 112.37/32.44/4.93 \n","04/22/2023 04:40:47 PM - INFO - [62:17] loss\t16.43 =\tBCE 16.43234 \tLL 0.01453 \tTotal 164.04/32.86/5.03 \n","04/22/2023 04:40:47 PM - INFO - [62:18] loss\t16.50 =\tBCE 16.49922 \tLL 0.01459 \tTotal 137.51/48.65/3.45 \n","04/22/2023 04:40:47 PM - INFO - Training epoch 63.\n","04/22/2023 04:40:48 PM - INFO - [63:0] loss\t16.17 =\tBCE 16.16974 \tLL 0.01436 \tTotal 116.07/22.34/4.03 \n","04/22/2023 04:40:49 PM - INFO - [63:1] loss\t16.34 =\tBCE 16.33772 \tLL 0.01449 \tTotal 97.69/26.13/2.60 \n","04/22/2023 04:40:49 PM - INFO - [63:2] loss\t16.30 =\tBCE 16.30047 \tLL 0.01451 \tTotal 108.02/23.60/2.63 \n","04/22/2023 04:40:50 PM - INFO - [63:3] loss\t16.13 =\tBCE 16.12792 \tLL 0.01442 \tTotal 97.84/28.99/3.40 \n","04/22/2023 04:40:50 PM - INFO - [63:4] loss\t15.83 =\tBCE 15.83079 \tLL 0.01436 \tTotal 249.07/36.24/2.47 \n","04/22/2023 04:40:51 PM - INFO - [63:5] loss\t16.20 =\tBCE 16.19839 \tLL 0.01436 \tTotal 223.39/36.28/2.16 \n","04/22/2023 04:40:51 PM - INFO - [63:6] loss\t15.90 =\tBCE 15.90108 \tLL 0.01425 \tTotal 339.92/39.18/5.57 \n","04/22/2023 04:40:52 PM - INFO - [63:7] loss\t16.10 =\tBCE 16.09908 \tLL 0.01442 \tTotal 249.26/33.26/7.63 \n","04/22/2023 04:40:52 PM - INFO - [63:8] loss\t15.96 =\tBCE 15.96494 \tLL 0.01407 \tTotal 325.33/42.68/3.74 \n","04/22/2023 04:40:53 PM - INFO - [63:9] loss\t16.36 =\tBCE 16.36034 \tLL 0.01496 \tTotal 233.23/33.14/2.04 \n","04/22/2023 04:40:53 PM - INFO - [63:10] loss\t15.79 =\tBCE 15.79262 \tLL 0.01390 \tTotal 323.99/62.79/2.08 \n","04/22/2023 04:40:54 PM - INFO - [63:11] loss\t16.01 =\tBCE 16.01252 \tLL 0.01457 \tTotal 291.68/57.27/5.45 \n","04/22/2023 04:40:54 PM - INFO - [63:12] loss\t15.84 =\tBCE 15.83828 \tLL 0.01409 \tTotal 317.19/50.74/5.63 \n","04/22/2023 04:40:55 PM - INFO - [63:13] loss\t15.71 =\tBCE 15.71099 \tLL 0.01459 \tTotal 153.27/33.78/4.54 \n","04/22/2023 04:40:55 PM - INFO - [63:14] loss\t15.65 =\tBCE 15.64550 \tLL 0.01430 \tTotal 199.69/27.55/5.26 \n","04/22/2023 04:40:56 PM - INFO - [63:15] loss\t15.82 =\tBCE 15.81680 \tLL 0.01413 \tTotal 160.79/29.98/8.83 \n","04/22/2023 04:40:57 PM - INFO - [63:16] loss\t15.66 =\tBCE 15.65829 \tLL 0.01440 \tTotal 248.90/31.36/8.66 \n","04/22/2023 04:40:57 PM - INFO - [63:17] loss\t15.54 =\tBCE 15.54005 \tLL 0.01380 \tTotal 209.53/56.20/8.73 \n","04/22/2023 04:40:58 PM - INFO - [63:18] loss\t15.55 =\tBCE 15.54685 \tLL 0.01372 \tTotal 215.93/29.12/6.67 \n","04/22/2023 04:40:58 PM - INFO - Training epoch 64.\n","04/22/2023 04:40:58 PM - INFO - [64:0] loss\t15.21 =\tBCE 15.20675 \tLL 0.01380 \tTotal 262.59/63.26/7.58 \n","04/22/2023 04:40:59 PM - INFO - [64:1] loss\t15.41 =\tBCE 15.41032 \tLL 0.01367 \tTotal 429.79/101.37/6.85 \n","04/22/2023 04:40:59 PM - INFO - [64:2] loss\t15.28 =\tBCE 15.28231 \tLL 0.01377 \tTotal 288.44/61.63/9.64 \n","04/22/2023 04:41:00 PM - INFO - [64:3] loss\t15.48 =\tBCE 15.48374 \tLL 0.01408 \tTotal 213.62/45.08/2.91 \n","04/22/2023 04:41:00 PM - INFO - [64:4] loss\t15.44 =\tBCE 15.43550 \tLL 0.01401 \tTotal 456.33/106.96/2.65 \n","04/22/2023 04:41:01 PM - INFO - [64:5] loss\t15.36 =\tBCE 15.35620 \tLL 0.01383 \tTotal 586.31/76.14/3.18 \n","04/22/2023 04:41:01 PM - INFO - [64:6] loss\t15.41 =\tBCE 15.40738 \tLL 0.01392 \tTotal 327.19/46.39/9.11 \n","04/22/2023 04:41:02 PM - INFO - [64:7] loss\t15.23 =\tBCE 15.22546 \tLL 0.01364 \tTotal 420.12/77.82/4.99 \n","04/22/2023 04:41:02 PM - INFO - [64:8] loss\t15.11 =\tBCE 15.10967 \tLL 0.01377 \tTotal 596.41/86.34/2.94 \n","04/22/2023 04:41:03 PM - INFO - [64:9] loss\t14.96 =\tBCE 14.96355 \tLL 0.01378 \tTotal 278.33/44.54/3.34 \n","04/22/2023 04:41:03 PM - INFO - [64:10] loss\t15.11 =\tBCE 15.11392 \tLL 0.01359 \tTotal 369.56/48.66/3.62 \n","04/22/2023 04:41:04 PM - INFO - [64:11] loss\t15.14 =\tBCE 15.14450 \tLL 0.01382 \tTotal 552.60/85.29/9.92 \n","04/22/2023 04:41:05 PM - INFO - [64:12] loss\t15.02 =\tBCE 15.02125 \tLL 0.01373 \tTotal 218.36/72.10/2.37 \n","04/22/2023 04:41:05 PM - INFO - [64:13] loss\t14.96 =\tBCE 14.96441 \tLL 0.01329 \tTotal 437.98/52.62/3.75 \n","04/22/2023 04:41:06 PM - INFO - [64:14] loss\t15.20 =\tBCE 15.19719 \tLL 0.01399 \tTotal 650.56/107.43/3.84 \n","04/22/2023 04:41:06 PM - INFO - [64:15] loss\t15.04 =\tBCE 15.03990 \tLL 0.01348 \tTotal 539.95/109.08/9.04 \n","04/22/2023 04:41:07 PM - INFO - [64:16] loss\t14.98 =\tBCE 14.98491 \tLL 0.01352 \tTotal 235.75/40.35/3.67 \n","04/22/2023 04:41:07 PM - INFO - [64:17] loss\t14.84 =\tBCE 14.84112 \tLL 0.01353 \tTotal 185.62/41.26/1.33 \n","04/22/2023 04:41:08 PM - INFO - [64:18] loss\t14.76 =\tBCE 14.75900 \tLL 0.01382 \tTotal 243.61/54.39/5.15 \n","04/22/2023 04:41:08 PM - INFO - Training epoch 65.\n","04/22/2023 04:41:08 PM - INFO - [65:0] loss\t14.81 =\tBCE 14.81124 \tLL 0.01335 \tTotal 418.95/54.25/4.58 \n","04/22/2023 04:41:09 PM - INFO - [65:1] loss\t14.49 =\tBCE 14.49115 \tLL 0.01309 \tTotal 245.50/35.58/3.76 \n","04/22/2023 04:41:09 PM - INFO - [65:2] loss\t14.62 =\tBCE 14.61837 \tLL 0.01348 \tTotal 177.27/36.29/1.42 \n","04/22/2023 04:41:10 PM - INFO - [65:3] loss\t14.61 =\tBCE 14.60544 \tLL 0.01298 \tTotal 408.11/72.91/7.15 \n","04/22/2023 04:41:10 PM - INFO - [65:4] loss\t14.38 =\tBCE 14.38266 \tLL 0.01323 \tTotal 457.99/91.24/2.20 \n","04/22/2023 04:41:11 PM - INFO - [65:5] loss\t14.89 =\tBCE 14.88571 \tLL 0.01381 \tTotal 383.59/77.70/4.62 \n","04/22/2023 04:41:11 PM - INFO - [65:6] loss\t14.80 =\tBCE 14.79865 \tLL 0.01376 \tTotal 414.14/45.30/1.38 \n","04/22/2023 04:41:12 PM - INFO - [65:7] loss\t14.44 =\tBCE 14.43602 \tLL 0.01311 \tTotal 367.49/66.31/5.70 \n","04/22/2023 04:41:12 PM - INFO - [65:8] loss\t14.60 =\tBCE 14.60402 \tLL 0.01369 \tTotal 366.15/69.16/3.43 \n","04/22/2023 04:41:13 PM - INFO - [65:9] loss\t14.46 =\tBCE 14.46211 \tLL 0.01358 \tTotal 421.67/58.13/2.97 \n","04/22/2023 04:41:13 PM - INFO - [65:10] loss\t14.33 =\tBCE 14.32792 \tLL 0.01326 \tTotal 229.04/32.27/4.55 \n","04/22/2023 04:41:14 PM - INFO - [65:11] loss\t14.45 =\tBCE 14.44591 \tLL 0.01322 \tTotal 381.87/48.51/4.86 \n","04/22/2023 04:41:14 PM - INFO - [65:12] loss\t14.27 =\tBCE 14.27218 \tLL 0.01327 \tTotal 415.01/84.42/2.49 \n","04/22/2023 04:41:15 PM - INFO - [65:13] loss\t14.35 =\tBCE 14.34855 \tLL 0.01286 \tTotal 356.39/106.35/4.10 \n","04/22/2023 04:41:16 PM - INFO - [65:14] loss\t14.12 =\tBCE 14.11855 \tLL 0.01280 \tTotal 585.27/91.97/5.96 \n","04/22/2023 04:41:16 PM - INFO - [65:15] loss\t14.20 =\tBCE 14.19727 \tLL 0.01304 \tTotal 620.99/70.91/1.67 \n","04/22/2023 04:41:17 PM - INFO - [65:16] loss\t14.31 =\tBCE 14.30781 \tLL 0.01330 \tTotal 458.98/90.78/2.85 \n","04/22/2023 04:41:17 PM - INFO - [65:17] loss\t14.28 =\tBCE 14.27925 \tLL 0.01309 \tTotal 459.56/111.19/2.47 \n","04/22/2023 04:41:18 PM - INFO - [65:18] loss\t14.11 =\tBCE 14.10799 \tLL 0.01271 \tTotal 637.93/110.11/5.23 \n","04/22/2023 04:41:18 PM - INFO - Training epoch 66.\n","04/22/2023 04:41:18 PM - INFO - [66:0] loss\t13.78 =\tBCE 13.78357 \tLL 0.01249 \tTotal 672.34/82.47/4.76 \n","04/22/2023 04:41:19 PM - INFO - [66:1] loss\t13.97 =\tBCE 13.97073 \tLL 0.01243 \tTotal 461.82/63.09/3.58 \n","04/22/2023 04:41:19 PM - INFO - [66:2] loss\t14.25 =\tBCE 14.25319 \tLL 0.01355 \tTotal 346.06/54.91/5.72 \n","04/22/2023 04:41:20 PM - INFO - [66:3] loss\t14.24 =\tBCE 14.23956 \tLL 0.01308 \tTotal 396.87/64.35/3.16 \n","04/22/2023 04:41:20 PM - INFO - [66:4] loss\t14.07 =\tBCE 14.07333 \tLL 0.01323 \tTotal 349.82/53.56/4.67 \n","04/22/2023 04:41:21 PM - INFO - [66:5] loss\t13.77 =\tBCE 13.76761 \tLL 0.01302 \tTotal 424.04/47.88/1.88 \n","04/22/2023 04:41:21 PM - INFO - [66:6] loss\t13.86 =\tBCE 13.86432 \tLL 0.01287 \tTotal 450.55/57.76/4.30 \n","04/22/2023 04:41:22 PM - INFO - [66:7] loss\t13.75 =\tBCE 13.75344 \tLL 0.01275 \tTotal 400.67/61.93/3.36 \n","04/22/2023 04:41:22 PM - INFO - [66:8] loss\t13.97 =\tBCE 13.97270 \tLL 0.01299 \tTotal 475.12/87.47/2.89 \n","04/22/2023 04:41:23 PM - INFO - [66:9] loss\t14.02 =\tBCE 14.02326 \tLL 0.01311 \tTotal 518.15/76.73/5.39 \n","04/22/2023 04:41:24 PM - INFO - [66:10] loss\t13.86 =\tBCE 13.86371 \tLL 0.01275 \tTotal 402.17/49.29/3.59 \n","04/22/2023 04:41:24 PM - INFO - [66:11] loss\t13.90 =\tBCE 13.89519 \tLL 0.01293 \tTotal 211.14/30.14/2.74 \n","04/22/2023 04:41:25 PM - INFO - [66:12] loss\t13.68 =\tBCE 13.68161 \tLL 0.01273 \tTotal 368.80/49.50/3.59 \n","04/22/2023 04:41:25 PM - INFO - [66:13] loss\t13.78 =\tBCE 13.78150 \tLL 0.01293 \tTotal 443.00/61.95/10.90 \n","04/22/2023 04:41:26 PM - INFO - [66:14] loss\t13.86 =\tBCE 13.86218 \tLL 0.01267 \tTotal 414.67/90.06/2.79 \n","04/22/2023 04:41:26 PM - INFO - [66:15] loss\t13.61 =\tBCE 13.60671 \tLL 0.01264 \tTotal 425.80/79.76/1.80 \n","04/22/2023 04:41:27 PM - INFO - [66:16] loss\t13.67 =\tBCE 13.66895 \tLL 0.01264 \tTotal 391.70/44.94/4.45 \n","04/22/2023 04:41:27 PM - INFO - [66:17] loss\t13.27 =\tBCE 13.27015 \tLL 0.01250 \tTotal 174.53/46.02/3.32 \n","04/22/2023 04:41:28 PM - INFO - [66:18] loss\t13.59 =\tBCE 13.59456 \tLL 0.01242 \tTotal 290.73/58.47/5.36 \n","04/22/2023 04:41:28 PM - INFO - Training epoch 67.\n","04/22/2023 04:41:28 PM - INFO - [67:0] loss\t13.65 =\tBCE 13.64802 \tLL 0.01262 \tTotal 274.78/57.12/2.51 \n","04/22/2023 04:41:29 PM - INFO - [67:1] loss\t13.39 =\tBCE 13.38544 \tLL 0.01262 \tTotal 389.42/63.73/3.09 \n","04/22/2023 04:41:29 PM - INFO - [67:2] loss\t13.63 =\tBCE 13.63400 \tLL 0.01298 \tTotal 625.84/72.36/8.17 \n","04/22/2023 04:41:30 PM - INFO - [67:3] loss\t13.57 =\tBCE 13.56740 \tLL 0.01245 \tTotal 883.59/90.84/1.53 \n","04/22/2023 04:41:30 PM - INFO - [67:4] loss\t13.55 =\tBCE 13.54675 \tLL 0.01264 \tTotal 917.91/94.57/5.53 \n","04/22/2023 04:41:31 PM - INFO - [67:5] loss\t13.71 =\tBCE 13.70970 \tLL 0.01282 \tTotal 676.38/86.03/2.76 \n","04/22/2023 04:41:31 PM - INFO - [67:6] loss\t13.47 =\tBCE 13.47044 \tLL 0.01250 \tTotal 387.87/64.22/6.40 \n","04/22/2023 04:41:32 PM - INFO - [67:7] loss\t13.34 =\tBCE 13.33816 \tLL 0.01263 \tTotal 329.91/69.02/5.08 \n","04/22/2023 04:41:32 PM - INFO - [67:8] loss\t13.40 =\tBCE 13.40084 \tLL 0.01231 \tTotal 610.08/93.56/2.46 \n","04/22/2023 04:41:33 PM - INFO - [67:9] loss\t13.54 =\tBCE 13.54437 \tLL 0.01251 \tTotal 862.61/123.47/3.62 \n","04/22/2023 04:41:34 PM - INFO - [67:10] loss\t13.58 =\tBCE 13.58356 \tLL 0.01270 \tTotal 958.88/172.98/6.65 \n","04/22/2023 04:41:34 PM - INFO - [67:11] loss\t13.57 =\tBCE 13.57165 \tLL 0.01234 \tTotal 1082.66/242.88/4.89 \n","04/22/2023 04:41:35 PM - INFO - [67:12] loss\t13.88 =\tBCE 13.88094 \tLL 0.01239 \tTotal 1263.36/335.90/4.04 \n","04/22/2023 04:41:35 PM - INFO - [67:13] loss\t14.72 =\tBCE 14.72060 \tLL 0.01255 \tTotal 1833.68/476.33/1.04 \n","04/22/2023 04:41:36 PM - INFO - [67:14] loss\t17.35 =\tBCE 17.35054 \tLL 0.01197 \tTotal 3205.43/781.81/4.97 \n","04/22/2023 04:41:36 PM - INFO - [67:15] loss\t25.99 =\tBCE 25.98508 \tLL 0.01234 \tTotal 5812.19/1313.67/1.86 \n","04/22/2023 04:41:37 PM - INFO - [67:16] loss\t49.22 =\tBCE 49.22390 \tLL 0.01233 \tTotal 10657.15/2232.95/1.25 \n","04/22/2023 04:41:37 PM - INFO - [67:17] loss\t129.86 =\tBCE 129.86113 \tLL 0.01225 \tTotal 17148.24/3497.74/5.79 \n","04/22/2023 04:41:38 PM - INFO - [67:18] loss\t187.81 =\tBCE 187.80695 \tLL 0.01291 \tTotal 25406.03/4575.23/5.26 \n","04/22/2023 04:41:38 PM - INFO - Training epoch 68.\n","04/22/2023 04:41:38 PM - INFO - [68:0] loss\t376.79 =\tBCE 376.79385 \tLL 0.01368 \tTotal 28832.50/4673.50/5.81 \n","04/22/2023 04:41:39 PM - INFO - [68:1] loss\t115.88 =\tBCE 115.88219 \tLL 0.01389 \tTotal 22476.09/2550.63/9.07 \n","04/22/2023 04:41:39 PM - INFO - [68:2] loss\t65.73 =\tBCE 65.72520 \tLL 0.01363 \tTotal 14260.89/2355.20/3.43 \n","04/22/2023 04:41:40 PM - INFO - [68:3] loss\t180.72 =\tBCE 180.71732 \tLL 0.01532 \tTotal 20749.18/3265.03/1.61 \n","04/22/2023 04:41:40 PM - INFO - [68:4] loss\t75.23 =\tBCE 75.23332 \tLL 0.01458 \tTotal 15500.39/1560.88/2.83 \n","04/22/2023 04:41:41 PM - INFO - [68:5] loss\t59.49 =\tBCE 59.49389 \tLL 0.01460 \tTotal 7020.70/1962.68/4.72 \n","04/22/2023 04:41:41 PM - INFO - [68:6] loss\t71.97 =\tBCE 71.96702 \tLL 0.01616 \tTotal 12797.10/1787.89/3.15 \n","04/22/2023 04:41:42 PM - INFO - [68:7] loss\t63.20 =\tBCE 63.20118 \tLL 0.01843 \tTotal 9706.66/1247.47/2.56 \n","04/22/2023 04:41:42 PM - INFO - [68:8] loss\t45.91 =\tBCE 45.91406 \tLL 0.01737 \tTotal 8618.67/1134.61/3.39 \n","04/22/2023 04:41:43 PM - INFO - [68:9] loss\t52.42 =\tBCE 52.41653 \tLL 0.01697 \tTotal 8807.76/1268.20/6.32 \n","04/22/2023 04:41:43 PM - INFO - [68:10] loss\t41.52 =\tBCE 41.51604 \tLL 0.01791 \tTotal 6179.88/1167.81/7.66 \n","04/22/2023 04:41:44 PM - INFO - [68:11] loss\t47.56 =\tBCE 47.56345 \tLL 0.01854 \tTotal 7489.89/1002.25/7.74 \n","04/22/2023 04:41:45 PM - INFO - [68:12] loss\t40.03 =\tBCE 40.03437 \tLL 0.01813 \tTotal 6225.74/1097.17/3.85 \n","04/22/2023 04:41:45 PM - INFO - [68:13] loss\t40.16 =\tBCE 40.15934 \tLL 0.01750 \tTotal 6418.00/806.07/3.29 \n","04/22/2023 04:41:46 PM - INFO - [68:14] loss\t29.63 =\tBCE 29.62926 \tLL 0.01791 \tTotal 4076.50/737.64/3.62 \n","04/22/2023 04:41:46 PM - INFO - [68:15] loss\t40.49 =\tBCE 40.49081 \tLL 0.01881 \tTotal 6790.21/781.75/4.70 \n","04/22/2023 04:41:47 PM - INFO - [68:16] loss\t27.54 =\tBCE 27.53713 \tLL 0.01897 \tTotal 3227.83/506.92/6.61 \n","04/22/2023 04:41:47 PM - INFO - [68:17] loss\t35.69 =\tBCE 35.69293 \tLL 0.01797 \tTotal 5676.38/664.90/5.15 \n","04/22/2023 04:41:48 PM - INFO - [68:18] loss\t25.37 =\tBCE 25.36882 \tLL 0.01812 \tTotal 3831.50/407.17/4.76 \n","Not implemented\n","04/22/2023 04:41:48 PM - INFO - Training epoch 69.\n","04/22/2023 04:41:48 PM - INFO - [69:0] loss\t31.33 =\tBCE 31.33376 \tLL 0.01904 \tTotal 4478.45/505.35/2.90 \n","04/22/2023 04:41:49 PM - INFO - [69:1] loss\t26.81 =\tBCE 26.80813 \tLL 0.01924 \tTotal 3924.86/381.58/8.63 \n","04/22/2023 04:41:49 PM - INFO - [69:2] loss\t25.48 =\tBCE 25.48171 \tLL 0.01844 \tTotal 3107.56/364.72/4.97 \n","04/22/2023 04:41:50 PM - INFO - [69:3] loss\t28.50 =\tBCE 28.49867 \tLL 0.01881 \tTotal 4609.42/489.56/5.13 \n","04/22/2023 04:41:50 PM - INFO - [69:4] loss\t25.57 =\tBCE 25.56772 \tLL 0.01922 \tTotal 3087.49/516.46/12.86 \n","04/22/2023 04:41:51 PM - INFO - [69:5] loss\t25.61 =\tBCE 25.60950 \tLL 0.01855 \tTotal 3390.58/371.43/4.31 \n","04/22/2023 04:41:51 PM - INFO - [69:6] loss\t26.33 =\tBCE 26.32677 \tLL 0.01808 \tTotal 2672.37/687.37/4.42 \n","04/22/2023 04:41:52 PM - INFO - [69:7] loss\t23.03 =\tBCE 23.02522 \tLL 0.01908 \tTotal 2312.66/238.75/10.68 \n","04/22/2023 04:41:52 PM - INFO - [69:8] loss\t26.82 =\tBCE 26.81523 \tLL 0.01921 \tTotal 2583.28/636.73/3.62 \n","04/22/2023 04:41:53 PM - INFO - [69:9] loss\t20.81 =\tBCE 20.80691 \tLL 0.01889 \tTotal 1362.81/238.37/1.65 \n","04/22/2023 04:41:53 PM - INFO - [69:10] loss\t24.38 =\tBCE 24.38299 \tLL 0.01763 \tTotal 2163.97/544.19/5.16 \n","04/22/2023 04:41:54 PM - INFO - [69:11] loss\t21.79 =\tBCE 21.79291 \tLL 0.01724 \tTotal 1441.58/377.04/9.54 \n","04/22/2023 04:41:55 PM - INFO - [69:12] loss\t21.62 =\tBCE 21.62374 \tLL 0.01805 \tTotal 1488.39/366.99/4.32 \n","04/22/2023 04:41:55 PM - INFO - [69:13] loss\t22.91 =\tBCE 22.90642 \tLL 0.01804 \tTotal 1608.89/514.33/3.52 \n","04/22/2023 04:41:56 PM - INFO - [69:14] loss\t19.48 =\tBCE 19.47578 \tLL 0.01764 \tTotal 921.91/196.28/6.45 \n","04/22/2023 04:41:56 PM - INFO - [69:15] loss\t21.84 =\tBCE 21.84066 \tLL 0.01740 \tTotal 1416.01/474.53/6.32 \n","04/22/2023 04:41:57 PM - INFO - [69:16] loss\t19.53 =\tBCE 19.52582 \tLL 0.01715 \tTotal 1346.51/149.27/7.63 \n","04/22/2023 04:41:57 PM - INFO - [69:17] loss\t20.22 =\tBCE 20.21690 \tLL 0.01748 \tTotal 977.83/359.19/3.95 \n","04/22/2023 04:41:58 PM - INFO - [69:18] loss\t19.94 =\tBCE 19.94082 \tLL 0.01758 \tTotal 1519.33/170.08/4.69 \n","04/22/2023 04:41:58 PM - INFO - EVALUATION prior to epoch [70]...\n","04/22/2023 04:41:58 PM - INFO - [70] loss\t19.48=\tBCE 19.48 \tLL 0.01563 \n","04/22/2023 04:41:59 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/70_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:42:05 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/70_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:42:10 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/70_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 04:42:11 PM - INFO - Training epoch 70.\n","04/22/2023 04:42:11 PM - INFO - [70:0] loss\t19.88 =\tBCE 19.87567 \tLL 0.01671 \tTotal 1292.71/257.79/11.21 \n","04/22/2023 04:42:12 PM - INFO - [70:1] loss\t20.01 =\tBCE 20.01037 \tLL 0.01754 \tTotal 1619.78/188.98/5.81 \n","04/22/2023 04:42:12 PM - INFO - [70:2] loss\t19.40 =\tBCE 19.39778 \tLL 0.01674 \tTotal 1524.58/206.37/4.77 \n","04/22/2023 04:42:13 PM - INFO - [70:3] loss\t18.82 =\tBCE 18.82368 \tLL 0.01689 \tTotal 1166.66/127.61/4.91 \n","04/22/2023 04:42:13 PM - INFO - [70:4] loss\t19.38 =\tBCE 19.38470 \tLL 0.01678 \tTotal 1662.80/179.24/8.00 \n","04/22/2023 04:42:14 PM - INFO - [70:5] loss\t18.54 =\tBCE 18.53905 \tLL 0.01680 \tTotal 942.91/128.65/10.14 \n","04/22/2023 04:42:14 PM - INFO - [70:6] loss\t18.50 =\tBCE 18.49522 \tLL 0.01671 \tTotal 1335.75/135.98/7.76 \n","04/22/2023 04:42:15 PM - INFO - [70:7] loss\t18.53 =\tBCE 18.52781 \tLL 0.01618 \tTotal 1049.04/135.37/3.40 \n","04/22/2023 04:42:15 PM - INFO - [70:8] loss\t18.18 =\tBCE 18.17883 \tLL 0.01578 \tTotal 1117.42/131.85/6.76 \n","04/22/2023 04:42:16 PM - INFO - [70:9] loss\t18.38 =\tBCE 18.37902 \tLL 0.01661 \tTotal 1135.35/142.10/4.91 \n","04/22/2023 04:42:16 PM - INFO - [70:10] loss\t17.84 =\tBCE 17.83532 \tLL 0.01600 \tTotal 966.01/118.62/4.08 \n","04/22/2023 04:42:17 PM - INFO - [70:11] loss\t17.71 =\tBCE 17.70687 \tLL 0.01596 \tTotal 869.60/121.19/4.81 \n","04/22/2023 04:42:17 PM - INFO - [70:12] loss\t17.91 =\tBCE 17.91063 \tLL 0.01578 \tTotal 863.05/118.52/2.52 \n","04/22/2023 04:42:18 PM - INFO - [70:13] loss\t17.77 =\tBCE 17.76897 \tLL 0.01568 \tTotal 916.22/111.79/8.07 \n","04/22/2023 04:42:19 PM - INFO - [70:14] loss\t17.83 =\tBCE 17.82925 \tLL 0.01655 \tTotal 662.98/111.56/8.07 \n","04/22/2023 04:42:19 PM - INFO - [70:15] loss\t18.16 =\tBCE 18.16407 \tLL 0.01626 \tTotal 980.20/108.19/2.66 \n","04/22/2023 04:42:20 PM - INFO - [70:16] loss\t17.39 =\tBCE 17.38521 \tLL 0.01540 \tTotal 577.02/91.76/3.35 \n","04/22/2023 04:42:20 PM - INFO - [70:17] loss\t17.47 =\tBCE 17.46694 \tLL 0.01544 \tTotal 1097.06/122.62/2.33 \n","04/22/2023 04:42:21 PM - INFO - [70:18] loss\t17.01 =\tBCE 17.00958 \tLL 0.01552 \tTotal 473.38/71.39/4.60 \n","04/22/2023 04:42:21 PM - INFO - Training epoch 71.\n","04/22/2023 04:42:21 PM - INFO - [71:0] loss\t17.36 =\tBCE 17.36130 \tLL 0.01568 \tTotal 950.31/113.63/2.37 \n","04/22/2023 04:42:22 PM - INFO - [71:1] loss\t16.69 =\tBCE 16.68685 \tLL 0.01523 \tTotal 531.19/66.05/4.42 \n","04/22/2023 04:42:22 PM - INFO - [71:2] loss\t17.04 =\tBCE 17.04446 \tLL 0.01511 \tTotal 817.01/107.54/2.50 \n","04/22/2023 04:42:23 PM - INFO - [71:3] loss\t16.51 =\tBCE 16.50591 \tLL 0.01518 \tTotal 522.45/75.04/2.41 \n","04/22/2023 04:42:23 PM - INFO - [71:4] loss\t16.72 =\tBCE 16.71770 \tLL 0.01504 \tTotal 766.22/106.50/2.43 \n","04/22/2023 04:42:24 PM - INFO - [71:5] loss\t16.18 =\tBCE 16.17785 \tLL 0.01487 \tTotal 326.90/47.77/5.89 \n","04/22/2023 04:42:24 PM - INFO - [71:6] loss\t16.67 =\tBCE 16.66534 \tLL 0.01516 \tTotal 772.49/106.22/3.42 \n","04/22/2023 04:42:25 PM - INFO - [71:7] loss\t16.59 =\tBCE 16.58625 \tLL 0.01517 \tTotal 314.21/42.42/2.80 \n","04/22/2023 04:42:25 PM - INFO - [71:8] loss\t16.50 =\tBCE 16.49940 \tLL 0.01512 \tTotal 666.93/96.91/9.98 \n","04/22/2023 04:42:26 PM - INFO - [71:9] loss\t16.60 =\tBCE 16.59835 \tLL 0.01516 \tTotal 334.99/44.10/3.88 \n","04/22/2023 04:42:26 PM - INFO - [71:10] loss\t16.38 =\tBCE 16.37774 \tLL 0.01492 \tTotal 736.26/89.86/4.99 \n","04/22/2023 04:42:27 PM - INFO - [71:11] loss\t16.10 =\tBCE 16.09754 \tLL 0.01475 \tTotal 501.81/56.49/4.58 \n","04/22/2023 04:42:27 PM - INFO - [71:12] loss\t16.16 =\tBCE 16.15569 \tLL 0.01486 \tTotal 627.27/64.48/5.83 \n","04/22/2023 04:42:28 PM - INFO - [71:13] loss\t16.07 =\tBCE 16.06852 \tLL 0.01474 \tTotal 482.42/55.89/2.34 \n","04/22/2023 04:42:29 PM - INFO - [71:14] loss\t15.87 =\tBCE 15.86899 \tLL 0.01424 \tTotal 522.75/59.79/4.29 \n","04/22/2023 04:42:29 PM - INFO - [71:15] loss\t15.89 =\tBCE 15.89075 \tLL 0.01453 \tTotal 414.32/47.07/4.84 \n","04/22/2023 04:42:30 PM - INFO - [71:16] loss\t15.67 =\tBCE 15.67048 \tLL 0.01468 \tTotal 433.47/64.37/1.80 \n","04/22/2023 04:42:30 PM - INFO - [71:17] loss\t15.67 =\tBCE 15.67399 \tLL 0.01429 \tTotal 383.51/56.67/0.89 \n","04/22/2023 04:42:31 PM - INFO - [71:18] loss\t15.74 =\tBCE 15.74327 \tLL 0.01398 \tTotal 339.27/62.55/1.74 \n","04/22/2023 04:42:31 PM - INFO - Training epoch 72.\n","04/22/2023 04:42:31 PM - INFO - [72:0] loss\t15.55 =\tBCE 15.55258 \tLL 0.01434 \tTotal 450.59/71.45/2.77 \n","04/22/2023 04:42:32 PM - INFO - [72:1] loss\t15.51 =\tBCE 15.50642 \tLL 0.01398 \tTotal 456.54/69.79/2.98 \n","04/22/2023 04:42:32 PM - INFO - [72:2] loss\t15.79 =\tBCE 15.78719 \tLL 0.01463 \tTotal 225.65/54.89/3.77 \n","04/22/2023 04:42:33 PM - INFO - [72:3] loss\t15.67 =\tBCE 15.66777 \tLL 0.01468 \tTotal 546.63/65.60/4.65 \n","04/22/2023 04:42:33 PM - INFO - [72:4] loss\t15.40 =\tBCE 15.40256 \tLL 0.01412 \tTotal 241.85/43.34/3.06 \n","04/22/2023 04:42:34 PM - INFO - [72:5] loss\t15.22 =\tBCE 15.22191 \tLL 0.01416 \tTotal 339.44/55.85/2.27 \n","04/22/2023 04:42:35 PM - INFO - [72:6] loss\t15.30 =\tBCE 15.29680 \tLL 0.01406 \tTotal 395.46/52.12/1.79 \n","04/22/2023 04:42:35 PM - INFO - [72:7] loss\t15.32 =\tBCE 15.32239 \tLL 0.01377 \tTotal 259.91/38.19/3.66 \n","04/22/2023 04:42:36 PM - INFO - [72:8] loss\t15.24 =\tBCE 15.24325 \tLL 0.01427 \tTotal 337.04/44.37/3.68 \n","04/22/2023 04:42:36 PM - INFO - [72:9] loss\t15.36 =\tBCE 15.36098 \tLL 0.01415 \tTotal 293.05/34.11/1.63 \n","04/22/2023 04:42:37 PM - INFO - [72:10] loss\t15.16 =\tBCE 15.15793 \tLL 0.01401 \tTotal 349.33/38.17/4.91 \n","04/22/2023 04:42:37 PM - INFO - [72:11] loss\t14.95 =\tBCE 14.95270 \tLL 0.01349 \tTotal 220.72/28.85/6.67 \n","04/22/2023 04:42:38 PM - INFO - [72:12] loss\t14.80 =\tBCE 14.79593 \tLL 0.01372 \tTotal 472.95/59.30/4.05 \n","04/22/2023 04:42:38 PM - INFO - [72:13] loss\t14.88 =\tBCE 14.87503 \tLL 0.01353 \tTotal 214.88/28.02/2.54 \n","04/22/2023 04:42:39 PM - INFO - [72:14] loss\t14.68 =\tBCE 14.68020 \tLL 0.01351 \tTotal 197.96/47.47/3.27 \n","04/22/2023 04:42:39 PM - INFO - [72:15] loss\t14.91 =\tBCE 14.90813 \tLL 0.01378 \tTotal 264.48/38.26/6.99 \n","04/22/2023 04:42:40 PM - INFO - [72:16] loss\t14.55 =\tBCE 14.55290 \tLL 0.01345 \tTotal 214.88/30.98/5.68 \n","04/22/2023 04:42:40 PM - INFO - [72:17] loss\t14.99 =\tBCE 14.99087 \tLL 0.01349 \tTotal 208.54/50.78/3.13 \n","04/22/2023 04:42:41 PM - INFO - [72:18] loss\t14.67 =\tBCE 14.66954 \tLL 0.01335 \tTotal 265.47/40.96/3.33 \n","04/22/2023 04:42:41 PM - INFO - Training epoch 73.\n","04/22/2023 04:42:42 PM - INFO - [73:0] loss\t14.51 =\tBCE 14.50808 \tLL 0.01332 \tTotal 284.73/35.47/7.33 \n","04/22/2023 04:42:42 PM - INFO - [73:1] loss\t14.74 =\tBCE 14.74265 \tLL 0.01368 \tTotal 271.92/49.61/9.86 \n","04/22/2023 04:42:43 PM - INFO - [73:2] loss\t14.45 =\tBCE 14.45485 \tLL 0.01310 \tTotal 400.89/44.38/1.08 \n","04/22/2023 04:42:43 PM - INFO - [73:3] loss\t14.65 =\tBCE 14.64684 \tLL 0.01350 \tTotal 285.12/51.90/3.48 \n","04/22/2023 04:42:44 PM - INFO - [73:4] loss\t14.55 =\tBCE 14.54587 \tLL 0.01362 \tTotal 288.82/39.76/4.94 \n","04/22/2023 04:42:44 PM - INFO - [73:5] loss\t14.53 =\tBCE 14.52928 \tLL 0.01351 \tTotal 218.23/34.88/4.27 \n","04/22/2023 04:42:45 PM - INFO - [73:6] loss\t14.58 =\tBCE 14.57924 \tLL 0.01331 \tTotal 218.79/29.93/4.91 \n","04/22/2023 04:42:45 PM - INFO - [73:7] loss\t14.09 =\tBCE 14.09363 \tLL 0.01288 \tTotal 293.03/39.08/3.97 \n","04/22/2023 04:42:46 PM - INFO - [73:8] loss\t13.97 =\tBCE 13.96695 \tLL 0.01265 \tTotal 441.57/46.90/2.39 \n","04/22/2023 04:42:47 PM - INFO - [73:9] loss\t14.58 =\tBCE 14.58428 \tLL 0.01351 \tTotal 224.02/37.76/3.11 \n","04/22/2023 04:42:47 PM - INFO - [73:10] loss\t14.25 =\tBCE 14.25409 \tLL 0.01305 \tTotal 180.79/41.69/5.36 \n","04/22/2023 04:42:48 PM - INFO - [73:11] loss\t14.26 =\tBCE 14.25974 \tLL 0.01335 \tTotal 186.84/24.67/2.69 \n","04/22/2023 04:42:48 PM - INFO - [73:12] loss\t14.25 =\tBCE 14.24976 \tLL 0.01352 \tTotal 182.01/27.42/2.78 \n","04/22/2023 04:42:49 PM - INFO - [73:13] loss\t14.03 =\tBCE 14.03416 \tLL 0.01281 \tTotal 157.63/29.86/3.56 \n","04/22/2023 04:42:49 PM - INFO - [73:14] loss\t14.19 =\tBCE 14.18951 \tLL 0.01328 \tTotal 225.70/33.92/3.32 \n","04/22/2023 04:42:50 PM - INFO - [73:15] loss\t14.13 =\tBCE 14.13150 \tLL 0.01319 \tTotal 167.61/34.05/1.98 \n","04/22/2023 04:42:50 PM - INFO - [73:16] loss\t13.79 =\tBCE 13.79385 \tLL 0.01277 \tTotal 336.13/50.70/2.25 \n","04/22/2023 04:42:51 PM - INFO - [73:17] loss\t13.99 =\tBCE 13.98881 \tLL 0.01321 \tTotal 211.75/33.47/2.22 \n","04/22/2023 04:42:51 PM - INFO - [73:18] loss\t14.10 =\tBCE 14.10438 \tLL 0.01305 \tTotal 244.39/51.65/3.17 \n","04/22/2023 04:42:51 PM - INFO - Training epoch 74.\n","04/22/2023 04:42:52 PM - INFO - [74:0] loss\t13.90 =\tBCE 13.89993 \tLL 0.01281 \tTotal 360.03/42.62/5.27 \n","04/22/2023 04:42:52 PM - INFO - [74:1] loss\t14.02 =\tBCE 14.01704 \tLL 0.01335 \tTotal 223.84/34.94/1.84 \n","04/22/2023 04:42:53 PM - INFO - [74:2] loss\t13.67 =\tBCE 13.66570 \tLL 0.01239 \tTotal 337.09/46.66/1.76 \n","04/22/2023 04:42:53 PM - INFO - [74:3] loss\t13.89 =\tBCE 13.88683 \tLL 0.01286 \tTotal 252.18/33.12/3.94 \n","04/22/2023 04:42:54 PM - INFO - [74:4] loss\t13.75 =\tBCE 13.75247 \tLL 0.01282 \tTotal 305.59/48.99/2.65 \n","04/22/2023 04:42:54 PM - INFO - [74:5] loss\t13.81 =\tBCE 13.81133 \tLL 0.01261 \tTotal 224.23/33.44/4.36 \n","04/22/2023 04:42:55 PM - INFO - [74:6] loss\t13.62 =\tBCE 13.62469 \tLL 0.01271 \tTotal 347.04/58.66/1.84 \n","04/22/2023 04:42:55 PM - INFO - [74:7] loss\t13.86 =\tBCE 13.85879 \tLL 0.01307 \tTotal 168.51/29.16/6.08 \n","04/22/2023 04:42:56 PM - INFO - [74:8] loss\t13.74 =\tBCE 13.73740 \tLL 0.01279 \tTotal 225.27/61.93/3.19 \n","04/22/2023 04:42:57 PM - INFO - [74:9] loss\t13.80 =\tBCE 13.80243 \tLL 0.01285 \tTotal 265.87/38.09/3.40 \n","04/22/2023 04:42:57 PM - INFO - [74:10] loss\t13.63 =\tBCE 13.63106 \tLL 0.01277 \tTotal 284.26/35.41/5.18 \n","04/22/2023 04:42:58 PM - INFO - [74:11] loss\t13.52 =\tBCE 13.51661 \tLL 0.01252 \tTotal 158.84/41.44/4.08 \n","04/22/2023 04:42:58 PM - INFO - [74:12] loss\t13.65 =\tBCE 13.64822 \tLL 0.01288 \tTotal 268.06/38.62/3.53 \n","04/22/2023 04:42:59 PM - INFO - [74:13] loss\t13.16 =\tBCE 13.16199 \tLL 0.01229 \tTotal 369.81/46.08/6.22 \n","04/22/2023 04:42:59 PM - INFO - [74:14] loss\t13.42 =\tBCE 13.42252 \tLL 0.01252 \tTotal 337.39/42.71/5.29 \n","04/22/2023 04:43:00 PM - INFO - [74:15] loss\t13.33 =\tBCE 13.33447 \tLL 0.01232 \tTotal 231.86/31.32/5.37 \n","04/22/2023 04:43:00 PM - INFO - [74:16] loss\t13.34 =\tBCE 13.33716 \tLL 0.01240 \tTotal 240.71/34.50/5.10 \n","04/22/2023 04:43:01 PM - INFO - [74:17] loss\t13.31 =\tBCE 13.30766 \tLL 0.01253 \tTotal 415.62/44.01/6.85 \n","04/22/2023 04:43:01 PM - INFO - [74:18] loss\t13.43 =\tBCE 13.43206 \tLL 0.01252 \tTotal 173.78/24.81/4.50 \n","04/22/2023 04:43:01 PM - INFO - Training epoch 75.\n","04/22/2023 04:43:02 PM - INFO - [75:0] loss\t13.13 =\tBCE 13.12581 \tLL 0.01201 \tTotal 308.10/38.44/3.55 \n","04/22/2023 04:43:02 PM - INFO - [75:1] loss\t13.22 =\tBCE 13.22253 \tLL 0.01232 \tTotal 208.69/41.07/4.09 \n","04/22/2023 04:43:03 PM - INFO - [75:2] loss\t13.37 =\tBCE 13.36588 \tLL 0.01254 \tTotal 209.78/31.32/6.89 \n","04/22/2023 04:43:03 PM - INFO - [75:3] loss\t13.30 =\tBCE 13.30191 \tLL 0.01253 \tTotal 205.90/36.90/7.33 \n","04/22/2023 04:43:04 PM - INFO - [75:4] loss\t13.50 =\tBCE 13.49948 \tLL 0.01271 \tTotal 324.19/40.12/3.65 \n","04/22/2023 04:43:05 PM - INFO - [75:5] loss\t13.35 =\tBCE 13.35184 \tLL 0.01255 \tTotal 498.65/53.81/4.95 \n","04/22/2023 04:43:05 PM - INFO - [75:6] loss\t13.02 =\tBCE 13.02238 \tLL 0.01198 \tTotal 316.50/43.77/4.40 \n","04/22/2023 04:43:06 PM - INFO - [75:7] loss\t13.34 =\tBCE 13.33702 \tLL 0.01252 \tTotal 195.52/28.86/2.42 \n","04/22/2023 04:43:06 PM - INFO - [75:8] loss\t12.88 =\tBCE 12.87938 \tLL 0.01192 \tTotal 308.44/38.27/2.32 \n","04/22/2023 04:43:07 PM - INFO - [75:9] loss\t13.04 =\tBCE 13.03652 \tLL 0.01241 \tTotal 354.20/42.59/1.03 \n","04/22/2023 04:43:07 PM - INFO - [75:10] loss\t12.83 =\tBCE 12.82898 \tLL 0.01181 \tTotal 329.33/39.43/2.98 \n","04/22/2023 04:43:08 PM - INFO - [75:11] loss\t12.92 =\tBCE 12.91981 \tLL 0.01246 \tTotal 348.46/42.46/1.27 \n","04/22/2023 04:43:08 PM - INFO - [75:12] loss\t12.69 =\tBCE 12.69024 \tLL 0.01183 \tTotal 400.91/67.30/1.70 \n","04/22/2023 04:43:09 PM - INFO - [75:13] loss\t12.87 =\tBCE 12.86507 \tLL 0.01218 \tTotal 352.49/73.06/3.17 \n","04/22/2023 04:43:09 PM - INFO - [75:14] loss\t13.04 =\tBCE 13.03570 \tLL 0.01254 \tTotal 421.14/54.63/3.46 \n","04/22/2023 04:43:10 PM - INFO - [75:15] loss\t13.20 =\tBCE 13.20474 \tLL 0.01235 \tTotal 489.34/115.96/2.06 \n","04/22/2023 04:43:10 PM - INFO - [75:16] loss\t12.87 =\tBCE 12.86974 \tLL 0.01197 \tTotal 553.43/110.11/2.03 \n","04/22/2023 04:43:11 PM - INFO - [75:17] loss\t13.12 =\tBCE 13.12108 \tLL 0.01243 \tTotal 404.14/65.04/12.43 \n","04/22/2023 04:43:11 PM - INFO - [75:18] loss\t12.49 =\tBCE 12.48736 \tLL 0.01154 \tTotal 400.39/65.21/4.79 \n","04/22/2023 04:43:11 PM - INFO - Training epoch 76.\n","04/22/2023 04:43:12 PM - INFO - [76:0] loss\t12.41 =\tBCE 12.41452 \tLL 0.01146 \tTotal 455.62/108.09/3.79 \n","04/22/2023 04:43:12 PM - INFO - [76:1] loss\t12.52 =\tBCE 12.52101 \tLL 0.01145 \tTotal 419.67/102.19/4.37 \n","04/22/2023 04:43:13 PM - INFO - [76:2] loss\t12.71 =\tBCE 12.70860 \tLL 0.01192 \tTotal 239.33/35.10/7.17 \n","04/22/2023 04:43:14 PM - INFO - [76:3] loss\t12.61 =\tBCE 12.60539 \tLL 0.01178 \tTotal 281.88/75.80/3.87 \n","04/22/2023 04:43:14 PM - INFO - [76:4] loss\t12.85 =\tBCE 12.85247 \tLL 0.01199 \tTotal 356.30/104.68/0.95 \n","04/22/2023 04:43:15 PM - INFO - [76:5] loss\t12.71 =\tBCE 12.71044 \tLL 0.01201 \tTotal 408.07/67.54/2.72 \n","04/22/2023 04:43:15 PM - INFO - [76:6] loss\t12.82 =\tBCE 12.82029 \tLL 0.01225 \tTotal 737.55/85.40/2.02 \n","04/22/2023 04:43:16 PM - INFO - [76:7] loss\t12.72 =\tBCE 12.72244 \tLL 0.01167 \tTotal 866.89/101.26/2.84 \n","04/22/2023 04:43:16 PM - INFO - [76:8] loss\t12.74 =\tBCE 12.74352 \tLL 0.01217 \tTotal 652.19/70.84/5.32 \n","04/22/2023 04:43:17 PM - INFO - [76:9] loss\t12.70 =\tBCE 12.69932 \tLL 0.01184 \tTotal 503.72/61.34/7.21 \n","04/22/2023 04:43:17 PM - INFO - [76:10] loss\t12.34 =\tBCE 12.34204 \tLL 0.01170 \tTotal 254.29/35.68/5.56 \n","04/22/2023 04:43:18 PM - INFO - [76:11] loss\t12.58 =\tBCE 12.58182 \tLL 0.01178 \tTotal 745.29/88.62/3.35 \n","04/22/2023 04:43:18 PM - INFO - [76:12] loss\t12.71 =\tBCE 12.71375 \tLL 0.01175 \tTotal 1024.16/108.50/3.06 \n","04/22/2023 04:43:19 PM - INFO - [76:13] loss\t12.64 =\tBCE 12.63792 \tLL 0.01170 \tTotal 882.37/94.28/6.54 \n","04/22/2023 04:43:19 PM - INFO - [76:14] loss\t12.58 =\tBCE 12.57535 \tLL 0.01217 \tTotal 829.56/83.91/4.29 \n","04/22/2023 04:43:20 PM - INFO - [76:15] loss\t12.65 =\tBCE 12.65324 \tLL 0.01207 \tTotal 587.47/93.61/3.05 \n","04/22/2023 04:43:20 PM - INFO - [76:16] loss\t12.67 =\tBCE 12.66727 \tLL 0.01219 \tTotal 332.67/85.85/6.91 \n","04/22/2023 04:43:21 PM - INFO - [76:17] loss\t12.40 =\tBCE 12.40275 \tLL 0.01164 \tTotal 544.88/66.28/3.56 \n","04/22/2023 04:43:21 PM - INFO - [76:18] loss\t12.64 =\tBCE 12.63654 \tLL 0.01181 \tTotal 1094.97/135.94/2.69 \n","04/22/2023 04:43:21 PM - INFO - Training epoch 77.\n","04/22/2023 04:43:22 PM - INFO - [77:0] loss\t12.67 =\tBCE 12.67269 \tLL 0.01174 \tTotal 1505.76/202.56/2.84 \n","04/22/2023 04:43:22 PM - INFO - [77:1] loss\t12.95 =\tBCE 12.94789 \tLL 0.01157 \tTotal 1727.25/214.84/4.66 \n","04/22/2023 04:43:23 PM - INFO - [77:2] loss\t13.07 =\tBCE 13.07173 \tLL 0.01157 \tTotal 2135.76/241.37/5.06 \n","04/22/2023 04:43:24 PM - INFO - [77:3] loss\t13.31 =\tBCE 13.31488 \tLL 0.01171 \tTotal 2416.12/273.82/2.18 \n","04/22/2023 04:43:24 PM - INFO - [77:4] loss\t13.21 =\tBCE 13.21375 \tLL 0.01154 \tTotal 2307.74/299.41/3.47 \n","04/22/2023 04:43:25 PM - INFO - [77:5] loss\t13.24 =\tBCE 13.24059 \tLL 0.01177 \tTotal 2066.66/306.90/1.69 \n","04/22/2023 04:43:25 PM - INFO - [77:6] loss\t13.15 =\tBCE 13.14754 \tLL 0.01173 \tTotal 2068.71/257.84/3.92 \n","04/22/2023 04:43:26 PM - INFO - [77:7] loss\t12.79 =\tBCE 12.78741 \tLL 0.01143 \tTotal 1966.10/209.10/4.15 \n","04/22/2023 04:43:26 PM - INFO - [77:8] loss\t12.78 =\tBCE 12.78138 \tLL 0.01171 \tTotal 1524.91/174.18/1.16 \n","04/22/2023 04:43:27 PM - INFO - [77:9] loss\t12.34 =\tBCE 12.33960 \tLL 0.01122 \tTotal 1297.12/163.71/1.31 \n","04/22/2023 04:43:27 PM - INFO - [77:10] loss\t12.62 =\tBCE 12.61687 \tLL 0.01183 \tTotal 1186.09/122.48/2.38 \n","04/22/2023 04:43:28 PM - INFO - [77:11] loss\t12.26 =\tBCE 12.26068 \tLL 0.01157 \tTotal 904.42/95.15/3.96 \n","04/22/2023 04:43:28 PM - INFO - [77:12] loss\t12.24 =\tBCE 12.24387 \tLL 0.01184 \tTotal 673.76/76.97/1.45 \n","04/22/2023 04:43:29 PM - INFO - [77:13] loss\t12.28 =\tBCE 12.28293 \tLL 0.01163 \tTotal 684.16/87.41/2.15 \n","04/22/2023 04:43:29 PM - INFO - [77:14] loss\t12.07 =\tBCE 12.06956 \tLL 0.01143 \tTotal 550.12/67.30/2.22 \n","04/22/2023 04:43:30 PM - INFO - [77:15] loss\t12.21 =\tBCE 12.20871 \tLL 0.01120 \tTotal 1106.53/148.19/4.95 \n","04/22/2023 04:43:30 PM - INFO - [77:16] loss\t12.43 =\tBCE 12.42632 \tLL 0.01110 \tTotal 1684.67/251.53/4.15 \n","04/22/2023 04:43:31 PM - INFO - [77:17] loss\t13.20 =\tBCE 13.20211 \tLL 0.01163 \tTotal 2488.52/314.93/3.89 \n","04/22/2023 04:43:31 PM - INFO - [77:18] loss\t14.15 =\tBCE 14.15238 \tLL 0.01125 \tTotal 3705.73/437.55/2.78 \n","04/22/2023 04:43:31 PM - INFO - Training epoch 78.\n","04/22/2023 04:43:32 PM - INFO - [78:0] loss\t16.81 =\tBCE 16.80574 \tLL 0.01129 \tTotal 5421.82/662.59/1.72 \n","04/22/2023 04:43:33 PM - INFO - [78:1] loss\t23.41 =\tBCE 23.41343 \tLL 0.01139 \tTotal 8799.03/1050.63/0.88 \n","04/22/2023 04:43:33 PM - INFO - [78:2] loss\t49.53 =\tBCE 49.53410 \tLL 0.01174 \tTotal 15240.97/1786.13/1.14 \n","04/22/2023 04:43:34 PM - INFO - [78:3] loss\t134.10 =\tBCE 134.10175 \tLL 0.01119 \tTotal 28894.17/3335.39/4.74 \n","04/22/2023 04:43:34 PM - INFO - [78:4] loss\t801.38 =\tBCE 801.38416 \tLL 0.01313 \tTotal 46833.98/5055.57/5.01 \n","04/22/2023 04:43:35 PM - INFO - [78:5] loss\t1091.46 =\tBCE 1091.46130 \tLL 0.01268 \tTotal 55592.53/5630.90/4.04 \n","04/22/2023 04:43:35 PM - INFO - [78:6] loss\t498.17 =\tBCE 498.17294 \tLL 0.01263 \tTotal 40919.58/4124.17/2.61 \n","04/22/2023 04:43:36 PM - INFO - [78:7] loss\t90.57 =\tBCE 90.57049 \tLL 0.01424 \tTotal 15329.93/1709.46/1.79 \n","04/22/2023 04:43:36 PM - INFO - [78:8] loss\t187.80 =\tBCE 187.79881 \tLL 0.01391 \tTotal 27098.09/2984.73/7.82 \n","04/22/2023 04:43:37 PM - INFO - [78:9] loss\t286.87 =\tBCE 286.86627 \tLL 0.01312 \tTotal 30422.26/3135.50/2.98 \n","04/22/2023 04:43:37 PM - INFO - [78:10] loss\t98.64 =\tBCE 98.63866 \tLL 0.01580 \tTotal 14308.46/1768.51/5.02 \n","04/22/2023 04:43:38 PM - INFO - [78:11] loss\t207.69 =\tBCE 207.68652 \tLL 0.01529 \tTotal 25810.77/3066.53/2.05 \n","04/22/2023 04:43:38 PM - INFO - [78:12] loss\t122.42 =\tBCE 122.41605 \tLL 0.01348 \tTotal 18623.50/1892.85/1.21 \n","04/22/2023 04:43:39 PM - INFO - [78:13] loss\t128.48 =\tBCE 128.47830 \tLL 0.01510 \tTotal 13848.24/2099.78/2.24 \n","04/22/2023 04:43:39 PM - INFO - [78:14] loss\t80.97 =\tBCE 80.97255 \tLL 0.01682 \tTotal 11705.14/1182.84/2.67 \n","04/22/2023 04:43:40 PM - INFO - [78:15] loss\t138.27 =\tBCE 138.27057 \tLL 0.01714 \tTotal 17294.47/2266.83/7.42 \n","04/22/2023 04:43:40 PM - INFO - [78:16] loss\t38.12 =\tBCE 38.11620 \tLL 0.01605 \tTotal 3642.20/409.39/3.26 \n","04/22/2023 04:43:41 PM - INFO - [78:17] loss\t100.90 =\tBCE 100.90310 \tLL 0.01513 \tTotal 11526.90/1429.56/2.73 \n","04/22/2023 04:43:41 PM - INFO - [78:18] loss\t40.17 =\tBCE 40.16774 \tLL 0.01609 \tTotal 4001.09/704.09/4.97 \n","Not implemented\n","04/22/2023 04:43:41 PM - INFO - Training epoch 79.\n","04/22/2023 04:43:42 PM - INFO - [79:0] loss\t60.24 =\tBCE 60.23805 \tLL 0.01675 \tTotal 8055.04/910.46/3.65 \n","04/22/2023 04:43:43 PM - INFO - [79:1] loss\t65.75 =\tBCE 65.74873 \tLL 0.01687 \tTotal 7343.77/1068.52/1.88 \n","04/22/2023 04:43:43 PM - INFO - [79:2] loss\t37.43 =\tBCE 37.43184 \tLL 0.01726 \tTotal 4408.65/496.35/3.06 \n","04/22/2023 04:43:44 PM - INFO - [79:3] loss\t53.40 =\tBCE 53.40369 \tLL 0.01621 \tTotal 6745.65/787.17/3.93 \n","04/22/2023 04:43:44 PM - INFO - [79:4] loss\t46.74 =\tBCE 46.73880 \tLL 0.01574 \tTotal 4980.09/725.01/6.54 \n","04/22/2023 04:43:45 PM - INFO - [79:5] loss\t38.15 =\tBCE 38.15390 \tLL 0.01721 \tTotal 3754.39/456.25/4.19 \n","04/22/2023 04:43:45 PM - INFO - [79:6] loss\t44.97 =\tBCE 44.97293 \tLL 0.01781 \tTotal 5235.35/675.06/5.91 \n","04/22/2023 04:43:46 PM - INFO - [79:7] loss\t40.58 =\tBCE 40.57981 \tLL 0.01766 \tTotal 4171.77/617.25/3.50 \n","04/22/2023 04:43:46 PM - INFO - [79:8] loss\t35.99 =\tBCE 35.99371 \tLL 0.01663 \tTotal 2790.44/388.43/2.76 \n","04/22/2023 04:43:47 PM - INFO - [79:9] loss\t42.86 =\tBCE 42.85523 \tLL 0.01545 \tTotal 4120.19/618.68/9.59 \n","04/22/2023 04:43:47 PM - INFO - [79:10] loss\t37.42 =\tBCE 37.41602 \tLL 0.01543 \tTotal 3089.41/506.46/5.84 \n","04/22/2023 04:43:48 PM - INFO - [79:11] loss\t30.65 =\tBCE 30.64657 \tLL 0.01597 \tTotal 2070.29/261.70/3.23 \n","04/22/2023 04:43:48 PM - INFO - [79:12] loss\t37.07 =\tBCE 37.07404 \tLL 0.01658 \tTotal 3201.37/519.33/3.30 \n","04/22/2023 04:43:49 PM - INFO - [79:13] loss\t35.51 =\tBCE 35.51098 \tLL 0.01669 \tTotal 2506.89/473.68/10.66 \n","04/22/2023 04:43:49 PM - INFO - [79:14] loss\t29.50 =\tBCE 29.50399 \tLL 0.01664 \tTotal 2097.45/253.09/3.77 \n","04/22/2023 04:43:50 PM - INFO - [79:15] loss\t31.96 =\tBCE 31.96282 \tLL 0.01652 \tTotal 1878.09/442.44/2.01 \n","04/22/2023 04:43:50 PM - INFO - [79:16] loss\t33.69 =\tBCE 33.68908 \tLL 0.01578 \tTotal 2212.58/382.89/2.05 \n","04/22/2023 04:43:51 PM - INFO - [79:17] loss\t30.34 =\tBCE 30.33961 \tLL 0.01591 \tTotal 2421.94/255.81/5.35 \n","04/22/2023 04:43:52 PM - INFO - [79:18] loss\t29.05 =\tBCE 29.05422 \tLL 0.01675 \tTotal 1299.89/354.80/5.94 \n","04/22/2023 04:43:52 PM - INFO - EVALUATION prior to epoch [80]...\n","04/22/2023 04:43:52 PM - INFO - [80] loss\t25.24=\tBCE 25.24 \tLL 0.01542 \n","04/22/2023 04:43:53 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/80_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:43:59 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/80_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:44:04 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/80_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 04:44:04 PM - INFO - Training epoch 80.\n","04/22/2023 04:44:05 PM - INFO - [80:0] loss\t30.77 =\tBCE 30.76714 \tLL 0.01677 \tTotal 2197.96/327.66/2.92 \n","04/22/2023 04:44:05 PM - INFO - [80:1] loss\t30.17 =\tBCE 30.16983 \tLL 0.01682 \tTotal 2057.43/218.77/2.69 \n","04/22/2023 04:44:06 PM - INFO - [80:2] loss\t28.08 =\tBCE 28.07987 \tLL 0.01579 \tTotal 1392.75/309.37/2.70 \n","04/22/2023 04:44:06 PM - INFO - [80:3] loss\t28.29 =\tBCE 28.28616 \tLL 0.01606 \tTotal 1913.18/258.21/3.29 \n","04/22/2023 04:44:07 PM - INFO - [80:4] loss\t27.59 =\tBCE 27.58805 \tLL 0.01566 \tTotal 1588.65/215.10/4.88 \n","04/22/2023 04:44:07 PM - INFO - [80:5] loss\t27.51 =\tBCE 27.50891 \tLL 0.01615 \tTotal 1462.93/269.44/3.33 \n","04/22/2023 04:44:08 PM - INFO - [80:6] loss\t27.31 =\tBCE 27.30785 \tLL 0.01618 \tTotal 1467.05/173.82/1.94 \n","04/22/2023 04:44:08 PM - INFO - [80:7] loss\t26.90 =\tBCE 26.89837 \tLL 0.01679 \tTotal 1701.21/205.32/3.43 \n","04/22/2023 04:44:09 PM - INFO - [80:8] loss\t25.67 =\tBCE 25.66627 \tLL 0.01582 \tTotal 1141.30/190.43/4.18 \n","04/22/2023 04:44:10 PM - INFO - [80:9] loss\t25.93 =\tBCE 25.93146 \tLL 0.01593 \tTotal 1118.99/117.14/3.86 \n","04/22/2023 04:44:10 PM - INFO - [80:10] loss\t27.11 =\tBCE 27.10597 \tLL 0.01585 \tTotal 1910.55/234.30/2.40 \n","04/22/2023 04:44:11 PM - INFO - [80:11] loss\t25.40 =\tBCE 25.39809 \tLL 0.01615 \tTotal 965.98/124.38/2.14 \n","04/22/2023 04:44:11 PM - INFO - [80:12] loss\t25.33 =\tBCE 25.32979 \tLL 0.01662 \tTotal 1051.41/152.61/4.22 \n","04/22/2023 04:44:12 PM - INFO - [80:13] loss\t25.69 =\tBCE 25.69376 \tLL 0.01584 \tTotal 1632.28/195.68/4.30 \n","04/22/2023 04:44:12 PM - INFO - [80:14] loss\t24.40 =\tBCE 24.40275 \tLL 0.01616 \tTotal 808.66/95.02/2.82 \n","04/22/2023 04:44:13 PM - INFO - [80:15] loss\t24.08 =\tBCE 24.07627 \tLL 0.01589 \tTotal 925.41/175.77/2.04 \n","04/22/2023 04:44:13 PM - INFO - [80:16] loss\t24.10 =\tBCE 24.09519 \tLL 0.01583 \tTotal 1025.18/135.01/1.80 \n","04/22/2023 04:44:14 PM - INFO - [80:17] loss\t24.01 =\tBCE 24.01452 \tLL 0.01540 \tTotal 784.09/116.57/2.79 \n","04/22/2023 04:44:14 PM - INFO - [80:18] loss\t23.75 =\tBCE 23.74832 \tLL 0.01644 \tTotal 693.18/169.53/7.40 \n","04/22/2023 04:44:14 PM - INFO - Training epoch 81.\n","04/22/2023 04:44:15 PM - INFO - [81:0] loss\t23.93 =\tBCE 23.92821 \tLL 0.01654 \tTotal 646.12/93.02/5.51 \n","04/22/2023 04:44:15 PM - INFO - [81:1] loss\t23.30 =\tBCE 23.29589 \tLL 0.01613 \tTotal 742.75/135.80/2.56 \n","04/22/2023 04:44:16 PM - INFO - [81:2] loss\t22.85 =\tBCE 22.84840 \tLL 0.01581 \tTotal 461.84/148.00/4.20 \n","04/22/2023 04:44:16 PM - INFO - [81:3] loss\t22.47 =\tBCE 22.46635 \tLL 0.01538 \tTotal 663.15/85.47/5.42 \n","04/22/2023 04:44:17 PM - INFO - [81:4] loss\t22.31 =\tBCE 22.31478 \tLL 0.01558 \tTotal 579.35/108.50/3.21 \n","04/22/2023 04:44:17 PM - INFO - [81:5] loss\t22.21 =\tBCE 22.21437 \tLL 0.01541 \tTotal 404.71/99.08/2.81 \n","04/22/2023 04:44:18 PM - INFO - [81:6] loss\t22.31 =\tBCE 22.30643 \tLL 0.01553 \tTotal 633.59/83.56/1.22 \n","04/22/2023 04:44:19 PM - INFO - [81:7] loss\t21.81 =\tBCE 21.81012 \tLL 0.01579 \tTotal 475.08/88.80/2.00 \n","04/22/2023 04:44:19 PM - INFO - [81:8] loss\t22.19 =\tBCE 22.18656 \tLL 0.01608 \tTotal 503.91/91.34/4.69 \n","04/22/2023 04:44:20 PM - INFO - [81:9] loss\t21.68 =\tBCE 21.67727 \tLL 0.01558 \tTotal 497.18/68.03/2.61 \n","04/22/2023 04:44:20 PM - INFO - [81:10] loss\t21.73 =\tBCE 21.73178 \tLL 0.01520 \tTotal 559.18/74.88/5.05 \n","04/22/2023 04:44:21 PM - INFO - [81:11] loss\t21.45 =\tBCE 21.45326 \tLL 0.01541 \tTotal 478.00/69.61/2.82 \n","04/22/2023 04:44:21 PM - INFO - [81:12] loss\t21.02 =\tBCE 21.02229 \tLL 0.01528 \tTotal 448.50/63.36/3.91 \n","04/22/2023 04:44:22 PM - INFO - [81:13] loss\t21.42 =\tBCE 21.42117 \tLL 0.01622 \tTotal 393.41/58.81/5.12 \n","04/22/2023 04:44:22 PM - INFO - [81:14] loss\t21.64 =\tBCE 21.63779 \tLL 0.01634 \tTotal 523.31/79.27/4.90 \n","04/22/2023 04:44:23 PM - INFO - [81:15] loss\t21.38 =\tBCE 21.37509 \tLL 0.01542 \tTotal 387.42/52.80/6.15 \n","04/22/2023 04:44:23 PM - INFO - [81:16] loss\t21.21 =\tBCE 21.21070 \tLL 0.01595 \tTotal 437.15/53.51/2.78 \n","04/22/2023 04:44:24 PM - INFO - [81:17] loss\t20.71 =\tBCE 20.71104 \tLL 0.01531 \tTotal 536.03/64.06/2.09 \n","04/22/2023 04:44:24 PM - INFO - [81:18] loss\t20.42 =\tBCE 20.42429 \tLL 0.01532 \tTotal 274.06/41.59/2.60 \n","04/22/2023 04:44:24 PM - INFO - Training epoch 82.\n","04/22/2023 04:44:25 PM - INFO - [82:0] loss\t20.70 =\tBCE 20.69520 \tLL 0.01576 \tTotal 495.04/61.20/3.05 \n","04/22/2023 04:44:26 PM - INFO - [82:1] loss\t20.16 =\tBCE 20.16135 \tLL 0.01558 \tTotal 348.00/48.64/8.58 \n","04/22/2023 04:44:26 PM - INFO - [82:2] loss\t20.38 =\tBCE 20.38370 \tLL 0.01585 \tTotal 362.77/49.98/8.30 \n","04/22/2023 04:44:27 PM - INFO - [82:3] loss\t20.04 =\tBCE 20.03814 \tLL 0.01521 \tTotal 369.65/46.97/2.91 \n","04/22/2023 04:44:27 PM - INFO - [82:4] loss\t20.00 =\tBCE 19.99833 \tLL 0.01507 \tTotal 267.99/40.88/4.01 \n","04/22/2023 04:44:28 PM - INFO - [82:5] loss\t19.74 =\tBCE 19.73959 \tLL 0.01515 \tTotal 329.07/41.54/9.93 \n","04/22/2023 04:44:28 PM - INFO - [82:6] loss\t19.82 =\tBCE 19.82090 \tLL 0.01547 \tTotal 396.43/54.10/4.62 \n","04/22/2023 04:44:29 PM - INFO - [82:7] loss\t19.74 =\tBCE 19.74041 \tLL 0.01477 \tTotal 242.37/39.13/2.50 \n","04/22/2023 04:44:29 PM - INFO - [82:8] loss\t19.60 =\tBCE 19.59678 \tLL 0.01530 \tTotal 306.68/37.52/5.52 \n","04/22/2023 04:44:30 PM - INFO - [82:9] loss\t19.19 =\tBCE 19.19241 \tLL 0.01484 \tTotal 312.26/39.49/4.27 \n","04/22/2023 04:44:30 PM - INFO - [82:10] loss\t19.41 =\tBCE 19.40810 \tLL 0.01501 \tTotal 344.23/42.25/4.80 \n","04/22/2023 04:44:31 PM - INFO - [82:11] loss\t19.07 =\tBCE 19.07206 \tLL 0.01543 \tTotal 169.49/34.85/6.85 \n","04/22/2023 04:44:31 PM - INFO - [82:12] loss\t19.20 =\tBCE 19.19619 \tLL 0.01466 \tTotal 342.73/44.78/6.36 \n","04/22/2023 04:44:32 PM - INFO - [82:13] loss\t18.87 =\tBCE 18.87468 \tLL 0.01494 \tTotal 304.03/40.14/2.86 \n","04/22/2023 04:44:32 PM - INFO - [82:14] loss\t18.70 =\tBCE 18.69900 \tLL 0.01457 \tTotal 221.74/30.03/3.29 \n","04/22/2023 04:44:33 PM - INFO - [82:15] loss\t18.86 =\tBCE 18.85532 \tLL 0.01492 \tTotal 331.20/43.29/7.89 \n","04/22/2023 04:44:34 PM - INFO - [82:16] loss\t18.33 =\tBCE 18.32994 \tLL 0.01462 \tTotal 148.78/30.03/4.21 \n","04/22/2023 04:44:34 PM - INFO - [82:17] loss\t18.76 =\tBCE 18.75591 \tLL 0.01522 \tTotal 234.76/39.16/1.16 \n","04/22/2023 04:44:35 PM - INFO - [82:18] loss\t18.37 =\tBCE 18.36849 \tLL 0.01480 \tTotal 155.05/29.45/1.39 \n","04/22/2023 04:44:35 PM - INFO - Training epoch 83.\n","04/22/2023 04:44:35 PM - INFO - [83:0] loss\t18.24 =\tBCE 18.24025 \tLL 0.01485 \tTotal 222.46/32.82/5.08 \n","04/22/2023 04:44:36 PM - INFO - [83:1] loss\t18.36 =\tBCE 18.36219 \tLL 0.01437 \tTotal 197.97/35.89/4.78 \n","04/22/2023 04:44:36 PM - INFO - [83:2] loss\t18.13 =\tBCE 18.12691 \tLL 0.01465 \tTotal 256.26/35.55/1.27 \n","04/22/2023 04:44:37 PM - INFO - [83:3] loss\t18.31 =\tBCE 18.31073 \tLL 0.01487 \tTotal 148.82/34.26/3.03 \n","04/22/2023 04:44:37 PM - INFO - [83:4] loss\t18.06 =\tBCE 18.06207 \tLL 0.01483 \tTotal 233.05/37.25/3.38 \n","04/22/2023 04:44:38 PM - INFO - [83:5] loss\t18.16 =\tBCE 18.16496 \tLL 0.01474 \tTotal 180.05/29.86/4.92 \n","04/22/2023 04:44:38 PM - INFO - [83:6] loss\t17.80 =\tBCE 17.80247 \tLL 0.01415 \tTotal 145.73/30.50/3.85 \n","04/22/2023 04:44:39 PM - INFO - [83:7] loss\t17.75 =\tBCE 17.74830 \tLL 0.01444 \tTotal 213.11/29.97/5.68 \n","04/22/2023 04:44:40 PM - INFO - [83:8] loss\t17.94 =\tBCE 17.93766 \tLL 0.01470 \tTotal 256.32/44.41/1.13 \n","04/22/2023 04:44:40 PM - INFO - [83:9] loss\t17.94 =\tBCE 17.93964 \tLL 0.01450 \tTotal 166.41/24.00/3.53 \n","04/22/2023 04:44:41 PM - INFO - [83:10] loss\t17.57 =\tBCE 17.57269 \tLL 0.01464 \tTotal 299.23/46.33/4.42 \n","04/22/2023 04:44:41 PM - INFO - [83:11] loss\t17.48 =\tBCE 17.48431 \tLL 0.01438 \tTotal 171.78/28.82/3.63 \n","04/22/2023 04:44:42 PM - INFO - [83:12] loss\t17.44 =\tBCE 17.43670 \tLL 0.01458 \tTotal 260.18/47.48/4.95 \n","04/22/2023 04:44:42 PM - INFO - [83:13] loss\t17.46 =\tBCE 17.45883 \tLL 0.01424 \tTotal 187.03/26.05/5.38 \n","04/22/2023 04:44:43 PM - INFO - [83:14] loss\t16.99 =\tBCE 16.99010 \tLL 0.01455 \tTotal 124.01/31.47/4.69 \n","04/22/2023 04:44:43 PM - INFO - [83:15] loss\t16.97 =\tBCE 16.96667 \tLL 0.01414 \tTotal 233.71/33.26/4.61 \n","04/22/2023 04:44:44 PM - INFO - [83:16] loss\t17.31 =\tBCE 17.30568 \tLL 0.01445 \tTotal 105.17/41.73/1.91 \n","04/22/2023 04:44:44 PM - INFO - [83:17] loss\t16.79 =\tBCE 16.79260 \tLL 0.01388 \tTotal 300.76/34.86/1.31 \n","04/22/2023 04:44:45 PM - INFO - [83:18] loss\t17.09 =\tBCE 17.09284 \tLL 0.01418 \tTotal 132.06/31.99/3.79 \n","04/22/2023 04:44:45 PM - INFO - Training epoch 84.\n","04/22/2023 04:44:45 PM - INFO - [84:0] loss\t17.02 =\tBCE 17.02294 \tLL 0.01424 \tTotal 197.03/33.58/4.20 \n","04/22/2023 04:44:46 PM - INFO - [84:1] loss\t17.15 =\tBCE 17.15046 \tLL 0.01436 \tTotal 115.24/25.64/2.99 \n","04/22/2023 04:44:46 PM - INFO - [84:2] loss\t16.87 =\tBCE 16.87230 \tLL 0.01413 \tTotal 333.98/51.03/2.30 \n","04/22/2023 04:44:47 PM - INFO - [84:3] loss\t16.91 =\tBCE 16.90783 \tLL 0.01426 \tTotal 130.11/20.88/3.24 \n","04/22/2023 04:44:48 PM - INFO - [84:4] loss\t16.80 =\tBCE 16.80036 \tLL 0.01442 \tTotal 343.59/46.92/4.23 \n","04/22/2023 04:44:48 PM - INFO - [84:5] loss\t16.89 =\tBCE 16.88969 \tLL 0.01416 \tTotal 123.60/23.84/8.48 \n","04/22/2023 04:44:49 PM - INFO - [84:6] loss\t16.45 =\tBCE 16.44677 \tLL 0.01395 \tTotal 281.59/35.40/1.26 \n","04/22/2023 04:44:49 PM - INFO - [84:7] loss\t16.36 =\tBCE 16.36131 \tLL 0.01346 \tTotal 148.27/25.36/5.04 \n","04/22/2023 04:44:50 PM - INFO - [84:8] loss\t16.44 =\tBCE 16.44327 \tLL 0.01384 \tTotal 325.66/40.30/6.04 \n","04/22/2023 04:44:50 PM - INFO - [84:9] loss\t16.44 =\tBCE 16.44414 \tLL 0.01392 \tTotal 143.10/20.76/3.87 \n","04/22/2023 04:44:51 PM - INFO - [84:10] loss\t16.10 =\tBCE 16.10316 \tLL 0.01353 \tTotal 351.90/40.86/7.30 \n","04/22/2023 04:44:51 PM - INFO - [84:11] loss\t15.98 =\tBCE 15.98113 \tLL 0.01375 \tTotal 213.59/33.65/1.18 \n","04/22/2023 04:44:52 PM - INFO - [84:12] loss\t16.19 =\tBCE 16.18833 \tLL 0.01389 \tTotal 300.10/37.48/6.80 \n","04/22/2023 04:44:52 PM - INFO - [84:13] loss\t16.18 =\tBCE 16.17647 \tLL 0.01353 \tTotal 310.81/40.18/5.16 \n","04/22/2023 04:44:53 PM - INFO - [84:14] loss\t15.68 =\tBCE 15.67586 \tLL 0.01382 \tTotal 251.12/27.31/10.74 \n","04/22/2023 04:44:53 PM - INFO - [84:15] loss\t15.87 =\tBCE 15.87270 \tLL 0.01346 \tTotal 227.73/28.90/5.39 \n","04/22/2023 04:44:54 PM - INFO - [84:16] loss\t15.96 =\tBCE 15.96235 \tLL 0.01388 \tTotal 219.37/30.56/1.75 \n","04/22/2023 04:44:55 PM - INFO - [84:17] loss\t15.84 =\tBCE 15.83583 \tLL 0.01363 \tTotal 212.83/28.89/4.47 \n","04/22/2023 04:44:55 PM - INFO - [84:18] loss\t15.79 =\tBCE 15.78648 \tLL 0.01374 \tTotal 193.73/27.60/6.30 \n","04/22/2023 04:44:55 PM - INFO - Training epoch 85.\n","04/22/2023 04:44:56 PM - INFO - [85:0] loss\t16.00 =\tBCE 15.99692 \tLL 0.01374 \tTotal 318.81/37.11/7.54 \n","04/22/2023 04:44:56 PM - INFO - [85:1] loss\t15.53 =\tBCE 15.53495 \tLL 0.01333 \tTotal 158.93/22.25/4.45 \n","04/22/2023 04:44:57 PM - INFO - [85:2] loss\t15.43 =\tBCE 15.42844 \tLL 0.01334 \tTotal 275.06/32.58/1.95 \n","04/22/2023 04:44:57 PM - INFO - [85:3] loss\t15.75 =\tBCE 15.75437 \tLL 0.01366 \tTotal 137.56/20.97/4.90 \n","04/22/2023 04:44:58 PM - INFO - [85:4] loss\t15.39 =\tBCE 15.39463 \tLL 0.01327 \tTotal 271.80/33.98/6.13 \n","04/22/2023 04:44:58 PM - INFO - [85:5] loss\t15.63 =\tBCE 15.62866 \tLL 0.01378 \tTotal 135.81/22.16/5.86 \n","04/22/2023 04:44:59 PM - INFO - [85:6] loss\t15.48 =\tBCE 15.47687 \tLL 0.01339 \tTotal 283.39/36.75/4.64 \n","04/22/2023 04:44:59 PM - INFO - [85:7] loss\t15.37 =\tBCE 15.36911 \tLL 0.01305 \tTotal 117.60/30.60/1.78 \n","04/22/2023 04:45:00 PM - INFO - [85:8] loss\t15.50 =\tBCE 15.49882 \tLL 0.01366 \tTotal 207.19/29.29/2.68 \n","04/22/2023 04:45:00 PM - INFO - [85:9] loss\t15.07 =\tBCE 15.07158 \tLL 0.01339 \tTotal 91.30/27.45/4.24 \n","04/22/2023 04:45:01 PM - INFO - [85:10] loss\t15.21 =\tBCE 15.20903 \tLL 0.01303 \tTotal 121.30/25.53/6.23 \n","04/22/2023 04:45:01 PM - INFO - [85:11] loss\t15.29 =\tBCE 15.29069 \tLL 0.01362 \tTotal 101.59/21.68/6.42 \n","04/22/2023 04:45:02 PM - INFO - [85:12] loss\t15.05 =\tBCE 15.05238 \tLL 0.01325 \tTotal 126.01/24.10/3.48 \n","04/22/2023 04:45:02 PM - INFO - [85:13] loss\t15.02 =\tBCE 15.02153 \tLL 0.01334 \tTotal 118.30/22.25/4.88 \n","04/22/2023 04:45:03 PM - INFO - [85:14] loss\t15.17 =\tBCE 15.16930 \tLL 0.01313 \tTotal 175.79/25.35/4.16 \n","04/22/2023 04:45:03 PM - INFO - [85:15] loss\t14.87 =\tBCE 14.87093 \tLL 0.01326 \tTotal 133.94/21.35/6.93 \n","04/22/2023 04:45:04 PM - INFO - [85:16] loss\t14.98 =\tBCE 14.98194 \tLL 0.01307 \tTotal 199.12/28.16/4.02 \n","04/22/2023 04:45:04 PM - INFO - [85:17] loss\t15.25 =\tBCE 15.25072 \tLL 0.01353 \tTotal 135.69/21.72/2.20 \n","04/22/2023 04:45:05 PM - INFO - [85:18] loss\t15.02 =\tBCE 15.02482 \tLL 0.01304 \tTotal 203.60/45.17/2.91 \n","04/22/2023 04:45:05 PM - INFO - Training epoch 86.\n","04/22/2023 04:45:06 PM - INFO - [86:0] loss\t14.98 =\tBCE 14.98184 \tLL 0.01311 \tTotal 206.85/50.89/6.02 \n","04/22/2023 04:45:06 PM - INFO - [86:1] loss\t14.84 =\tBCE 14.84342 \tLL 0.01312 \tTotal 230.03/30.05/3.36 \n","04/22/2023 04:45:07 PM - INFO - [86:2] loss\t14.99 =\tBCE 14.98717 \tLL 0.01337 \tTotal 137.80/35.46/3.37 \n","04/22/2023 04:45:07 PM - INFO - [86:3] loss\t14.39 =\tBCE 14.39034 \tLL 0.01273 \tTotal 126.45/21.45/3.99 \n","04/22/2023 04:45:08 PM - INFO - [86:4] loss\t14.78 =\tBCE 14.77806 \tLL 0.01320 \tTotal 162.29/25.22/2.19 \n","04/22/2023 04:45:08 PM - INFO - [86:5] loss\t14.55 =\tBCE 14.55303 \tLL 0.01282 \tTotal 139.58/22.49/3.54 \n","04/22/2023 04:45:09 PM - INFO - [86:6] loss\t14.82 =\tBCE 14.81688 \tLL 0.01300 \tTotal 147.37/28.93/4.37 \n","04/22/2023 04:45:09 PM - INFO - [86:7] loss\t14.49 =\tBCE 14.49378 \tLL 0.01293 \tTotal 162.16/30.41/3.97 \n","04/22/2023 04:45:10 PM - INFO - [86:8] loss\t14.60 =\tBCE 14.59514 \tLL 0.01311 \tTotal 217.54/24.94/1.09 \n","04/22/2023 04:45:10 PM - INFO - [86:9] loss\t14.27 =\tBCE 14.27403 \tLL 0.01275 \tTotal 204.86/33.80/3.96 \n","04/22/2023 04:45:11 PM - INFO - [86:10] loss\t14.34 =\tBCE 14.34314 \tLL 0.01278 \tTotal 148.92/25.15/6.70 \n","04/22/2023 04:45:11 PM - INFO - [86:11] loss\t14.15 =\tBCE 14.14807 \tLL 0.01272 \tTotal 282.31/37.85/2.07 \n","04/22/2023 04:45:12 PM - INFO - [86:12] loss\t14.29 =\tBCE 14.28687 \tLL 0.01269 \tTotal 160.49/25.94/1.56 \n","04/22/2023 04:45:12 PM - INFO - [86:13] loss\t14.59 =\tBCE 14.59397 \tLL 0.01300 \tTotal 181.91/34.10/3.04 \n","04/22/2023 04:45:13 PM - INFO - [86:14] loss\t14.45 =\tBCE 14.45312 \tLL 0.01311 \tTotal 91.70/28.62/3.54 \n","04/22/2023 04:45:13 PM - INFO - [86:15] loss\t13.93 =\tBCE 13.92615 \tLL 0.01263 \tTotal 226.09/34.88/6.49 \n","04/22/2023 04:45:14 PM - INFO - [86:16] loss\t14.18 =\tBCE 14.18339 \tLL 0.01266 \tTotal 140.68/27.55/3.18 \n","04/22/2023 04:45:15 PM - INFO - [86:17] loss\t14.02 =\tBCE 14.01885 \tLL 0.01253 \tTotal 245.51/42.74/1.28 \n","04/22/2023 04:45:15 PM - INFO - [86:18] loss\t13.99 =\tBCE 13.98507 \tLL 0.01250 \tTotal 143.57/24.97/2.84 \n","04/22/2023 04:45:15 PM - INFO - Training epoch 87.\n","04/22/2023 04:45:16 PM - INFO - [87:0] loss\t14.13 =\tBCE 14.12926 \tLL 0.01300 \tTotal 192.32/27.33/1.92 \n","04/22/2023 04:45:16 PM - INFO - [87:1] loss\t13.91 =\tBCE 13.91467 \tLL 0.01234 \tTotal 150.76/23.57/4.46 \n","04/22/2023 04:45:17 PM - INFO - [87:2] loss\t13.74 =\tBCE 13.73892 \tLL 0.01210 \tTotal 195.14/27.66/2.85 \n","04/22/2023 04:45:17 PM - INFO - [87:3] loss\t13.85 =\tBCE 13.85386 \tLL 0.01240 \tTotal 247.03/39.80/3.80 \n","04/22/2023 04:45:18 PM - INFO - [87:4] loss\t13.88 =\tBCE 13.88354 \tLL 0.01248 \tTotal 132.23/24.56/1.66 \n","04/22/2023 04:45:18 PM - INFO - [87:5] loss\t14.06 =\tBCE 14.05927 \tLL 0.01297 \tTotal 222.00/46.80/3.87 \n","04/22/2023 04:45:19 PM - INFO - [87:6] loss\t13.80 =\tBCE 13.79870 \tLL 0.01241 \tTotal 216.92/29.90/5.70 \n","04/22/2023 04:45:19 PM - INFO - [87:7] loss\t13.83 =\tBCE 13.82675 \tLL 0.01253 \tTotal 171.29/55.82/1.83 \n","04/22/2023 04:45:20 PM - INFO - [87:8] loss\t13.58 =\tBCE 13.58390 \tLL 0.01250 \tTotal 152.32/52.78/2.16 \n","04/22/2023 04:45:20 PM - INFO - [87:9] loss\t13.71 =\tBCE 13.71048 \tLL 0.01263 \tTotal 133.19/35.96/3.17 \n","04/22/2023 04:45:21 PM - INFO - [87:10] loss\t13.76 =\tBCE 13.76254 \tLL 0.01250 \tTotal 168.20/59.41/4.40 \n","04/22/2023 04:45:21 PM - INFO - [87:11] loss\t13.63 =\tBCE 13.63217 \tLL 0.01210 \tTotal 110.19/25.18/4.97 \n","04/22/2023 04:45:22 PM - INFO - [87:12] loss\t13.82 =\tBCE 13.82420 \tLL 0.01267 \tTotal 133.88/44.95/3.96 \n","04/22/2023 04:45:22 PM - INFO - [87:13] loss\t13.58 =\tBCE 13.57672 \tLL 0.01233 \tTotal 259.56/39.92/3.63 \n","04/22/2023 04:45:23 PM - INFO - [87:14] loss\t13.58 =\tBCE 13.58179 \tLL 0.01220 \tTotal 238.18/27.67/2.84 \n","04/22/2023 04:45:24 PM - INFO - [87:15] loss\t13.43 =\tBCE 13.42964 \tLL 0.01239 \tTotal 203.36/41.46/2.89 \n","04/22/2023 04:45:24 PM - INFO - [87:16] loss\t13.74 =\tBCE 13.74148 \tLL 0.01250 \tTotal 185.65/28.01/3.56 \n","04/22/2023 04:45:25 PM - INFO - [87:17] loss\t13.50 =\tBCE 13.50293 \tLL 0.01233 \tTotal 140.24/40.02/1.19 \n","04/22/2023 04:45:25 PM - INFO - [87:18] loss\t13.60 =\tBCE 13.60393 \tLL 0.01231 \tTotal 296.16/61.11/4.67 \n","04/22/2023 04:45:25 PM - INFO - Training epoch 88.\n","04/22/2023 04:45:26 PM - INFO - [88:0] loss\t13.52 =\tBCE 13.51960 \tLL 0.01255 \tTotal 176.60/26.51/3.20 \n","04/22/2023 04:45:26 PM - INFO - [88:1] loss\t13.30 =\tBCE 13.30014 \tLL 0.01221 \tTotal 321.43/35.71/4.12 \n","04/22/2023 04:45:27 PM - INFO - [88:2] loss\t12.91 =\tBCE 12.90652 \tLL 0.01166 \tTotal 316.14/48.88/1.79 \n","04/22/2023 04:45:27 PM - INFO - [88:3] loss\t13.45 =\tBCE 13.45008 \tLL 0.01254 \tTotal 119.54/26.34/4.00 \n","04/22/2023 04:45:28 PM - INFO - [88:4] loss\t13.42 =\tBCE 13.41582 \tLL 0.01223 \tTotal 283.33/41.34/2.16 \n","04/22/2023 04:45:28 PM - INFO - [88:5] loss\t13.10 =\tBCE 13.10334 \tLL 0.01179 \tTotal 174.19/45.75/3.87 \n","04/22/2023 04:45:29 PM - INFO - [88:6] loss\t13.42 =\tBCE 13.42439 \tLL 0.01253 \tTotal 197.83/38.02/4.23 \n","04/22/2023 04:45:29 PM - INFO - [88:7] loss\t13.31 =\tBCE 13.30551 \tLL 0.01204 \tTotal 242.19/35.10/1.69 \n","04/22/2023 04:45:30 PM - INFO - [88:8] loss\t12.97 =\tBCE 12.96876 \tLL 0.01194 \tTotal 181.94/48.16/2.44 \n","04/22/2023 04:45:30 PM - INFO - [88:9] loss\t13.16 =\tBCE 13.15724 \tLL 0.01211 \tTotal 257.73/33.57/2.24 \n","04/22/2023 04:45:31 PM - INFO - [88:10] loss\t13.21 =\tBCE 13.20946 \tLL 0.01206 \tTotal 307.14/56.84/2.63 \n","04/22/2023 04:45:31 PM - INFO - [88:11] loss\t13.18 =\tBCE 13.18099 \tLL 0.01192 \tTotal 220.20/54.45/5.97 \n","04/22/2023 04:45:32 PM - INFO - [88:12] loss\t13.24 =\tBCE 13.24242 \tLL 0.01236 \tTotal 263.50/35.91/2.66 \n","04/22/2023 04:45:32 PM - INFO - [88:13] loss\t13.15 =\tBCE 13.15013 \tLL 0.01206 \tTotal 209.38/31.13/1.45 \n","04/22/2023 04:45:33 PM - INFO - [88:14] loss\t13.01 =\tBCE 13.01478 \tLL 0.01198 \tTotal 167.35/32.20/5.40 \n","04/22/2023 04:45:33 PM - INFO - [88:15] loss\t12.99 =\tBCE 12.98615 \tLL 0.01216 \tTotal 281.91/33.87/4.75 \n","04/22/2023 04:45:34 PM - INFO - [88:16] loss\t12.94 =\tBCE 12.94163 \tLL 0.01201 \tTotal 400.36/59.54/1.35 \n","04/22/2023 04:45:35 PM - INFO - [88:17] loss\t12.56 =\tBCE 12.56358 \tLL 0.01165 \tTotal 239.05/48.71/1.10 \n","04/22/2023 04:45:35 PM - INFO - [88:18] loss\t12.80 =\tBCE 12.79896 \tLL 0.01202 \tTotal 274.18/39.34/1.59 \n","Not implemented\n","04/22/2023 04:45:35 PM - INFO - Training epoch 89.\n","04/22/2023 04:45:36 PM - INFO - [89:0] loss\t12.96 =\tBCE 12.95740 \tLL 0.01200 \tTotal 403.73/49.06/3.54 \n","04/22/2023 04:45:36 PM - INFO - [89:1] loss\t12.65 =\tBCE 12.64560 \tLL 0.01181 \tTotal 142.26/25.96/1.36 \n","04/22/2023 04:45:37 PM - INFO - [89:2] loss\t12.86 =\tBCE 12.86343 \tLL 0.01169 \tTotal 310.54/47.19/5.77 \n","04/22/2023 04:45:37 PM - INFO - [89:3] loss\t12.94 =\tBCE 12.93653 \tLL 0.01202 \tTotal 202.49/25.82/1.45 \n","04/22/2023 04:45:38 PM - INFO - [89:4] loss\t12.72 =\tBCE 12.72169 \tLL 0.01176 \tTotal 215.12/39.52/1.06 \n","04/22/2023 04:45:38 PM - INFO - [89:5] loss\t12.62 =\tBCE 12.61961 \tLL 0.01167 \tTotal 275.93/46.90/6.12 \n","04/22/2023 04:45:39 PM - INFO - [89:6] loss\t12.86 =\tBCE 12.85553 \tLL 0.01187 \tTotal 229.81/42.31/1.24 \n","04/22/2023 04:45:39 PM - INFO - [89:7] loss\t13.03 =\tBCE 13.02740 \tLL 0.01216 \tTotal 197.56/35.37/3.96 \n","04/22/2023 04:45:40 PM - INFO - [89:8] loss\t12.28 =\tBCE 12.27978 \tLL 0.01139 \tTotal 226.07/28.59/2.56 \n","04/22/2023 04:45:40 PM - INFO - [89:9] loss\t12.55 =\tBCE 12.55231 \tLL 0.01179 \tTotal 256.56/38.91/2.11 \n","04/22/2023 04:45:41 PM - INFO - [89:10] loss\t12.61 =\tBCE 12.60598 \tLL 0.01169 \tTotal 246.71/33.88/4.81 \n","04/22/2023 04:45:41 PM - INFO - [89:11] loss\t12.72 =\tBCE 12.72495 \tLL 0.01205 \tTotal 248.96/46.08/2.07 \n","04/22/2023 04:45:42 PM - INFO - [89:12] loss\t12.53 =\tBCE 12.52726 \tLL 0.01182 \tTotal 271.74/46.92/5.55 \n","04/22/2023 04:45:43 PM - INFO - [89:13] loss\t12.34 =\tBCE 12.34342 \tLL 0.01171 \tTotal 184.85/27.32/2.21 \n","04/22/2023 04:45:43 PM - INFO - [89:14] loss\t12.39 =\tBCE 12.38915 \tLL 0.01162 \tTotal 329.72/75.57/3.22 \n","04/22/2023 04:45:44 PM - INFO - [89:15] loss\t12.40 =\tBCE 12.40108 \tLL 0.01167 \tTotal 301.86/94.90/2.41 \n","04/22/2023 04:45:44 PM - INFO - [89:16] loss\t12.35 =\tBCE 12.34820 \tLL 0.01173 \tTotal 324.90/59.20/2.22 \n","04/22/2023 04:45:45 PM - INFO - [89:17] loss\t12.27 =\tBCE 12.26667 \tLL 0.01154 \tTotal 163.57/24.57/4.13 \n","04/22/2023 04:45:45 PM - INFO - [89:18] loss\t12.40 =\tBCE 12.39953 \tLL 0.01159 \tTotal 238.91/30.79/3.63 \n","04/22/2023 04:45:45 PM - INFO - EVALUATION prior to epoch [90]...\n","04/22/2023 04:45:45 PM - INFO - [90] loss\t11.19=\tBCE 11.19 \tLL 0.01086 \n","04/22/2023 04:45:46 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/90_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:45:52 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/90_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:45:57 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/90_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 04:45:58 PM - INFO - Training epoch 90.\n","04/22/2023 04:45:58 PM - INFO - [90:0] loss\t12.52 =\tBCE 12.51703 \tLL 0.01163 \tTotal 266.89/36.49/3.96 \n","04/22/2023 04:45:59 PM - INFO - [90:1] loss\t12.39 =\tBCE 12.39265 \tLL 0.01186 \tTotal 231.17/30.63/3.77 \n","04/22/2023 04:46:00 PM - INFO - [90:2] loss\t12.36 =\tBCE 12.35769 \tLL 0.01165 \tTotal 289.24/36.47/0.95 \n","04/22/2023 04:46:00 PM - INFO - [90:3] loss\t12.23 =\tBCE 12.22584 \tLL 0.01127 \tTotal 315.64/57.66/2.33 \n","04/22/2023 04:46:01 PM - INFO - [90:4] loss\t12.16 =\tBCE 12.16434 \tLL 0.01173 \tTotal 199.54/66.29/6.53 \n","04/22/2023 04:46:01 PM - INFO - [90:5] loss\t12.33 =\tBCE 12.32662 \tLL 0.01168 \tTotal 209.78/45.45/1.43 \n","04/22/2023 04:46:02 PM - INFO - [90:6] loss\t12.19 =\tBCE 12.18673 \tLL 0.01141 \tTotal 278.06/36.48/2.47 \n","04/22/2023 04:46:02 PM - INFO - [90:7] loss\t12.12 =\tBCE 12.11598 \tLL 0.01136 \tTotal 190.85/28.24/1.40 \n","04/22/2023 04:46:03 PM - INFO - [90:8] loss\t12.10 =\tBCE 12.09671 \tLL 0.01121 \tTotal 219.54/32.52/4.66 \n","04/22/2023 04:46:03 PM - INFO - [90:9] loss\t11.93 =\tBCE 11.92714 \tLL 0.01137 \tTotal 242.53/29.82/1.68 \n","04/22/2023 04:46:04 PM - INFO - [90:10] loss\t12.01 =\tBCE 12.01465 \tLL 0.01152 \tTotal 248.57/41.33/3.52 \n","04/22/2023 04:46:04 PM - INFO - [90:11] loss\t12.25 =\tBCE 12.24923 \tLL 0.01166 \tTotal 182.87/44.31/5.13 \n","04/22/2023 04:46:05 PM - INFO - [90:12] loss\t12.21 =\tBCE 12.21307 \tLL 0.01169 \tTotal 213.78/51.37/2.16 \n","04/22/2023 04:46:05 PM - INFO - [90:13] loss\t11.92 =\tBCE 11.92181 \tLL 0.01119 \tTotal 236.15/34.26/1.68 \n","04/22/2023 04:46:06 PM - INFO - [90:14] loss\t12.02 =\tBCE 12.01638 \tLL 0.01127 \tTotal 327.06/45.26/1.84 \n","04/22/2023 04:46:06 PM - INFO - [90:15] loss\t12.35 =\tBCE 12.34781 \tLL 0.01179 \tTotal 509.88/56.69/4.23 \n","04/22/2023 04:46:07 PM - INFO - [90:16] loss\t11.81 =\tBCE 11.80587 \tLL 0.01119 \tTotal 425.09/62.25/5.26 \n","04/22/2023 04:46:07 PM - INFO - [90:17] loss\t12.10 =\tBCE 12.09944 \tLL 0.01113 \tTotal 545.85/83.41/4.49 \n","04/22/2023 04:46:08 PM - INFO - [90:18] loss\t11.79 =\tBCE 11.79025 \tLL 0.01118 \tTotal 520.60/69.67/3.08 \n","04/22/2023 04:46:08 PM - INFO - Training epoch 91.\n","04/22/2023 04:46:09 PM - INFO - [91:0] loss\t11.98 =\tBCE 11.98076 \tLL 0.01129 \tTotal 120.39/30.67/2.44 \n","04/22/2023 04:46:09 PM - INFO - [91:1] loss\t11.91 =\tBCE 11.90800 \tLL 0.01126 \tTotal 493.90/65.14/5.91 \n","04/22/2023 04:46:10 PM - INFO - [91:2] loss\t11.91 =\tBCE 11.91446 \tLL 0.01117 \tTotal 597.67/83.32/3.07 \n","04/22/2023 04:46:10 PM - INFO - [91:3] loss\t11.81 =\tBCE 11.80970 \tLL 0.01129 \tTotal 241.76/35.18/4.31 \n","04/22/2023 04:46:11 PM - INFO - [91:4] loss\t11.96 =\tBCE 11.95903 \tLL 0.01121 \tTotal 431.53/57.99/2.61 \n","04/22/2023 04:46:11 PM - INFO - [91:5] loss\t11.80 =\tBCE 11.79883 \tLL 0.01134 \tTotal 571.40/65.49/3.47 \n","04/22/2023 04:46:12 PM - INFO - [91:6] loss\t11.71 =\tBCE 11.71316 \tLL 0.01145 \tTotal 298.78/42.20/7.92 \n","04/22/2023 04:46:12 PM - INFO - [91:7] loss\t11.87 =\tBCE 11.87026 \tLL 0.01133 \tTotal 518.19/63.88/4.11 \n","04/22/2023 04:46:13 PM - INFO - [91:8] loss\t11.74 =\tBCE 11.74063 \tLL 0.01137 \tTotal 462.22/56.92/2.85 \n","04/22/2023 04:46:13 PM - INFO - [91:9] loss\t11.90 =\tBCE 11.89944 \tLL 0.01149 \tTotal 333.45/60.89/2.86 \n","04/22/2023 04:46:14 PM - INFO - [91:10] loss\t11.82 =\tBCE 11.82442 \tLL 0.01122 \tTotal 585.71/94.74/4.61 \n","04/22/2023 04:46:14 PM - INFO - [91:11] loss\t11.92 =\tBCE 11.92003 \tLL 0.01121 \tTotal 575.39/106.62/6.62 \n","04/22/2023 04:46:15 PM - INFO - [91:12] loss\t11.84 =\tBCE 11.84255 \tLL 0.01122 \tTotal 337.77/72.98/2.52 \n","04/22/2023 04:46:15 PM - INFO - [91:13] loss\t11.53 =\tBCE 11.52885 \tLL 0.01101 \tTotal 192.18/36.48/1.42 \n","04/22/2023 04:46:16 PM - INFO - [91:14] loss\t11.50 =\tBCE 11.49691 \tLL 0.01118 \tTotal 263.38/40.11/4.52 \n","04/22/2023 04:46:16 PM - INFO - [91:15] loss\t11.53 =\tBCE 11.52706 \tLL 0.01093 \tTotal 396.15/77.55/6.73 \n","04/22/2023 04:46:17 PM - INFO - [91:16] loss\t11.55 =\tBCE 11.54570 \tLL 0.01090 \tTotal 456.22/106.49/4.49 \n","04/22/2023 04:46:18 PM - INFO - [91:17] loss\t11.55 =\tBCE 11.55301 \tLL 0.01093 \tTotal 458.19/104.17/1.16 \n","04/22/2023 04:46:18 PM - INFO - [91:18] loss\t11.53 =\tBCE 11.52715 \tLL 0.01106 \tTotal 307.04/79.39/2.42 \n","04/22/2023 04:46:18 PM - INFO - Training epoch 92.\n","04/22/2023 04:46:19 PM - INFO - [92:0] loss\t11.31 =\tBCE 11.30936 \tLL 0.01102 \tTotal 297.12/39.48/2.84 \n","04/22/2023 04:46:19 PM - INFO - [92:1] loss\t11.33 =\tBCE 11.33248 \tLL 0.01095 \tTotal 449.76/91.28/4.41 \n","04/22/2023 04:46:20 PM - INFO - [92:2] loss\t11.54 =\tBCE 11.54283 \tLL 0.01109 \tTotal 492.40/127.17/3.88 \n","04/22/2023 04:46:20 PM - INFO - [92:3] loss\t11.52 =\tBCE 11.51957 \tLL 0.01115 \tTotal 335.48/78.86/4.90 \n","04/22/2023 04:46:21 PM - INFO - [92:4] loss\t11.47 =\tBCE 11.46512 \tLL 0.01097 \tTotal 507.14/58.69/1.86 \n","04/22/2023 04:46:21 PM - INFO - [92:5] loss\t11.57 =\tBCE 11.56911 \tLL 0.01103 \tTotal 584.39/72.42/2.92 \n","04/22/2023 04:46:22 PM - INFO - [92:6] loss\t11.30 =\tBCE 11.29689 \tLL 0.01078 \tTotal 346.74/46.37/1.75 \n","04/22/2023 04:46:22 PM - INFO - [92:7] loss\t11.40 =\tBCE 11.40299 \tLL 0.01132 \tTotal 246.91/38.51/3.84 \n","04/22/2023 04:46:23 PM - INFO - [92:8] loss\t11.62 =\tBCE 11.62285 \tLL 0.01125 \tTotal 498.79/61.23/4.95 \n","04/22/2023 04:46:24 PM - INFO - [92:9] loss\t11.50 =\tBCE 11.49872 \tLL 0.01094 \tTotal 368.33/50.45/1.47 \n","04/22/2023 04:46:24 PM - INFO - [92:10] loss\t11.33 =\tBCE 11.33025 \tLL 0.01097 \tTotal 142.21/21.95/1.15 \n","04/22/2023 04:46:25 PM - INFO - [92:11] loss\t11.29 =\tBCE 11.29016 \tLL 0.01072 \tTotal 356.71/49.09/4.10 \n","04/22/2023 04:46:25 PM - INFO - [92:12] loss\t11.40 =\tBCE 11.39954 \tLL 0.01107 \tTotal 443.05/55.49/4.31 \n","04/22/2023 04:46:26 PM - INFO - [92:13] loss\t11.12 =\tBCE 11.11586 \tLL 0.01050 \tTotal 194.05/43.81/4.59 \n","04/22/2023 04:46:26 PM - INFO - [92:14] loss\t11.46 =\tBCE 11.45816 \tLL 0.01099 \tTotal 304.12/45.39/1.26 \n","04/22/2023 04:46:27 PM - INFO - [92:15] loss\t11.12 =\tBCE 11.11612 \tLL 0.01077 \tTotal 409.43/47.73/1.24 \n","04/22/2023 04:46:27 PM - INFO - [92:16] loss\t11.10 =\tBCE 11.10392 \tLL 0.01095 \tTotal 373.60/55.05/3.70 \n","04/22/2023 04:46:28 PM - INFO - [92:17] loss\t11.28 =\tBCE 11.27742 \tLL 0.01109 \tTotal 182.13/31.35/6.06 \n","04/22/2023 04:46:28 PM - INFO - [92:18] loss\t11.32 =\tBCE 11.32189 \tLL 0.01082 \tTotal 302.29/41.83/1.54 \n","04/22/2023 04:46:28 PM - INFO - Training epoch 93.\n","04/22/2023 04:46:29 PM - INFO - [93:0] loss\t11.26 =\tBCE 11.26150 \tLL 0.01097 \tTotal 614.08/83.71/0.92 \n","04/22/2023 04:46:29 PM - INFO - [93:1] loss\t11.36 =\tBCE 11.35514 \tLL 0.01108 \tTotal 624.12/105.43/5.40 \n","04/22/2023 04:46:30 PM - INFO - [93:2] loss\t11.42 =\tBCE 11.42280 \tLL 0.01082 \tTotal 609.11/143.02/3.88 \n","04/22/2023 04:46:30 PM - INFO - [93:3] loss\t11.22 =\tBCE 11.21846 \tLL 0.01065 \tTotal 800.04/201.87/2.87 \n","04/22/2023 04:46:31 PM - INFO - [93:4] loss\t11.22 =\tBCE 11.22369 \tLL 0.01071 \tTotal 797.39/211.45/2.01 \n","04/22/2023 04:46:32 PM - INFO - [93:5] loss\t11.34 =\tBCE 11.34409 \tLL 0.01083 \tTotal 800.28/165.53/3.12 \n","04/22/2023 04:46:32 PM - INFO - [93:6] loss\t11.59 =\tBCE 11.59221 \tLL 0.01068 \tTotal 1068.11/149.81/2.28 \n","04/22/2023 04:46:33 PM - INFO - [93:7] loss\t11.14 =\tBCE 11.13791 \tLL 0.01071 \tTotal 1048.49/150.59/5.15 \n","04/22/2023 04:46:33 PM - INFO - [93:8] loss\t11.19 =\tBCE 11.19307 \tLL 0.01077 \tTotal 595.32/171.45/3.03 \n","04/22/2023 04:46:34 PM - INFO - [93:9] loss\t11.15 =\tBCE 11.15273 \tLL 0.01081 \tTotal 616.37/178.52/1.74 \n","04/22/2023 04:46:34 PM - INFO - [93:10] loss\t10.97 =\tBCE 10.96853 \tLL 0.01052 \tTotal 834.31/146.65/1.27 \n","04/22/2023 04:46:35 PM - INFO - [93:11] loss\t11.03 =\tBCE 11.02548 \tLL 0.01063 \tTotal 643.47/124.98/1.00 \n","04/22/2023 04:46:35 PM - INFO - [93:12] loss\t11.17 =\tBCE 11.16864 \tLL 0.01089 \tTotal 707.18/188.44/4.79 \n","04/22/2023 04:46:36 PM - INFO - [93:13] loss\t11.51 =\tBCE 11.51393 \tLL 0.01101 \tTotal 987.96/229.48/5.26 \n","04/22/2023 04:46:36 PM - INFO - [93:14] loss\t11.75 =\tBCE 11.74897 \tLL 0.01062 \tTotal 1434.07/271.80/6.56 \n","04/22/2023 04:46:37 PM - INFO - [93:15] loss\t12.66 =\tBCE 12.65900 \tLL 0.01089 \tTotal 1898.40/400.36/0.77 \n","04/22/2023 04:46:38 PM - INFO - [93:16] loss\t13.49 =\tBCE 13.49300 \tLL 0.01066 \tTotal 2336.75/626.58/5.09 \n","04/22/2023 04:46:38 PM - INFO - [93:17] loss\t17.30 =\tBCE 17.30260 \tLL 0.01070 \tTotal 3369.81/945.28/5.22 \n","04/22/2023 04:46:39 PM - INFO - [93:18] loss\t25.05 =\tBCE 25.05392 \tLL 0.01010 \tTotal 6491.78/1500.12/6.67 \n","04/22/2023 04:46:39 PM - INFO - Training epoch 94.\n","04/22/2023 04:46:39 PM - INFO - [94:0] loss\t57.07 =\tBCE 57.06515 \tLL 0.01180 \tTotal 8941.06/2560.30/4.91 \n","04/22/2023 04:46:40 PM - INFO - [94:1] loss\t82.19 =\tBCE 82.18684 \tLL 0.01043 \tTotal 13971.42/3902.29/3.53 \n","04/22/2023 04:46:40 PM - INFO - [94:2] loss\t257.64 =\tBCE 257.63855 \tLL 0.01384 \tTotal 14378.40/5415.27/6.16 \n","04/22/2023 04:46:41 PM - INFO - [94:3] loss\t131.06 =\tBCE 131.06198 \tLL 0.01404 \tTotal 12103.39/4367.41/7.37 \n","04/22/2023 04:46:41 PM - INFO - [94:4] loss\t68.06 =\tBCE 68.06142 \tLL 0.01287 \tTotal 10427.20/1371.04/5.35 \n","04/22/2023 04:46:42 PM - INFO - [94:5] loss\t91.76 =\tBCE 91.75550 \tLL 0.01468 \tTotal 9523.44/3052.19/4.80 \n","04/22/2023 04:46:42 PM - INFO - [94:6] loss\t82.23 =\tBCE 82.23186 \tLL 0.01499 \tTotal 7643.53/2689.10/2.96 \n","04/22/2023 04:46:43 PM - INFO - [94:7] loss\t73.30 =\tBCE 73.30284 \tLL 0.01348 \tTotal 14892.21/1558.80/11.26 \n","04/22/2023 04:46:43 PM - INFO - [94:8] loss\t102.23 =\tBCE 102.23074 \tLL 0.01486 \tTotal 15211.18/2640.55/7.22 \n","04/22/2023 04:46:44 PM - INFO - [94:9] loss\t49.36 =\tBCE 49.36179 \tLL 0.01580 \tTotal 9482.78/1275.37/3.13 \n","04/22/2023 04:46:44 PM - INFO - [94:10] loss\t64.81 =\tBCE 64.81139 \tLL 0.01551 \tTotal 9246.43/1768.98/9.29 \n","04/22/2023 04:46:45 PM - INFO - [94:11] loss\t41.22 =\tBCE 41.22025 \tLL 0.01632 \tTotal 6513.71/1230.38/4.31 \n","04/22/2023 04:46:45 PM - INFO - [94:12] loss\t49.91 =\tBCE 49.90675 \tLL 0.01691 \tTotal 9598.86/1336.23/1.78 \n","04/22/2023 04:46:46 PM - INFO - [94:13] loss\t51.28 =\tBCE 51.28478 \tLL 0.01730 \tTotal 8449.22/1419.23/3.88 \n","04/22/2023 04:46:46 PM - INFO - [94:14] loss\t31.75 =\tBCE 31.74635 \tLL 0.01651 \tTotal 5571.00/670.14/4.47 \n","04/22/2023 04:46:47 PM - INFO - [94:15] loss\t50.17 =\tBCE 50.16850 \tLL 0.01706 \tTotal 8784.08/1290.07/3.53 \n","04/22/2023 04:46:48 PM - INFO - [94:16] loss\t24.94 =\tBCE 24.93838 \tLL 0.01801 \tTotal 3629.28/419.43/3.09 \n","04/22/2023 04:46:48 PM - INFO - [94:17] loss\t49.89 =\tBCE 49.89186 \tLL 0.01760 \tTotal 9597.59/1210.83/3.58 \n","04/22/2023 04:46:49 PM - INFO - [94:18] loss\t26.69 =\tBCE 26.68584 \tLL 0.01732 \tTotal 4166.31/397.50/1.84 \n","04/22/2023 04:46:49 PM - INFO - Training epoch 95.\n","04/22/2023 04:46:49 PM - INFO - [95:0] loss\t40.22 =\tBCE 40.22262 \tLL 0.01782 \tTotal 7973.70/959.21/1.61 \n","04/22/2023 04:46:50 PM - INFO - [95:1] loss\t27.30 =\tBCE 27.29543 \tLL 0.01865 \tTotal 3981.00/454.10/2.71 \n","04/22/2023 04:46:50 PM - INFO - [95:2] loss\t33.08 =\tBCE 33.07846 \tLL 0.01825 \tTotal 6255.35/698.44/4.10 \n","04/22/2023 04:46:51 PM - INFO - [95:3] loss\t23.80 =\tBCE 23.79731 \tLL 0.01727 \tTotal 2792.79/373.19/4.76 \n","04/22/2023 04:46:51 PM - INFO - [95:4] loss\t32.59 =\tBCE 32.58685 \tLL 0.01717 \tTotal 5350.53/712.32/5.93 \n","04/22/2023 04:46:52 PM - INFO - [95:5] loss\t20.22 =\tBCE 20.22430 \tLL 0.01696 \tTotal 2459.57/267.78/1.74 \n","04/22/2023 04:46:52 PM - INFO - [95:6] loss\t32.49 =\tBCE 32.48513 \tLL 0.01685 \tTotal 5820.42/723.50/11.18 \n","04/22/2023 04:46:53 PM - INFO - [95:7] loss\t20.51 =\tBCE 20.50693 \tLL 0.01624 \tTotal 2316.10/285.04/8.08 \n","04/22/2023 04:46:53 PM - INFO - [95:8] loss\t27.44 =\tBCE 27.43537 \tLL 0.01584 \tTotal 4445.35/581.34/3.56 \n","04/22/2023 04:46:54 PM - INFO - [95:9] loss\t18.94 =\tBCE 18.94494 \tLL 0.01680 \tTotal 1644.35/201.67/8.32 \n","04/22/2023 04:46:54 PM - INFO - [95:10] loss\t24.44 =\tBCE 24.43559 \tLL 0.01684 \tTotal 4411.08/613.16/5.83 \n","04/22/2023 04:46:55 PM - INFO - [95:11] loss\t19.19 =\tBCE 19.18826 \tLL 0.01644 \tTotal 2109.48/235.51/1.75 \n","04/22/2023 04:46:56 PM - INFO - [95:12] loss\t23.08 =\tBCE 23.08493 \tLL 0.01663 \tTotal 3079.61/557.09/2.74 \n","04/22/2023 04:46:56 PM - INFO - [95:13] loss\t19.98 =\tBCE 19.98294 \tLL 0.01608 \tTotal 2338.34/318.06/5.77 \n","04/22/2023 04:46:57 PM - INFO - [95:14] loss\t18.69 =\tBCE 18.69465 \tLL 0.01676 \tTotal 1521.00/421.22/4.93 \n","04/22/2023 04:46:57 PM - INFO - [95:15] loss\t20.42 =\tBCE 20.42206 \tLL 0.01676 \tTotal 2475.05/421.64/7.73 \n","04/22/2023 04:46:58 PM - INFO - [95:16] loss\t18.23 =\tBCE 18.22879 \tLL 0.01619 \tTotal 1224.52/353.10/2.60 \n","04/22/2023 04:46:58 PM - INFO - [95:17] loss\t19.46 =\tBCE 19.46110 \tLL 0.01526 \tTotal 1898.62/442.09/5.56 \n","04/22/2023 04:46:59 PM - INFO - [95:18] loss\t18.17 =\tBCE 18.17182 \tLL 0.01548 \tTotal 1647.66/285.86/6.49 \n","04/22/2023 04:46:59 PM - INFO - Training epoch 96.\n","04/22/2023 04:46:59 PM - INFO - [96:0] loss\t18.19 =\tBCE 18.18723 \tLL 0.01595 \tTotal 1394.51/437.09/6.34 \n","04/22/2023 04:47:00 PM - INFO - [96:1] loss\t17.28 =\tBCE 17.28403 \tLL 0.01545 \tTotal 1845.43/205.48/5.29 \n","04/22/2023 04:47:00 PM - INFO - [96:2] loss\t17.55 =\tBCE 17.55153 \tLL 0.01539 \tTotal 1073.89/402.42/3.81 \n","04/22/2023 04:47:01 PM - INFO - [96:3] loss\t16.89 =\tBCE 16.89450 \tLL 0.01514 \tTotal 1733.93/197.62/9.86 \n","04/22/2023 04:47:01 PM - INFO - [96:4] loss\t17.08 =\tBCE 17.08131 \tLL 0.01518 \tTotal 918.10/341.65/10.60 \n","04/22/2023 04:47:02 PM - INFO - [96:5] loss\t16.20 =\tBCE 16.19975 \tLL 0.01532 \tTotal 1376.68/184.06/6.06 \n","04/22/2023 04:47:02 PM - INFO - [96:6] loss\t16.84 =\tBCE 16.83562 \tLL 0.01541 \tTotal 1015.63/262.01/5.66 \n","04/22/2023 04:47:03 PM - INFO - [96:7] loss\t15.95 =\tBCE 15.94655 \tLL 0.01487 \tTotal 1284.53/201.18/9.93 \n","04/22/2023 04:47:03 PM - INFO - [96:8] loss\t16.45 =\tBCE 16.44939 \tLL 0.01473 \tTotal 1360.66/233.06/3.17 \n","04/22/2023 04:47:04 PM - INFO - [96:9] loss\t15.48 =\tBCE 15.47585 \tLL 0.01421 \tTotal 1084.49/202.61/4.50 \n","04/22/2023 04:47:04 PM - INFO - [96:10] loss\t16.04 =\tBCE 16.03883 \tLL 0.01490 \tTotal 1081.70/161.53/5.23 \n","04/22/2023 04:47:05 PM - INFO - [96:11] loss\t15.89 =\tBCE 15.89230 \tLL 0.01504 \tTotal 963.73/194.69/5.79 \n","04/22/2023 04:47:06 PM - INFO - [96:12] loss\t14.95 =\tBCE 14.95378 \tLL 0.01424 \tTotal 908.99/114.65/3.64 \n","04/22/2023 04:47:06 PM - INFO - [96:13] loss\t15.54 =\tBCE 15.53780 \tLL 0.01434 \tTotal 1058.03/190.35/1.56 \n","04/22/2023 04:47:07 PM - INFO - [96:14] loss\t14.96 =\tBCE 14.96190 \tLL 0.01433 \tTotal 906.07/98.95/5.42 \n","04/22/2023 04:47:07 PM - INFO - [96:15] loss\t15.16 =\tBCE 15.16289 \tLL 0.01458 \tTotal 944.53/148.17/4.07 \n","04/22/2023 04:47:08 PM - INFO - [96:16] loss\t14.92 =\tBCE 14.92344 \tLL 0.01424 \tTotal 1034.61/117.13/7.77 \n","04/22/2023 04:47:08 PM - INFO - [96:17] loss\t15.13 =\tBCE 15.12733 \tLL 0.01392 \tTotal 1223.71/151.61/6.93 \n","04/22/2023 04:47:09 PM - INFO - [96:18] loss\t14.61 =\tBCE 14.60955 \tLL 0.01374 \tTotal 727.26/108.61/4.08 \n","04/22/2023 04:47:09 PM - INFO - Training epoch 97.\n","04/22/2023 04:47:09 PM - INFO - [97:0] loss\t14.80 =\tBCE 14.79549 \tLL 0.01401 \tTotal 921.83/132.89/6.19 \n","04/22/2023 04:47:10 PM - INFO - [97:1] loss\t14.83 =\tBCE 14.82681 \tLL 0.01431 \tTotal 718.25/122.00/7.11 \n","04/22/2023 04:47:10 PM - INFO - [97:2] loss\t14.18 =\tBCE 14.17517 \tLL 0.01343 \tTotal 821.95/110.41/8.32 \n","04/22/2023 04:47:11 PM - INFO - [97:3] loss\t14.47 =\tBCE 14.47365 \tLL 0.01365 \tTotal 681.79/139.51/4.58 \n","04/22/2023 04:47:11 PM - INFO - [97:4] loss\t13.89 =\tBCE 13.88717 \tLL 0.01336 \tTotal 542.87/69.38/6.18 \n","04/22/2023 04:47:12 PM - INFO - [97:5] loss\t14.38 =\tBCE 14.38178 \tLL 0.01398 \tTotal 687.93/134.42/9.64 \n","04/22/2023 04:47:12 PM - INFO - [97:6] loss\t13.86 =\tBCE 13.85550 \tLL 0.01394 \tTotal 335.74/45.34/3.36 \n","04/22/2023 04:47:13 PM - INFO - [97:7] loss\t14.13 =\tBCE 14.12942 \tLL 0.01361 \tTotal 691.09/146.14/3.21 \n","04/22/2023 04:47:13 PM - INFO - [97:8] loss\t13.96 =\tBCE 13.96298 \tLL 0.01368 \tTotal 181.32/49.55/5.15 \n","04/22/2023 04:47:14 PM - INFO - [97:9] loss\t13.75 =\tBCE 13.74509 \tLL 0.01322 \tTotal 566.27/122.81/7.86 \n","04/22/2023 04:47:14 PM - INFO - [97:10] loss\t13.70 =\tBCE 13.70309 \tLL 0.01345 \tTotal 241.87/58.29/4.45 \n","04/22/2023 04:47:15 PM - INFO - [97:11] loss\t13.91 =\tBCE 13.90835 \tLL 0.01338 \tTotal 428.54/95.67/4.21 \n","04/22/2023 04:47:15 PM - INFO - [97:12] loss\t13.26 =\tBCE 13.26297 \tLL 0.01311 \tTotal 315.42/62.77/3.74 \n","04/22/2023 04:47:16 PM - INFO - [97:13] loss\t13.71 =\tBCE 13.70510 \tLL 0.01324 \tTotal 356.15/76.61/7.37 \n","04/22/2023 04:47:17 PM - INFO - [97:14] loss\t13.47 =\tBCE 13.46930 \tLL 0.01314 \tTotal 311.69/61.66/2.98 \n","04/22/2023 04:47:17 PM - INFO - [97:15] loss\t13.12 =\tBCE 13.12201 \tLL 0.01284 \tTotal 351.24/77.09/2.85 \n","04/22/2023 04:47:18 PM - INFO - [97:16] loss\t13.55 =\tBCE 13.54513 \tLL 0.01347 \tTotal 304.78/71.59/2.75 \n","04/22/2023 04:47:18 PM - INFO - [97:17] loss\t13.51 =\tBCE 13.50766 \tLL 0.01336 \tTotal 405.01/73.84/5.41 \n","04/22/2023 04:47:19 PM - INFO - [97:18] loss\t13.41 =\tBCE 13.41188 \tLL 0.01313 \tTotal 403.91/54.31/7.10 \n","04/22/2023 04:47:19 PM - INFO - Training epoch 98.\n","04/22/2023 04:47:19 PM - INFO - [98:0] loss\t13.10 =\tBCE 13.10393 \tLL 0.01267 \tTotal 341.34/74.86/2.26 \n","04/22/2023 04:47:20 PM - INFO - [98:1] loss\t13.27 =\tBCE 13.26658 \tLL 0.01282 \tTotal 474.42/63.95/3.10 \n","04/22/2023 04:47:20 PM - INFO - [98:2] loss\t13.06 =\tBCE 13.05932 \tLL 0.01279 \tTotal 225.41/75.56/4.63 \n","04/22/2023 04:47:21 PM - INFO - [98:3] loss\t13.27 =\tBCE 13.27477 \tLL 0.01312 \tTotal 414.04/60.14/6.58 \n","04/22/2023 04:47:21 PM - INFO - [98:4] loss\t12.93 =\tBCE 12.92657 \tLL 0.01238 \tTotal 267.13/76.34/2.75 \n","04/22/2023 04:47:22 PM - INFO - [98:5] loss\t13.32 =\tBCE 13.32148 \tLL 0.01290 \tTotal 660.25/84.53/3.48 \n","04/22/2023 04:47:22 PM - INFO - [98:6] loss\t12.95 =\tBCE 12.94519 \tLL 0.01274 \tTotal 387.15/84.85/4.95 \n","04/22/2023 04:47:23 PM - INFO - [98:7] loss\t12.93 =\tBCE 12.92849 \tLL 0.01285 \tTotal 398.09/60.54/2.36 \n","04/22/2023 04:47:23 PM - INFO - [98:8] loss\t12.86 =\tBCE 12.85719 \tLL 0.01235 \tTotal 631.31/94.03/3.13 \n","04/22/2023 04:47:24 PM - INFO - [98:9] loss\t12.96 =\tBCE 12.96253 \tLL 0.01265 \tTotal 292.87/46.84/8.63 \n","04/22/2023 04:47:24 PM - INFO - [98:10] loss\t13.10 =\tBCE 13.09572 \tLL 0.01281 \tTotal 751.64/85.91/5.88 \n","04/22/2023 04:47:25 PM - INFO - [98:11] loss\t12.70 =\tBCE 12.70127 \tLL 0.01234 \tTotal 375.23/50.48/2.27 \n","04/22/2023 04:47:25 PM - INFO - [98:12] loss\t12.87 =\tBCE 12.86969 \tLL 0.01263 \tTotal 450.01/58.87/4.77 \n","04/22/2023 04:47:26 PM - INFO - [98:13] loss\t12.74 =\tBCE 12.73559 \tLL 0.01220 \tTotal 532.19/63.87/3.63 \n","04/22/2023 04:47:27 PM - INFO - [98:14] loss\t12.65 =\tBCE 12.65237 \tLL 0.01263 \tTotal 225.15/37.94/6.65 \n","04/22/2023 04:47:27 PM - INFO - [98:15] loss\t12.70 =\tBCE 12.69548 \tLL 0.01243 \tTotal 583.50/69.93/1.28 \n","04/22/2023 04:47:28 PM - INFO - [98:16] loss\t12.68 =\tBCE 12.68210 \tLL 0.01235 \tTotal 330.60/53.90/2.05 \n","04/22/2023 04:47:28 PM - INFO - [98:17] loss\t12.50 =\tBCE 12.49914 \tLL 0.01234 \tTotal 448.94/51.91/2.32 \n","04/22/2023 04:47:29 PM - INFO - [98:18] loss\t12.53 =\tBCE 12.53427 \tLL 0.01226 \tTotal 501.58/57.16/4.61 \n","Not implemented\n","04/22/2023 04:47:29 PM - INFO - Training epoch 99.\n","04/22/2023 04:47:29 PM - INFO - [99:0] loss\t12.61 =\tBCE 12.61074 \tLL 0.01243 \tTotal 182.19/21.93/3.98 \n","04/22/2023 04:47:30 PM - INFO - [99:1] loss\t12.48 =\tBCE 12.47887 \tLL 0.01225 \tTotal 694.40/75.06/2.50 \n","04/22/2023 04:47:30 PM - INFO - [99:2] loss\t12.50 =\tBCE 12.50389 \tLL 0.01216 \tTotal 462.33/55.31/6.19 \n","04/22/2023 04:47:31 PM - INFO - [99:3] loss\t12.38 =\tBCE 12.37715 \tLL 0.01238 \tTotal 185.12/25.54/5.39 \n","04/22/2023 04:47:31 PM - INFO - [99:4] loss\t12.24 =\tBCE 12.23737 \tLL 0.01197 \tTotal 488.97/56.27/3.52 \n","04/22/2023 04:47:32 PM - INFO - [99:5] loss\t12.24 =\tBCE 12.23882 \tLL 0.01180 \tTotal 302.01/40.65/5.21 \n","04/22/2023 04:47:32 PM - INFO - [99:6] loss\t12.32 =\tBCE 12.31697 \tLL 0.01202 \tTotal 233.87/36.16/1.28 \n","04/22/2023 04:47:33 PM - INFO - [99:7] loss\t12.10 =\tBCE 12.10032 \tLL 0.01189 \tTotal 362.92/45.30/4.44 \n","04/22/2023 04:47:33 PM - INFO - [99:8] loss\t12.10 =\tBCE 12.10428 \tLL 0.01179 \tTotal 180.96/29.28/4.74 \n","04/22/2023 04:47:34 PM - INFO - [99:9] loss\t12.25 =\tBCE 12.25069 \tLL 0.01194 \tTotal 376.00/42.13/1.13 \n","04/22/2023 04:47:35 PM - INFO - [99:10] loss\t12.22 =\tBCE 12.21507 \tLL 0.01199 \tTotal 336.40/44.06/1.55 \n","04/22/2023 04:47:35 PM - INFO - [99:11] loss\t12.01 =\tBCE 12.01471 \tLL 0.01192 \tTotal 156.28/24.33/1.40 \n","04/22/2023 04:47:36 PM - INFO - [99:12] loss\t12.03 =\tBCE 12.03129 \tLL 0.01182 \tTotal 219.48/32.98/2.15 \n","04/22/2023 04:47:36 PM - INFO - [99:13] loss\t12.35 =\tBCE 12.34912 \tLL 0.01163 \tTotal 197.60/31.23/1.41 \n","04/22/2023 04:47:37 PM - INFO - [99:14] loss\t11.81 =\tBCE 11.80887 \tLL 0.01126 \tTotal 250.26/36.73/1.70 \n","04/22/2023 04:47:37 PM - INFO - [99:15] loss\t11.96 =\tBCE 11.95748 \tLL 0.01161 \tTotal 345.28/35.01/3.06 \n","04/22/2023 04:47:38 PM - INFO - [99:16] loss\t12.04 =\tBCE 12.03852 \tLL 0.01183 \tTotal 137.44/43.55/2.88 \n","04/22/2023 04:47:38 PM - INFO - [99:17] loss\t11.97 =\tBCE 11.96864 \tLL 0.01181 \tTotal 360.76/36.59/2.82 \n","04/22/2023 04:47:39 PM - INFO - [99:18] loss\t11.94 =\tBCE 11.94355 \tLL 0.01179 \tTotal 349.38/55.17/0.75 \n","04/22/2023 04:47:39 PM - INFO - EVALUATION prior to epoch [100]...\n","04/22/2023 04:47:39 PM - INFO - [100] loss\t10.48=\tBCE 10.48 \tLL 0.01068 \n","04/22/2023 04:47:40 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/100_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:47:45 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/100_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 04:47:51 PM - INFO - Figure saved ./out/run_2023-04-22_16-28-30/figures/100_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 04:47:51 PM - INFO - Training epoch 100.\n","04/22/2023 04:47:52 PM - INFO - [100:0] loss\t11.67 =\tBCE 11.67084 \tLL 0.01132 \tTotal 238.18/46.54/4.50 \n","04/22/2023 04:47:52 PM - INFO - [100:1] loss\t11.97 =\tBCE 11.97164 \tLL 0.01125 \tTotal 430.04/52.66/4.49 \n","04/22/2023 04:47:53 PM - INFO - [100:2] loss\t12.03 =\tBCE 12.02969 \tLL 0.01164 \tTotal 359.90/47.35/4.47 \n","04/22/2023 04:47:53 PM - INFO - [100:3] loss\t11.56 =\tBCE 11.56257 \tLL 0.01138 \tTotal 242.87/30.63/1.17 \n","04/22/2023 04:47:54 PM - INFO - [100:4] loss\t11.86 =\tBCE 11.86466 \tLL 0.01174 \tTotal 531.97/57.59/2.25 \n","04/22/2023 04:47:55 PM - INFO - [100:5] loss\t11.76 =\tBCE 11.75705 \tLL 0.01152 \tTotal 406.07/47.22/3.56 \n","04/22/2023 04:47:55 PM - INFO - [100:6] loss\t11.98 =\tBCE 11.97522 \tLL 0.01187 \tTotal 255.94/30.48/4.80 \n","04/22/2023 04:47:56 PM - INFO - [100:7] loss\t11.67 =\tBCE 11.67447 \tLL 0.01132 \tTotal 519.81/61.83/4.92 \n","04/22/2023 04:47:56 PM - INFO - [100:8] loss\t11.80 =\tBCE 11.80234 \tLL 0.01178 \tTotal 250.09/28.57/2.83 \n","04/22/2023 04:47:57 PM - INFO - [100:9] loss\t11.65 =\tBCE 11.65252 \tLL 0.01126 \tTotal 373.47/44.77/2.89 \n","04/22/2023 04:47:57 PM - INFO - [100:10] loss\t11.75 =\tBCE 11.75113 \tLL 0.01153 \tTotal 515.07/59.47/5.23 \n","04/22/2023 04:47:58 PM - INFO - [100:11] loss\t11.58 =\tBCE 11.57874 \tLL 0.01143 \tTotal 272.70/28.37/2.49 \n","04/22/2023 04:47:58 PM - INFO - [100:12] loss\t11.68 =\tBCE 11.67504 \tLL 0.01161 \tTotal 330.61/41.39/1.81 \n","04/22/2023 04:47:59 PM - INFO - [100:13] loss\t11.48 =\tBCE 11.47507 \tLL 0.01135 \tTotal 538.51/59.18/2.33 \n","04/22/2023 04:47:59 PM - INFO - [100:14] loss\t11.30 =\tBCE 11.30106 \tLL 0.01139 \tTotal 177.38/20.31/8.36 \n","04/22/2023 04:48:00 PM - INFO - [100:15] loss\t11.56 =\tBCE 11.55532 \tLL 0.01135 \tTotal 467.47/55.81/2.14 \n","04/22/2023 04:48:00 PM - INFO - [100:16] loss\t11.58 =\tBCE 11.57989 \tLL 0.01100 \tTotal 731.61/83.87/4.64 \n","04/22/2023 04:48:01 PM - INFO - [100:17] loss\t11.46 =\tBCE 11.45549 \tLL 0.01090 \tTotal 528.90/57.97/5.03 \n","04/22/2023 04:48:01 PM - INFO - [100:18] loss\t11.07 =\tBCE 11.06963 \tLL 0.01074 \tTotal 181.41/43.47/4.45 \n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/bce_loss █▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train/ll_loss ▂▅█▆▄▄▃▃▂▃▃▂▃▂▂▃▂▂▂▂▁▁▃▂▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/total_loss █▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:     val/bce_loss █▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:        val/epoch ▁▂▂▃▄▅▅▆▇▇█\n","\u001b[34m\u001b[1mwandb\u001b[0m:      val/ll_loss ▁█▅▄▅▄▄▃▃▃▃\n","\u001b[34m\u001b[1mwandb\u001b[0m:   val/total_loss █▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/bce_loss 11.06963\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train/epoch 100\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train/ll_loss 0.01074\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/total_loss 11.06963\n","\u001b[34m\u001b[1mwandb\u001b[0m:     val/bce_loss 10.48341\n","\u001b[34m\u001b[1mwandb\u001b[0m:        val/epoch 100\n","\u001b[34m\u001b[1mwandb\u001b[0m:      val/ll_loss 0.01068\n","\u001b[34m\u001b[1mwandb\u001b[0m:   val/total_loss 10.48341\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mskilled-snowflake-19\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/simonecaldarella/homomorphism-autoencoder/runs/3ey46wbr\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 33 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230422_162838-3ey46wbr/logs\u001b[0m\n"]}]},{"cell_type":"markdown","source":["### Recombination to range"],"metadata":{"id":"Ygike9Sr5PW1"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/\n","!python3 train_block_mlp_repr.py --combinatorial_indices=/content/drive/MyDrive/Advanced_Machine_Learning/remove_from_train_shape_equal_1___posX_greater_equal_15__posY_greater_equal_15.json --dataset=dsprites --data_root=/content/drive/MyDrive/Advanced_Machine_Learning/dsprites-dataset --cyclic_trans --fixed_in_intervention=0,1,2,3 --fixed_in_sampling=0,1,2,3 --fixed_values=0,1,5,14 --distrib=uniform --displacement_range=-10,10 --n_steps=2 --rotate_actions=45 --num_train=10000 --batch_size=500 --epochs=101 --log_wandb --lr=0.001 --toggle_training_every=2,2 --shuffle=1 --use_adam --use_cuda --conv_channels=64,64,64,64 --kernel_sizes=6,4,4,4 --strides=2,2,1,1 --lin_channels=1024 --net_act=relu --dims=2,2 --group_hidden_units=128,128 --reconstruct_first_only --exponential_map --latent_loss --latent_loss_weight=400 --val_epoch=10 --num_val=500 --plot_epoch=10 --plot_manifold_latent=[0,1] --plot_manifold --plot_reconstruction --plot_pca --plot_vary_latents=[4,5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zu-8pW-d5OjJ","executionInfo":{"status":"ok","timestamp":1682183774075,"user_tz":-120,"elapsed":620660,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"outputId":"9d07c6fc-8446-4fc4-f249-8019b64877f6"},"execution_count":124,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism\n","Created output folder ./out/run_2023-04-22_17-05-56.\n","04/22/2023 05:05:56 PM - INFO - Using cuda : True\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimonecaldarella\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.0\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/wandb/run-20230422_170622-4you5i73\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlively-bird-20\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/simonecaldarella/homomorphism-autoencoder\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/simonecaldarella/homomorphism-autoencoder/runs/4you5i73\u001b[0m\n","04/22/2023 05:06:22 PM - INFO - ### Training ###\n","04/22/2023 05:06:23 PM - INFO - EVALUATION prior to epoch [0]...\n","04/22/2023 05:06:23 PM - INFO - [0] loss\t2897.66=\tBCE 2897.66 \tLL 0.00051 \n","04/22/2023 05:06:24 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/0_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:06:29 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/0_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:06:35 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/0_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 05:06:36 PM - INFO - Training epoch 0.\n","04/22/2023 05:06:37 PM - INFO - [0:0] loss\t2897.56 =\tBCE 2897.55664 \tLL 0.00050 \tTotal 2204.29/2204.25/3.22 \n","04/22/2023 05:06:37 PM - INFO - [0:1] loss\t2873.96 =\tBCE 2873.95850 \tLL 0.03557 \tTotal 2185.97/2150.19/220.10 \n","04/22/2023 05:06:38 PM - INFO - [0:2] loss\t2783.91 =\tBCE 2783.91284 \tLL 0.00007 \tTotal 2134.91/2134.89/0.52 \n","04/22/2023 05:06:38 PM - INFO - [0:3] loss\t2606.38 =\tBCE 2606.37744 \tLL 0.00005 \tTotal 2175.94/2175.59/0.64 \n","04/22/2023 05:06:39 PM - INFO - [0:4] loss\t2390.53 =\tBCE 2390.52563 \tLL 0.00039 \tTotal 1667.96/1667.70/9.98 \n","04/22/2023 05:06:39 PM - INFO - [0:5] loss\t2422.69 =\tBCE 2422.69043 \tLL 0.00134 \tTotal 1995.05/1976.19/33.61 \n","04/22/2023 05:06:40 PM - INFO - [0:6] loss\t2303.88 =\tBCE 2303.88086 \tLL 0.00015 \tTotal 1807.16/1804.13/2.27 \n","04/22/2023 05:06:40 PM - INFO - [0:7] loss\t2129.84 =\tBCE 2129.83813 \tLL 0.00018 \tTotal 1197.71/1197.61/1.44 \n","04/22/2023 05:06:40 PM - INFO - Training epoch 1.\n","04/22/2023 05:06:41 PM - INFO - [1:0] loss\t2031.94 =\tBCE 2031.94019 \tLL 0.00024 \tTotal 1366.01/1365.76/1.94 \n","04/22/2023 05:06:41 PM - INFO - [1:1] loss\t1959.07 =\tBCE 1959.06702 \tLL 0.00029 \tTotal 1606.44/1606.08/2.32 \n","04/22/2023 05:06:42 PM - INFO - [1:2] loss\t1841.48 =\tBCE 1841.47815 \tLL 0.00040 \tTotal 1501.10/1500.55/3.07 \n","04/22/2023 05:06:42 PM - INFO - [1:3] loss\t1732.66 =\tBCE 1732.65662 \tLL 0.00072 \tTotal 1045.64/1044.90/4.86 \n","04/22/2023 05:06:43 PM - INFO - [1:4] loss\t1654.57 =\tBCE 1654.56555 \tLL 0.00147 \tTotal 902.92/902.83/8.39 \n","04/22/2023 05:06:43 PM - INFO - [1:5] loss\t1589.87 =\tBCE 1589.87036 \tLL 0.00280 \tTotal 1096.02/1094.73/15.18 \n","04/22/2023 05:06:44 PM - INFO - [1:6] loss\t1480.93 =\tBCE 1480.93042 \tLL 0.00244 \tTotal 948.71/948.34/14.07 \n","04/22/2023 05:06:44 PM - INFO - [1:7] loss\t1381.64 =\tBCE 1381.63928 \tLL 0.00174 \tTotal 723.10/722.52/12.26 \n","04/22/2023 05:06:44 PM - INFO - Training epoch 2.\n","04/22/2023 05:06:45 PM - INFO - [2:0] loss\t1293.40 =\tBCE 1293.39587 \tLL 0.00146 \tTotal 663.41/659.47/13.07 \n","04/22/2023 05:06:45 PM - INFO - [2:1] loss\t1211.32 =\tBCE 1211.31763 \tLL 0.00170 \tTotal 732.61/721.10/15.61 \n","04/22/2023 05:06:46 PM - INFO - [2:2] loss\t1141.11 =\tBCE 1141.11243 \tLL 0.00281 \tTotal 636.48/597.96/27.34 \n","04/22/2023 05:06:47 PM - INFO - [2:3] loss\t1063.04 =\tBCE 1063.03784 \tLL 0.00646 \tTotal 493.31/458.16/63.00 \n","04/22/2023 05:06:47 PM - INFO - [2:4] loss\t1021.40 =\tBCE 1021.40271 \tLL 0.02406 \tTotal 1351.21/941.95/419.20 \n","04/22/2023 05:06:48 PM - INFO - [2:5] loss\t961.80 =\tBCE 961.80029 \tLL 0.01244 \tTotal 495.53/409.41/274.20 \n","04/22/2023 05:06:48 PM - INFO - [2:6] loss\t937.95 =\tBCE 937.95343 \tLL 0.00718 \tTotal 644.11/496.09/131.80 \n","04/22/2023 05:06:49 PM - INFO - [2:7] loss\t909.03 =\tBCE 909.02777 \tLL 0.00741 \tTotal 640.99/479.47/150.25 \n","04/22/2023 05:06:49 PM - INFO - Training epoch 3.\n","04/22/2023 05:06:49 PM - INFO - [3:0] loss\t895.33 =\tBCE 895.32623 \tLL 0.01192 \tTotal 399.21/264.19/280.39 \n","04/22/2023 05:06:50 PM - INFO - [3:1] loss\t897.36 =\tBCE 897.36133 \tLL 0.01316 \tTotal 613.12/404.58/189.24 \n","04/22/2023 05:06:50 PM - INFO - [3:2] loss\t875.18 =\tBCE 875.17596 \tLL 0.01488 \tTotal 596.92/370.36/250.84 \n","04/22/2023 05:06:51 PM - INFO - [3:3] loss\t862.81 =\tBCE 862.80676 \tLL 0.01109 \tTotal 309.11/260.71/112.39 \n","04/22/2023 05:06:51 PM - INFO - [3:4] loss\t859.54 =\tBCE 859.53662 \tLL 0.00928 \tTotal 369.25/273.95/220.10 \n","04/22/2023 05:06:52 PM - INFO - [3:5] loss\t844.57 =\tBCE 844.57074 \tLL 0.00738 \tTotal 394.10/314.78/68.26 \n","04/22/2023 05:06:52 PM - INFO - [3:6] loss\t833.27 =\tBCE 833.27332 \tLL 0.00694 \tTotal 339.38/263.84/95.58 \n","04/22/2023 05:06:53 PM - INFO - [3:7] loss\t804.46 =\tBCE 804.45709 \tLL 0.00988 \tTotal 244.84/152.83/151.36 \n","04/22/2023 05:06:53 PM - INFO - Training epoch 4.\n","04/22/2023 05:06:54 PM - INFO - [4:0] loss\t804.50 =\tBCE 804.49951 \tLL 0.01120 \tTotal 290.83/243.50/104.36 \n","04/22/2023 05:06:54 PM - INFO - [4:1] loss\t798.73 =\tBCE 798.72559 \tLL 0.01315 \tTotal 446.56/330.72/106.17 \n","04/22/2023 05:06:55 PM - INFO - [4:2] loss\t799.40 =\tBCE 799.40479 \tLL 0.01385 \tTotal 352.74/255.54/155.90 \n","04/22/2023 05:06:55 PM - INFO - [4:3] loss\t803.10 =\tBCE 803.09674 \tLL 0.01188 \tTotal 127.22/116.23/45.91 \n","04/22/2023 05:06:56 PM - INFO - [4:4] loss\t796.32 =\tBCE 796.31830 \tLL 0.00938 \tTotal 273.76/214.09/45.47 \n","04/22/2023 05:06:56 PM - INFO - [4:5] loss\t790.64 =\tBCE 790.63812 \tLL 0.00981 \tTotal 337.44/271.25/83.91 \n","04/22/2023 05:06:57 PM - INFO - [4:6] loss\t781.17 =\tBCE 781.16949 \tLL 0.01181 \tTotal 285.00/193.10/90.03 \n","04/22/2023 05:06:57 PM - INFO - [4:7] loss\t781.57 =\tBCE 781.57050 \tLL 0.01494 \tTotal 126.69/119.43/27.19 \n","04/22/2023 05:06:57 PM - INFO - Training epoch 5.\n","04/22/2023 05:06:58 PM - INFO - [5:0] loss\t790.46 =\tBCE 790.45703 \tLL 0.01746 \tTotal 357.74/280.06/102.71 \n","04/22/2023 05:06:58 PM - INFO - [5:1] loss\t774.37 =\tBCE 774.37061 \tLL 0.01638 \tTotal 254.04/229.53/70.13 \n","04/22/2023 05:06:59 PM - INFO - [5:2] loss\t768.86 =\tBCE 768.85651 \tLL 0.01669 \tTotal 142.16/110.61/19.40 \n","04/22/2023 05:06:59 PM - INFO - [5:3] loss\t764.72 =\tBCE 764.72101 \tLL 0.01878 \tTotal 166.24/115.34/47.39 \n","04/22/2023 05:07:00 PM - INFO - [5:4] loss\t763.70 =\tBCE 763.69769 \tLL 0.02196 \tTotal 174.94/149.93/83.59 \n","04/22/2023 05:07:00 PM - INFO - [5:5] loss\t753.02 =\tBCE 753.01801 \tLL 0.02389 \tTotal 178.75/160.03/70.00 \n","04/22/2023 05:07:01 PM - INFO - [5:6] loss\t749.99 =\tBCE 749.98993 \tLL 0.02518 \tTotal 179.80/118.38/53.84 \n","04/22/2023 05:07:02 PM - INFO - [5:7] loss\t747.81 =\tBCE 747.80627 \tLL 0.02444 \tTotal 206.49/84.23/70.34 \n","04/22/2023 05:07:02 PM - INFO - Training epoch 6.\n","04/22/2023 05:07:02 PM - INFO - [6:0] loss\t748.34 =\tBCE 748.34241 \tLL 0.02030 \tTotal 200.78/115.89/25.13 \n","04/22/2023 05:07:03 PM - INFO - [6:1] loss\t746.13 =\tBCE 746.12952 \tLL 0.02363 \tTotal 115.10/103.33/25.48 \n","04/22/2023 05:07:03 PM - INFO - [6:2] loss\t749.94 =\tBCE 749.93988 \tLL 0.02434 \tTotal 148.30/135.24/34.04 \n","04/22/2023 05:07:04 PM - INFO - [6:3] loss\t733.34 =\tBCE 733.33649 \tLL 0.02564 \tTotal 120.87/99.04/39.07 \n","04/22/2023 05:07:04 PM - INFO - [6:4] loss\t738.36 =\tBCE 738.36084 \tLL 0.03134 \tTotal 174.81/108.38/28.57 \n","04/22/2023 05:07:05 PM - INFO - [6:5] loss\t733.73 =\tBCE 733.72803 \tLL 0.03014 \tTotal 149.69/115.66/85.67 \n","04/22/2023 05:07:06 PM - INFO - [6:6] loss\t722.09 =\tBCE 722.09094 \tLL 0.03230 \tTotal 312.13/111.10/32.40 \n","04/22/2023 05:07:06 PM - INFO - [6:7] loss\t716.22 =\tBCE 716.21509 \tLL 0.04008 \tTotal 241.63/98.70/79.27 \n","04/22/2023 05:07:06 PM - INFO - Training epoch 7.\n","04/22/2023 05:07:07 PM - INFO - [7:0] loss\t722.20 =\tBCE 722.20337 \tLL 0.04491 \tTotal 291.81/144.38/49.44 \n","04/22/2023 05:07:07 PM - INFO - [7:1] loss\t703.75 =\tBCE 703.75018 \tLL 0.03677 \tTotal 680.33/130.19/50.30 \n","04/22/2023 05:07:08 PM - INFO - [7:2] loss\t713.48 =\tBCE 713.47601 \tLL 0.06135 \tTotal 681.06/146.27/33.24 \n","04/22/2023 05:07:08 PM - INFO - [7:3] loss\t704.12 =\tBCE 704.12396 \tLL 0.05176 \tTotal 176.19/94.41/103.01 \n","04/22/2023 05:07:09 PM - INFO - [7:4] loss\t694.06 =\tBCE 694.06293 \tLL 0.03878 \tTotal 990.82/169.11/31.35 \n","04/22/2023 05:07:09 PM - INFO - [7:5] loss\t705.49 =\tBCE 705.49139 \tLL 0.05943 \tTotal 746.61/134.13/66.35 \n","04/22/2023 05:07:10 PM - INFO - [7:6] loss\t690.60 =\tBCE 690.60205 \tLL 0.05155 \tTotal 542.45/114.31/139.89 \n","04/22/2023 05:07:10 PM - INFO - [7:7] loss\t692.83 =\tBCE 692.83344 \tLL 0.04825 \tTotal 818.69/138.53/34.73 \n","04/22/2023 05:07:10 PM - INFO - Training epoch 8.\n","04/22/2023 05:07:11 PM - INFO - [8:0] loss\t671.97 =\tBCE 671.97345 \tLL 0.05052 \tTotal 374.62/114.76/22.82 \n","04/22/2023 05:07:11 PM - INFO - [8:1] loss\t674.55 =\tBCE 674.55371 \tLL 0.07024 \tTotal 980.56/151.69/93.93 \n","04/22/2023 05:07:12 PM - INFO - [8:2] loss\t659.01 =\tBCE 659.00946 \tLL 0.06043 \tTotal 150.51/127.15/40.63 \n","04/22/2023 05:07:12 PM - INFO - [8:3] loss\t653.04 =\tBCE 653.03522 \tLL 0.05486 \tTotal 1266.69/185.36/21.97 \n","04/22/2023 05:07:13 PM - INFO - [8:4] loss\t638.18 =\tBCE 638.17780 \tLL 0.08498 \tTotal 925.66/165.94/41.01 \n","04/22/2023 05:07:14 PM - INFO - [8:5] loss\t615.88 =\tBCE 615.87695 \tLL 0.08204 \tTotal 730.90/158.03/89.25 \n","04/22/2023 05:07:14 PM - INFO - [8:6] loss\t616.34 =\tBCE 616.33521 \tLL 0.06759 \tTotal 1489.41/212.30/35.71 \n","04/22/2023 05:07:15 PM - INFO - [8:7] loss\t599.19 =\tBCE 599.18762 \tLL 0.08767 \tTotal 557.13/159.42/45.65 \n","Not implemented\n","04/22/2023 05:07:15 PM - INFO - Training epoch 9.\n","04/22/2023 05:07:15 PM - INFO - [9:0] loss\t585.75 =\tBCE 585.74719 \tLL 0.09768 \tTotal 1064.48/182.05/137.00 \n","04/22/2023 05:07:16 PM - INFO - [9:1] loss\t571.13 =\tBCE 571.12891 \tLL 0.08579 \tTotal 1335.97/217.52/46.50 \n","04/22/2023 05:07:16 PM - INFO - [9:2] loss\t549.51 =\tBCE 549.51410 \tLL 0.09351 \tTotal 310.24/159.51/43.77 \n","04/22/2023 05:07:17 PM - INFO - [9:3] loss\t543.66 =\tBCE 543.65918 \tLL 0.09442 \tTotal 925.02/168.33/164.19 \n","04/22/2023 05:07:17 PM - INFO - [9:4] loss\t527.93 =\tBCE 527.93390 \tLL 0.07356 \tTotal 975.91/188.84/69.83 \n","04/22/2023 05:07:18 PM - INFO - [9:5] loss\t503.30 =\tBCE 503.29587 \tLL 0.08054 \tTotal 553.17/168.39/106.52 \n","04/22/2023 05:07:19 PM - INFO - [9:6] loss\t507.12 =\tBCE 507.12454 \tLL 0.06860 \tTotal 266.92/171.10/121.14 \n","04/22/2023 05:07:19 PM - INFO - [9:7] loss\t490.82 =\tBCE 490.81863 \tLL 0.05735 \tTotal 415.80/171.16/55.00 \n","04/22/2023 05:07:19 PM - INFO - EVALUATION prior to epoch [10]...\n","04/22/2023 05:07:19 PM - INFO - [10] loss\t1626.84=\tBCE 1626.84 \tLL 0.04969 \n","04/22/2023 05:07:21 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/10_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:07:25 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/10_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:07:32 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/10_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 05:07:33 PM - INFO - Training epoch 10.\n","04/22/2023 05:07:33 PM - INFO - [10:0] loss\t481.93 =\tBCE 481.93451 \tLL 0.05825 \tTotal 338.14/154.56/79.34 \n","04/22/2023 05:07:34 PM - INFO - [10:1] loss\t468.03 =\tBCE 468.03043 \tLL 0.05356 \tTotal 324.69/150.32/94.55 \n","04/22/2023 05:07:35 PM - INFO - [10:2] loss\t458.03 =\tBCE 458.02719 \tLL 0.04984 \tTotal 601.81/154.79/19.78 \n","04/22/2023 05:07:35 PM - INFO - [10:3] loss\t453.28 =\tBCE 453.28119 \tLL 0.04886 \tTotal 1010.14/189.09/39.00 \n","04/22/2023 05:07:36 PM - INFO - [10:4] loss\t444.99 =\tBCE 444.99121 \tLL 0.04580 \tTotal 1053.36/170.95/103.27 \n","04/22/2023 05:07:36 PM - INFO - [10:5] loss\t443.01 =\tBCE 443.01242 \tLL 0.04928 \tTotal 1455.89/196.44/58.34 \n","04/22/2023 05:07:37 PM - INFO - [10:6] loss\t428.25 =\tBCE 428.24576 \tLL 0.04076 \tTotal 1852.24/239.56/91.68 \n","04/22/2023 05:07:37 PM - INFO - [10:7] loss\t428.34 =\tBCE 428.34467 \tLL 0.04419 \tTotal 1841.40/189.81/97.04 \n","04/22/2023 05:07:37 PM - INFO - Training epoch 11.\n","04/22/2023 05:07:38 PM - INFO - [11:0] loss\t417.94 =\tBCE 417.94064 \tLL 0.03916 \tTotal 1806.86/262.31/117.66 \n","04/22/2023 05:07:38 PM - INFO - [11:1] loss\t407.24 =\tBCE 407.24265 \tLL 0.04309 \tTotal 1527.80/194.57/76.06 \n","04/22/2023 05:07:39 PM - INFO - [11:2] loss\t400.26 =\tBCE 400.25613 \tLL 0.03717 \tTotal 1857.05/229.13/86.84 \n","04/22/2023 05:07:39 PM - INFO - [11:3] loss\t391.82 =\tBCE 391.82193 \tLL 0.04590 \tTotal 1929.01/222.06/87.27 \n","04/22/2023 05:07:40 PM - INFO - [11:4] loss\t379.38 =\tBCE 379.37924 \tLL 0.03907 \tTotal 2147.20/219.37/32.36 \n","04/22/2023 05:07:40 PM - INFO - [11:5] loss\t398.22 =\tBCE 398.21799 \tLL 0.04322 \tTotal 4085.73/380.59/69.33 \n","04/22/2023 05:07:41 PM - INFO - [11:6] loss\t374.19 =\tBCE 374.19275 \tLL 0.03531 \tTotal 3753.27/403.62/102.57 \n","04/22/2023 05:07:41 PM - INFO - [11:7] loss\t379.78 =\tBCE 379.78314 \tLL 0.04972 \tTotal 4381.04/408.69/49.73 \n","04/22/2023 05:07:41 PM - INFO - Training epoch 12.\n","04/22/2023 05:07:42 PM - INFO - [12:0] loss\t363.23 =\tBCE 363.22980 \tLL 0.03907 \tTotal 3905.91/368.95/111.17 \n","04/22/2023 05:07:43 PM - INFO - [12:1] loss\t353.40 =\tBCE 353.40366 \tLL 0.04229 \tTotal 2912.71/447.43/132.59 \n","04/22/2023 05:07:43 PM - INFO - [12:2] loss\t328.94 =\tBCE 328.93710 \tLL 0.03995 \tTotal 2091.36/265.09/97.92 \n","04/22/2023 05:07:44 PM - INFO - [12:3] loss\t321.26 =\tBCE 321.25632 \tLL 0.03788 \tTotal 2443.25/407.76/114.33 \n","04/22/2023 05:07:44 PM - INFO - [12:4] loss\t340.30 =\tBCE 340.30341 \tLL 0.04261 \tTotal 5964.75/519.21/67.36 \n","04/22/2023 05:07:45 PM - INFO - [12:5] loss\t364.78 =\tBCE 364.78125 \tLL 0.03200 \tTotal 10194.03/923.37/70.65 \n","04/22/2023 05:07:45 PM - INFO - [12:6] loss\t407.74 =\tBCE 407.74268 \tLL 0.06318 \tTotal 7796.94/1030.91/150.63 \n","04/22/2023 05:07:46 PM - INFO - [12:7] loss\t351.00 =\tBCE 351.00006 \tLL 0.06454 \tTotal 3673.97/803.28/42.69 \n","04/22/2023 05:07:46 PM - INFO - Training epoch 13.\n","04/22/2023 05:07:46 PM - INFO - [13:0] loss\t341.32 =\tBCE 341.31598 \tLL 0.04880 \tTotal 3820.60/810.99/106.43 \n","04/22/2023 05:07:47 PM - INFO - [13:1] loss\t343.52 =\tBCE 343.51947 \tLL 0.04411 \tTotal 5621.44/1014.74/71.85 \n","04/22/2023 05:07:48 PM - INFO - [13:2] loss\t302.51 =\tBCE 302.50760 \tLL 0.05532 \tTotal 2395.94/402.66/37.95 \n","04/22/2023 05:07:48 PM - INFO - [13:3] loss\t333.74 =\tBCE 333.74438 \tLL 0.05885 \tTotal 4376.28/727.93/48.82 \n","04/22/2023 05:07:49 PM - INFO - [13:4] loss\t299.84 =\tBCE 299.83673 \tLL 0.05382 \tTotal 1420.71/525.39/101.39 \n","04/22/2023 05:07:49 PM - INFO - [13:5] loss\t312.44 =\tBCE 312.44250 \tLL 0.04830 \tTotal 4468.36/632.76/30.07 \n","04/22/2023 05:07:50 PM - INFO - [13:6] loss\t289.74 =\tBCE 289.74127 \tLL 0.05664 \tTotal 1405.69/724.08/78.08 \n","04/22/2023 05:07:50 PM - INFO - [13:7] loss\t279.51 =\tBCE 279.50839 \tLL 0.06565 \tTotal 2706.64/500.53/59.94 \n","04/22/2023 05:07:50 PM - INFO - Training epoch 14.\n","04/22/2023 05:07:51 PM - INFO - [14:0] loss\t272.85 =\tBCE 272.84940 \tLL 0.06823 \tTotal 1518.14/390.69/48.13 \n","04/22/2023 05:07:51 PM - INFO - [14:1] loss\t271.65 =\tBCE 271.64551 \tLL 0.06510 \tTotal 2355.64/636.94/80.01 \n","04/22/2023 05:07:52 PM - INFO - [14:2] loss\t250.54 =\tBCE 250.54027 \tLL 0.06398 \tTotal 1402.58/231.96/98.08 \n","04/22/2023 05:07:52 PM - INFO - [14:3] loss\t249.67 =\tBCE 249.66943 \tLL 0.05973 \tTotal 2820.11/726.93/28.31 \n","04/22/2023 05:07:53 PM - INFO - [14:4] loss\t222.88 =\tBCE 222.88301 \tLL 0.05471 \tTotal 1467.86/283.31/54.03 \n","04/22/2023 05:07:54 PM - INFO - [14:5] loss\t222.72 =\tBCE 222.71628 \tLL 0.05572 \tTotal 2313.63/520.86/79.26 \n","04/22/2023 05:07:54 PM - INFO - [14:6] loss\t205.86 =\tBCE 205.86038 \tLL 0.05390 \tTotal 1938.21/309.14/41.62 \n","04/22/2023 05:07:55 PM - INFO - [14:7] loss\t210.59 =\tBCE 210.59113 \tLL 0.05386 \tTotal 3169.32/589.80/40.82 \n","04/22/2023 05:07:55 PM - INFO - Training epoch 15.\n","04/22/2023 05:07:55 PM - INFO - [15:0] loss\t195.11 =\tBCE 195.10652 \tLL 0.05147 \tTotal 2764.19/348.63/68.83 \n","04/22/2023 05:07:56 PM - INFO - [15:1] loss\t198.14 =\tBCE 198.13530 \tLL 0.05533 \tTotal 2915.44/630.19/54.20 \n","04/22/2023 05:07:56 PM - INFO - [15:2] loss\t172.40 =\tBCE 172.39816 \tLL 0.04871 \tTotal 1534.53/348.29/26.71 \n","04/22/2023 05:07:57 PM - INFO - [15:3] loss\t175.40 =\tBCE 175.39636 \tLL 0.04546 \tTotal 2782.91/537.04/37.92 \n","04/22/2023 05:07:57 PM - INFO - [15:4] loss\t181.42 =\tBCE 181.42154 \tLL 0.05090 \tTotal 3871.25/959.30/95.51 \n","04/22/2023 05:07:58 PM - INFO - [15:5] loss\t183.85 =\tBCE 183.84979 \tLL 0.04695 \tTotal 5325.37/1280.28/78.32 \n","04/22/2023 05:07:58 PM - INFO - [15:6] loss\t205.43 =\tBCE 205.43289 \tLL 0.04999 \tTotal 8202.69/1752.86/46.49 \n","04/22/2023 05:07:59 PM - INFO - [15:7] loss\t211.91 =\tBCE 211.91269 \tLL 0.04598 \tTotal 9920.20/2145.58/99.35 \n","04/22/2023 05:07:59 PM - INFO - Training epoch 16.\n","04/22/2023 05:08:00 PM - INFO - [16:0] loss\t184.65 =\tBCE 184.65338 \tLL 0.04739 \tTotal 6220.74/1619.43/84.05 \n","04/22/2023 05:08:00 PM - INFO - [16:1] loss\t159.33 =\tBCE 159.33028 \tLL 0.05129 \tTotal 4749.66/581.28/11.38 \n","04/22/2023 05:08:01 PM - INFO - [16:2] loss\t188.46 =\tBCE 188.45923 \tLL 0.04775 \tTotal 8778.19/1573.24/78.34 \n","04/22/2023 05:08:01 PM - INFO - [16:3] loss\t161.60 =\tBCE 161.60434 \tLL 0.05312 \tTotal 5494.39/1244.57/86.97 \n","04/22/2023 05:08:02 PM - INFO - [16:4] loss\t154.90 =\tBCE 154.90436 \tLL 0.04725 \tTotal 6761.46/751.44/52.87 \n","04/22/2023 05:08:02 PM - INFO - [16:5] loss\t150.74 =\tBCE 150.74049 \tLL 0.05038 \tTotal 5297.12/953.97/18.04 \n","04/22/2023 05:08:03 PM - INFO - [16:6] loss\t146.09 =\tBCE 146.08911 \tLL 0.05243 \tTotal 5784.04/743.43/81.70 \n","04/22/2023 05:08:04 PM - INFO - [16:7] loss\t163.90 =\tBCE 163.90498 \tLL 0.04535 \tTotal 8285.86/907.87/102.85 \n","04/22/2023 05:08:04 PM - INFO - Training epoch 17.\n","04/22/2023 05:08:04 PM - INFO - [17:0] loss\t136.89 =\tBCE 136.89456 \tLL 0.05216 \tTotal 5480.96/595.32/53.90 \n","04/22/2023 05:08:05 PM - INFO - [17:1] loss\t135.48 =\tBCE 135.47778 \tLL 0.04993 \tTotal 5633.68/533.16/59.31 \n","04/22/2023 05:08:05 PM - INFO - [17:2] loss\t131.00 =\tBCE 131.00407 \tLL 0.05085 \tTotal 3370.58/623.37/65.21 \n","04/22/2023 05:08:06 PM - INFO - [17:3] loss\t135.76 =\tBCE 135.76051 \tLL 0.05380 \tTotal 6369.01/462.12/80.26 \n","04/22/2023 05:08:06 PM - INFO - [17:4] loss\t121.59 =\tBCE 121.58640 \tLL 0.04701 \tTotal 3748.46/867.75/17.32 \n","04/22/2023 05:08:07 PM - INFO - [17:5] loss\t131.29 =\tBCE 131.29402 \tLL 0.05213 \tTotal 5238.90/820.54/24.90 \n","04/22/2023 05:08:07 PM - INFO - [17:6] loss\t114.03 =\tBCE 114.02727 \tLL 0.04910 \tTotal 2686.66/309.02/87.54 \n","04/22/2023 05:08:08 PM - INFO - [17:7] loss\t117.61 =\tBCE 117.60892 \tLL 0.04966 \tTotal 4725.14/682.48/64.48 \n","04/22/2023 05:08:08 PM - INFO - Training epoch 18.\n","04/22/2023 05:08:08 PM - INFO - [18:0] loss\t107.17 =\tBCE 107.16601 \tLL 0.05127 \tTotal 2955.46/370.84/13.06 \n","04/22/2023 05:08:09 PM - INFO - [18:1] loss\t115.19 =\tBCE 115.18563 \tLL 0.04492 \tTotal 6562.72/540.98/32.08 \n","04/22/2023 05:08:10 PM - INFO - [18:2] loss\t121.89 =\tBCE 121.88829 \tLL 0.05146 \tTotal 7908.31/719.97/86.45 \n","04/22/2023 05:08:10 PM - INFO - [18:3] loss\t131.98 =\tBCE 131.98434 \tLL 0.04405 \tTotal 10069.50/917.43/53.32 \n","04/22/2023 05:08:11 PM - INFO - [18:4] loss\t157.72 =\tBCE 157.71906 \tLL 0.05148 \tTotal 11711.93/1478.87/21.36 \n","04/22/2023 05:08:11 PM - INFO - [18:5] loss\t142.77 =\tBCE 142.77310 \tLL 0.04397 \tTotal 12234.60/1935.31/41.92 \n","04/22/2023 05:08:12 PM - INFO - [18:6] loss\t163.21 =\tBCE 163.20558 \tLL 0.06011 \tTotal 10399.13/1991.73/82.85 \n","04/22/2023 05:08:12 PM - INFO - [18:7] loss\t95.82 =\tBCE 95.82220 \tLL 0.05369 \tTotal 1531.52/313.31/42.04 \n","Not implemented\n","04/22/2023 05:08:12 PM - INFO - Training epoch 19.\n","04/22/2023 05:08:13 PM - INFO - [19:0] loss\t153.49 =\tBCE 153.48947 \tLL 0.04679 \tTotal 11739.13/2380.05/15.11 \n","04/22/2023 05:08:13 PM - INFO - [19:1] loss\t195.81 =\tBCE 195.81189 \tLL 0.06524 \tTotal 12268.40/2304.19/56.37 \n","04/22/2023 05:08:14 PM - INFO - [19:2] loss\t113.87 =\tBCE 113.86801 \tLL 0.05776 \tTotal 5518.95/1018.79/34.88 \n","04/22/2023 05:08:15 PM - INFO - [19:3] loss\t198.79 =\tBCE 198.79472 \tLL 0.04929 \tTotal 15554.72/2937.53/24.30 \n","04/22/2023 05:08:15 PM - INFO - [19:4] loss\t163.05 =\tBCE 163.04817 \tLL 0.06587 \tTotal 11570.24/1401.96/16.11 \n","04/22/2023 05:08:16 PM - INFO - [19:5] loss\t143.47 =\tBCE 143.46564 \tLL 0.06821 \tTotal 7472.20/1876.03/28.89 \n","04/22/2023 05:08:16 PM - INFO - [19:6] loss\t142.27 =\tBCE 142.27464 \tLL 0.06135 \tTotal 9123.06/1282.41/9.94 \n","04/22/2023 05:08:17 PM - INFO - [19:7] loss\t130.78 =\tBCE 130.78134 \tLL 0.06288 \tTotal 6228.73/1736.57/15.35 \n","04/22/2023 05:08:17 PM - INFO - EVALUATION prior to epoch [20]...\n","04/22/2023 05:08:17 PM - INFO - [20] loss\t1359.78=\tBCE 1359.78 \tLL 0.06875 \n","04/22/2023 05:08:19 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/20_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:08:23 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/20_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:08:29 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/20_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 05:08:29 PM - INFO - Training epoch 20.\n","04/22/2023 05:08:30 PM - INFO - [20:0] loss\t122.27 =\tBCE 122.27446 \tLL 0.06915 \tTotal 6792.05/948.53/27.14 \n","04/22/2023 05:08:31 PM - INFO - [20:1] loss\t136.80 =\tBCE 136.79710 \tLL 0.07130 \tTotal 5419.79/1679.06/46.72 \n","04/22/2023 05:08:31 PM - INFO - [20:2] loss\t102.57 =\tBCE 102.57176 \tLL 0.06517 \tTotal 4003.28/492.83/8.92 \n","04/22/2023 05:08:32 PM - INFO - [20:3] loss\t133.81 =\tBCE 133.80676 \tLL 0.06244 \tTotal 5684.25/1896.96/6.35 \n","04/22/2023 05:08:32 PM - INFO - [20:4] loss\t93.65 =\tBCE 93.65265 \tLL 0.06628 \tTotal 2004.84/230.42/28.87 \n","04/22/2023 05:08:33 PM - INFO - [20:5] loss\t123.79 =\tBCE 123.78705 \tLL 0.07042 \tTotal 3917.68/1468.63/54.08 \n","04/22/2023 05:08:33 PM - INFO - [20:6] loss\t101.35 =\tBCE 101.34752 \tLL 0.06183 \tTotal 2818.57/748.97/19.08 \n","04/22/2023 05:08:34 PM - INFO - [20:7] loss\t103.32 =\tBCE 103.31949 \tLL 0.05791 \tTotal 2632.64/1171.62/56.78 \n","04/22/2023 05:08:34 PM - INFO - Training epoch 21.\n","04/22/2023 05:08:34 PM - INFO - [21:0] loss\t102.48 =\tBCE 102.48190 \tLL 0.05613 \tTotal 3345.08/1069.85/17.02 \n","04/22/2023 05:08:35 PM - INFO - [21:1] loss\t95.99 =\tBCE 95.98758 \tLL 0.06075 \tTotal 1242.55/585.52/12.04 \n","04/22/2023 05:08:36 PM - INFO - [21:2] loss\t104.56 =\tBCE 104.56033 \tLL 0.06027 \tTotal 3055.85/1145.37/10.47 \n","04/22/2023 05:08:36 PM - INFO - [21:3] loss\t87.30 =\tBCE 87.29570 \tLL 0.05413 \tTotal 1708.09/161.77/23.21 \n","04/22/2023 05:08:37 PM - INFO - [21:4] loss\t96.54 =\tBCE 96.54443 \tLL 0.05095 \tTotal 2730.49/1141.48/38.07 \n","04/22/2023 05:08:37 PM - INFO - [21:5] loss\t87.11 =\tBCE 87.10728 \tLL 0.05314 \tTotal 2239.39/444.64/12.84 \n","04/22/2023 05:08:38 PM - INFO - [21:6] loss\t89.94 =\tBCE 89.94415 \tLL 0.05735 \tTotal 1921.28/757.31/44.91 \n","04/22/2023 05:08:38 PM - INFO - [21:7] loss\t87.34 =\tBCE 87.33727 \tLL 0.05434 \tTotal 2556.92/657.76/17.90 \n","04/22/2023 05:08:38 PM - INFO - Training epoch 22.\n","04/22/2023 05:08:39 PM - INFO - [22:0] loss\t82.91 =\tBCE 82.90646 \tLL 0.04875 \tTotal 1389.71/458.98/7.99 \n","04/22/2023 05:08:39 PM - INFO - [22:1] loss\t84.92 =\tBCE 84.92088 \tLL 0.04664 \tTotal 3244.15/854.60/20.21 \n","04/22/2023 05:08:40 PM - INFO - [22:2] loss\t76.33 =\tBCE 76.32590 \tLL 0.04803 \tTotal 1621.28/233.20/10.22 \n","04/22/2023 05:08:40 PM - INFO - [22:3] loss\t84.46 =\tBCE 84.45856 \tLL 0.04966 \tTotal 2711.04/804.72/28.87 \n","04/22/2023 05:08:41 PM - INFO - [22:4] loss\t76.39 =\tBCE 76.39133 \tLL 0.04571 \tTotal 1480.54/197.11/7.49 \n","04/22/2023 05:08:41 PM - INFO - [22:5] loss\t80.64 =\tBCE 80.64209 \tLL 0.04333 \tTotal 2457.12/979.33/12.69 \n","04/22/2023 05:08:42 PM - INFO - [22:6] loss\t72.24 =\tBCE 72.24249 \tLL 0.04535 \tTotal 1999.68/208.99/9.45 \n","04/22/2023 05:08:43 PM - INFO - [22:7] loss\t77.89 =\tBCE 77.88750 \tLL 0.04434 \tTotal 1737.45/983.56/15.16 \n","04/22/2023 05:08:43 PM - INFO - Training epoch 23.\n","04/22/2023 05:08:43 PM - INFO - [23:0] loss\t68.53 =\tBCE 68.52912 \tLL 0.04123 \tTotal 1118.30/217.12/31.33 \n","04/22/2023 05:08:44 PM - INFO - [23:1] loss\t74.24 =\tBCE 74.23691 \tLL 0.04072 \tTotal 1795.36/956.22/9.31 \n","04/22/2023 05:08:44 PM - INFO - [23:2] loss\t67.98 =\tBCE 67.97699 \tLL 0.04163 \tTotal 1176.67/520.45/27.51 \n","04/22/2023 05:08:45 PM - INFO - [23:3] loss\t67.97 =\tBCE 67.96822 \tLL 0.04052 \tTotal 1260.20/619.21/33.60 \n","04/22/2023 05:08:45 PM - INFO - [23:4] loss\t68.77 =\tBCE 68.77375 \tLL 0.03921 \tTotal 1969.89/808.68/32.21 \n","04/22/2023 05:08:46 PM - INFO - [23:5] loss\t65.25 =\tBCE 65.25465 \tLL 0.03973 \tTotal 2496.56/269.80/15.57 \n","04/22/2023 05:08:47 PM - INFO - [23:6] loss\t66.39 =\tBCE 66.38900 \tLL 0.04123 \tTotal 2931.74/563.79/11.95 \n","04/22/2023 05:08:47 PM - INFO - [23:7] loss\t62.60 =\tBCE 62.60270 \tLL 0.03869 \tTotal 1465.47/270.28/17.26 \n","04/22/2023 05:08:47 PM - INFO - Training epoch 24.\n","04/22/2023 05:08:48 PM - INFO - [24:0] loss\t61.87 =\tBCE 61.86822 \tLL 0.03769 \tTotal 2506.41/425.67/15.10 \n","04/22/2023 05:08:48 PM - INFO - [24:1] loss\t63.34 =\tBCE 63.34287 \tLL 0.03781 \tTotal 4026.92/524.12/11.46 \n","04/22/2023 05:08:49 PM - INFO - [24:2] loss\t60.99 =\tBCE 60.98676 \tLL 0.03687 \tTotal 2946.53/231.09/15.67 \n","04/22/2023 05:08:49 PM - INFO - [24:3] loss\t59.21 =\tBCE 59.21234 \tLL 0.03798 \tTotal 2381.56/580.84/40.98 \n","04/22/2023 05:08:50 PM - INFO - [24:4] loss\t62.19 =\tBCE 62.18812 \tLL 0.03784 \tTotal 2796.64/752.69/6.91 \n","04/22/2023 05:08:50 PM - INFO - [24:5] loss\t58.04 =\tBCE 58.04267 \tLL 0.03772 \tTotal 1567.23/565.41/40.27 \n","04/22/2023 05:08:51 PM - INFO - [24:6] loss\t55.87 =\tBCE 55.86913 \tLL 0.03638 \tTotal 2717.27/207.14/8.94 \n","04/22/2023 05:08:51 PM - INFO - [24:7] loss\t59.51 =\tBCE 59.50503 \tLL 0.03888 \tTotal 4478.09/394.90/20.48 \n","04/22/2023 05:08:51 PM - INFO - Training epoch 25.\n","04/22/2023 05:08:52 PM - INFO - [25:0] loss\t61.00 =\tBCE 61.00425 \tLL 0.03371 \tTotal 6232.90/633.49/7.68 \n","04/22/2023 05:08:53 PM - INFO - [25:1] loss\t76.76 =\tBCE 76.76282 \tLL 0.03951 \tTotal 10156.27/849.84/10.56 \n","04/22/2023 05:08:53 PM - INFO - [25:2] loss\t127.39 =\tBCE 127.38602 \tLL 0.03301 \tTotal 18080.36/1589.38/35.06 \n","04/22/2023 05:08:54 PM - INFO - [25:3] loss\t249.95 =\tBCE 249.94835 \tLL 0.04175 \tTotal 29191.42/2831.67/27.57 \n","04/22/2023 05:08:54 PM - INFO - [25:4] loss\t306.38 =\tBCE 306.37811 \tLL 0.03135 \tTotal 28865.99/3169.37/32.27 \n","04/22/2023 05:08:55 PM - INFO - [25:5] loss\t74.71 =\tBCE 74.70930 \tLL 0.04035 \tTotal 6134.05/720.53/18.56 \n","04/22/2023 05:08:55 PM - INFO - [25:6] loss\t207.82 =\tBCE 207.82111 \tLL 0.04401 \tTotal 22515.44/2943.82/42.55 \n","04/22/2023 05:08:56 PM - INFO - [25:7] loss\t162.01 =\tBCE 162.00706 \tLL 0.03653 \tTotal 17331.38/2024.90/10.09 \n","04/22/2023 05:08:56 PM - INFO - Training epoch 26.\n","04/22/2023 05:08:56 PM - INFO - [26:0] loss\t119.69 =\tBCE 119.68549 \tLL 0.03971 \tTotal 11642.59/1461.47/11.09 \n","04/22/2023 05:08:57 PM - INFO - [26:1] loss\t142.14 =\tBCE 142.14062 \tLL 0.04662 \tTotal 14647.39/1730.00/29.37 \n","04/22/2023 05:08:57 PM - INFO - [26:2] loss\t89.57 =\tBCE 89.57264 \tLL 0.04627 \tTotal 8657.21/984.03/40.54 \n","04/22/2023 05:08:58 PM - INFO - [26:3] loss\t126.63 =\tBCE 126.62880 \tLL 0.04008 \tTotal 12377.20/1396.35/15.13 \n","04/22/2023 05:08:59 PM - INFO - [26:4] loss\t84.90 =\tBCE 84.89944 \tLL 0.04700 \tTotal 6129.55/959.89/50.40 \n","04/22/2023 05:08:59 PM - INFO - [26:5] loss\t103.46 =\tBCE 103.46219 \tLL 0.05171 \tTotal 8140.99/964.45/46.10 \n","04/22/2023 05:09:00 PM - INFO - [26:6] loss\t90.17 =\tBCE 90.16696 \tLL 0.04910 \tTotal 8093.15/982.29/20.06 \n","04/22/2023 05:09:00 PM - INFO - [26:7] loss\t88.64 =\tBCE 88.63968 \tLL 0.04685 \tTotal 5950.25/763.71/11.13 \n","04/22/2023 05:09:00 PM - INFO - Training epoch 27.\n","04/22/2023 05:09:01 PM - INFO - [27:0] loss\t94.50 =\tBCE 94.50490 \tLL 0.04522 \tTotal 7755.17/871.76/61.12 \n","04/22/2023 05:09:01 PM - INFO - [27:1] loss\t70.73 =\tBCE 70.73034 \tLL 0.04793 \tTotal 2851.55/462.45/28.23 \n","04/22/2023 05:09:02 PM - INFO - [27:2] loss\t97.17 =\tBCE 97.17342 \tLL 0.05244 \tTotal 7125.40/838.22/12.87 \n","04/22/2023 05:09:02 PM - INFO - [27:3] loss\t72.89 =\tBCE 72.89120 \tLL 0.04907 \tTotal 3945.60/423.99/18.13 \n","04/22/2023 05:09:03 PM - INFO - [27:4] loss\t80.32 =\tBCE 80.32492 \tLL 0.04586 \tTotal 4756.10/575.53/61.99 \n","04/22/2023 05:09:04 PM - INFO - [27:5] loss\t82.59 =\tBCE 82.59491 \tLL 0.04433 \tTotal 6096.12/643.76/14.96 \n","04/22/2023 05:09:04 PM - INFO - [27:6] loss\t64.39 =\tBCE 64.39377 \tLL 0.04568 \tTotal 1782.11/255.90/15.89 \n","04/22/2023 05:09:05 PM - INFO - [27:7] loss\t81.36 =\tBCE 81.35874 \tLL 0.04864 \tTotal 5341.80/589.08/10.87 \n","04/22/2023 05:09:05 PM - INFO - Training epoch 28.\n","04/22/2023 05:09:05 PM - INFO - [28:0] loss\t68.75 =\tBCE 68.75298 \tLL 0.04772 \tTotal 3647.01/380.34/28.36 \n","04/22/2023 05:09:06 PM - INFO - [28:1] loss\t70.67 =\tBCE 70.67499 \tLL 0.04386 \tTotal 3280.48/449.64/15.06 \n","04/22/2023 05:09:06 PM - INFO - [28:2] loss\t74.89 =\tBCE 74.89317 \tLL 0.04043 \tTotal 4962.79/579.51/27.95 \n","04/22/2023 05:09:07 PM - INFO - [28:3] loss\t61.89 =\tBCE 61.89108 \tLL 0.04375 \tTotal 733.66/239.85/28.89 \n","04/22/2023 05:09:07 PM - INFO - [28:4] loss\t74.16 =\tBCE 74.15828 \tLL 0.04552 \tTotal 4197.31/515.35/23.89 \n","04/22/2023 05:09:08 PM - INFO - [28:5] loss\t66.37 =\tBCE 66.37054 \tLL 0.04337 \tTotal 2827.84/461.65/31.15 \n","04/22/2023 05:09:08 PM - INFO - [28:6] loss\t63.89 =\tBCE 63.88614 \tLL 0.04071 \tTotal 2278.54/301.16/10.71 \n","04/22/2023 05:09:09 PM - INFO - [28:7] loss\t70.27 =\tBCE 70.26958 \tLL 0.04013 \tTotal 4040.92/540.68/28.28 \n","Not implemented\n","04/22/2023 05:09:09 PM - INFO - Training epoch 29.\n","04/22/2023 05:09:09 PM - INFO - [29:0] loss\t58.46 =\tBCE 58.46350 \tLL 0.04038 \tTotal 698.76/148.92/31.64 \n","04/22/2023 05:09:10 PM - INFO - [29:1] loss\t66.22 =\tBCE 66.21893 \tLL 0.04122 \tTotal 3676.99/467.36/18.08 \n","04/22/2023 05:09:10 PM - INFO - [29:2] loss\t60.22 =\tBCE 60.21532 \tLL 0.03951 \tTotal 2437.01/281.45/27.56 \n","04/22/2023 05:09:11 PM - INFO - [29:3] loss\t60.48 =\tBCE 60.48483 \tLL 0.03768 \tTotal 2195.81/289.62/25.89 \n","04/22/2023 05:09:12 PM - INFO - [29:4] loss\t62.78 =\tBCE 62.78037 \tLL 0.03700 \tTotal 3596.51/418.20/33.23 \n","04/22/2023 05:09:12 PM - INFO - [29:5] loss\t54.83 =\tBCE 54.82794 \tLL 0.03810 \tTotal 741.08/101.53/14.79 \n","04/22/2023 05:09:13 PM - INFO - [29:6] loss\t62.24 =\tBCE 62.23613 \tLL 0.04042 \tTotal 3339.18/379.58/24.79 \n","04/22/2023 05:09:13 PM - INFO - [29:7] loss\t54.44 =\tBCE 54.43699 \tLL 0.03874 \tTotal 1242.33/157.12/42.17 \n","04/22/2023 05:09:13 PM - INFO - EVALUATION prior to epoch [30]...\n","04/22/2023 05:09:13 PM - INFO - [30] loss\t1242.81=\tBCE 1242.81 \tLL 0.04056 \n","04/22/2023 05:09:15 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/30_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:09:20 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/30_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:09:25 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/30_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 05:09:26 PM - INFO - Training epoch 30.\n","04/22/2023 05:09:27 PM - INFO - [30:0] loss\t57.75 =\tBCE 57.75474 \tLL 0.03532 \tTotal 2866.73/349.94/19.19 \n","04/22/2023 05:09:27 PM - INFO - [30:1] loss\t53.77 =\tBCE 53.76840 \tLL 0.03531 \tTotal 1979.99/285.32/9.06 \n","04/22/2023 05:09:28 PM - INFO - [30:2] loss\t54.45 =\tBCE 54.45383 \tLL 0.03716 \tTotal 1752.17/256.68/13.75 \n","04/22/2023 05:09:28 PM - INFO - [30:3] loss\t55.19 =\tBCE 55.18720 \tLL 0.03676 \tTotal 2484.31/313.36/22.79 \n","04/22/2023 05:09:29 PM - INFO - [30:4] loss\t51.04 =\tBCE 51.03778 \tLL 0.03558 \tTotal 864.43/171.48/13.67 \n","04/22/2023 05:09:29 PM - INFO - [30:5] loss\t52.32 =\tBCE 52.32051 \tLL 0.03280 \tTotal 2668.83/332.41/8.21 \n","04/22/2023 05:09:30 PM - INFO - [30:6] loss\t49.57 =\tBCE 49.56781 \tLL 0.03581 \tTotal 1037.30/114.01/16.09 \n","04/22/2023 05:09:30 PM - INFO - [30:7] loss\t52.15 =\tBCE 52.15491 \tLL 0.03459 \tTotal 2403.49/323.21/13.61 \n","04/22/2023 05:09:30 PM - INFO - Training epoch 31.\n","04/22/2023 05:09:31 PM - INFO - [31:0] loss\t47.51 =\tBCE 47.50741 \tLL 0.03387 \tTotal 855.19/107.36/23.95 \n","04/22/2023 05:09:31 PM - INFO - [31:1] loss\t50.24 =\tBCE 50.24045 \tLL 0.03334 \tTotal 2653.29/321.37/26.78 \n","04/22/2023 05:09:32 PM - INFO - [31:2] loss\t47.55 =\tBCE 47.55120 \tLL 0.03310 \tTotal 794.77/158.57/7.49 \n","04/22/2023 05:09:32 PM - INFO - [31:3] loss\t49.24 =\tBCE 49.23730 \tLL 0.03371 \tTotal 2184.62/262.66/19.29 \n","04/22/2023 05:09:33 PM - INFO - [31:4] loss\t46.50 =\tBCE 46.50003 \tLL 0.03375 \tTotal 509.21/72.46/11.63 \n","04/22/2023 05:09:33 PM - INFO - [31:5] loss\t47.77 =\tBCE 47.77081 \tLL 0.03239 \tTotal 2163.18/261.97/6.32 \n","04/22/2023 05:09:34 PM - INFO - [31:6] loss\t45.20 =\tBCE 45.19996 \tLL 0.03219 \tTotal 890.18/135.21/17.61 \n","04/22/2023 05:09:35 PM - INFO - [31:7] loss\t45.28 =\tBCE 45.28137 \tLL 0.03207 \tTotal 1948.58/253.18/21.20 \n","04/22/2023 05:09:35 PM - INFO - Training epoch 32.\n","04/22/2023 05:09:35 PM - INFO - [32:0] loss\t44.22 =\tBCE 44.22373 \tLL 0.03210 \tTotal 978.46/181.32/26.06 \n","04/22/2023 05:09:36 PM - INFO - [32:1] loss\t44.57 =\tBCE 44.56894 \tLL 0.03229 \tTotal 1942.01/309.28/20.15 \n","04/22/2023 05:09:36 PM - INFO - [32:2] loss\t44.40 =\tBCE 44.39687 \tLL 0.03087 \tTotal 2056.57/444.58/7.95 \n","04/22/2023 05:09:37 PM - INFO - [32:3] loss\t46.97 =\tBCE 46.96801 \tLL 0.03219 \tTotal 3496.53/703.28/39.93 \n","04/22/2023 05:09:37 PM - INFO - [32:4] loss\t53.61 =\tBCE 53.60734 \tLL 0.03144 \tTotal 5866.27/1265.65/23.26 \n","04/22/2023 05:09:38 PM - INFO - [32:5] loss\t84.02 =\tBCE 84.01985 \tLL 0.03241 \tTotal 10056.74/2430.90/9.38 \n","04/22/2023 05:09:38 PM - INFO - [32:6] loss\t176.30 =\tBCE 176.30186 \tLL 0.02884 \tTotal 22368.29/4616.38/13.39 \n","04/22/2023 05:09:39 PM - INFO - [32:7] loss\t465.00 =\tBCE 464.99768 \tLL 0.04015 \tTotal 24286.55/6799.60/18.64 \n","04/22/2023 05:09:39 PM - INFO - Training epoch 33.\n","04/22/2023 05:09:39 PM - INFO - [33:0] loss\t70.17 =\tBCE 70.16664 \tLL 0.04058 \tTotal 2494.83/1100.86/30.15 \n","04/22/2023 05:09:40 PM - INFO - [33:1] loss\t382.69 =\tBCE 382.68637 \tLL 0.03864 \tTotal 26882.92/6231.27/26.58 \n","04/22/2023 05:09:40 PM - INFO - [33:2] loss\t194.15 =\tBCE 194.14870 \tLL 0.05487 \tTotal 15017.53/2398.21/24.69 \n","04/22/2023 05:09:41 PM - INFO - [33:3] loss\t313.82 =\tBCE 313.82275 \tLL 0.06299 \tTotal 15411.08/4067.53/39.05 \n","04/22/2023 05:09:42 PM - INFO - [33:4] loss\t106.78 =\tBCE 106.77814 \tLL 0.06275 \tTotal 4280.23/1175.21/32.55 \n","04/22/2023 05:09:42 PM - INFO - [33:5] loss\t240.67 =\tBCE 240.66940 \tLL 0.06047 \tTotal 12808.58/3464.70/25.48 \n","04/22/2023 05:09:43 PM - INFO - [33:6] loss\t163.01 =\tBCE 163.01352 \tLL 0.06853 \tTotal 5042.11/2901.65/36.41 \n","04/22/2023 05:09:43 PM - INFO - [33:7] loss\t86.82 =\tBCE 86.82172 \tLL 0.06918 \tTotal 5592.41/583.64/24.52 \n","04/22/2023 05:09:43 PM - INFO - Training epoch 34.\n","04/22/2023 05:09:44 PM - INFO - [34:0] loss\t165.67 =\tBCE 165.66762 \tLL 0.06941 \tTotal 5480.94/2725.23/22.64 \n","04/22/2023 05:09:44 PM - INFO - [34:1] loss\t134.78 =\tBCE 134.78052 \tLL 0.06933 \tTotal 2955.44/2229.27/12.22 \n","04/22/2023 05:09:45 PM - INFO - [34:2] loss\t91.30 =\tBCE 91.30046 \tLL 0.06614 \tTotal 4788.04/437.08/6.03 \n","04/22/2023 05:09:45 PM - INFO - [34:3] loss\t123.33 =\tBCE 123.33200 \tLL 0.06693 \tTotal 3128.59/1785.62/18.09 \n","04/22/2023 05:09:46 PM - INFO - [34:4] loss\t127.81 =\tBCE 127.81415 \tLL 0.06347 \tTotal 4171.85/1764.84/40.77 \n","04/22/2023 05:09:46 PM - INFO - [34:5] loss\t81.10 =\tBCE 81.10234 \tLL 0.06296 \tTotal 2107.35/410.87/22.95 \n","04/22/2023 05:09:47 PM - INFO - [34:6] loss\t97.24 =\tBCE 97.23595 \tLL 0.06483 \tTotal 2608.18/1062.58/16.72 \n","04/22/2023 05:09:48 PM - INFO - [34:7] loss\t114.83 =\tBCE 114.82881 \tLL 0.06635 \tTotal 2669.85/1354.86/32.29 \n","04/22/2023 05:09:48 PM - INFO - Training epoch 35.\n","04/22/2023 05:09:48 PM - INFO - [35:0] loss\t95.70 =\tBCE 95.70387 \tLL 0.06810 \tTotal 2673.61/818.56/17.98 \n","04/22/2023 05:09:49 PM - INFO - [35:1] loss\t81.03 =\tBCE 81.02657 \tLL 0.06393 \tTotal 2727.02/323.88/18.41 \n","04/22/2023 05:09:49 PM - INFO - [35:2] loss\t92.70 =\tBCE 92.70143 \tLL 0.06023 \tTotal 2624.02/849.58/21.51 \n","04/22/2023 05:09:50 PM - INFO - [35:3] loss\t95.19 =\tBCE 95.18611 \tLL 0.05901 \tTotal 3130.28/891.51/32.85 \n","04/22/2023 05:09:50 PM - INFO - [35:4] loss\t85.12 =\tBCE 85.11798 \tLL 0.06015 \tTotal 2735.10/584.35/37.87 \n","04/22/2023 05:09:51 PM - INFO - [35:5] loss\t80.11 =\tBCE 80.10925 \tLL 0.05775 \tTotal 2191.96/262.16/32.10 \n","04/22/2023 05:09:51 PM - INFO - [35:6] loss\t85.23 =\tBCE 85.23486 \tLL 0.05761 \tTotal 2389.33/517.08/15.63 \n","04/22/2023 05:09:52 PM - INFO - [35:7] loss\t85.12 =\tBCE 85.11581 \tLL 0.05538 \tTotal 2080.45/678.78/18.82 \n","04/22/2023 05:09:52 PM - INFO - Training epoch 36.\n","04/22/2023 05:09:52 PM - INFO - [36:0] loss\t80.73 =\tBCE 80.72672 \tLL 0.05492 \tTotal 1941.95/511.33/36.05 \n","04/22/2023 05:09:53 PM - INFO - [36:1] loss\t75.59 =\tBCE 75.59050 \tLL 0.05273 \tTotal 1750.63/238.99/14.18 \n","04/22/2023 05:09:54 PM - INFO - [36:2] loss\t76.05 =\tBCE 76.04610 \tLL 0.04984 \tTotal 1491.01/498.33/35.13 \n","04/22/2023 05:09:54 PM - INFO - [36:3] loss\t80.51 =\tBCE 80.50603 \tLL 0.04904 \tTotal 2126.07/710.41/5.00 \n","04/22/2023 05:09:55 PM - INFO - [36:4] loss\t74.24 =\tBCE 74.24313 \tLL 0.04812 \tTotal 1718.21/527.83/8.82 \n","04/22/2023 05:09:55 PM - INFO - [36:5] loss\t67.58 =\tBCE 67.58177 \tLL 0.04559 \tTotal 795.28/141.47/23.30 \n","04/22/2023 05:09:56 PM - INFO - [36:6] loss\t74.62 =\tBCE 74.61582 \tLL 0.04594 \tTotal 1792.30/520.80/8.23 \n","04/22/2023 05:09:56 PM - INFO - [36:7] loss\t73.68 =\tBCE 73.67683 \tLL 0.04395 \tTotal 1882.25/556.65/11.34 \n","04/22/2023 05:09:56 PM - INFO - Training epoch 37.\n","04/22/2023 05:09:57 PM - INFO - [37:0] loss\t66.65 =\tBCE 66.65264 \tLL 0.04322 \tTotal 684.75/239.69/9.90 \n","04/22/2023 05:09:57 PM - INFO - [37:1] loss\t67.43 =\tBCE 67.42577 \tLL 0.04163 \tTotal 1417.21/266.64/8.48 \n","04/22/2023 05:09:58 PM - INFO - [37:2] loss\t68.75 =\tBCE 68.74744 \tLL 0.03985 \tTotal 1770.60/498.81/8.92 \n","04/22/2023 05:09:59 PM - INFO - [37:3] loss\t67.36 =\tBCE 67.36397 \tLL 0.04243 \tTotal 1045.49/410.10/30.97 \n","04/22/2023 05:09:59 PM - INFO - [37:4] loss\t62.89 =\tBCE 62.89286 \tLL 0.03928 \tTotal 1238.06/177.59/26.12 \n","04/22/2023 05:10:00 PM - INFO - [37:5] loss\t62.74 =\tBCE 62.74239 \tLL 0.04154 \tTotal 1274.98/288.93/13.90 \n","04/22/2023 05:10:00 PM - INFO - [37:6] loss\t62.42 =\tBCE 62.41990 \tLL 0.03987 \tTotal 1185.01/349.66/13.80 \n","04/22/2023 05:10:01 PM - INFO - [37:7] loss\t61.61 =\tBCE 61.60980 \tLL 0.03978 \tTotal 1039.92/213.43/11.60 \n","04/22/2023 05:10:01 PM - INFO - Training epoch 38.\n","04/22/2023 05:10:01 PM - INFO - [38:0] loss\t59.37 =\tBCE 59.37466 \tLL 0.03822 \tTotal 1240.83/188.57/8.41 \n","04/22/2023 05:10:02 PM - INFO - [38:1] loss\t59.39 =\tBCE 59.39455 \tLL 0.03673 \tTotal 911.32/355.86/7.22 \n","04/22/2023 05:10:02 PM - INFO - [38:2] loss\t58.46 =\tBCE 58.45816 \tLL 0.03753 \tTotal 1298.43/302.75/13.14 \n","04/22/2023 05:10:03 PM - INFO - [38:3] loss\t55.64 =\tBCE 55.64347 \tLL 0.03575 \tTotal 550.98/99.08/4.66 \n","04/22/2023 05:10:04 PM - INFO - [38:4] loss\t56.13 =\tBCE 56.13062 \tLL 0.03728 \tTotal 1121.59/208.92/13.30 \n","04/22/2023 05:10:04 PM - INFO - [38:5] loss\t57.56 =\tBCE 57.55973 \tLL 0.03837 \tTotal 824.65/261.84/21.16 \n","04/22/2023 05:10:05 PM - INFO - [38:6] loss\t53.66 =\tBCE 53.66076 \tLL 0.03496 \tTotal 860.00/125.30/16.72 \n","04/22/2023 05:10:05 PM - INFO - [38:7] loss\t54.42 =\tBCE 54.41893 \tLL 0.03552 \tTotal 741.59/217.20/5.95 \n","Not implemented\n","04/22/2023 05:10:05 PM - INFO - Training epoch 39.\n","04/22/2023 05:10:06 PM - INFO - [39:0] loss\t53.31 =\tBCE 53.30818 \tLL 0.03424 \tTotal 869.25/313.40/6.90 \n","04/22/2023 05:10:06 PM - INFO - [39:1] loss\t51.67 =\tBCE 51.66891 \tLL 0.03525 \tTotal 737.57/128.27/31.22 \n","04/22/2023 05:10:07 PM - INFO - [39:2] loss\t51.76 =\tBCE 51.76005 \tLL 0.03464 \tTotal 815.48/215.75/21.86 \n","04/22/2023 05:10:07 PM - INFO - [39:3] loss\t50.22 =\tBCE 50.21935 \tLL 0.03339 \tTotal 845.90/254.28/8.19 \n","04/22/2023 05:10:08 PM - INFO - [39:4] loss\t50.55 =\tBCE 50.55131 \tLL 0.03451 \tTotal 783.88/99.69/31.07 \n","04/22/2023 05:10:08 PM - INFO - [39:5] loss\t50.51 =\tBCE 50.50965 \tLL 0.03559 \tTotal 971.06/227.02/10.72 \n","04/22/2023 05:10:09 PM - INFO - [39:6] loss\t48.28 =\tBCE 48.28213 \tLL 0.03208 \tTotal 763.86/229.29/8.13 \n","04/22/2023 05:10:09 PM - INFO - [39:7] loss\t48.07 =\tBCE 48.06535 \tLL 0.03229 \tTotal 881.24/79.60/10.43 \n","04/22/2023 05:10:10 PM - INFO - EVALUATION prior to epoch [40]...\n","04/22/2023 05:10:10 PM - INFO - [40] loss\t1334.98=\tBCE 1334.98 \tLL 0.04001 \n","04/22/2023 05:10:11 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/40_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:10:17 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/40_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:10:22 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/40_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 05:10:23 PM - INFO - Training epoch 40.\n","04/22/2023 05:10:23 PM - INFO - [40:0] loss\t47.45 =\tBCE 47.45424 \tLL 0.03310 \tTotal 611.40/184.19/20.51 \n","04/22/2023 05:10:24 PM - INFO - [40:1] loss\t46.21 =\tBCE 46.21108 \tLL 0.03160 \tTotal 991.01/152.39/15.91 \n","04/22/2023 05:10:24 PM - INFO - [40:2] loss\t46.43 =\tBCE 46.43225 \tLL 0.03226 \tTotal 406.59/107.84/4.04 \n","04/22/2023 05:10:25 PM - INFO - [40:3] loss\t47.05 =\tBCE 47.04699 \tLL 0.03264 \tTotal 1117.07/194.84/4.85 \n","04/22/2023 05:10:25 PM - INFO - [40:4] loss\t44.51 =\tBCE 44.51096 \tLL 0.03075 \tTotal 371.52/115.41/7.07 \n","04/22/2023 05:10:26 PM - INFO - [40:5] loss\t45.36 =\tBCE 45.36042 \tLL 0.03203 \tTotal 954.48/135.07/24.93 \n","04/22/2023 05:10:27 PM - INFO - [40:6] loss\t43.57 =\tBCE 43.56956 \tLL 0.03029 \tTotal 449.84/151.94/11.77 \n","04/22/2023 05:10:27 PM - INFO - [40:7] loss\t44.90 =\tBCE 44.90310 \tLL 0.03211 \tTotal 727.78/82.35/9.55 \n","04/22/2023 05:10:27 PM - INFO - Training epoch 41.\n","04/22/2023 05:10:28 PM - INFO - [41:0] loss\t43.65 =\tBCE 43.64850 \tLL 0.03101 \tTotal 649.65/213.58/27.76 \n","04/22/2023 05:10:28 PM - INFO - [41:1] loss\t42.79 =\tBCE 42.79238 \tLL 0.03042 \tTotal 827.20/124.01/23.77 \n","04/22/2023 05:10:29 PM - INFO - [41:2] loss\t41.78 =\tBCE 41.77507 \tLL 0.02957 \tTotal 574.06/142.59/18.00 \n","04/22/2023 05:10:29 PM - INFO - [41:3] loss\t42.44 =\tBCE 42.44231 \tLL 0.03021 \tTotal 506.53/134.58/4.84 \n","04/22/2023 05:10:30 PM - INFO - [41:4] loss\t40.89 =\tBCE 40.88997 \tLL 0.02903 \tTotal 406.63/96.51/18.76 \n","04/22/2023 05:10:30 PM - INFO - [41:5] loss\t42.22 =\tBCE 42.22063 \tLL 0.03014 \tTotal 454.85/174.93/11.87 \n","04/22/2023 05:10:31 PM - INFO - [41:6] loss\t41.15 =\tBCE 41.14767 \tLL 0.02952 \tTotal 479.67/57.81/17.27 \n","04/22/2023 05:10:31 PM - INFO - [41:7] loss\t40.59 =\tBCE 40.58617 \tLL 0.02977 \tTotal 770.16/130.50/16.14 \n","04/22/2023 05:10:31 PM - INFO - Training epoch 42.\n","04/22/2023 05:10:32 PM - INFO - [42:0] loss\t39.65 =\tBCE 39.64548 \tLL 0.02901 \tTotal 713.74/72.07/5.51 \n","04/22/2023 05:10:33 PM - INFO - [42:1] loss\t39.82 =\tBCE 39.81629 \tLL 0.02841 \tTotal 803.19/168.25/8.53 \n","04/22/2023 05:10:33 PM - INFO - [42:2] loss\t38.61 =\tBCE 38.60641 \tLL 0.02739 \tTotal 392.69/103.75/14.47 \n","04/22/2023 05:10:34 PM - INFO - [42:3] loss\t40.23 =\tBCE 40.23400 \tLL 0.02956 \tTotal 537.01/111.37/27.86 \n","04/22/2023 05:10:34 PM - INFO - [42:4] loss\t38.61 =\tBCE 38.60585 \tLL 0.02787 \tTotal 710.62/110.01/11.25 \n","04/22/2023 05:10:35 PM - INFO - [42:5] loss\t39.09 =\tBCE 39.08632 \tLL 0.02882 \tTotal 421.11/91.89/19.53 \n","04/22/2023 05:10:35 PM - INFO - [42:6] loss\t38.15 =\tBCE 38.15145 \tLL 0.02832 \tTotal 552.10/149.24/16.38 \n","04/22/2023 05:10:36 PM - INFO - [42:7] loss\t37.88 =\tBCE 37.88474 \tLL 0.02756 \tTotal 475.09/67.54/27.54 \n","04/22/2023 05:10:36 PM - INFO - Training epoch 43.\n","04/22/2023 05:10:36 PM - INFO - [43:0] loss\t37.45 =\tBCE 37.44933 \tLL 0.02712 \tTotal 973.67/165.09/6.28 \n","04/22/2023 05:10:37 PM - INFO - [43:1] loss\t37.45 =\tBCE 37.44899 \tLL 0.02785 \tTotal 1541.32/164.18/20.00 \n","04/22/2023 05:10:37 PM - INFO - [43:2] loss\t37.77 =\tBCE 37.76988 \tLL 0.02736 \tTotal 2065.27/139.64/28.58 \n","04/22/2023 05:10:38 PM - INFO - [43:3] loss\t37.32 =\tBCE 37.32059 \tLL 0.02653 \tTotal 2601.75/177.64/4.57 \n","04/22/2023 05:10:38 PM - INFO - [43:4] loss\t38.27 =\tBCE 38.27493 \tLL 0.02644 \tTotal 3203.98/249.37/20.61 \n","04/22/2023 05:10:39 PM - INFO - [43:5] loss\t39.05 =\tBCE 39.05373 \tLL 0.02613 \tTotal 4033.97/291.13/18.20 \n","04/22/2023 05:10:39 PM - INFO - [43:6] loss\t42.14 =\tBCE 42.13835 \tLL 0.02761 \tTotal 5814.46/387.09/33.43 \n","04/22/2023 05:10:40 PM - INFO - [43:7] loss\t51.76 =\tBCE 51.75575 \tLL 0.02574 \tTotal 9636.70/696.78/9.58 \n","04/22/2023 05:10:40 PM - INFO - Training epoch 44.\n","04/22/2023 05:10:41 PM - INFO - [44:0] loss\t85.51 =\tBCE 85.50677 \tLL 0.02746 \tTotal 16330.22/1146.98/5.82 \n","04/22/2023 05:10:41 PM - INFO - [44:1] loss\t134.15 =\tBCE 134.15054 \tLL 0.02571 \tTotal 23714.80/1660.86/9.18 \n","04/22/2023 05:10:42 PM - INFO - [44:2] loss\t163.07 =\tBCE 163.06644 \tLL 0.02848 \tTotal 23651.30/1855.73/16.54 \n","04/22/2023 05:10:42 PM - INFO - [44:3] loss\t53.37 =\tBCE 53.36529 \tLL 0.02730 \tTotal 8841.57/637.38/24.84 \n","04/22/2023 05:10:43 PM - INFO - [44:4] loss\t75.77 =\tBCE 75.77004 \tLL 0.02677 \tTotal 13454.71/1493.22/5.90 \n","04/22/2023 05:10:43 PM - INFO - [44:5] loss\t146.70 =\tBCE 146.70076 \tLL 0.03106 \tTotal 22020.70/1477.88/19.27 \n","04/22/2023 05:10:44 PM - INFO - [44:6] loss\t53.62 =\tBCE 53.61988 \tLL 0.02975 \tTotal 6425.05/888.82/24.27 \n","04/22/2023 05:10:44 PM - INFO - [44:7] loss\t99.57 =\tBCE 99.56677 \tLL 0.02734 \tTotal 17120.62/1189.24/4.51 \n","04/22/2023 05:10:44 PM - INFO - Training epoch 45.\n","04/22/2023 05:10:45 PM - INFO - [45:0] loss\t111.66 =\tBCE 111.66236 \tLL 0.03226 \tTotal 18327.32/1135.54/5.40 \n","04/22/2023 05:10:46 PM - INFO - [45:1] loss\t44.50 =\tBCE 44.49965 \tLL 0.03150 \tTotal 4405.16/411.02/8.09 \n","04/22/2023 05:10:46 PM - INFO - [45:2] loss\t107.44 =\tBCE 107.43622 \tLL 0.03029 \tTotal 16621.63/1080.86/14.27 \n","04/22/2023 05:10:47 PM - INFO - [45:3] loss\t42.39 =\tBCE 42.39006 \tLL 0.03165 \tTotal 2293.70/536.69/29.74 \n","04/22/2023 05:10:47 PM - INFO - [45:4] loss\t90.29 =\tBCE 90.28945 \tLL 0.03293 \tTotal 13839.44/909.44/12.29 \n","04/22/2023 05:10:48 PM - INFO - [45:5] loss\t43.95 =\tBCE 43.95290 \tLL 0.03235 \tTotal 3761.62/399.64/14.09 \n","04/22/2023 05:10:48 PM - INFO - [45:6] loss\t73.63 =\tBCE 73.62852 \tLL 0.03240 \tTotal 11239.01/795.32/15.91 \n","04/22/2023 05:10:49 PM - INFO - [45:7] loss\t48.36 =\tBCE 48.35767 \tLL 0.03433 \tTotal 3914.83/504.59/39.37 \n","04/22/2023 05:10:49 PM - INFO - Training epoch 46.\n","04/22/2023 05:10:49 PM - INFO - [46:0] loss\t68.96 =\tBCE 68.96044 \tLL 0.03412 \tTotal 10262.68/734.23/6.19 \n","04/22/2023 05:10:50 PM - INFO - [46:1] loss\t44.11 =\tBCE 44.11043 \tLL 0.03256 \tTotal 3098.82/418.83/15.09 \n","04/22/2023 05:10:50 PM - INFO - [46:2] loss\t65.15 =\tBCE 65.15363 \tLL 0.03133 \tTotal 9052.76/811.23/37.93 \n","04/22/2023 05:10:51 PM - INFO - [46:3] loss\t44.32 =\tBCE 44.32322 \tLL 0.03447 \tTotal 2450.39/462.76/20.21 \n","04/22/2023 05:10:51 PM - INFO - [46:4] loss\t62.39 =\tBCE 62.38943 \tLL 0.03442 \tTotal 8034.91/781.16/24.20 \n","04/22/2023 05:10:52 PM - INFO - [46:5] loss\t42.17 =\tBCE 42.17459 \tLL 0.03270 \tTotal 1795.40/300.72/27.08 \n","04/22/2023 05:10:53 PM - INFO - [46:6] loss\t60.29 =\tBCE 60.28881 \tLL 0.03215 \tTotal 8113.15/889.75/16.63 \n","04/22/2023 05:10:53 PM - INFO - [46:7] loss\t40.28 =\tBCE 40.27654 \tLL 0.03216 \tTotal 1544.15/206.45/15.27 \n","04/22/2023 05:10:53 PM - INFO - Training epoch 47.\n","04/22/2023 05:10:54 PM - INFO - [47:0] loss\t57.64 =\tBCE 57.64030 \tLL 0.03427 \tTotal 6598.21/769.80/24.63 \n","04/22/2023 05:10:54 PM - INFO - [47:1] loss\t41.18 =\tBCE 41.17517 \tLL 0.03292 \tTotal 2204.66/266.29/27.36 \n","04/22/2023 05:10:55 PM - INFO - [47:2] loss\t49.87 =\tBCE 49.87277 \tLL 0.03085 \tTotal 5575.40/658.78/7.21 \n","04/22/2023 05:10:55 PM - INFO - [47:3] loss\t43.20 =\tBCE 43.20466 \tLL 0.03310 \tTotal 2671.09/400.80/9.02 \n","04/22/2023 05:10:56 PM - INFO - [47:4] loss\t45.79 =\tBCE 45.79483 \tLL 0.03342 \tTotal 4498.91/414.63/9.74 \n","04/22/2023 05:10:56 PM - INFO - [47:5] loss\t43.14 =\tBCE 43.13716 \tLL 0.03345 \tTotal 2875.18/458.98/4.07 \n","04/22/2023 05:10:57 PM - INFO - [47:6] loss\t42.92 =\tBCE 42.92188 \tLL 0.03098 \tTotal 3471.56/327.62/23.45 \n","04/22/2023 05:10:58 PM - INFO - [47:7] loss\t43.41 =\tBCE 43.40620 \tLL 0.03106 \tTotal 3238.95/480.43/6.41 \n","04/22/2023 05:10:58 PM - INFO - Training epoch 48.\n","04/22/2023 05:10:58 PM - INFO - [48:0] loss\t39.91 =\tBCE 39.90700 \tLL 0.03192 \tTotal 2524.14/227.59/7.41 \n","04/22/2023 05:10:59 PM - INFO - [48:1] loss\t42.69 =\tBCE 42.69143 \tLL 0.03336 \tTotal 3005.89/419.34/13.74 \n","04/22/2023 05:10:59 PM - INFO - [48:2] loss\t40.11 =\tBCE 40.10785 \tLL 0.03203 \tTotal 2022.62/278.08/12.38 \n","04/22/2023 05:11:00 PM - INFO - [48:3] loss\t39.97 =\tBCE 39.97119 \tLL 0.02892 \tTotal 2815.07/421.82/22.32 \n","04/22/2023 05:11:00 PM - INFO - [48:4] loss\t38.72 =\tBCE 38.72317 \tLL 0.03036 \tTotal 1599.98/296.63/10.13 \n","04/22/2023 05:11:01 PM - INFO - [48:5] loss\t39.93 =\tBCE 39.92601 \tLL 0.03029 \tTotal 2388.75/368.50/23.32 \n","04/22/2023 05:11:01 PM - INFO - [48:6] loss\t37.33 =\tBCE 37.32729 \tLL 0.02918 \tTotal 1028.58/289.57/15.64 \n","04/22/2023 05:11:02 PM - INFO - [48:7] loss\t38.77 =\tBCE 38.77398 \tLL 0.03006 \tTotal 2097.78/324.29/20.21 \n","Not implemented\n","04/22/2023 05:11:02 PM - INFO - Training epoch 49.\n","04/22/2023 05:11:02 PM - INFO - [49:0] loss\t37.19 =\tBCE 37.18774 \tLL 0.02876 \tTotal 1064.55/343.09/9.39 \n","04/22/2023 05:11:03 PM - INFO - [49:1] loss\t37.85 =\tBCE 37.85128 \tLL 0.02949 \tTotal 1995.69/233.49/28.65 \n","04/22/2023 05:11:03 PM - INFO - [49:2] loss\t37.02 =\tBCE 37.01654 \tLL 0.02931 \tTotal 1080.67/305.64/27.79 \n","04/22/2023 05:11:04 PM - INFO - [49:3] loss\t36.97 =\tBCE 36.97109 \tLL 0.02899 \tTotal 1955.42/193.90/7.11 \n","04/22/2023 05:11:05 PM - INFO - [49:4] loss\t36.25 =\tBCE 36.24686 \tLL 0.02791 \tTotal 1221.59/315.34/8.93 \n","04/22/2023 05:11:05 PM - INFO - [49:5] loss\t36.05 =\tBCE 36.05104 \tLL 0.02935 \tTotal 1547.63/128.24/20.29 \n","04/22/2023 05:11:06 PM - INFO - [49:6] loss\t36.16 =\tBCE 36.16107 \tLL 0.02959 \tTotal 1119.90/243.11/22.02 \n","04/22/2023 05:11:06 PM - INFO - [49:7] loss\t34.71 =\tBCE 34.71393 \tLL 0.02771 \tTotal 1428.85/122.00/10.24 \n","04/22/2023 05:11:06 PM - INFO - EVALUATION prior to epoch [50]...\n","04/22/2023 05:11:06 PM - INFO - [50] loss\t1512.75=\tBCE 1512.75 \tLL 0.03234 \n","04/22/2023 05:11:08 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/50_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:11:14 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/50_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:11:19 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/50_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 05:11:19 PM - INFO - Training epoch 50.\n","04/22/2023 05:11:20 PM - INFO - [50:0] loss\t34.59 =\tBCE 34.58746 \tLL 0.02675 \tTotal 908.66/248.18/10.11 \n","04/22/2023 05:11:20 PM - INFO - [50:1] loss\t34.28 =\tBCE 34.27743 \tLL 0.02648 \tTotal 1305.47/124.43/11.38 \n","04/22/2023 05:11:21 PM - INFO - [50:2] loss\t34.87 =\tBCE 34.87138 \tLL 0.02801 \tTotal 872.31/228.05/16.41 \n","04/22/2023 05:11:21 PM - INFO - [50:3] loss\t33.60 =\tBCE 33.59918 \tLL 0.02695 \tTotal 1343.04/125.43/19.87 \n","04/22/2023 05:11:22 PM - INFO - [50:4] loss\t33.95 =\tBCE 33.95137 \tLL 0.02675 \tTotal 996.28/223.28/7.01 \n","04/22/2023 05:11:23 PM - INFO - [50:5] loss\t33.76 =\tBCE 33.75728 \tLL 0.02630 \tTotal 1206.91/123.39/8.44 \n","04/22/2023 05:11:23 PM - INFO - [50:6] loss\t33.38 =\tBCE 33.37613 \tLL 0.02655 \tTotal 944.03/175.23/31.71 \n","04/22/2023 05:11:24 PM - INFO - [50:7] loss\t33.98 =\tBCE 33.98449 \tLL 0.02780 \tTotal 1275.83/165.15/33.18 \n","04/22/2023 05:11:24 PM - INFO - Training epoch 51.\n","04/22/2023 05:11:24 PM - INFO - [51:0] loss\t32.77 =\tBCE 32.77348 \tLL 0.02578 \tTotal 932.63/152.67/3.26 \n","04/22/2023 05:11:25 PM - INFO - [51:1] loss\t32.86 =\tBCE 32.86309 \tLL 0.02586 \tTotal 1129.03/164.54/12.64 \n","04/22/2023 05:11:25 PM - INFO - [51:2] loss\t32.09 =\tBCE 32.08867 \tLL 0.02562 \tTotal 1163.32/115.62/43.00 \n","04/22/2023 05:11:26 PM - INFO - [51:3] loss\t32.69 =\tBCE 32.68799 \tLL 0.02574 \tTotal 1041.33/161.01/26.38 \n","04/22/2023 05:11:26 PM - INFO - [51:4] loss\t31.67 =\tBCE 31.67430 \tLL 0.02517 \tTotal 1115.41/94.85/11.22 \n","04/22/2023 05:11:27 PM - INFO - [51:5] loss\t31.99 =\tBCE 31.98557 \tLL 0.02612 \tTotal 761.87/131.87/13.11 \n","04/22/2023 05:11:27 PM - INFO - [51:6] loss\t31.70 =\tBCE 31.69939 \tLL 0.02442 \tTotal 1190.17/119.30/16.50 \n","04/22/2023 05:11:28 PM - INFO - [51:7] loss\t30.89 =\tBCE 30.89396 \tLL 0.02440 \tTotal 586.75/112.09/14.89 \n","04/22/2023 05:11:28 PM - INFO - Training epoch 52.\n","04/22/2023 05:11:29 PM - INFO - [52:0] loss\t31.98 =\tBCE 31.97510 \tLL 0.02598 \tTotal 868.29/106.82/13.95 \n","04/22/2023 05:11:29 PM - INFO - [52:1] loss\t30.96 =\tBCE 30.95697 \tLL 0.02449 \tTotal 810.50/88.32/3.03 \n","04/22/2023 05:11:30 PM - INFO - [52:2] loss\t30.03 =\tBCE 30.02813 \tLL 0.02350 \tTotal 677.38/119.87/11.45 \n","04/22/2023 05:11:30 PM - INFO - [52:3] loss\t30.99 =\tBCE 30.98733 \tLL 0.02402 \tTotal 1036.86/102.83/20.51 \n","04/22/2023 05:11:31 PM - INFO - [52:4] loss\t29.98 =\tBCE 29.97905 \tLL 0.02412 \tTotal 853.47/121.51/12.91 \n","04/22/2023 05:11:31 PM - INFO - [52:5] loss\t30.31 =\tBCE 30.30668 \tLL 0.02383 \tTotal 1002.40/135.95/7.86 \n","04/22/2023 05:11:32 PM - INFO - [52:6] loss\t29.72 =\tBCE 29.72081 \tLL 0.02395 \tTotal 551.44/83.78/8.56 \n","04/22/2023 05:11:32 PM - INFO - [52:7] loss\t29.96 =\tBCE 29.95674 \tLL 0.02416 \tTotal 747.07/98.12/8.60 \n","04/22/2023 05:11:32 PM - INFO - Training epoch 53.\n","04/22/2023 05:11:33 PM - INFO - [53:0] loss\t29.71 =\tBCE 29.71115 \tLL 0.02336 \tTotal 1052.34/98.79/23.72 \n","04/22/2023 05:11:33 PM - INFO - [53:1] loss\t29.57 =\tBCE 29.56630 \tLL 0.02365 \tTotal 1055.77/112.18/4.83 \n","04/22/2023 05:11:34 PM - INFO - [53:2] loss\t29.05 =\tBCE 29.04665 \tLL 0.02250 \tTotal 1416.47/134.08/12.34 \n","04/22/2023 05:11:34 PM - INFO - [53:3] loss\t29.39 =\tBCE 29.38797 \tLL 0.02355 \tTotal 1106.61/106.44/14.50 \n","04/22/2023 05:11:35 PM - INFO - [53:4] loss\t29.07 =\tBCE 29.07411 \tLL 0.02305 \tTotal 819.03/73.52/5.30 \n","04/22/2023 05:11:35 PM - INFO - [53:5] loss\t29.05 =\tBCE 29.05433 \tLL 0.02349 \tTotal 731.68/78.35/7.20 \n","04/22/2023 05:11:36 PM - INFO - [53:6] loss\t28.70 =\tBCE 28.70087 \tLL 0.02218 \tTotal 313.89/45.75/6.95 \n","04/22/2023 05:11:36 PM - INFO - [53:7] loss\t28.90 =\tBCE 28.89880 \tLL 0.02338 \tTotal 952.23/88.32/9.33 \n","04/22/2023 05:11:36 PM - INFO - Training epoch 54.\n","04/22/2023 05:11:37 PM - INFO - [54:0] loss\t28.46 =\tBCE 28.46329 \tLL 0.02289 \tTotal 1246.65/106.96/14.48 \n","04/22/2023 05:11:38 PM - INFO - [54:1] loss\t28.87 =\tBCE 28.86852 \tLL 0.02320 \tTotal 1440.33/119.22/7.53 \n","04/22/2023 05:11:38 PM - INFO - [54:2] loss\t28.69 =\tBCE 28.68649 \tLL 0.02271 \tTotal 1938.39/166.08/8.16 \n","04/22/2023 05:11:39 PM - INFO - [54:3] loss\t28.94 =\tBCE 28.93794 \tLL 0.02213 \tTotal 2691.65/239.14/11.94 \n","04/22/2023 05:11:39 PM - INFO - [54:4] loss\t30.23 =\tBCE 30.22603 \tLL 0.02268 \tTotal 3978.10/327.90/7.60 \n","04/22/2023 05:11:40 PM - INFO - [54:5] loss\t34.14 =\tBCE 34.14029 \tLL 0.02148 \tTotal 6518.60/509.80/6.84 \n","04/22/2023 05:11:40 PM - INFO - [54:6] loss\t47.30 =\tBCE 47.29847 \tLL 0.02287 \tTotal 11398.63/904.41/4.83 \n","04/22/2023 05:11:41 PM - INFO - [54:7] loss\t88.68 =\tBCE 88.67505 \tLL 0.02015 \tTotal 20384.15/1661.96/2.45 \n","04/22/2023 05:11:41 PM - INFO - Training epoch 55.\n","04/22/2023 05:11:41 PM - INFO - [55:0] loss\t229.08 =\tBCE 229.08476 \tLL 0.02560 \tTotal 35015.12/2815.97/18.54 \n","04/22/2023 05:11:42 PM - INFO - [55:1] loss\t437.36 =\tBCE 437.35965 \tLL 0.02073 \tTotal 47798.86/3866.54/17.54 \n","04/22/2023 05:11:43 PM - INFO - [55:2] loss\t287.63 =\tBCE 287.63220 \tLL 0.02909 \tTotal 35810.30/3035.56/14.16 \n","04/22/2023 05:11:43 PM - INFO - [55:3] loss\t47.28 =\tBCE 47.28213 \tLL 0.02754 \tTotal 3928.92/590.20/14.60 \n","04/22/2023 05:11:44 PM - INFO - [55:4] loss\t254.80 =\tBCE 254.79845 \tLL 0.02456 \tTotal 31489.12/3082.12/8.36 \n","04/22/2023 05:11:44 PM - INFO - [55:5] loss\t82.53 =\tBCE 82.53320 \tLL 0.03492 \tTotal 11149.86/1229.88/38.05 \n","04/22/2023 05:11:45 PM - INFO - [55:6] loss\t173.13 =\tBCE 173.13255 \tLL 0.03724 \tTotal 20889.83/1916.10/13.46 \n","04/22/2023 05:11:45 PM - INFO - [55:7] loss\t77.52 =\tBCE 77.52405 \tLL 0.03561 \tTotal 10277.28/1174.77/25.38 \n","04/22/2023 05:11:45 PM - INFO - Training epoch 56.\n","04/22/2023 05:11:46 PM - INFO - [56:0] loss\t145.38 =\tBCE 145.38052 \tLL 0.03604 \tTotal 16750.94/1940.70/6.56 \n","04/22/2023 05:11:46 PM - INFO - [56:1] loss\t60.23 =\tBCE 60.23351 \tLL 0.03785 \tTotal 6711.82/1141.32/10.24 \n","04/22/2023 05:11:47 PM - INFO - [56:2] loss\t107.24 =\tBCE 107.24043 \tLL 0.04282 \tTotal 11983.77/1359.88/13.81 \n","04/22/2023 05:11:47 PM - INFO - [56:3] loss\t83.88 =\tBCE 83.88235 \tLL 0.04297 \tTotal 7151.51/1632.22/28.29 \n","04/22/2023 05:11:48 PM - INFO - [56:4] loss\t69.99 =\tBCE 69.98553 \tLL 0.04097 \tTotal 8324.99/700.89/19.75 \n","04/22/2023 05:11:48 PM - INFO - [56:5] loss\t87.74 =\tBCE 87.73630 \tLL 0.04366 \tTotal 7696.36/1658.47/7.26 \n","04/22/2023 05:11:49 PM - INFO - [56:6] loss\t52.46 =\tBCE 52.46418 \tLL 0.04498 \tTotal 2730.19/661.04/13.41 \n","04/22/2023 05:11:50 PM - INFO - [56:7] loss\t74.70 =\tBCE 74.69582 \tLL 0.04483 \tTotal 6660.00/1119.25/12.38 \n","04/22/2023 05:11:50 PM - INFO - Training epoch 57.\n","04/22/2023 05:11:50 PM - INFO - [57:0] loss\t62.75 =\tBCE 62.74632 \tLL 0.04606 \tTotal 2948.65/1161.52/11.67 \n","04/22/2023 05:11:51 PM - INFO - [57:1] loss\t57.73 =\tBCE 57.73481 \tLL 0.04527 \tTotal 4654.80/493.92/21.78 \n","04/22/2023 05:11:51 PM - INFO - [57:2] loss\t65.97 =\tBCE 65.96672 \tLL 0.04423 \tTotal 5083.97/1070.07/15.19 \n","04/22/2023 05:11:52 PM - INFO - [57:3] loss\t54.87 =\tBCE 54.87052 \tLL 0.04487 \tTotal 3843.27/572.95/6.41 \n","04/22/2023 05:11:52 PM - INFO - [57:4] loss\t58.08 =\tBCE 58.08301 \tLL 0.04540 \tTotal 4967.03/579.97/32.92 \n","04/22/2023 05:11:53 PM - INFO - [57:5] loss\t57.52 =\tBCE 57.51640 \tLL 0.04576 \tTotal 3482.76/680.90/17.57 \n","04/22/2023 05:11:53 PM - INFO - [57:6] loss\t58.50 =\tBCE 58.49599 \tLL 0.04583 \tTotal 4873.75/514.37/21.62 \n","04/22/2023 05:11:54 PM - INFO - [57:7] loss\t50.74 =\tBCE 50.74450 \tLL 0.04501 \tTotal 2959.83/310.19/8.02 \n","04/22/2023 05:11:54 PM - INFO - Training epoch 58.\n","04/22/2023 05:11:55 PM - INFO - [58:0] loss\t56.67 =\tBCE 56.66534 \tLL 0.04165 \tTotal 4649.02/581.73/18.02 \n","04/22/2023 05:11:55 PM - INFO - [58:1] loss\t53.14 =\tBCE 53.14491 \tLL 0.04288 \tTotal 3137.80/452.16/17.14 \n","04/22/2023 05:11:56 PM - INFO - [58:2] loss\t47.71 =\tBCE 47.71244 \tLL 0.04195 \tTotal 2434.37/227.94/13.95 \n","04/22/2023 05:11:56 PM - INFO - [58:3] loss\t52.91 =\tBCE 52.90984 \tLL 0.04118 \tTotal 4319.37/507.59/11.02 \n","04/22/2023 05:11:57 PM - INFO - [58:4] loss\t46.62 =\tBCE 46.62483 \tLL 0.04107 \tTotal 1126.80/432.24/27.96 \n","04/22/2023 05:11:57 PM - INFO - [58:5] loss\t47.21 =\tBCE 47.21478 \tLL 0.03824 \tTotal 2831.64/318.45/10.18 \n","04/22/2023 05:11:58 PM - INFO - [58:6] loss\t49.62 =\tBCE 49.61902 \tLL 0.03876 \tTotal 2652.74/548.99/14.00 \n","04/22/2023 05:11:58 PM - INFO - [58:7] loss\t45.45 =\tBCE 45.44745 \tLL 0.03849 \tTotal 1036.27/476.62/27.50 \n","Not implemented\n","04/22/2023 05:11:58 PM - INFO - Training epoch 59.\n","04/22/2023 05:11:59 PM - INFO - [59:0] loss\t45.65 =\tBCE 45.64827 \tLL 0.03852 \tTotal 2193.70/258.64/25.50 \n","04/22/2023 05:11:59 PM - INFO - [59:1] loss\t46.26 =\tBCE 46.25635 \tLL 0.03801 \tTotal 1165.38/515.58/8.21 \n","04/22/2023 05:12:00 PM - INFO - [59:2] loss\t43.18 =\tBCE 43.18494 \tLL 0.03495 \tTotal 1553.80/447.03/20.17 \n","04/22/2023 05:12:01 PM - INFO - [59:3] loss\t42.32 =\tBCE 42.32140 \tLL 0.03540 \tTotal 1152.73/241.05/8.66 \n","04/22/2023 05:12:01 PM - INFO - [59:4] loss\t44.61 =\tBCE 44.61433 \tLL 0.03566 \tTotal 1242.32/596.81/5.66 \n","04/22/2023 05:12:02 PM - INFO - [59:5] loss\t40.99 =\tBCE 40.99150 \tLL 0.03413 \tTotal 974.94/259.73/5.29 \n","04/22/2023 05:12:02 PM - INFO - [59:6] loss\t42.39 =\tBCE 42.38596 \tLL 0.03492 \tTotal 756.40/356.44/9.59 \n","04/22/2023 05:12:03 PM - INFO - [59:7] loss\t42.84 =\tBCE 42.83648 \tLL 0.03453 \tTotal 1184.76/486.18/14.73 \n","04/22/2023 05:12:03 PM - INFO - EVALUATION prior to epoch [60]...\n","04/22/2023 05:12:03 PM - INFO - [60] loss\t1434.05=\tBCE 1434.05 \tLL 0.04030 \n","04/22/2023 05:12:04 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/60_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:12:10 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/60_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:12:15 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/60_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 05:12:16 PM - INFO - Training epoch 60.\n","04/22/2023 05:12:16 PM - INFO - [60:0] loss\t39.21 =\tBCE 39.21064 \tLL 0.03355 \tTotal 703.39/103.15/10.18 \n","04/22/2023 05:12:17 PM - INFO - [60:1] loss\t41.46 =\tBCE 41.45889 \tLL 0.03304 \tTotal 899.43/421.75/18.23 \n","04/22/2023 05:12:18 PM - INFO - [60:2] loss\t39.97 =\tBCE 39.96671 \tLL 0.03214 \tTotal 1089.67/277.31/22.16 \n","04/22/2023 05:12:18 PM - INFO - [60:3] loss\t39.59 =\tBCE 39.58524 \tLL 0.03285 \tTotal 1024.77/210.45/4.74 \n","04/22/2023 05:12:19 PM - INFO - [60:4] loss\t39.61 =\tBCE 39.61080 \tLL 0.03269 \tTotal 846.12/339.75/9.54 \n","04/22/2023 05:12:19 PM - INFO - [60:5] loss\t38.34 =\tBCE 38.33723 \tLL 0.03206 \tTotal 1288.29/129.36/30.68 \n","04/22/2023 05:12:20 PM - INFO - [60:6] loss\t38.53 =\tBCE 38.53056 \tLL 0.03151 \tTotal 1179.46/285.08/17.51 \n","04/22/2023 05:12:20 PM - INFO - [60:7] loss\t38.23 =\tBCE 38.23324 \tLL 0.03063 \tTotal 1004.55/209.29/9.60 \n","04/22/2023 05:12:20 PM - INFO - Training epoch 61.\n","04/22/2023 05:12:21 PM - INFO - [61:0] loss\t37.49 =\tBCE 37.49152 \tLL 0.02994 \tTotal 1579.75/176.32/9.21 \n","04/22/2023 05:12:21 PM - INFO - [61:1] loss\t37.82 =\tBCE 37.82436 \tLL 0.03032 \tTotal 696.36/182.47/32.63 \n","04/22/2023 05:12:22 PM - INFO - [61:2] loss\t37.43 =\tBCE 37.42868 \tLL 0.03007 \tTotal 1567.13/153.27/23.21 \n","04/22/2023 05:12:22 PM - INFO - [61:3] loss\t36.55 =\tBCE 36.54515 \tLL 0.03044 \tTotal 1051.48/132.08/6.33 \n","04/22/2023 05:12:23 PM - INFO - [61:4] loss\t36.14 =\tBCE 36.14193 \tLL 0.02900 \tTotal 1171.50/131.17/29.42 \n","04/22/2023 05:12:23 PM - INFO - [61:5] loss\t35.99 =\tBCE 35.98624 \tLL 0.02936 \tTotal 1153.98/115.89/26.86 \n","04/22/2023 05:12:24 PM - INFO - [61:6] loss\t35.19 =\tBCE 35.19088 \tLL 0.02884 \tTotal 843.19/102.60/8.02 \n","04/22/2023 05:12:25 PM - INFO - [61:7] loss\t34.75 =\tBCE 34.75100 \tLL 0.02790 \tTotal 1077.52/101.00/7.41 \n","04/22/2023 05:12:25 PM - INFO - Training epoch 62.\n","04/22/2023 05:12:25 PM - INFO - [62:0] loss\t34.90 =\tBCE 34.89697 \tLL 0.02854 \tTotal 890.26/103.99/33.27 \n","04/22/2023 05:12:26 PM - INFO - [62:1] loss\t34.69 =\tBCE 34.69132 \tLL 0.02771 \tTotal 935.62/104.77/23.77 \n","04/22/2023 05:12:26 PM - INFO - [62:2] loss\t33.68 =\tBCE 33.67930 \tLL 0.02621 \tTotal 958.26/96.95/5.30 \n","04/22/2023 05:12:27 PM - INFO - [62:3] loss\t33.52 =\tBCE 33.52299 \tLL 0.02727 \tTotal 811.56/92.45/31.87 \n","04/22/2023 05:12:27 PM - INFO - [62:4] loss\t33.79 =\tBCE 33.78564 \tLL 0.02771 \tTotal 865.49/95.64/30.71 \n","04/22/2023 05:12:28 PM - INFO - [62:5] loss\t33.20 =\tBCE 33.19558 \tLL 0.02693 \tTotal 876.06/94.66/10.07 \n","04/22/2023 05:12:28 PM - INFO - [62:6] loss\t33.37 =\tBCE 33.36972 \tLL 0.02724 \tTotal 688.10/73.55/27.07 \n","04/22/2023 05:12:29 PM - INFO - [62:7] loss\t33.19 =\tBCE 33.18508 \tLL 0.02666 \tTotal 975.85/103.56/25.89 \n","04/22/2023 05:12:29 PM - INFO - Training epoch 63.\n","04/22/2023 05:12:29 PM - INFO - [63:0] loss\t31.93 =\tBCE 31.92563 \tLL 0.02520 \tTotal 540.15/78.53/9.16 \n","04/22/2023 05:12:30 PM - INFO - [63:1] loss\t32.10 =\tBCE 32.09578 \tLL 0.02554 \tTotal 831.44/85.62/10.73 \n","04/22/2023 05:12:30 PM - INFO - [63:2] loss\t31.90 =\tBCE 31.90440 \tLL 0.02607 \tTotal 325.58/45.19/28.36 \n","04/22/2023 05:12:31 PM - INFO - [63:3] loss\t32.38 =\tBCE 32.37570 \tLL 0.02603 \tTotal 845.05/94.67/10.43 \n","04/22/2023 05:12:31 PM - INFO - [63:4] loss\t31.73 =\tBCE 31.73446 \tLL 0.02584 \tTotal 371.84/55.33/3.32 \n","04/22/2023 05:12:32 PM - INFO - [63:5] loss\t30.93 =\tBCE 30.92899 \tLL 0.02537 \tTotal 718.05/86.06/10.46 \n","04/22/2023 05:12:33 PM - INFO - [63:6] loss\t31.22 =\tBCE 31.22499 \tLL 0.02586 \tTotal 579.64/67.10/17.86 \n","04/22/2023 05:12:33 PM - INFO - [63:7] loss\t31.09 =\tBCE 31.09333 \tLL 0.02447 \tTotal 647.93/72.95/5.57 \n","04/22/2023 05:12:33 PM - INFO - Training epoch 64.\n","04/22/2023 05:12:34 PM - INFO - [64:0] loss\t30.34 =\tBCE 30.34297 \tLL 0.02413 \tTotal 776.69/83.74/8.43 \n","04/22/2023 05:12:34 PM - INFO - [64:1] loss\t30.83 =\tBCE 30.83374 \tLL 0.02541 \tTotal 416.62/53.57/10.50 \n","04/22/2023 05:12:35 PM - INFO - [64:2] loss\t30.60 =\tBCE 30.59869 \tLL 0.02517 \tTotal 654.68/71.75/7.49 \n","04/22/2023 05:12:35 PM - INFO - [64:3] loss\t29.92 =\tBCE 29.91634 \tLL 0.02405 \tTotal 291.81/44.17/11.12 \n","04/22/2023 05:12:36 PM - INFO - [64:4] loss\t29.99 =\tBCE 29.99177 \tLL 0.02413 \tTotal 576.90/67.11/4.27 \n","04/22/2023 05:12:36 PM - INFO - [64:5] loss\t29.10 =\tBCE 29.09666 \tLL 0.02366 \tTotal 137.77/64.52/5.61 \n","04/22/2023 05:12:37 PM - INFO - [64:6] loss\t29.75 =\tBCE 29.74747 \tLL 0.02461 \tTotal 469.72/57.01/19.54 \n","04/22/2023 05:12:37 PM - INFO - [64:7] loss\t28.90 =\tBCE 28.89657 \tLL 0.02306 \tTotal 232.44/59.28/4.57 \n","04/22/2023 05:12:37 PM - INFO - Training epoch 65.\n","04/22/2023 05:12:38 PM - INFO - [65:0] loss\t28.88 =\tBCE 28.88395 \tLL 0.02356 \tTotal 433.72/56.67/13.10 \n","04/22/2023 05:12:39 PM - INFO - [65:1] loss\t28.64 =\tBCE 28.63758 \tLL 0.02269 \tTotal 190.32/59.56/18.99 \n","04/22/2023 05:12:39 PM - INFO - [65:2] loss\t28.74 =\tBCE 28.73828 \tLL 0.02326 \tTotal 287.96/35.89/5.10 \n","04/22/2023 05:12:40 PM - INFO - [65:3] loss\t28.23 =\tBCE 28.22761 \tLL 0.02322 \tTotal 388.73/47.55/9.13 \n","04/22/2023 05:12:40 PM - INFO - [65:4] loss\t28.34 =\tBCE 28.34415 \tLL 0.02335 \tTotal 239.57/39.10/8.01 \n","04/22/2023 05:12:41 PM - INFO - [65:5] loss\t28.49 =\tBCE 28.48739 \tLL 0.02284 \tTotal 382.78/57.97/12.50 \n","04/22/2023 05:12:41 PM - INFO - [65:6] loss\t28.35 =\tBCE 28.34706 \tLL 0.02255 \tTotal 283.33/50.16/7.73 \n","04/22/2023 05:12:42 PM - INFO - [65:7] loss\t27.79 =\tBCE 27.79057 \tLL 0.02292 \tTotal 468.18/54.93/4.13 \n","04/22/2023 05:12:42 PM - INFO - Training epoch 66.\n","04/22/2023 05:12:42 PM - INFO - [66:0] loss\t27.88 =\tBCE 27.87653 \tLL 0.02273 \tTotal 433.92/72.99/24.48 \n","04/22/2023 05:12:43 PM - INFO - [66:1] loss\t27.56 =\tBCE 27.56207 \tLL 0.02227 \tTotal 226.11/46.29/11.31 \n","04/22/2023 05:12:43 PM - INFO - [66:2] loss\t27.71 =\tBCE 27.70963 \tLL 0.02294 \tTotal 583.18/85.44/14.77 \n","04/22/2023 05:12:44 PM - INFO - [66:3] loss\t27.40 =\tBCE 27.39958 \tLL 0.02199 \tTotal 407.14/48.31/9.49 \n","04/22/2023 05:12:45 PM - INFO - [66:4] loss\t26.88 =\tBCE 26.87566 \tLL 0.02204 \tTotal 485.44/70.89/19.06 \n","04/22/2023 05:12:45 PM - INFO - [66:5] loss\t26.73 =\tBCE 26.73370 \tLL 0.02159 \tTotal 778.53/72.12/26.45 \n","04/22/2023 05:12:46 PM - INFO - [66:6] loss\t26.97 =\tBCE 26.96555 \tLL 0.02234 \tTotal 413.12/43.83/10.96 \n","04/22/2023 05:12:46 PM - INFO - [66:7] loss\t27.08 =\tBCE 27.08439 \tLL 0.02213 \tTotal 409.75/64.58/4.46 \n","04/22/2023 05:12:46 PM - INFO - Training epoch 67.\n","04/22/2023 05:12:47 PM - INFO - [67:0] loss\t26.54 =\tBCE 26.53520 \tLL 0.02120 \tTotal 584.66/56.45/7.29 \n","04/22/2023 05:12:47 PM - INFO - [67:1] loss\t26.47 =\tBCE 26.47327 \tLL 0.02174 \tTotal 428.22/77.51/26.45 \n","04/22/2023 05:12:48 PM - INFO - [67:2] loss\t26.92 =\tBCE 26.91692 \tLL 0.02193 \tTotal 784.98/79.45/16.95 \n","04/22/2023 05:12:48 PM - INFO - [67:3] loss\t26.29 =\tBCE 26.28834 \tLL 0.02133 \tTotal 845.52/90.07/12.44 \n","04/22/2023 05:12:49 PM - INFO - [67:4] loss\t25.90 =\tBCE 25.89985 \tLL 0.02116 \tTotal 872.98/103.94/25.14 \n","04/22/2023 05:12:49 PM - INFO - [67:5] loss\t26.16 =\tBCE 26.16471 \tLL 0.02165 \tTotal 564.05/77.88/11.45 \n","04/22/2023 05:12:50 PM - INFO - [67:6] loss\t25.84 =\tBCE 25.83755 \tLL 0.02065 \tTotal 695.38/95.35/12.64 \n","04/22/2023 05:12:51 PM - INFO - [67:7] loss\t25.91 =\tBCE 25.90999 \tLL 0.02096 \tTotal 1151.89/183.99/15.49 \n","04/22/2023 05:12:51 PM - INFO - Training epoch 68.\n","04/22/2023 05:12:51 PM - INFO - [68:0] loss\t26.16 =\tBCE 26.15787 \tLL 0.02141 \tTotal 967.63/131.34/10.61 \n","04/22/2023 05:12:52 PM - INFO - [68:1] loss\t25.57 =\tBCE 25.56551 \tLL 0.02084 \tTotal 513.43/62.93/11.84 \n","04/22/2023 05:12:52 PM - INFO - [68:2] loss\t25.17 =\tBCE 25.16784 \tLL 0.02006 \tTotal 910.31/151.57/21.25 \n","04/22/2023 05:12:53 PM - INFO - [68:3] loss\t25.68 =\tBCE 25.67901 \tLL 0.02012 \tTotal 1471.32/165.29/6.07 \n","04/22/2023 05:12:53 PM - INFO - [68:4] loss\t25.31 =\tBCE 25.31425 \tLL 0.02053 \tTotal 1747.76/120.68/23.03 \n","04/22/2023 05:12:54 PM - INFO - [68:5] loss\t24.59 =\tBCE 24.58570 \tLL 0.01956 \tTotal 1216.73/104.51/20.55 \n","04/22/2023 05:12:54 PM - INFO - [68:6] loss\t25.00 =\tBCE 24.99769 \tLL 0.02088 \tTotal 600.03/75.12/8.95 \n","04/22/2023 05:12:55 PM - INFO - [68:7] loss\t24.90 =\tBCE 24.90252 \tLL 0.02079 \tTotal 667.61/82.34/15.26 \n","Not implemented\n","04/22/2023 05:12:55 PM - INFO - Training epoch 69.\n","04/22/2023 05:12:56 PM - INFO - [69:0] loss\t24.31 =\tBCE 24.30941 \tLL 0.01996 \tTotal 1124.02/108.92/16.12 \n","04/22/2023 05:12:56 PM - INFO - [69:1] loss\t24.97 =\tBCE 24.96897 \tLL 0.02026 \tTotal 1370.25/175.68/16.35 \n","04/22/2023 05:12:57 PM - INFO - [69:2] loss\t24.59 =\tBCE 24.58669 \tLL 0.02007 \tTotal 1469.77/190.86/16.05 \n","04/22/2023 05:12:57 PM - INFO - [69:3] loss\t24.59 =\tBCE 24.58980 \tLL 0.02008 \tTotal 1377.66/128.82/24.20 \n","04/22/2023 05:12:58 PM - INFO - [69:4] loss\t24.76 =\tBCE 24.75527 \tLL 0.02040 \tTotal 791.00/66.38/32.99 \n","04/22/2023 05:12:58 PM - INFO - [69:5] loss\t23.75 =\tBCE 23.75080 \tLL 0.01935 \tTotal 501.23/59.32/9.55 \n","04/22/2023 05:12:59 PM - INFO - [69:6] loss\t24.11 =\tBCE 24.11496 \tLL 0.01963 \tTotal 560.32/70.63/9.60 \n","04/22/2023 05:12:59 PM - INFO - [69:7] loss\t23.48 =\tBCE 23.48072 \tLL 0.01918 \tTotal 434.43/67.33/25.00 \n","04/22/2023 05:12:59 PM - INFO - EVALUATION prior to epoch [70]...\n","04/22/2023 05:12:59 PM - INFO - [70] loss\t2372.89=\tBCE 2372.89 \tLL 0.02623 \n","04/22/2023 05:13:01 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/70_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:13:06 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/70_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:13:12 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/70_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 05:13:13 PM - INFO - Training epoch 70.\n","04/22/2023 05:13:13 PM - INFO - [70:0] loss\t23.66 =\tBCE 23.65943 \tLL 0.01944 \tTotal 590.58/59.60/33.79 \n","04/22/2023 05:13:14 PM - INFO - [70:1] loss\t23.92 =\tBCE 23.92474 \tLL 0.01989 \tTotal 485.85/58.86/11.08 \n","04/22/2023 05:13:14 PM - INFO - [70:2] loss\t23.85 =\tBCE 23.84599 \tLL 0.02011 \tTotal 203.21/50.29/22.37 \n","04/22/2023 05:13:15 PM - INFO - [70:3] loss\t23.61 =\tBCE 23.61299 \tLL 0.01954 \tTotal 458.28/78.36/22.49 \n","04/22/2023 05:13:15 PM - INFO - [70:4] loss\t23.46 =\tBCE 23.45913 \tLL 0.01970 \tTotal 642.09/60.23/3.64 \n","04/22/2023 05:13:16 PM - INFO - [70:5] loss\t23.23 =\tBCE 23.22623 \tLL 0.01898 \tTotal 827.44/77.62/9.60 \n","04/22/2023 05:13:16 PM - INFO - [70:6] loss\t22.82 =\tBCE 22.82246 \tLL 0.01838 \tTotal 993.03/170.18/22.26 \n","04/22/2023 05:13:17 PM - INFO - [70:7] loss\t23.47 =\tBCE 23.46959 \tLL 0.01909 \tTotal 1208.91/214.86/5.06 \n","04/22/2023 05:13:17 PM - INFO - Training epoch 71.\n","04/22/2023 05:13:17 PM - INFO - [71:0] loss\t22.95 =\tBCE 22.95282 \tLL 0.01828 \tTotal 1598.23/254.27/6.09 \n","04/22/2023 05:13:18 PM - INFO - [71:1] loss\t23.94 =\tBCE 23.93898 \tLL 0.01899 \tTotal 2436.93/277.62/13.92 \n","04/22/2023 05:13:18 PM - INFO - [71:2] loss\t25.26 =\tBCE 25.26330 \tLL 0.01921 \tTotal 3630.88/347.91/17.23 \n","04/22/2023 05:13:19 PM - INFO - [71:3] loss\t26.64 =\tBCE 26.63714 \tLL 0.01910 \tTotal 4937.16/499.27/16.91 \n","04/22/2023 05:13:20 PM - INFO - [71:4] loss\t30.49 =\tBCE 30.49174 \tLL 0.01875 \tTotal 6914.11/793.89/11.09 \n","04/22/2023 05:13:20 PM - INFO - [71:5] loss\t40.77 =\tBCE 40.77399 \tLL 0.01906 \tTotal 10658.85/1266.30/17.64 \n","04/22/2023 05:13:21 PM - INFO - [71:6] loss\t74.12 =\tBCE 74.12476 \tLL 0.01796 \tTotal 19813.01/2101.72/20.77 \n","04/22/2023 05:13:21 PM - INFO - [71:7] loss\t233.06 =\tBCE 233.05664 \tLL 0.02105 \tTotal 35472.97/3418.82/7.92 \n","04/22/2023 05:13:21 PM - INFO - Training epoch 72.\n","04/22/2023 05:13:22 PM - INFO - [72:0] loss\t383.24 =\tBCE 383.24298 \tLL 0.01907 \tTotal 51686.36/4937.81/12.89 \n","04/22/2023 05:13:22 PM - INFO - [72:1] loss\t535.84 =\tBCE 535.84375 \tLL 0.02357 \tTotal 41905.47/4960.20/6.76 \n","04/22/2023 05:13:23 PM - INFO - [72:2] loss\t72.67 =\tBCE 72.67077 \tLL 0.02395 \tTotal 10266.13/985.83/17.89 \n","04/22/2023 05:13:23 PM - INFO - [72:3] loss\t461.42 =\tBCE 461.41794 \tLL 0.02289 \tTotal 45497.04/5929.65/10.81 \n","04/22/2023 05:13:24 PM - INFO - [72:4] loss\t155.64 =\tBCE 155.63869 \tLL 0.02753 \tTotal 16145.86/2894.81/11.95 \n","04/22/2023 05:13:24 PM - INFO - [72:5] loss\t319.56 =\tBCE 319.55627 \tLL 0.03262 \tTotal 28297.40/3081.13/9.33 \n","04/22/2023 05:13:25 PM - INFO - [72:6] loss\t86.43 =\tBCE 86.43050 \tLL 0.03230 \tTotal 12232.40/1124.02/11.94 \n","04/22/2023 05:13:26 PM - INFO - [72:7] loss\t247.40 =\tBCE 247.40306 \tLL 0.02987 \tTotal 24096.13/2978.40/7.02 \n","04/22/2023 05:13:26 PM - INFO - Training epoch 73.\n","04/22/2023 05:13:26 PM - INFO - [73:0] loss\t96.56 =\tBCE 96.56110 \tLL 0.03184 \tTotal 11608.30/1134.01/8.20 \n","04/22/2023 05:13:27 PM - INFO - [73:1] loss\t118.20 =\tBCE 118.20312 \tLL 0.03660 \tTotal 13383.50/1310.92/7.30 \n","04/22/2023 05:13:27 PM - INFO - [73:2] loss\t159.94 =\tBCE 159.94463 \tLL 0.04042 \tTotal 14377.04/1768.81/17.76 \n","04/22/2023 05:13:28 PM - INFO - [73:3] loss\t70.14 =\tBCE 70.14109 \tLL 0.03873 \tTotal 5704.17/982.72/9.54 \n","04/22/2023 05:13:28 PM - INFO - [73:4] loss\t84.51 =\tBCE 84.51013 \tLL 0.03835 \tTotal 8232.34/1085.36/19.90 \n","04/22/2023 05:13:29 PM - INFO - [73:5] loss\t129.31 =\tBCE 129.30537 \tLL 0.03794 \tTotal 11039.11/1647.48/23.81 \n","04/22/2023 05:13:29 PM - INFO - [73:6] loss\t60.60 =\tBCE 60.59998 \tLL 0.03978 \tTotal 3853.53/546.70/50.85 \n","04/22/2023 05:13:30 PM - INFO - [73:7] loss\t70.11 =\tBCE 70.11488 \tLL 0.04096 \tTotal 4372.10/908.21/9.48 \n","04/22/2023 05:13:30 PM - INFO - Training epoch 74.\n","04/22/2023 05:13:30 PM - INFO - [74:0] loss\t99.56 =\tBCE 99.55848 \tLL 0.04485 \tTotal 7073.32/1171.38/28.25 \n","04/22/2023 05:13:31 PM - INFO - [74:1] loss\t64.71 =\tBCE 64.71432 \tLL 0.04368 \tTotal 3621.13/580.57/26.30 \n","04/22/2023 05:13:31 PM - INFO - [74:2] loss\t77.65 =\tBCE 77.64978 \tLL 0.04136 \tTotal 6171.15/623.61/26.44 \n","04/22/2023 05:13:32 PM - INFO - [74:3] loss\t64.80 =\tBCE 64.80171 \tLL 0.04224 \tTotal 2163.85/950.02/6.72 \n","04/22/2023 05:13:32 PM - INFO - [74:4] loss\t61.75 =\tBCE 61.75341 \tLL 0.04099 \tTotal 3208.04/780.07/6.91 \n","04/22/2023 05:13:33 PM - INFO - [74:5] loss\t56.75 =\tBCE 56.75069 \tLL 0.04019 \tTotal 3095.81/323.68/16.12 \n","04/22/2023 05:13:34 PM - INFO - [74:6] loss\t61.39 =\tBCE 61.39155 \tLL 0.04065 \tTotal 2167.90/815.26/36.13 \n","04/22/2023 05:13:34 PM - INFO - [74:7] loss\t59.03 =\tBCE 59.03094 \tLL 0.04056 \tTotal 2330.51/600.47/9.34 \n","04/22/2023 05:13:34 PM - INFO - Training epoch 75.\n","04/22/2023 05:13:35 PM - INFO - [75:0] loss\t55.43 =\tBCE 55.43280 \tLL 0.04316 \tTotal 2558.72/272.80/31.66 \n","04/22/2023 05:13:35 PM - INFO - [75:1] loss\t52.05 =\tBCE 52.04548 \tLL 0.03808 \tTotal 1806.81/420.11/18.33 \n","04/22/2023 05:13:36 PM - INFO - [75:2] loss\t57.90 =\tBCE 57.89635 \tLL 0.03895 \tTotal 2758.34/497.05/10.48 \n","04/22/2023 05:13:36 PM - INFO - [75:3] loss\t52.91 =\tBCE 52.91094 \tLL 0.03792 \tTotal 2762.91/325.71/29.25 \n","04/22/2023 05:13:37 PM - INFO - [75:4] loss\t48.93 =\tBCE 48.93227 \tLL 0.03818 \tTotal 1114.13/123.80/26.06 \n","04/22/2023 05:13:38 PM - INFO - [75:5] loss\t52.25 =\tBCE 52.25476 \tLL 0.03756 \tTotal 2138.08/305.67/14.28 \n","04/22/2023 05:13:38 PM - INFO - [75:6] loss\t52.90 =\tBCE 52.89992 \tLL 0.03907 \tTotal 2232.49/322.85/9.11 \n","04/22/2023 05:13:39 PM - INFO - [75:7] loss\t48.35 =\tBCE 48.34598 \tLL 0.03616 \tTotal 1017.69/175.32/23.18 \n","04/22/2023 05:13:39 PM - INFO - Training epoch 76.\n","04/22/2023 05:13:39 PM - INFO - [76:0] loss\t49.93 =\tBCE 49.93319 \tLL 0.03776 \tTotal 1893.17/234.05/16.90 \n","04/22/2023 05:13:40 PM - INFO - [76:1] loss\t49.42 =\tBCE 49.41555 \tLL 0.03688 \tTotal 1679.20/311.97/11.35 \n","04/22/2023 05:13:40 PM - INFO - [76:2] loss\t47.05 =\tBCE 47.04501 \tLL 0.03558 \tTotal 779.82/341.28/22.54 \n","04/22/2023 05:13:41 PM - INFO - [76:3] loss\t48.03 =\tBCE 48.03165 \tLL 0.03543 \tTotal 1579.37/240.56/11.73 \n","04/22/2023 05:13:41 PM - INFO - [76:4] loss\t47.55 =\tBCE 47.54621 \tLL 0.03539 \tTotal 1210.77/201.80/8.97 \n","04/22/2023 05:13:42 PM - INFO - [76:5] loss\t46.93 =\tBCE 46.92528 \tLL 0.03390 \tTotal 741.43/310.50/9.84 \n","04/22/2023 05:13:42 PM - INFO - [76:6] loss\t46.42 =\tBCE 46.42451 \tLL 0.03294 \tTotal 1398.22/245.74/15.03 \n","04/22/2023 05:13:43 PM - INFO - [76:7] loss\t44.74 =\tBCE 44.74412 \tLL 0.03195 \tTotal 864.08/173.42/10.68 \n","04/22/2023 05:13:43 PM - INFO - Training epoch 77.\n","04/22/2023 05:13:43 PM - INFO - [77:0] loss\t45.81 =\tBCE 45.80931 \tLL 0.03305 \tTotal 926.64/305.32/9.24 \n","04/22/2023 05:13:44 PM - INFO - [77:1] loss\t42.76 =\tBCE 42.75764 \tLL 0.03074 \tTotal 1082.48/218.16/19.61 \n","04/22/2023 05:13:45 PM - INFO - [77:2] loss\t43.83 =\tBCE 43.83363 \tLL 0.03250 \tTotal 1030.67/122.63/14.30 \n","04/22/2023 05:13:45 PM - INFO - [77:3] loss\t43.10 =\tBCE 43.10320 \tLL 0.03210 \tTotal 864.50/238.36/21.74 \n","04/22/2023 05:13:46 PM - INFO - [77:4] loss\t42.92 =\tBCE 42.92111 \tLL 0.03307 \tTotal 673.56/161.81/18.14 \n","04/22/2023 05:13:46 PM - INFO - [77:5] loss\t43.26 =\tBCE 43.25591 \tLL 0.03306 \tTotal 1255.83/138.31/33.23 \n","04/22/2023 05:13:47 PM - INFO - [77:6] loss\t41.65 =\tBCE 41.64820 \tLL 0.03159 \tTotal 927.27/187.55/15.40 \n","04/22/2023 05:13:47 PM - INFO - [77:7] loss\t40.84 =\tBCE 40.84301 \tLL 0.03157 \tTotal 346.69/111.10/15.15 \n","04/22/2023 05:13:47 PM - INFO - Training epoch 78.\n","04/22/2023 05:13:48 PM - INFO - [78:0] loss\t41.09 =\tBCE 41.08625 \tLL 0.03063 \tTotal 1095.94/115.96/13.92 \n","04/22/2023 05:13:48 PM - INFO - [78:1] loss\t40.54 =\tBCE 40.53986 \tLL 0.03071 \tTotal 941.58/104.42/24.00 \n","04/22/2023 05:13:49 PM - INFO - [78:2] loss\t39.41 =\tBCE 39.41402 \tLL 0.03051 \tTotal 463.43/65.07/22.23 \n","04/22/2023 05:13:49 PM - INFO - [78:3] loss\t40.26 =\tBCE 40.25977 \tLL 0.03154 \tTotal 767.55/111.10/15.64 \n","04/22/2023 05:13:50 PM - INFO - [78:4] loss\t39.61 =\tBCE 39.61121 \tLL 0.03071 \tTotal 795.86/85.59/15.41 \n","04/22/2023 05:13:51 PM - INFO - [78:5] loss\t37.79 =\tBCE 37.78555 \tLL 0.02916 \tTotal 537.95/75.10/18.65 \n","04/22/2023 05:13:51 PM - INFO - [78:6] loss\t38.34 =\tBCE 38.33984 \tLL 0.03002 \tTotal 567.01/86.33/6.68 \n","04/22/2023 05:13:52 PM - INFO - [78:7] loss\t37.49 =\tBCE 37.48937 \tLL 0.02921 \tTotal 666.89/70.52/7.71 \n","Not implemented\n","04/22/2023 05:13:52 PM - INFO - Training epoch 79.\n","04/22/2023 05:13:52 PM - INFO - [79:0] loss\t37.21 =\tBCE 37.21189 \tLL 0.02895 \tTotal 470.68/98.92/11.17 \n","04/22/2023 05:13:53 PM - INFO - [79:1] loss\t36.77 =\tBCE 36.77120 \tLL 0.02852 \tTotal 292.53/75.20/26.50 \n","04/22/2023 05:13:53 PM - INFO - [79:2] loss\t36.64 =\tBCE 36.64229 \tLL 0.02861 \tTotal 667.70/88.73/16.75 \n","04/22/2023 05:13:54 PM - INFO - [79:3] loss\t36.83 =\tBCE 36.82512 \tLL 0.02859 \tTotal 421.33/105.35/13.67 \n","04/22/2023 05:13:54 PM - INFO - [79:4] loss\t35.78 =\tBCE 35.77912 \tLL 0.02820 \tTotal 421.32/54.39/15.95 \n","04/22/2023 05:13:55 PM - INFO - [79:5] loss\t36.29 =\tBCE 36.28558 \tLL 0.02925 \tTotal 594.21/85.10/7.22 \n","04/22/2023 05:13:55 PM - INFO - [79:6] loss\t35.73 =\tBCE 35.73285 \tLL 0.02812 \tTotal 395.62/97.93/6.51 \n","04/22/2023 05:13:56 PM - INFO - [79:7] loss\t34.77 =\tBCE 34.76520 \tLL 0.02776 \tTotal 619.03/83.33/14.24 \n","04/22/2023 05:13:56 PM - INFO - EVALUATION prior to epoch [80]...\n","04/22/2023 05:13:56 PM - INFO - [80] loss\t1339.86=\tBCE 1339.86 \tLL 0.03549 \n","04/22/2023 05:13:57 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/80_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:14:02 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/80_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:14:09 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/80_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 05:14:09 PM - INFO - Training epoch 80.\n","04/22/2023 05:14:10 PM - INFO - [80:0] loss\t34.42 =\tBCE 34.41836 \tLL 0.02709 \tTotal 357.92/62.08/5.58 \n","04/22/2023 05:14:10 PM - INFO - [80:1] loss\t34.87 =\tBCE 34.87241 \tLL 0.02798 \tTotal 484.31/73.15/13.18 \n","04/22/2023 05:14:11 PM - INFO - [80:2] loss\t33.68 =\tBCE 33.67960 \tLL 0.02660 \tTotal 482.29/67.11/8.39 \n","04/22/2023 05:14:11 PM - INFO - [80:3] loss\t34.40 =\tBCE 34.40473 \tLL 0.02725 \tTotal 323.46/54.14/17.79 \n","04/22/2023 05:14:12 PM - INFO - [80:4] loss\t33.17 =\tBCE 33.16919 \tLL 0.02676 \tTotal 513.29/65.49/3.59 \n","04/22/2023 05:14:12 PM - INFO - [80:5] loss\t33.13 =\tBCE 33.12672 \tLL 0.02679 \tTotal 390.83/54.01/7.08 \n","04/22/2023 05:14:13 PM - INFO - [80:6] loss\t31.97 =\tBCE 31.96872 \tLL 0.02503 \tTotal 392.26/50.46/4.76 \n","04/22/2023 05:14:13 PM - INFO - [80:7] loss\t33.12 =\tBCE 33.11635 \tLL 0.02705 \tTotal 342.26/48.18/4.43 \n","04/22/2023 05:14:13 PM - INFO - Training epoch 81.\n","04/22/2023 05:14:14 PM - INFO - [81:0] loss\t32.29 =\tBCE 32.29205 \tLL 0.02572 \tTotal 504.25/59.00/13.10 \n","04/22/2023 05:14:15 PM - INFO - [81:1] loss\t32.24 =\tBCE 32.23624 \tLL 0.02558 \tTotal 258.73/43.24/16.66 \n","04/22/2023 05:14:15 PM - INFO - [81:2] loss\t32.47 =\tBCE 32.47134 \tLL 0.02658 \tTotal 481.79/64.52/11.49 \n","04/22/2023 05:14:16 PM - INFO - [81:3] loss\t31.73 =\tBCE 31.73437 \tLL 0.02597 \tTotal 299.31/68.81/4.53 \n","04/22/2023 05:14:16 PM - INFO - [81:4] loss\t31.29 =\tBCE 31.28919 \tLL 0.02507 \tTotal 332.60/48.38/5.79 \n","04/22/2023 05:14:17 PM - INFO - [81:5] loss\t30.56 =\tBCE 30.55843 \tLL 0.02465 \tTotal 411.60/54.12/1.82 \n","04/22/2023 05:14:17 PM - INFO - [81:6] loss\t30.66 =\tBCE 30.66075 \tLL 0.02492 \tTotal 296.94/45.90/5.88 \n","04/22/2023 05:14:18 PM - INFO - [81:7] loss\t30.58 =\tBCE 30.58119 \tLL 0.02495 \tTotal 414.75/55.78/13.72 \n","04/22/2023 05:14:18 PM - INFO - Training epoch 82.\n","04/22/2023 05:14:18 PM - INFO - [82:0] loss\t29.92 =\tBCE 29.91863 \tLL 0.02405 \tTotal 223.58/51.38/3.67 \n","04/22/2023 05:14:19 PM - INFO - [82:1] loss\t30.44 =\tBCE 30.43549 \tLL 0.02510 \tTotal 463.88/55.69/8.43 \n","04/22/2023 05:14:19 PM - INFO - [82:2] loss\t30.28 =\tBCE 30.27949 \tLL 0.02455 \tTotal 281.46/45.68/13.90 \n","04/22/2023 05:14:20 PM - INFO - [82:3] loss\t30.47 =\tBCE 30.46778 \tLL 0.02541 \tTotal 531.54/60.00/3.51 \n","04/22/2023 05:14:20 PM - INFO - [82:4] loss\t30.10 =\tBCE 30.10041 \tLL 0.02465 \tTotal 340.25/55.47/9.09 \n","04/22/2023 05:14:21 PM - INFO - [82:5] loss\t29.32 =\tBCE 29.32179 \tLL 0.02390 \tTotal 565.21/62.21/9.91 \n","04/22/2023 05:14:22 PM - INFO - [82:6] loss\t28.86 =\tBCE 28.86386 \tLL 0.02330 \tTotal 453.50/60.63/11.44 \n","04/22/2023 05:14:22 PM - INFO - [82:7] loss\t28.62 =\tBCE 28.62294 \tLL 0.02360 \tTotal 409.71/58.48/3.61 \n","04/22/2023 05:14:22 PM - INFO - Training epoch 83.\n","04/22/2023 05:14:23 PM - INFO - [83:0] loss\t28.61 =\tBCE 28.60972 \tLL 0.02330 \tTotal 189.76/69.22/20.86 \n","04/22/2023 05:14:23 PM - INFO - [83:1] loss\t28.57 =\tBCE 28.56922 \tLL 0.02358 \tTotal 392.13/50.05/6.18 \n","04/22/2023 05:14:24 PM - INFO - [83:2] loss\t29.02 =\tBCE 29.02383 \tLL 0.02404 \tTotal 214.45/72.33/6.52 \n","04/22/2023 05:14:24 PM - INFO - [83:3] loss\t28.53 =\tBCE 28.52993 \tLL 0.02346 \tTotal 327.35/51.90/7.63 \n","04/22/2023 05:14:25 PM - INFO - [83:4] loss\t28.01 =\tBCE 28.01460 \tLL 0.02271 \tTotal 261.29/87.17/14.50 \n","04/22/2023 05:14:25 PM - INFO - [83:5] loss\t28.72 =\tBCE 28.71531 \tLL 0.02448 \tTotal 331.35/65.41/25.26 \n","04/22/2023 05:14:26 PM - INFO - [83:6] loss\t27.58 =\tBCE 27.58481 \tLL 0.02255 \tTotal 374.33/80.40/6.66 \n","04/22/2023 05:14:26 PM - INFO - [83:7] loss\t27.45 =\tBCE 27.44769 \tLL 0.02291 \tTotal 237.61/42.57/26.12 \n","04/22/2023 05:14:26 PM - INFO - Training epoch 84.\n","04/22/2023 05:14:27 PM - INFO - [84:0] loss\t27.38 =\tBCE 27.37651 \tLL 0.02257 \tTotal 291.23/49.72/13.15 \n","04/22/2023 05:14:27 PM - INFO - [84:1] loss\t27.24 =\tBCE 27.23794 \tLL 0.02281 \tTotal 178.47/58.60/2.92 \n","04/22/2023 05:14:28 PM - INFO - [84:2] loss\t27.12 =\tBCE 27.12346 \tLL 0.02232 \tTotal 331.82/45.62/8.96 \n","04/22/2023 05:14:28 PM - INFO - [84:3] loss\t27.36 =\tBCE 27.35741 \tLL 0.02305 \tTotal 218.74/52.73/10.27 \n","04/22/2023 05:14:29 PM - INFO - [84:4] loss\t26.86 =\tBCE 26.86483 \tLL 0.02198 \tTotal 409.20/49.73/10.65 \n","04/22/2023 05:14:30 PM - INFO - [84:5] loss\t26.68 =\tBCE 26.68011 \tLL 0.02217 \tTotal 184.69/57.29/5.15 \n","04/22/2023 05:14:30 PM - INFO - [84:6] loss\t26.24 =\tBCE 26.24376 \tLL 0.02208 \tTotal 408.36/52.44/12.38 \n","04/22/2023 05:14:31 PM - INFO - [84:7] loss\t26.19 =\tBCE 26.19285 \tLL 0.02185 \tTotal 192.90/29.42/8.90 \n","04/22/2023 05:14:31 PM - INFO - Training epoch 85.\n","04/22/2023 05:14:31 PM - INFO - [85:0] loss\t26.31 =\tBCE 26.31112 \tLL 0.02208 \tTotal 394.15/56.75/8.04 \n","04/22/2023 05:14:32 PM - INFO - [85:1] loss\t25.92 =\tBCE 25.92134 \tLL 0.02163 \tTotal 210.62/35.19/12.23 \n","04/22/2023 05:14:32 PM - INFO - [85:2] loss\t25.95 =\tBCE 25.94851 \tLL 0.02155 \tTotal 244.44/43.03/2.85 \n","04/22/2023 05:14:33 PM - INFO - [85:3] loss\t25.93 =\tBCE 25.93500 \tLL 0.02165 \tTotal 138.60/48.56/3.05 \n","04/22/2023 05:14:33 PM - INFO - [85:4] loss\t25.54 =\tBCE 25.54440 \tLL 0.02107 \tTotal 248.32/34.46/12.32 \n","04/22/2023 05:14:34 PM - INFO - [85:5] loss\t25.36 =\tBCE 25.35615 \tLL 0.02122 \tTotal 189.53/30.87/10.92 \n","04/22/2023 05:14:35 PM - INFO - [85:6] loss\t25.50 =\tBCE 25.50448 \tLL 0.02202 \tTotal 465.66/47.14/16.05 \n","04/22/2023 05:14:35 PM - INFO - [85:7] loss\t25.50 =\tBCE 25.50360 \tLL 0.02150 \tTotal 391.11/66.90/12.13 \n","04/22/2023 05:14:35 PM - INFO - Training epoch 86.\n","04/22/2023 05:14:36 PM - INFO - [86:0] loss\t25.19 =\tBCE 25.18715 \tLL 0.02055 \tTotal 239.65/34.69/4.08 \n","04/22/2023 05:14:36 PM - INFO - [86:1] loss\t25.54 =\tBCE 25.54459 \tLL 0.02204 \tTotal 274.69/36.40/16.79 \n","04/22/2023 05:14:37 PM - INFO - [86:2] loss\t25.02 =\tBCE 25.02275 \tLL 0.02071 \tTotal 292.60/42.73/13.37 \n","04/22/2023 05:14:37 PM - INFO - [86:3] loss\t24.69 =\tBCE 24.68799 \tLL 0.02089 \tTotal 243.53/51.63/6.00 \n","04/22/2023 05:14:38 PM - INFO - [86:4] loss\t24.56 =\tBCE 24.56269 \tLL 0.02078 \tTotal 363.80/42.84/7.99 \n","04/22/2023 05:14:38 PM - INFO - [86:5] loss\t24.08 =\tBCE 24.07777 \tLL 0.02005 \tTotal 301.62/38.33/9.09 \n","04/22/2023 05:14:39 PM - INFO - [86:6] loss\t24.14 =\tBCE 24.13543 \tLL 0.01995 \tTotal 477.30/55.36/6.44 \n","04/22/2023 05:14:39 PM - INFO - [86:7] loss\t24.32 =\tBCE 24.32215 \tLL 0.02092 \tTotal 382.42/58.52/8.05 \n","04/22/2023 05:14:39 PM - INFO - Training epoch 87.\n","04/22/2023 05:14:40 PM - INFO - [87:0] loss\t24.20 =\tBCE 24.19553 \tLL 0.02063 \tTotal 374.34/43.59/8.58 \n","04/22/2023 05:14:41 PM - INFO - [87:1] loss\t24.20 =\tBCE 24.19889 \tLL 0.02027 \tTotal 274.00/42.08/4.74 \n","04/22/2023 05:14:41 PM - INFO - [87:2] loss\t23.96 =\tBCE 23.95512 \tLL 0.02026 \tTotal 388.11/47.82/4.83 \n","04/22/2023 05:14:42 PM - INFO - [87:3] loss\t23.86 =\tBCE 23.86385 \tLL 0.01995 \tTotal 389.14/60.26/4.33 \n","04/22/2023 05:14:42 PM - INFO - [87:4] loss\t23.79 =\tBCE 23.79393 \tLL 0.02002 \tTotal 568.54/46.70/4.44 \n","04/22/2023 05:14:43 PM - INFO - [87:5] loss\t23.13 =\tBCE 23.12801 \tLL 0.01958 \tTotal 172.91/42.29/8.69 \n","04/22/2023 05:14:43 PM - INFO - [87:6] loss\t23.60 =\tBCE 23.60455 \tLL 0.01983 \tTotal 379.45/46.15/2.64 \n","04/22/2023 05:14:44 PM - INFO - [87:7] loss\t23.38 =\tBCE 23.37814 \tLL 0.02009 \tTotal 270.86/46.02/6.32 \n","04/22/2023 05:14:44 PM - INFO - Training epoch 88.\n","04/22/2023 05:14:44 PM - INFO - [88:0] loss\t23.46 =\tBCE 23.46445 \tLL 0.01984 \tTotal 359.14/42.80/7.42 \n","04/22/2023 05:14:45 PM - INFO - [88:1] loss\t23.12 =\tBCE 23.12318 \tLL 0.01972 \tTotal 159.96/30.63/3.78 \n","04/22/2023 05:14:45 PM - INFO - [88:2] loss\t23.38 =\tBCE 23.38247 \tLL 0.02012 \tTotal 297.65/37.10/6.60 \n","04/22/2023 05:14:46 PM - INFO - [88:3] loss\t23.36 =\tBCE 23.36319 \tLL 0.01986 \tTotal 290.34/40.31/6.27 \n","04/22/2023 05:14:47 PM - INFO - [88:4] loss\t22.53 =\tBCE 22.52502 \tLL 0.01895 \tTotal 399.12/44.37/7.19 \n","04/22/2023 05:14:47 PM - INFO - [88:5] loss\t22.32 =\tBCE 22.31675 \tLL 0.01899 \tTotal 204.61/27.78/2.85 \n","04/22/2023 05:14:48 PM - INFO - [88:6] loss\t22.63 =\tBCE 22.63200 \tLL 0.01923 \tTotal 302.76/47.41/6.07 \n","04/22/2023 05:14:48 PM - INFO - [88:7] loss\t22.62 =\tBCE 22.61630 \tLL 0.01906 \tTotal 186.67/31.44/9.25 \n","Not implemented\n","04/22/2023 05:14:48 PM - INFO - Training epoch 89.\n","04/22/2023 05:14:49 PM - INFO - [89:0] loss\t22.48 =\tBCE 22.48030 \tLL 0.01906 \tTotal 518.37/56.59/2.63 \n","04/22/2023 05:14:49 PM - INFO - [89:1] loss\t21.99 =\tBCE 21.99203 \tLL 0.01902 \tTotal 203.57/44.47/5.31 \n","04/22/2023 05:14:50 PM - INFO - [89:2] loss\t22.08 =\tBCE 22.08081 \tLL 0.01844 \tTotal 519.58/59.74/6.30 \n","04/22/2023 05:14:50 PM - INFO - [89:3] loss\t22.43 =\tBCE 22.42512 \tLL 0.01905 \tTotal 183.37/28.65/5.07 \n","04/22/2023 05:14:51 PM - INFO - [89:4] loss\t22.08 =\tBCE 22.08276 \tLL 0.01878 \tTotal 383.30/45.75/3.58 \n","04/22/2023 05:14:51 PM - INFO - [89:5] loss\t22.13 =\tBCE 22.13297 \tLL 0.01912 \tTotal 219.59/38.00/5.17 \n","04/22/2023 05:14:52 PM - INFO - [89:6] loss\t22.40 =\tBCE 22.39898 \tLL 0.01900 \tTotal 302.31/51.32/9.55 \n","04/22/2023 05:14:52 PM - INFO - [89:7] loss\t21.61 =\tBCE 21.61121 \tLL 0.01840 \tTotal 338.29/43.25/4.18 \n","04/22/2023 05:14:53 PM - INFO - EVALUATION prior to epoch [90]...\n","04/22/2023 05:14:53 PM - INFO - [90] loss\t2716.54=\tBCE 2716.54 \tLL 0.02450 \n","04/22/2023 05:14:54 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/90_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:14:59 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/90_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:15:05 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/90_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 05:15:06 PM - INFO - Training epoch 90.\n","04/22/2023 05:15:06 PM - INFO - [90:0] loss\t21.42 =\tBCE 21.42359 \tLL 0.01813 \tTotal 287.09/38.04/12.19 \n","04/22/2023 05:15:07 PM - INFO - [90:1] loss\t22.25 =\tBCE 22.24557 \tLL 0.01926 \tTotal 375.46/69.15/13.34 \n","04/22/2023 05:15:07 PM - INFO - [90:2] loss\t21.70 =\tBCE 21.70180 \tLL 0.01823 \tTotal 181.73/43.66/14.43 \n","04/22/2023 05:15:08 PM - INFO - [90:3] loss\t22.09 =\tBCE 22.09094 \tLL 0.01904 \tTotal 305.58/77.18/2.84 \n","04/22/2023 05:15:08 PM - INFO - [90:4] loss\t21.15 =\tBCE 21.14985 \tLL 0.01794 \tTotal 234.93/43.13/4.68 \n","04/22/2023 05:15:09 PM - INFO - [90:5] loss\t21.74 =\tBCE 21.74201 \tLL 0.01864 \tTotal 371.39/74.94/15.22 \n","04/22/2023 05:15:09 PM - INFO - [90:6] loss\t20.74 =\tBCE 20.74127 \tLL 0.01767 \tTotal 349.93/50.16/9.58 \n","04/22/2023 05:15:10 PM - INFO - [90:7] loss\t21.01 =\tBCE 21.01181 \tLL 0.01838 \tTotal 381.49/46.32/8.41 \n","04/22/2023 05:15:10 PM - INFO - Training epoch 91.\n","04/22/2023 05:15:10 PM - INFO - [91:0] loss\t21.20 =\tBCE 21.19516 \tLL 0.01822 \tTotal 430.46/53.18/12.98 \n","04/22/2023 05:15:11 PM - INFO - [91:1] loss\t20.94 =\tBCE 20.94039 \tLL 0.01813 \tTotal 228.50/43.77/9.57 \n","04/22/2023 05:15:12 PM - INFO - [91:2] loss\t21.07 =\tBCE 21.06694 \tLL 0.01799 \tTotal 617.46/66.31/6.22 \n","04/22/2023 05:15:12 PM - INFO - [91:3] loss\t20.67 =\tBCE 20.67178 \tLL 0.01753 \tTotal 561.23/86.03/5.84 \n","04/22/2023 05:15:13 PM - INFO - [91:4] loss\t20.97 =\tBCE 20.97333 \tLL 0.01812 \tTotal 411.32/73.22/8.07 \n","04/22/2023 05:15:13 PM - INFO - [91:5] loss\t21.04 =\tBCE 21.04020 \tLL 0.01834 \tTotal 506.04/58.31/8.04 \n","04/22/2023 05:15:14 PM - INFO - [91:6] loss\t20.74 =\tBCE 20.73578 \tLL 0.01754 \tTotal 668.66/97.49/8.33 \n","04/22/2023 05:15:14 PM - INFO - [91:7] loss\t20.63 =\tBCE 20.63412 \tLL 0.01736 \tTotal 897.12/116.05/7.47 \n","04/22/2023 05:15:14 PM - INFO - Training epoch 92.\n","04/22/2023 05:15:15 PM - INFO - [92:0] loss\t20.13 =\tBCE 20.12977 \tLL 0.01704 \tTotal 803.71/71.23/2.39 \n","04/22/2023 05:15:15 PM - INFO - [92:1] loss\t20.47 =\tBCE 20.46959 \tLL 0.01771 \tTotal 361.33/59.70/8.50 \n","04/22/2023 05:15:16 PM - INFO - [92:2] loss\t20.44 =\tBCE 20.43605 \tLL 0.01756 \tTotal 650.22/90.82/9.85 \n","04/22/2023 05:15:16 PM - INFO - [92:3] loss\t20.62 =\tBCE 20.62008 \tLL 0.01785 \tTotal 1121.56/97.00/21.38 \n","04/22/2023 05:15:17 PM - INFO - [92:4] loss\t20.49 =\tBCE 20.49041 \tLL 0.01763 \tTotal 1244.67/155.49/4.04 \n","04/22/2023 05:15:17 PM - INFO - [92:5] loss\t20.10 =\tBCE 20.10054 \tLL 0.01695 \tTotal 1046.33/156.71/6.03 \n","04/22/2023 05:15:18 PM - INFO - [92:6] loss\t20.23 =\tBCE 20.23061 \tLL 0.01730 \tTotal 681.59/61.24/9.02 \n","04/22/2023 05:15:19 PM - INFO - [92:7] loss\t20.23 =\tBCE 20.23208 \tLL 0.01764 \tTotal 297.36/59.23/9.43 \n","04/22/2023 05:15:19 PM - INFO - Training epoch 93.\n","04/22/2023 05:15:19 PM - INFO - [93:0] loss\t19.84 =\tBCE 19.83552 \tLL 0.01687 \tTotal 638.44/72.39/4.46 \n","04/22/2023 05:15:20 PM - INFO - [93:1] loss\t20.03 =\tBCE 20.02932 \tLL 0.01707 \tTotal 1163.55/109.78/8.59 \n","04/22/2023 05:15:20 PM - INFO - [93:2] loss\t20.27 =\tBCE 20.27251 \tLL 0.01738 \tTotal 1288.68/129.79/9.52 \n","04/22/2023 05:15:21 PM - INFO - [93:3] loss\t19.87 =\tBCE 19.86692 \tLL 0.01723 \tTotal 936.66/102.37/12.32 \n","04/22/2023 05:15:21 PM - INFO - [93:4] loss\t19.55 =\tBCE 19.55318 \tLL 0.01653 \tTotal 513.98/99.58/5.53 \n","04/22/2023 05:15:22 PM - INFO - [93:5] loss\t19.57 =\tBCE 19.56721 \tLL 0.01688 \tTotal 354.05/68.59/4.45 \n","04/22/2023 05:15:22 PM - INFO - [93:6] loss\t19.61 =\tBCE 19.61427 \tLL 0.01720 \tTotal 391.98/50.72/2.15 \n","04/22/2023 05:15:23 PM - INFO - [93:7] loss\t19.79 =\tBCE 19.79226 \tLL 0.01769 \tTotal 780.21/69.12/22.65 \n","04/22/2023 05:15:23 PM - INFO - Training epoch 94.\n","04/22/2023 05:15:23 PM - INFO - [94:0] loss\t19.34 =\tBCE 19.34170 \tLL 0.01637 \tTotal 1051.97/102.49/2.27 \n","04/22/2023 05:15:24 PM - INFO - [94:1] loss\t19.36 =\tBCE 19.35885 \tLL 0.01655 \tTotal 1095.27/124.36/16.58 \n","04/22/2023 05:15:24 PM - INFO - [94:2] loss\t19.83 =\tBCE 19.82613 \tLL 0.01723 \tTotal 1081.06/132.20/7.76 \n","04/22/2023 05:15:25 PM - INFO - [94:3] loss\t19.69 =\tBCE 19.68987 \tLL 0.01711 \tTotal 1023.77/133.31/10.94 \n","04/22/2023 05:15:26 PM - INFO - [94:4] loss\t19.22 =\tBCE 19.22285 \tLL 0.01660 \tTotal 850.01/135.62/6.64 \n","04/22/2023 05:15:26 PM - INFO - [94:5] loss\t19.03 =\tBCE 19.03332 \tLL 0.01664 \tTotal 539.99/82.61/10.92 \n","04/22/2023 05:15:27 PM - INFO - [94:6] loss\t19.24 =\tBCE 19.24480 \tLL 0.01675 \tTotal 429.38/44.26/4.73 \n","04/22/2023 05:15:27 PM - INFO - [94:7] loss\t19.05 =\tBCE 19.05122 \tLL 0.01647 \tTotal 550.80/103.73/5.59 \n","04/22/2023 05:15:27 PM - INFO - Training epoch 95.\n","04/22/2023 05:15:28 PM - INFO - [95:0] loss\t19.48 =\tBCE 19.48165 \tLL 0.01700 \tTotal 803.82/140.99/1.52 \n","04/22/2023 05:15:28 PM - INFO - [95:1] loss\t19.14 =\tBCE 19.13750 \tLL 0.01646 \tTotal 961.81/180.65/7.80 \n","04/22/2023 05:15:29 PM - INFO - [95:2] loss\t18.68 =\tBCE 18.67935 \tLL 0.01619 \tTotal 847.06/180.72/14.46 \n","04/22/2023 05:15:29 PM - INFO - [95:3] loss\t18.65 =\tBCE 18.65267 \tLL 0.01615 \tTotal 1081.06/144.54/7.02 \n","04/22/2023 05:15:30 PM - INFO - [95:4] loss\t19.21 =\tBCE 19.21244 \tLL 0.01607 \tTotal 1777.80/147.65/8.20 \n","04/22/2023 05:15:30 PM - INFO - [95:5] loss\t19.37 =\tBCE 19.36576 \tLL 0.01618 \tTotal 2494.65/210.21/4.07 \n","04/22/2023 05:15:31 PM - INFO - [95:6] loss\t20.09 =\tBCE 20.08907 \tLL 0.01607 \tTotal 3332.07/281.45/5.06 \n","04/22/2023 05:15:32 PM - INFO - [95:7] loss\t21.50 =\tBCE 21.50211 \tLL 0.01567 \tTotal 4662.59/427.36/12.60 \n","04/22/2023 05:15:32 PM - INFO - Training epoch 96.\n","04/22/2023 05:15:32 PM - INFO - [96:0] loss\t26.07 =\tBCE 26.07347 \tLL 0.01673 \tTotal 7121.42/645.14/8.73 \n","04/22/2023 05:15:33 PM - INFO - [96:1] loss\t36.49 =\tBCE 36.48623 \tLL 0.01557 \tTotal 11900.40/1047.05/7.88 \n","04/22/2023 05:15:33 PM - INFO - [96:2] loss\t77.76 =\tBCE 77.75893 \tLL 0.01722 \tTotal 21003.12/1881.69/13.41 \n","04/22/2023 05:15:34 PM - INFO - [96:3] loss\t220.93 =\tBCE 220.92929 \tLL 0.01487 \tTotal 40623.64/3797.10/12.23 \n","04/22/2023 05:15:34 PM - INFO - [96:4] loss\t883.99 =\tBCE 883.98907 \tLL 0.02113 \tTotal 56946.24/5956.84/17.91 \n","04/22/2023 05:15:35 PM - INFO - [96:5] loss\t358.32 =\tBCE 358.32220 \tLL 0.01911 \tTotal 42575.29/3826.40/13.74 \n","04/22/2023 05:15:35 PM - INFO - [96:6] loss\t79.45 =\tBCE 79.45451 \tLL 0.02059 \tTotal 7839.80/2326.27/3.55 \n","04/22/2023 05:15:36 PM - INFO - [96:7] loss\t329.28 =\tBCE 329.28036 \tLL 0.02406 \tTotal 37688.37/3301.11/11.88 \n","04/22/2023 05:15:36 PM - INFO - Training epoch 97.\n","04/22/2023 05:15:37 PM - INFO - [97:0] loss\t165.75 =\tBCE 165.75218 \tLL 0.02197 \tTotal 17494.29/3284.90/7.26 \n","04/22/2023 05:15:37 PM - INFO - [97:1] loss\t232.09 =\tBCE 232.08871 \tLL 0.02219 \tTotal 27650.81/3192.98/5.42 \n","04/22/2023 05:15:38 PM - INFO - [97:2] loss\t132.62 =\tBCE 132.62401 \tLL 0.02498 \tTotal 18469.18/2066.15/4.74 \n","04/22/2023 05:15:38 PM - INFO - [97:3] loss\t162.00 =\tBCE 161.99525 \tLL 0.02733 \tTotal 19080.43/2519.79/14.70 \n","04/22/2023 05:15:39 PM - INFO - [97:4] loss\t85.42 =\tBCE 85.41962 \tLL 0.02779 \tTotal 10420.55/1376.67/6.06 \n","04/22/2023 05:15:39 PM - INFO - [97:5] loss\t144.29 =\tBCE 144.29199 \tLL 0.02901 \tTotal 17123.86/1879.11/4.42 \n","04/22/2023 05:15:40 PM - INFO - [97:6] loss\t66.93 =\tBCE 66.92632 \tLL 0.03202 \tTotal 6454.63/1013.41/8.88 \n","04/22/2023 05:15:40 PM - INFO - [97:7] loss\t119.09 =\tBCE 119.08963 \tLL 0.03253 \tTotal 14330.24/1384.20/3.57 \n","04/22/2023 05:15:40 PM - INFO - Training epoch 98.\n","04/22/2023 05:15:41 PM - INFO - [98:0] loss\t69.21 =\tBCE 69.21299 \tLL 0.03269 \tTotal 7680.68/946.14/14.06 \n","04/22/2023 05:15:41 PM - INFO - [98:1] loss\t79.52 =\tBCE 79.51854 \tLL 0.03410 \tTotal 8555.12/989.56/5.96 \n","04/22/2023 05:15:42 PM - INFO - [98:2] loss\t80.39 =\tBCE 80.39351 \tLL 0.03431 \tTotal 9884.85/928.99/23.72 \n","04/22/2023 05:15:42 PM - INFO - [98:3] loss\t55.80 =\tBCE 55.80413 \tLL 0.03350 \tTotal 5504.53/713.04/22.04 \n","04/22/2023 05:15:43 PM - INFO - [98:4] loss\t70.07 =\tBCE 70.07198 \tLL 0.03248 \tTotal 7908.56/907.87/23.92 \n","04/22/2023 05:15:44 PM - INFO - [98:5] loss\t62.26 =\tBCE 62.26487 \tLL 0.03259 \tTotal 6890.70/641.39/11.84 \n","04/22/2023 05:15:44 PM - INFO - [98:6] loss\t57.12 =\tBCE 57.12229 \tLL 0.03285 \tTotal 5158.38/654.90/12.71 \n","04/22/2023 05:15:45 PM - INFO - [98:7] loss\t57.64 =\tBCE 57.63509 \tLL 0.03447 \tTotal 5928.24/661.80/8.09 \n","Not implemented\n","04/22/2023 05:15:45 PM - INFO - Training epoch 99.\n","04/22/2023 05:15:45 PM - INFO - [99:0] loss\t58.04 =\tBCE 58.03527 \tLL 0.03374 \tTotal 6867.99/590.17/19.87 \n","04/22/2023 05:15:46 PM - INFO - [99:1] loss\t50.01 =\tBCE 50.00611 \tLL 0.03442 \tTotal 4165.58/553.87/11.39 \n","04/22/2023 05:15:46 PM - INFO - [99:2] loss\t53.21 =\tBCE 53.21207 \tLL 0.03471 \tTotal 5192.55/580.47/10.54 \n","04/22/2023 05:15:47 PM - INFO - [99:3] loss\t50.23 =\tBCE 50.23281 \tLL 0.03306 \tTotal 4839.17/383.35/17.48 \n","04/22/2023 05:15:47 PM - INFO - [99:4] loss\t47.00 =\tBCE 46.99837 \tLL 0.03195 \tTotal 3520.77/477.79/14.78 \n","04/22/2023 05:15:48 PM - INFO - [99:5] loss\t47.61 =\tBCE 47.60532 \tLL 0.03250 \tTotal 3916.45/480.36/23.14 \n","04/22/2023 05:15:49 PM - INFO - [99:6] loss\t46.69 =\tBCE 46.68927 \tLL 0.03233 \tTotal 4253.15/338.22/14.41 \n","04/22/2023 05:15:49 PM - INFO - [99:7] loss\t44.28 =\tBCE 44.28463 \tLL 0.03195 \tTotal 3170.45/434.79/8.53 \n","04/22/2023 05:15:49 PM - INFO - EVALUATION prior to epoch [100]...\n","04/22/2023 05:15:49 PM - INFO - [100] loss\t1300.78=\tBCE 1300.78 \tLL 0.04343 \n","04/22/2023 05:15:50 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/100_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:15:55 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/100_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/22/2023 05:16:01 PM - INFO - Figure saved ./out/run_2023-04-22_17-05-56/figures/100_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/22/2023 05:16:02 PM - INFO - Training epoch 100.\n","04/22/2023 05:16:03 PM - INFO - [100:0] loss\t42.29 =\tBCE 42.29332 \tLL 0.03100 \tTotal 3068.74/386.21/7.40 \n","04/22/2023 05:16:03 PM - INFO - [100:1] loss\t44.40 =\tBCE 44.39879 \tLL 0.03166 \tTotal 3376.42/255.67/25.78 \n","04/22/2023 05:16:04 PM - INFO - [100:2] loss\t44.39 =\tBCE 44.38811 \tLL 0.03206 \tTotal 2934.53/329.72/9.19 \n","04/22/2023 05:16:04 PM - INFO - [100:3] loss\t40.52 =\tBCE 40.52106 \tLL 0.02981 \tTotal 2316.02/275.10/3.49 \n","04/22/2023 05:16:05 PM - INFO - [100:4] loss\t41.80 =\tBCE 41.79652 \tLL 0.03185 \tTotal 2777.27/221.59/15.36 \n","04/22/2023 05:16:05 PM - INFO - [100:5] loss\t41.62 =\tBCE 41.61758 \tLL 0.02975 \tTotal 2883.19/309.52/9.11 \n","04/22/2023 05:16:06 PM - INFO - [100:6] loss\t39.61 =\tBCE 39.61406 \tLL 0.03001 \tTotal 1880.03/237.06/6.81 \n","04/22/2023 05:16:06 PM - INFO - [100:7] loss\t40.12 =\tBCE 40.11845 \tLL 0.02929 \tTotal 2666.11/203.69/7.18 \n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/bce_loss █▄▄▄▃▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train/ll_loss ▁▂▃▇▆▇▇██▆▆▆▅█▆▅▅▄▅▄▄▃▆▅▄▄▃▃▃▆▅▄▄▄▃▃▃▃▃▅\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/total_loss █▄▄▄▃▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:     val/bce_loss █▃▁▁▁▂▂▆▁▇▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:        val/epoch ▁▂▂▃▄▅▅▆▇▇█\n","\u001b[34m\u001b[1mwandb\u001b[0m:      val/ll_loss ▁▆█▅▅▄▅▄▅▃▅\n","\u001b[34m\u001b[1mwandb\u001b[0m:   val/total_loss █▃▁▁▁▂▂▆▁▇▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/bce_loss 40.11845\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train/epoch 100\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train/ll_loss 0.02929\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/total_loss 40.11845\n","\u001b[34m\u001b[1mwandb\u001b[0m:     val/bce_loss 1300.78259\n","\u001b[34m\u001b[1mwandb\u001b[0m:        val/epoch 100\n","\u001b[34m\u001b[1mwandb\u001b[0m:      val/ll_loss 0.04343\n","\u001b[34m\u001b[1mwandb\u001b[0m:   val/total_loss 1300.78259\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mlively-bird-20\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/simonecaldarella/homomorphism-autoencoder/runs/4you5i73\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 33 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230422_170622-4you5i73/logs\u001b[0m\n"]}]},{"cell_type":"markdown","source":["### Extrapolation"],"metadata":{"id":"Da4FlcKYMpLE"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/\n","!python3 train_block_mlp_repr.py --combinatorial_indices=/content/drive/MyDrive/Advanced_Machine_Learning/remove_from_train_shape_equal_1__posX_greater_equal_15.json --dataset=dsprites --data_root=/content/drive/MyDrive/Advanced_Machine_Learning/dsprites-dataset --cyclic_trans --fixed_in_intervention=0,1,2,3 --fixed_in_sampling=0,1,2,3 --fixed_values=0,1,5,14 --distrib=uniform --displacement_range=-10,10 --n_steps=2 --rotate_actions=45 --num_train=10000 --batch_size=500 --epochs=101 --log_wandb --lr=0.001 --toggle_training_every=2,2 --shuffle=1 --use_adam --use_cuda --conv_channels=64,64,64,64 --kernel_sizes=6,4,4,4 --strides=2,2,1,1 --lin_channels=1024 --net_act=relu --dims=2,2 --group_hidden_units=128,128 --reconstruct_first --exponential_map --latent_loss --latent_loss_weight=400 --val_epoch=10 --num_val=500 --plot_epoch=10 --plot_manifold_latent=[0,1] --plot_manifold --plot_reconstruction --plot_pca --plot_vary_latents=[4,5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XuKrZWYJGUmM","executionInfo":{"status":"ok","timestamp":1682006402091,"user_tz":-120,"elapsed":352612,"user":{"displayName":"Simone Caldarella","userId":"06749461626406930087"}},"outputId":"bd012a2c-ae79-4ccf-f472-9c008bc082a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism\n","Created output folder ./out/run_2023-04-20_15-54-11.\n","04/20/2023 03:54:11 PM - INFO - Using cuda : True\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimonecaldarella\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.0\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/wandb/run-20230420_155441-27unq9li\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mancient-frog-15\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/simonecaldarella/homomorphism-autoencoder\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/simonecaldarella/homomorphism-autoencoder/runs/27unq9li\u001b[0m\n","04/20/2023 03:54:43 PM - INFO - ### Training ###\n","04/20/2023 03:54:43 PM - INFO - EVALUATION prior to epoch [0]...\n","04/20/2023 03:54:43 PM - INFO - [0] loss\t2897.61=\tBCE 2897.61 \tLL 0.00049 \n","04/20/2023 03:54:45 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/0_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:54:51 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/0_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:54:56 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/0_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/20/2023 03:54:57 PM - INFO - Training epoch 0.\n","04/20/2023 03:54:58 PM - INFO - [0:0] loss\t2897.57 =\tBCE 2897.56958 \tLL 0.00049 \tTotal 2204.18/2204.14/3.12 \n","04/20/2023 03:54:58 PM - INFO - [0:1] loss\t2870.93 =\tBCE 2870.93140 \tLL 0.02747 \tTotal 2174.81/2151.82/171.29 \n","04/20/2023 03:54:59 PM - INFO - [0:2] loss\t2783.01 =\tBCE 2783.00537 \tLL 0.00006 \tTotal 2137.36/2137.35/1.40 \n","04/20/2023 03:54:59 PM - INFO - Training epoch 1.\n","04/20/2023 03:54:59 PM - INFO - [1:0] loss\t2600.75 =\tBCE 2600.75098 \tLL 0.00009 \tTotal 2184.44/2184.16/5.30 \n","04/20/2023 03:55:00 PM - INFO - [1:1] loss\t2389.32 =\tBCE 2389.31738 \tLL 0.00162 \tTotal 1656.54/1656.43/17.62 \n","04/20/2023 03:55:00 PM - INFO - [1:2] loss\t2365.24 =\tBCE 2365.23633 \tLL 0.00486 \tTotal 1964.23/1913.01/291.82 \n","04/20/2023 03:55:00 PM - INFO - Training epoch 2.\n","04/20/2023 03:55:01 PM - INFO - [2:0] loss\t2185.72 =\tBCE 2185.71802 \tLL 0.00032 \tTotal 1587.22/1586.25/19.19 \n","04/20/2023 03:55:01 PM - INFO - [2:1] loss\t1995.22 =\tBCE 1995.22241 \tLL 0.00012 \tTotal 1177.06/1176.92/3.16 \n","04/20/2023 03:55:02 PM - INFO - [2:2] loss\t1865.57 =\tBCE 1865.57336 \tLL 0.00012 \tTotal 1300.75/1300.59/1.99 \n","04/20/2023 03:55:02 PM - INFO - Training epoch 3.\n","04/20/2023 03:55:02 PM - INFO - [3:0] loss\t1748.30 =\tBCE 1748.30054 \tLL 0.00014 \tTotal 1453.44/1453.32/2.08 \n","04/20/2023 03:55:02 PM - INFO - [3:1] loss\t1634.75 =\tBCE 1634.74939 \tLL 0.00018 \tTotal 1294.72/1294.63/3.09 \n","04/20/2023 03:55:03 PM - INFO - [3:2] loss\t1518.15 =\tBCE 1518.14844 \tLL 0.00027 \tTotal 967.35/967.25/4.46 \n","04/20/2023 03:55:03 PM - INFO - Training epoch 4.\n","04/20/2023 03:55:03 PM - INFO - [4:0] loss\t1437.53 =\tBCE 1437.53345 \tLL 0.00054 \tTotal 747.29/747.21/6.04 \n","04/20/2023 03:55:04 PM - INFO - [4:1] loss\t1382.37 =\tBCE 1382.36963 \tLL 0.00119 \tTotal 805.41/805.17/12.66 \n","04/20/2023 03:55:04 PM - INFO - [4:2] loss\t1310.35 =\tBCE 1310.34753 \tLL 0.00130 \tTotal 760.63/760.31/14.39 \n","04/20/2023 03:55:04 PM - INFO - Training epoch 5.\n","04/20/2023 03:55:05 PM - INFO - [5:0] loss\t1239.45 =\tBCE 1239.44983 \tLL 0.00086 \tTotal 642.07/641.99/5.98 \n","04/20/2023 03:55:05 PM - INFO - [5:1] loss\t1165.12 =\tBCE 1165.12329 \tLL 0.00063 \tTotal 561.29/560.85/5.48 \n","04/20/2023 03:55:06 PM - INFO - [5:2] loss\t1114.17 =\tBCE 1114.17017 \tLL 0.00072 \tTotal 605.97/604.70/10.30 \n","04/20/2023 03:55:06 PM - INFO - Training epoch 6.\n","04/20/2023 03:55:06 PM - INFO - [6:0] loss\t1055.44 =\tBCE 1055.43555 \tLL 0.00167 \tTotal 632.00/628.73/9.60 \n","04/20/2023 03:55:07 PM - INFO - [6:1] loss\t1008.52 =\tBCE 1008.52362 \tLL 0.00648 \tTotal 559.02/547.45/90.43 \n","04/20/2023 03:55:07 PM - INFO - [6:2] loss\t960.69 =\tBCE 960.68860 \tLL 0.00776 \tTotal 449.30/434.48/91.70 \n","04/20/2023 03:55:07 PM - INFO - Training epoch 7.\n","04/20/2023 03:55:08 PM - INFO - [7:0] loss\t926.59 =\tBCE 926.59009 \tLL 0.01484 \tTotal 644.44/533.11/282.10 \n","04/20/2023 03:55:08 PM - INFO - [7:1] loss\t867.02 =\tBCE 867.01990 \tLL 0.00571 \tTotal 427.40/418.51/61.87 \n","04/20/2023 03:55:09 PM - INFO - [7:2] loss\t841.95 =\tBCE 841.95001 \tLL 0.00509 \tTotal 397.63/333.49/213.12 \n","04/20/2023 03:55:09 PM - INFO - Training epoch 8.\n","04/20/2023 03:55:09 PM - INFO - [8:0] loss\t809.71 =\tBCE 809.70807 \tLL 0.00316 \tTotal 315.14/288.95/16.82 \n","04/20/2023 03:55:10 PM - INFO - [8:1] loss\t786.21 =\tBCE 786.21179 \tLL 0.00374 \tTotal 294.53/244.18/91.78 \n","04/20/2023 03:55:10 PM - INFO - [8:2] loss\t768.27 =\tBCE 768.26825 \tLL 0.00530 \tTotal 261.01/240.94/66.60 \n","Not implemented\n","04/20/2023 03:55:10 PM - INFO - Training epoch 9.\n","04/20/2023 03:55:11 PM - INFO - [9:0] loss\t746.55 =\tBCE 746.54974 \tLL 0.00568 \tTotal 343.07/301.69/110.30 \n","04/20/2023 03:55:11 PM - INFO - [9:1] loss\t740.56 =\tBCE 740.56158 \tLL 0.00707 \tTotal 408.48/206.48/344.08 \n","04/20/2023 03:55:12 PM - INFO - [9:2] loss\t726.45 =\tBCE 726.44849 \tLL 0.00522 \tTotal 298.72/178.98/235.07 \n","04/20/2023 03:55:12 PM - INFO - EVALUATION prior to epoch [10]...\n","04/20/2023 03:55:12 PM - INFO - [10] loss\t2542.56=\tBCE 2542.56 \tLL 0.00353 \n","04/20/2023 03:55:14 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/10_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:55:19 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/10_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:55:24 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/10_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/20/2023 03:55:25 PM - INFO - Training epoch 10.\n","04/20/2023 03:55:25 PM - INFO - [10:0] loss\t724.81 =\tBCE 724.80566 \tLL 0.00365 \tTotal 330.57/303.21/101.67 \n","04/20/2023 03:55:26 PM - INFO - [10:1] loss\t702.88 =\tBCE 702.87506 \tLL 0.00273 \tTotal 323.82/196.80/235.58 \n","04/20/2023 03:55:26 PM - INFO - [10:2] loss\t695.00 =\tBCE 695.00452 \tLL 0.00311 \tTotal 492.68/245.28/398.83 \n","04/20/2023 03:55:26 PM - INFO - Training epoch 11.\n","04/20/2023 03:55:27 PM - INFO - [11:0] loss\t696.02 =\tBCE 696.01599 \tLL 0.00618 \tTotal 518.14/182.45/473.55 \n","04/20/2023 03:55:27 PM - INFO - [11:1] loss\t682.07 =\tBCE 682.07324 \tLL 0.00184 \tTotal 200.89/147.73/81.74 \n","04/20/2023 03:55:28 PM - INFO - [11:2] loss\t689.95 =\tBCE 689.94800 \tLL 0.00694 \tTotal 661.52/121.99/649.98 \n","04/20/2023 03:55:28 PM - INFO - Training epoch 12.\n","04/20/2023 03:55:28 PM - INFO - [12:0] loss\t683.88 =\tBCE 683.87701 \tLL 0.00176 \tTotal 356.45/177.65/263.95 \n","04/20/2023 03:55:29 PM - INFO - [12:1] loss\t671.69 =\tBCE 671.69061 \tLL 0.00378 \tTotal 476.08/116.83/459.96 \n","04/20/2023 03:55:29 PM - INFO - [12:2] loss\t675.47 =\tBCE 675.47131 \tLL 0.00477 \tTotal 1058.18/292.92/927.62 \n","04/20/2023 03:55:29 PM - INFO - Training epoch 13.\n","04/20/2023 03:55:30 PM - INFO - [13:0] loss\t672.09 =\tBCE 672.08997 \tLL 0.00533 \tTotal 606.19/146.09/587.50 \n","04/20/2023 03:55:30 PM - INFO - [13:1] loss\t666.99 =\tBCE 666.98669 \tLL 0.00372 \tTotal 668.77/237.56/591.90 \n","04/20/2023 03:55:31 PM - INFO - [13:2] loss\t660.33 =\tBCE 660.33331 \tLL 0.00316 \tTotal 357.78/89.23/342.54 \n","04/20/2023 03:55:31 PM - INFO - Training epoch 14.\n","04/20/2023 03:55:32 PM - INFO - [14:0] loss\t664.12 =\tBCE 664.11633 \tLL 0.00752 \tTotal 928.57/237.19/879.35 \n","04/20/2023 03:55:32 PM - INFO - [14:1] loss\t655.66 =\tBCE 655.66351 \tLL 0.00137 \tTotal 160.80/73.28/125.43 \n","04/20/2023 03:55:33 PM - INFO - [14:2] loss\t651.96 =\tBCE 651.96039 \tLL 0.00545 \tTotal 623.50/143.52/595.52 \n","04/20/2023 03:55:33 PM - INFO - Training epoch 15.\n","04/20/2023 03:55:33 PM - INFO - [15:0] loss\t650.49 =\tBCE 650.48602 \tLL 0.00384 \tTotal 427.60/68.03/422.07 \n","04/20/2023 03:55:34 PM - INFO - [15:1] loss\t650.38 =\tBCE 650.37848 \tLL 0.00163 \tTotal 345.64/163.97/251.62 \n","04/20/2023 03:55:34 PM - INFO - [15:2] loss\t644.86 =\tBCE 644.85828 \tLL 0.00334 \tTotal 473.09/99.97/452.74 \n","04/20/2023 03:55:34 PM - INFO - Training epoch 16.\n","04/20/2023 03:55:35 PM - INFO - [16:0] loss\t639.35 =\tBCE 639.35089 \tLL 0.00125 \tTotal 187.64/129.96/22.14 \n","04/20/2023 03:55:35 PM - INFO - [16:1] loss\t649.66 =\tBCE 649.66071 \tLL 0.00087 \tTotal 228.47/188.46/92.06 \n","04/20/2023 03:55:36 PM - INFO - [16:2] loss\t643.85 =\tBCE 643.85461 \tLL 0.00110 \tTotal 126.87/55.70/102.48 \n","04/20/2023 03:55:36 PM - INFO - Training epoch 17.\n","04/20/2023 03:55:36 PM - INFO - [17:0] loss\t640.63 =\tBCE 640.62689 \tLL 0.00139 \tTotal 163.25/149.55/30.89 \n","04/20/2023 03:55:37 PM - INFO - [17:1] loss\t648.56 =\tBCE 648.55829 \tLL 0.00139 \tTotal 280.52/234.81/73.65 \n","04/20/2023 03:55:37 PM - INFO - [17:2] loss\t641.24 =\tBCE 641.23706 \tLL 0.00150 \tTotal 109.68/50.41/89.10 \n","04/20/2023 03:55:37 PM - INFO - Training epoch 18.\n","04/20/2023 03:55:38 PM - INFO - [18:0] loss\t641.21 =\tBCE 641.21246 \tLL 0.00133 \tTotal 193.64/124.80/75.71 \n","04/20/2023 03:55:38 PM - INFO - [18:1] loss\t642.08 =\tBCE 642.08234 \tLL 0.00171 \tTotal 153.78/127.07/32.76 \n","04/20/2023 03:55:39 PM - INFO - [18:2] loss\t641.02 =\tBCE 641.02307 \tLL 0.00275 \tTotal 248.66/61.97/236.02 \n","Not implemented\n","04/20/2023 03:55:39 PM - INFO - Training epoch 19.\n","04/20/2023 03:55:39 PM - INFO - [19:0] loss\t640.48 =\tBCE 640.48206 \tLL 0.00229 \tTotal 168.72/86.61/116.91 \n","04/20/2023 03:55:40 PM - INFO - [19:1] loss\t640.26 =\tBCE 640.25659 \tLL 0.00305 \tTotal 227.36/28.44/223.66 \n","04/20/2023 03:55:40 PM - INFO - [19:2] loss\t637.04 =\tBCE 637.03839 \tLL 0.00248 \tTotal 212.56/61.79/199.15 \n","04/20/2023 03:55:40 PM - INFO - EVALUATION prior to epoch [20]...\n","04/20/2023 03:55:40 PM - INFO - [20] loss\t2867.71=\tBCE 2867.71 \tLL 0.00301 \n","04/20/2023 03:55:42 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/20_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:55:47 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/20_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:55:52 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/20_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/20/2023 03:55:53 PM - INFO - Training epoch 20.\n","04/20/2023 03:55:53 PM - INFO - [20:0] loss\t633.28 =\tBCE 633.27588 \tLL 0.00228 \tTotal 87.21/73.98/29.77 \n","04/20/2023 03:55:54 PM - INFO - [20:1] loss\t636.60 =\tBCE 636.60468 \tLL 0.00278 \tTotal 233.32/75.16/213.91 \n","04/20/2023 03:55:54 PM - INFO - [20:2] loss\t641.05 =\tBCE 641.04633 \tLL 0.00256 \tTotal 171.06/54.56/151.70 \n","04/20/2023 03:55:54 PM - INFO - Training epoch 21.\n","04/20/2023 03:55:55 PM - INFO - [21:0] loss\t643.13 =\tBCE 643.13208 \tLL 0.00211 \tTotal 110.67/71.65/79.25 \n","04/20/2023 03:55:55 PM - INFO - [21:1] loss\t631.65 =\tBCE 631.64673 \tLL 0.00202 \tTotal 252.34/98.25/187.99 \n","04/20/2023 03:55:56 PM - INFO - [21:2] loss\t639.29 =\tBCE 639.29352 \tLL 0.00238 \tTotal 119.12/109.12/26.58 \n","04/20/2023 03:55:56 PM - INFO - Training epoch 22.\n","04/20/2023 03:55:57 PM - INFO - [22:0] loss\t633.38 =\tBCE 633.37659 \tLL 0.00261 \tTotal 177.86/55.93/148.55 \n","04/20/2023 03:55:57 PM - INFO - [22:1] loss\t639.10 =\tBCE 639.09521 \tLL 0.00229 \tTotal 86.47/73.57/21.59 \n","04/20/2023 03:55:58 PM - INFO - [22:2] loss\t637.67 =\tBCE 637.66821 \tLL 0.00206 \tTotal 192.78/134.19/123.56 \n","04/20/2023 03:55:58 PM - INFO - Training epoch 23.\n","04/20/2023 03:55:58 PM - INFO - [23:0] loss\t637.28 =\tBCE 637.27582 \tLL 0.00205 \tTotal 141.43/124.53/39.07 \n","04/20/2023 03:55:59 PM - INFO - [23:1] loss\t636.20 =\tBCE 636.19562 \tLL 0.00244 \tTotal 189.89/61.62/175.69 \n","04/20/2023 03:55:59 PM - INFO - [23:2] loss\t636.52 =\tBCE 636.52362 \tLL 0.00212 \tTotal 165.00/106.92/111.09 \n","04/20/2023 03:55:59 PM - INFO - Training epoch 24.\n","04/20/2023 03:56:00 PM - INFO - [24:0] loss\t640.64 =\tBCE 640.63977 \tLL 0.00224 \tTotal 159.19/32.87/155.17 \n","04/20/2023 03:56:00 PM - INFO - [24:1] loss\t633.69 =\tBCE 633.68683 \tLL 0.00232 \tTotal 231.99/67.81/202.17 \n","04/20/2023 03:56:01 PM - INFO - [24:2] loss\t638.58 =\tBCE 638.57788 \tLL 0.00209 \tTotal 123.99/56.84/99.83 \n","04/20/2023 03:56:01 PM - INFO - Training epoch 25.\n","04/20/2023 03:56:01 PM - INFO - [25:0] loss\t634.54 =\tBCE 634.53558 \tLL 0.00212 \tTotal 137.41/61.69/117.82 \n","04/20/2023 03:56:02 PM - INFO - [25:1] loss\t640.48 =\tBCE 640.47638 \tLL 0.00233 \tTotal 71.94/20.97/62.06 \n","04/20/2023 03:56:02 PM - INFO - [25:2] loss\t630.66 =\tBCE 630.66254 \tLL 0.00204 \tTotal 213.61/120.87/135.12 \n","04/20/2023 03:56:02 PM - INFO - Training epoch 26.\n","04/20/2023 03:56:03 PM - INFO - [26:0] loss\t635.65 =\tBCE 635.65009 \tLL 0.00230 \tTotal 62.37/50.17/23.10 \n","04/20/2023 03:56:03 PM - INFO - [26:1] loss\t644.45 =\tBCE 644.44891 \tLL 0.00251 \tTotal 271.02/184.50/105.88 \n","04/20/2023 03:56:04 PM - INFO - [26:2] loss\t629.22 =\tBCE 629.21777 \tLL 0.00210 \tTotal 208.90/83.81/152.32 \n","04/20/2023 03:56:04 PM - INFO - Training epoch 27.\n","04/20/2023 03:56:04 PM - INFO - [27:0] loss\t636.84 =\tBCE 636.83844 \tLL 0.00210 \tTotal 71.24/48.80/11.38 \n","04/20/2023 03:56:05 PM - INFO - [27:1] loss\t629.82 =\tBCE 629.81854 \tLL 0.00237 \tTotal 44.60/31.00/22.00 \n","04/20/2023 03:56:05 PM - INFO - [27:2] loss\t640.45 =\tBCE 640.44843 \tLL 0.00297 \tTotal 339.17/76.49/293.47 \n","04/20/2023 03:56:05 PM - INFO - Training epoch 28.\n","04/20/2023 03:56:06 PM - INFO - [28:0] loss\t639.87 =\tBCE 639.87201 \tLL 0.00255 \tTotal 135.39/71.65/114.74 \n","04/20/2023 03:56:06 PM - INFO - [28:1] loss\t634.42 =\tBCE 634.42279 \tLL 0.00272 \tTotal 316.98/72.72/276.82 \n","04/20/2023 03:56:07 PM - INFO - [28:2] loss\t632.48 =\tBCE 632.48114 \tLL 0.00246 \tTotal 98.13/38.96/81.98 \n","Not implemented\n","04/20/2023 03:56:07 PM - INFO - Training epoch 29.\n","04/20/2023 03:56:07 PM - INFO - [29:0] loss\t631.65 =\tBCE 631.65350 \tLL 0.00337 \tTotal 346.97/181.11/270.21 \n","04/20/2023 03:56:08 PM - INFO - [29:1] loss\t636.37 =\tBCE 636.37335 \tLL 0.00303 \tTotal 247.75/58.06/229.23 \n","04/20/2023 03:56:08 PM - INFO - [29:2] loss\t634.19 =\tBCE 634.19202 \tLL 0.00282 \tTotal 320.14/166.42/233.48 \n","04/20/2023 03:56:08 PM - INFO - EVALUATION prior to epoch [30]...\n","04/20/2023 03:56:08 PM - INFO - [30] loss\t3045.61=\tBCE 3045.61 \tLL 0.00337 \n","04/20/2023 03:56:10 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/30_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:56:16 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/30_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:56:21 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/30_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/20/2023 03:56:21 PM - INFO - Training epoch 30.\n","04/20/2023 03:56:22 PM - INFO - [30:0] loss\t638.14 =\tBCE 638.14264 \tLL 0.00318 \tTotal 264.59/89.73/236.35 \n","04/20/2023 03:56:22 PM - INFO - [30:1] loss\t635.70 =\tBCE 635.69745 \tLL 0.00323 \tTotal 178.03/64.68/99.45 \n","04/20/2023 03:56:23 PM - INFO - [30:2] loss\t635.39 =\tBCE 635.39026 \tLL 0.00380 \tTotal 373.09/73.49/322.37 \n","04/20/2023 03:56:23 PM - INFO - Training epoch 31.\n","04/20/2023 03:56:23 PM - INFO - [31:0] loss\t629.51 =\tBCE 629.50793 \tLL 0.00245 \tTotal 193.62/56.54/118.31 \n","04/20/2023 03:56:24 PM - INFO - [31:1] loss\t634.79 =\tBCE 634.78564 \tLL 0.00289 \tTotal 229.77/61.64/177.46 \n","04/20/2023 03:56:24 PM - INFO - [31:2] loss\t633.70 =\tBCE 633.69617 \tLL 0.00318 \tTotal 162.79/131.20/95.87 \n","04/20/2023 03:56:24 PM - INFO - Training epoch 32.\n","04/20/2023 03:56:25 PM - INFO - [32:0] loss\t634.22 =\tBCE 634.21655 \tLL 0.00370 \tTotal 298.73/147.83/209.07 \n","04/20/2023 03:56:25 PM - INFO - [32:1] loss\t631.05 =\tBCE 631.05255 \tLL 0.00340 \tTotal 74.30/56.51/45.32 \n","04/20/2023 03:56:26 PM - INFO - [32:2] loss\t637.91 =\tBCE 637.91052 \tLL 0.00321 \tTotal 138.79/114.72/44.97 \n","04/20/2023 03:56:26 PM - INFO - Training epoch 33.\n","04/20/2023 03:56:27 PM - INFO - [33:0] loss\t633.45 =\tBCE 633.44550 \tLL 0.00377 \tTotal 118.78/98.23/48.25 \n","04/20/2023 03:56:27 PM - INFO - [33:1] loss\t637.90 =\tBCE 637.90369 \tLL 0.00399 \tTotal 115.02/79.74/30.22 \n","04/20/2023 03:56:28 PM - INFO - [33:2] loss\t630.07 =\tBCE 630.07471 \tLL 0.00401 \tTotal 98.18/93.92/14.48 \n","04/20/2023 03:56:28 PM - INFO - Training epoch 34.\n","04/20/2023 03:56:28 PM - INFO - [34:0] loss\t635.03 =\tBCE 635.02637 \tLL 0.00384 \tTotal 98.48/71.98/56.76 \n","04/20/2023 03:56:29 PM - INFO - [34:1] loss\t632.02 =\tBCE 632.01764 \tLL 0.00386 \tTotal 117.77/66.32/31.34 \n","04/20/2023 03:56:29 PM - INFO - [34:2] loss\t631.66 =\tBCE 631.66492 \tLL 0.00401 \tTotal 136.26/40.03/101.11 \n","04/20/2023 03:56:29 PM - INFO - Training epoch 35.\n","04/20/2023 03:56:30 PM - INFO - [35:0] loss\t627.80 =\tBCE 627.80170 \tLL 0.00472 \tTotal 125.28/73.70/83.31 \n","04/20/2023 03:56:30 PM - INFO - [35:1] loss\t638.96 =\tBCE 638.95502 \tLL 0.00538 \tTotal 315.32/67.79/230.22 \n","04/20/2023 03:56:31 PM - INFO - [35:2] loss\t637.23 =\tBCE 637.23444 \tLL 0.00445 \tTotal 170.69/82.63/123.47 \n","04/20/2023 03:56:31 PM - INFO - Training epoch 36.\n","04/20/2023 03:56:31 PM - INFO - [36:0] loss\t630.13 =\tBCE 630.12897 \tLL 0.00489 \tTotal 444.57/146.58/347.24 \n","04/20/2023 03:56:32 PM - INFO - [36:1] loss\t632.99 =\tBCE 632.99487 \tLL 0.00513 \tTotal 323.23/149.00/244.56 \n","04/20/2023 03:56:32 PM - INFO - [36:2] loss\t635.11 =\tBCE 635.10791 \tLL 0.00559 \tTotal 291.76/122.05/186.89 \n","04/20/2023 03:56:32 PM - INFO - Training epoch 37.\n","04/20/2023 03:56:33 PM - INFO - [37:0] loss\t630.72 =\tBCE 630.71759 \tLL 0.00455 \tTotal 273.58/75.34/185.16 \n","04/20/2023 03:56:33 PM - INFO - [37:1] loss\t639.29 =\tBCE 639.28687 \tLL 0.00493 \tTotal 114.65/48.06/71.14 \n","04/20/2023 03:56:34 PM - INFO - [37:2] loss\t633.90 =\tBCE 633.89966 \tLL 0.00528 \tTotal 80.55/67.52/33.47 \n","04/20/2023 03:56:34 PM - INFO - Training epoch 38.\n","04/20/2023 03:56:34 PM - INFO - [38:0] loss\t634.45 =\tBCE 634.44922 \tLL 0.00598 \tTotal 294.96/64.46/210.25 \n","04/20/2023 03:56:35 PM - INFO - [38:1] loss\t631.41 =\tBCE 631.40509 \tLL 0.00511 \tTotal 138.75/64.72/96.09 \n","04/20/2023 03:56:35 PM - INFO - [38:2] loss\t635.29 =\tBCE 635.29028 \tLL 0.00501 \tTotal 141.55/81.21/81.34 \n","Not implemented\n","04/20/2023 03:56:35 PM - INFO - Training epoch 39.\n","04/20/2023 03:56:36 PM - INFO - [39:0] loss\t631.53 =\tBCE 631.52832 \tLL 0.00539 \tTotal 78.05/51.46/47.22 \n","04/20/2023 03:56:36 PM - INFO - [39:1] loss\t632.49 =\tBCE 632.48907 \tLL 0.00616 \tTotal 102.94/43.52/60.20 \n","04/20/2023 03:56:37 PM - INFO - [39:2] loss\t626.97 =\tBCE 626.97168 \tLL 0.00577 \tTotal 129.76/40.29/116.45 \n","04/20/2023 03:56:37 PM - INFO - EVALUATION prior to epoch [40]...\n","04/20/2023 03:56:37 PM - INFO - [40] loss\t3321.29=\tBCE 3321.29 \tLL 0.00672 \n","04/20/2023 03:56:38 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/40_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:56:44 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/40_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:56:49 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/40_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/20/2023 03:56:50 PM - INFO - Training epoch 40.\n","04/20/2023 03:56:50 PM - INFO - [40:0] loss\t633.38 =\tBCE 633.37927 \tLL 0.00627 \tTotal 69.28/56.55/39.09 \n","04/20/2023 03:56:51 PM - INFO - [40:1] loss\t622.54 =\tBCE 622.54150 \tLL 0.00572 \tTotal 273.46/73.38/177.20 \n","04/20/2023 03:56:51 PM - INFO - [40:2] loss\t634.30 =\tBCE 634.29919 \tLL 0.00810 \tTotal 446.38/107.87/294.89 \n","04/20/2023 03:56:51 PM - INFO - Training epoch 41.\n","04/20/2023 03:56:52 PM - INFO - [41:0] loss\t629.40 =\tBCE 629.39716 \tLL 0.00680 \tTotal 256.38/61.20/211.14 \n","04/20/2023 03:56:53 PM - INFO - [41:1] loss\t632.37 =\tBCE 632.36707 \tLL 0.00664 \tTotal 186.61/46.61/109.24 \n","04/20/2023 03:56:53 PM - INFO - [41:2] loss\t629.39 =\tBCE 629.38855 \tLL 0.00862 \tTotal 270.77/65.59/195.81 \n","04/20/2023 03:56:53 PM - INFO - Training epoch 42.\n","04/20/2023 03:56:54 PM - INFO - [42:0] loss\t628.34 =\tBCE 628.34106 \tLL 0.00727 \tTotal 65.52/39.71/50.61 \n","04/20/2023 03:56:54 PM - INFO - [42:1] loss\t627.76 =\tBCE 627.76086 \tLL 0.00701 \tTotal 168.86/51.66/82.27 \n","04/20/2023 03:56:55 PM - INFO - [42:2] loss\t629.57 =\tBCE 629.56622 \tLL 0.00782 \tTotal 76.76/27.89/70.81 \n","04/20/2023 03:56:55 PM - INFO - Training epoch 43.\n","04/20/2023 03:56:55 PM - INFO - [43:0] loss\t632.89 =\tBCE 632.89429 \tLL 0.00796 \tTotal 285.95/70.95/114.69 \n","04/20/2023 03:56:56 PM - INFO - [43:1] loss\t622.76 =\tBCE 622.76318 \tLL 0.00676 \tTotal 426.34/83.48/246.83 \n","04/20/2023 03:56:56 PM - INFO - [43:2] loss\t623.69 =\tBCE 623.69226 \tLL 0.00981 \tTotal 272.79/56.79/234.66 \n","04/20/2023 03:56:56 PM - INFO - Training epoch 44.\n","04/20/2023 03:56:57 PM - INFO - [44:0] loss\t630.47 =\tBCE 630.46533 \tLL 0.00986 \tTotal 442.54/92.17/267.70 \n","04/20/2023 03:56:57 PM - INFO - [44:1] loss\t627.07 =\tBCE 627.06500 \tLL 0.00776 \tTotal 781.88/158.78/475.61 \n","04/20/2023 03:56:58 PM - INFO - [44:2] loss\t630.32 =\tBCE 630.32263 \tLL 0.01008 \tTotal 360.21/103.54/154.45 \n","04/20/2023 03:56:58 PM - INFO - Training epoch 45.\n","04/20/2023 03:56:58 PM - INFO - [45:0] loss\t621.35 =\tBCE 621.35345 \tLL 0.01036 \tTotal 163.22/62.88/85.61 \n","04/20/2023 03:56:59 PM - INFO - [45:1] loss\t626.34 =\tBCE 626.33728 \tLL 0.01000 \tTotal 371.58/70.56/228.36 \n","04/20/2023 03:56:59 PM - INFO - [45:2] loss\t626.72 =\tBCE 626.72253 \tLL 0.01161 \tTotal 503.04/75.14/346.77 \n","04/20/2023 03:56:59 PM - INFO - Training epoch 46.\n","04/20/2023 03:57:00 PM - INFO - [46:0] loss\t619.43 =\tBCE 619.42798 \tLL 0.00955 \tTotal 612.63/127.39/359.77 \n","04/20/2023 03:57:01 PM - INFO - [46:1] loss\t627.07 =\tBCE 627.07208 \tLL 0.01230 \tTotal 785.43/131.96/495.07 \n","04/20/2023 03:57:01 PM - INFO - [46:2] loss\t633.20 =\tBCE 633.19550 \tLL 0.00945 \tTotal 536.66/119.35/318.25 \n","04/20/2023 03:57:01 PM - INFO - Training epoch 47.\n","04/20/2023 03:57:02 PM - INFO - [47:0] loss\t628.27 =\tBCE 628.27283 \tLL 0.01080 \tTotal 447.04/90.94/332.19 \n","04/20/2023 03:57:02 PM - INFO - [47:1] loss\t629.12 =\tBCE 629.12073 \tLL 0.01256 \tTotal 1943.77/253.49/1201.40 \n","04/20/2023 03:57:03 PM - INFO - [47:2] loss\t640.98 =\tBCE 640.98175 \tLL 0.01047 \tTotal 1219.03/250.19/657.25 \n","04/20/2023 03:57:03 PM - INFO - Training epoch 48.\n","04/20/2023 03:57:03 PM - INFO - [48:0] loss\t639.54 =\tBCE 639.53967 \tLL 0.01164 \tTotal 1081.64/215.03/570.27 \n","04/20/2023 03:57:04 PM - INFO - [48:1] loss\t618.04 =\tBCE 618.04462 \tLL 0.01464 \tTotal 278.80/160.32/218.55 \n","04/20/2023 03:57:04 PM - INFO - [48:2] loss\t652.80 =\tBCE 652.80170 \tLL 0.02022 \tTotal 2970.32/463.55/1682.57 \n","Not implemented\n","04/20/2023 03:57:04 PM - INFO - Training epoch 49.\n","04/20/2023 03:57:05 PM - INFO - [49:0] loss\t629.72 =\tBCE 629.72400 \tLL 0.01509 \tTotal 826.67/311.31/522.30 \n","04/20/2023 03:57:05 PM - INFO - [49:1] loss\t641.09 =\tBCE 641.09338 \tLL 0.01308 \tTotal 701.02/301.61/362.48 \n","04/20/2023 03:57:06 PM - INFO - [49:2] loss\t645.59 =\tBCE 645.58710 \tLL 0.01230 \tTotal 577.84/200.91/294.14 \n","04/20/2023 03:57:06 PM - INFO - EVALUATION prior to epoch [50]...\n","04/20/2023 03:57:06 PM - INFO - [50] loss\t3865.92=\tBCE 3865.92 \tLL 0.01181 \n","04/20/2023 03:57:07 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/50_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:57:13 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/50_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:57:18 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/50_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/20/2023 03:57:19 PM - INFO - Training epoch 50.\n","04/20/2023 03:57:19 PM - INFO - [50:0] loss\t636.94 =\tBCE 636.94470 \tLL 0.01230 \tTotal 539.67/235.35/271.98 \n","04/20/2023 03:57:20 PM - INFO - [50:1] loss\t628.87 =\tBCE 628.86658 \tLL 0.01358 \tTotal 421.64/340.67/135.37 \n","04/20/2023 03:57:20 PM - INFO - [50:2] loss\t630.09 =\tBCE 630.09119 \tLL 0.01782 \tTotal 512.55/287.39/187.76 \n","04/20/2023 03:57:20 PM - INFO - Training epoch 51.\n","04/20/2023 03:57:21 PM - INFO - [51:0] loss\t631.57 =\tBCE 631.56641 \tLL 0.01941 \tTotal 953.11/243.95/593.71 \n","04/20/2023 03:57:21 PM - INFO - [51:1] loss\t631.57 =\tBCE 631.56854 \tLL 0.01802 \tTotal 456.51/441.13/54.95 \n","04/20/2023 03:57:22 PM - INFO - [51:2] loss\t625.46 =\tBCE 625.45587 \tLL 0.01475 \tTotal 412.09/350.90/131.90 \n","04/20/2023 03:57:22 PM - INFO - Training epoch 52.\n","04/20/2023 03:57:22 PM - INFO - [52:0] loss\t624.61 =\tBCE 624.60974 \tLL 0.01383 \tTotal 384.73/90.14/189.75 \n","04/20/2023 03:57:23 PM - INFO - [52:1] loss\t627.95 =\tBCE 627.95135 \tLL 0.01422 \tTotal 399.50/297.99/116.06 \n","04/20/2023 03:57:23 PM - INFO - [52:2] loss\t623.87 =\tBCE 623.87268 \tLL 0.01637 \tTotal 404.82/337.30/147.40 \n","04/20/2023 03:57:23 PM - INFO - Training epoch 53.\n","04/20/2023 03:57:24 PM - INFO - [53:0] loss\t620.74 =\tBCE 620.74084 \tLL 0.01912 \tTotal 378.07/249.89/211.03 \n","04/20/2023 03:57:24 PM - INFO - [53:1] loss\t612.25 =\tBCE 612.25153 \tLL 0.01933 \tTotal 173.42/145.46/65.59 \n","04/20/2023 03:57:25 PM - INFO - [53:2] loss\t622.08 =\tBCE 622.07623 \tLL 0.02199 \tTotal 371.12/365.18/28.23 \n","04/20/2023 03:57:25 PM - INFO - Training epoch 54.\n","04/20/2023 03:57:26 PM - INFO - [54:0] loss\t614.14 =\tBCE 614.13983 \tLL 0.02225 \tTotal 249.16/234.36/76.04 \n","04/20/2023 03:57:26 PM - INFO - [54:1] loss\t608.91 =\tBCE 608.91101 \tLL 0.02218 \tTotal 136.89/85.30/90.42 \n","04/20/2023 03:57:27 PM - INFO - [54:2] loss\t608.27 =\tBCE 608.27258 \tLL 0.02076 \tTotal 300.08/284.04/78.06 \n","04/20/2023 03:57:27 PM - INFO - Training epoch 55.\n","04/20/2023 03:57:27 PM - INFO - [55:0] loss\t599.02 =\tBCE 599.02197 \tLL 0.02057 \tTotal 676.07/277.01/423.50 \n","04/20/2023 03:57:28 PM - INFO - [55:1] loss\t605.01 =\tBCE 605.00781 \tLL 0.02349 \tTotal 985.61/129.32/650.04 \n","04/20/2023 03:57:28 PM - INFO - [55:2] loss\t601.32 =\tBCE 601.32404 \tLL 0.02237 \tTotal 485.13/291.12/284.45 \n","04/20/2023 03:57:28 PM - INFO - Training epoch 56.\n","04/20/2023 03:57:29 PM - INFO - [56:0] loss\t585.71 =\tBCE 585.70746 \tLL 0.02167 \tTotal 998.32/135.13/702.15 \n","04/20/2023 03:57:29 PM - INFO - [56:1] loss\t594.65 =\tBCE 594.64728 \tLL 0.02565 \tTotal 1795.03/198.02/1128.75 \n","04/20/2023 03:57:30 PM - INFO - [56:2] loss\t595.92 =\tBCE 595.92242 \tLL 0.02329 \tTotal 1647.07/469.00/953.11 \n","04/20/2023 03:57:30 PM - INFO - Training epoch 57.\n","04/20/2023 03:57:30 PM - INFO - [57:0] loss\t584.62 =\tBCE 584.61969 \tLL 0.02796 \tTotal 976.98/356.49/494.25 \n","04/20/2023 03:57:31 PM - INFO - [57:1] loss\t578.15 =\tBCE 578.15222 \tLL 0.02563 \tTotal 260.80/234.80/65.15 \n","04/20/2023 03:57:31 PM - INFO - [57:2] loss\t578.15 =\tBCE 578.15497 \tLL 0.02203 \tTotal 1385.57/469.76/762.95 \n","04/20/2023 03:57:31 PM - INFO - Training epoch 58.\n","04/20/2023 03:57:32 PM - INFO - [58:0] loss\t596.03 =\tBCE 596.03223 \tLL 0.02690 \tTotal 4454.94/429.27/3122.91 \n","04/20/2023 03:57:32 PM - INFO - [58:1] loss\t647.37 =\tBCE 647.37201 \tLL 0.01955 \tTotal 3718.84/637.42/1830.27 \n","04/20/2023 03:57:33 PM - INFO - [58:2] loss\t601.70 =\tBCE 601.70447 \tLL 0.02799 \tTotal 2548.65/327.30/1712.49 \n","Not implemented\n","04/20/2023 03:57:33 PM - INFO - Training epoch 59.\n","04/20/2023 03:57:33 PM - INFO - [59:0] loss\t604.71 =\tBCE 604.70923 \tLL 0.04164 \tTotal 3336.89/507.18/1359.15 \n","04/20/2023 03:57:34 PM - INFO - [59:1] loss\t593.74 =\tBCE 593.73901 \tLL 0.04186 \tTotal 2416.15/401.32/991.23 \n","04/20/2023 03:57:34 PM - INFO - [59:2] loss\t584.60 =\tBCE 584.60486 \tLL 0.03465 \tTotal 1171.93/233.45/854.93 \n","04/20/2023 03:57:34 PM - INFO - EVALUATION prior to epoch [60]...\n","04/20/2023 03:57:34 PM - INFO - [60] loss\t4034.36=\tBCE 4034.36 \tLL 0.02159 \n","04/20/2023 03:57:36 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/60_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:57:42 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/60_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:57:47 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/60_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/20/2023 03:57:47 PM - INFO - Training epoch 60.\n","04/20/2023 03:57:48 PM - INFO - [60:0] loss\t591.20 =\tBCE 591.20111 \tLL 0.02858 \tTotal 1339.07/272.12/671.68 \n","04/20/2023 03:57:48 PM - INFO - [60:1] loss\t596.02 =\tBCE 596.02106 \tLL 0.03061 \tTotal 1275.50/371.27/696.82 \n","04/20/2023 03:57:49 PM - INFO - [60:2] loss\t571.08 =\tBCE 571.08289 \tLL 0.03639 \tTotal 414.15/162.01/220.37 \n","04/20/2023 03:57:49 PM - INFO - Training epoch 61.\n","04/20/2023 03:57:49 PM - INFO - [61:0] loss\t580.00 =\tBCE 580.00348 \tLL 0.04433 \tTotal 1711.79/240.15/1216.72 \n","04/20/2023 03:57:50 PM - INFO - [61:1] loss\t576.52 =\tBCE 576.51581 \tLL 0.04162 \tTotal 1313.57/261.19/862.46 \n","04/20/2023 03:57:50 PM - INFO - [61:2] loss\t568.90 =\tBCE 568.89948 \tLL 0.03370 \tTotal 425.76/182.09/275.56 \n","04/20/2023 03:57:50 PM - INFO - Training epoch 62.\n","04/20/2023 03:57:51 PM - INFO - [62:0] loss\t564.25 =\tBCE 564.24750 \tLL 0.02606 \tTotal 766.48/233.67/337.73 \n","04/20/2023 03:57:52 PM - INFO - [62:1] loss\t576.19 =\tBCE 576.19232 \tLL 0.02324 \tTotal 895.09/189.49/381.20 \n","04/20/2023 03:57:52 PM - INFO - [62:2] loss\t561.93 =\tBCE 561.93427 \tLL 0.02580 \tTotal 741.46/324.79/333.36 \n","04/20/2023 03:57:52 PM - INFO - Training epoch 63.\n","04/20/2023 03:57:53 PM - INFO - [63:0] loss\t556.17 =\tBCE 556.17084 \tLL 0.03101 \tTotal 364.51/99.33/293.77 \n","04/20/2023 03:57:53 PM - INFO - [63:1] loss\t558.97 =\tBCE 558.96655 \tLL 0.03551 \tTotal 659.35/268.75/197.76 \n","04/20/2023 03:57:54 PM - INFO - [63:2] loss\t548.79 =\tBCE 548.79309 \tLL 0.03662 \tTotal 895.98/189.70/370.57 \n","04/20/2023 03:57:54 PM - INFO - Training epoch 64.\n","04/20/2023 03:57:54 PM - INFO - [64:0] loss\t547.29 =\tBCE 547.29382 \tLL 0.03296 \tTotal 471.71/262.37/90.95 \n","04/20/2023 03:57:55 PM - INFO - [64:1] loss\t554.51 =\tBCE 554.50732 \tLL 0.02966 \tTotal 293.54/102.84/122.42 \n","04/20/2023 03:57:55 PM - INFO - [64:2] loss\t549.69 =\tBCE 549.68506 \tLL 0.02367 \tTotal 896.16/388.32/471.35 \n","04/20/2023 03:57:55 PM - INFO - Training epoch 65.\n","04/20/2023 03:57:56 PM - INFO - [65:0] loss\t543.72 =\tBCE 543.71802 \tLL 0.02135 \tTotal 778.08/399.51/344.38 \n","04/20/2023 03:57:56 PM - INFO - [65:1] loss\t541.49 =\tBCE 541.49359 \tLL 0.02143 \tTotal 269.67/151.63/93.71 \n","04/20/2023 03:57:57 PM - INFO - [65:2] loss\t543.44 =\tBCE 543.44482 \tLL 0.02238 \tTotal 933.84/341.88/531.76 \n","04/20/2023 03:57:57 PM - INFO - Training epoch 66.\n","04/20/2023 03:57:57 PM - INFO - [66:0] loss\t539.07 =\tBCE 539.07489 \tLL 0.02108 \tTotal 479.00/447.49/114.47 \n","04/20/2023 03:57:58 PM - INFO - [66:1] loss\t537.47 =\tBCE 537.46686 \tLL 0.02067 \tTotal 674.02/355.45/313.07 \n","04/20/2023 03:57:58 PM - INFO - [66:2] loss\t531.85 =\tBCE 531.84882 \tLL 0.01927 \tTotal 321.31/145.04/128.21 \n","04/20/2023 03:57:58 PM - INFO - Training epoch 67.\n","04/20/2023 03:57:59 PM - INFO - [67:0] loss\t539.50 =\tBCE 539.50092 \tLL 0.01945 \tTotal 650.12/518.01/126.67 \n","04/20/2023 03:58:00 PM - INFO - [67:1] loss\t538.88 =\tBCE 538.87933 \tLL 0.02014 \tTotal 956.20/676.24/460.53 \n","04/20/2023 03:58:00 PM - INFO - [67:2] loss\t524.19 =\tBCE 524.18927 \tLL 0.01912 \tTotal 958.06/660.56/419.96 \n","04/20/2023 03:58:00 PM - INFO - Training epoch 68.\n","04/20/2023 03:58:01 PM - INFO - [68:0] loss\t531.11 =\tBCE 531.10541 \tLL 0.01981 \tTotal 717.50/509.14/189.92 \n","04/20/2023 03:58:01 PM - INFO - [68:1] loss\t523.47 =\tBCE 523.47290 \tLL 0.01955 \tTotal 387.35/128.07/124.98 \n","04/20/2023 03:58:02 PM - INFO - [68:2] loss\t532.63 =\tBCE 532.63391 \tLL 0.01888 \tTotal 832.30/432.45/413.42 \n","Not implemented\n","04/20/2023 03:58:02 PM - INFO - Training epoch 69.\n","04/20/2023 03:58:02 PM - INFO - [69:0] loss\t527.91 =\tBCE 527.91278 \tLL 0.01817 \tTotal 525.43/445.49/164.24 \n","04/20/2023 03:58:03 PM - INFO - [69:1] loss\t527.21 =\tBCE 527.21088 \tLL 0.01737 \tTotal 1410.11/470.36/812.27 \n","04/20/2023 03:58:03 PM - INFO - [69:2] loss\t524.11 =\tBCE 524.11145 \tLL 0.01934 \tTotal 676.84/169.49/455.24 \n","04/20/2023 03:58:03 PM - INFO - EVALUATION prior to epoch [70]...\n","04/20/2023 03:58:03 PM - INFO - [70] loss\t6149.33=\tBCE 6149.33 \tLL 0.02581 \n","04/20/2023 03:58:05 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/70_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:58:11 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/70_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:58:16 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/70_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/20/2023 03:58:16 PM - INFO - Training epoch 70.\n","04/20/2023 03:58:17 PM - INFO - [70:0] loss\t531.84 =\tBCE 531.84448 \tLL 0.01866 \tTotal 1587.37/533.94/1007.78 \n","04/20/2023 03:58:17 PM - INFO - [70:1] loss\t525.43 =\tBCE 525.43433 \tLL 0.01667 \tTotal 475.81/405.57/177.41 \n","04/20/2023 03:58:18 PM - INFO - [70:2] loss\t529.89 =\tBCE 529.88611 \tLL 0.01618 \tTotal 1961.85/401.84/1240.40 \n","04/20/2023 03:58:18 PM - INFO - Training epoch 71.\n","04/20/2023 03:58:19 PM - INFO - [71:0] loss\t520.94 =\tBCE 520.94409 \tLL 0.01768 \tTotal 568.50/441.11/282.10 \n","04/20/2023 03:58:19 PM - INFO - [71:1] loss\t523.17 =\tBCE 523.17169 \tLL 0.01991 \tTotal 1229.48/380.34/656.06 \n","04/20/2023 03:58:20 PM - INFO - [71:2] loss\t519.25 =\tBCE 519.25446 \tLL 0.01956 \tTotal 1141.17/231.82/631.32 \n","04/20/2023 03:58:20 PM - INFO - Training epoch 72.\n","04/20/2023 03:58:20 PM - INFO - [72:0] loss\t522.91 =\tBCE 522.90619 \tLL 0.01748 \tTotal 683.41/382.16/348.65 \n","04/20/2023 03:58:21 PM - INFO - [72:1] loss\t525.76 =\tBCE 525.76129 \tLL 0.01550 \tTotal 1233.09/320.44/668.74 \n","04/20/2023 03:58:21 PM - INFO - [72:2] loss\t516.78 =\tBCE 516.77740 \tLL 0.01613 \tTotal 632.10/326.65/99.47 \n","04/20/2023 03:58:21 PM - INFO - Training epoch 73.\n","04/20/2023 03:58:22 PM - INFO - [73:0] loss\t523.49 =\tBCE 523.49060 \tLL 0.01890 \tTotal 930.98/438.73/477.37 \n","04/20/2023 03:58:22 PM - INFO - [73:1] loss\t509.50 =\tBCE 509.49826 \tLL 0.02005 \tTotal 671.86/160.51/319.15 \n","04/20/2023 03:58:23 PM - INFO - [73:2] loss\t519.44 =\tBCE 519.44464 \tLL 0.01877 \tTotal 544.92/379.26/79.83 \n","04/20/2023 03:58:23 PM - INFO - Training epoch 74.\n","04/20/2023 03:58:23 PM - INFO - [74:0] loss\t511.50 =\tBCE 511.49619 \tLL 0.01761 \tTotal 677.58/254.30/433.25 \n","04/20/2023 03:58:24 PM - INFO - [74:1] loss\t517.03 =\tBCE 517.02673 \tLL 0.01703 \tTotal 516.48/217.07/211.80 \n","04/20/2023 03:58:25 PM - INFO - [74:2] loss\t516.78 =\tBCE 516.77509 \tLL 0.01869 \tTotal 733.46/422.49/210.89 \n","04/20/2023 03:58:25 PM - INFO - Training epoch 75.\n","04/20/2023 03:58:25 PM - INFO - [75:0] loss\t516.95 =\tBCE 516.95135 \tLL 0.01938 \tTotal 544.39/236.69/107.89 \n","04/20/2023 03:58:26 PM - INFO - [75:1] loss\t510.50 =\tBCE 510.49902 \tLL 0.01811 \tTotal 664.68/246.41/107.66 \n","04/20/2023 03:58:26 PM - INFO - [75:2] loss\t508.09 =\tBCE 508.08585 \tLL 0.01594 \tTotal 492.36/297.05/56.68 \n","04/20/2023 03:58:26 PM - INFO - Training epoch 76.\n","04/20/2023 03:58:27 PM - INFO - [76:0] loss\t507.49 =\tBCE 507.48526 \tLL 0.01522 \tTotal 574.07/310.56/57.84 \n","04/20/2023 03:58:27 PM - INFO - [76:1] loss\t510.49 =\tBCE 510.48743 \tLL 0.01621 \tTotal 358.62/180.07/131.30 \n","04/20/2023 03:58:28 PM - INFO - [76:2] loss\t510.20 =\tBCE 510.19714 \tLL 0.01682 \tTotal 638.55/395.26/272.88 \n","04/20/2023 03:58:28 PM - INFO - Training epoch 77.\n","04/20/2023 03:58:28 PM - INFO - [77:0] loss\t513.13 =\tBCE 513.12695 \tLL 0.01853 \tTotal 768.66/310.37/239.31 \n","04/20/2023 03:58:29 PM - INFO - [77:1] loss\t502.73 =\tBCE 502.73145 \tLL 0.01696 \tTotal 340.70/187.32/95.63 \n","04/20/2023 03:58:29 PM - INFO - [77:2] loss\t506.45 =\tBCE 506.44641 \tLL 0.01602 \tTotal 401.93/127.73/107.74 \n","04/20/2023 03:58:29 PM - INFO - Training epoch 78.\n","04/20/2023 03:58:30 PM - INFO - [78:0] loss\t498.88 =\tBCE 498.87985 \tLL 0.01621 \tTotal 230.61/153.25/88.07 \n","04/20/2023 03:58:30 PM - INFO - [78:1] loss\t506.38 =\tBCE 506.38220 \tLL 0.01644 \tTotal 560.76/250.05/145.09 \n","04/20/2023 03:58:31 PM - INFO - [78:2] loss\t501.48 =\tBCE 501.47568 \tLL 0.01585 \tTotal 311.83/203.81/158.52 \n","Not implemented\n","04/20/2023 03:58:31 PM - INFO - Training epoch 79.\n","04/20/2023 03:58:31 PM - INFO - [79:0] loss\t504.11 =\tBCE 504.11099 \tLL 0.01533 \tTotal 464.60/384.71/25.32 \n","04/20/2023 03:58:32 PM - INFO - [79:1] loss\t503.82 =\tBCE 503.81909 \tLL 0.01432 \tTotal 560.57/325.75/184.49 \n","04/20/2023 03:58:33 PM - INFO - [79:2] loss\t501.84 =\tBCE 501.84100 \tLL 0.01521 \tTotal 536.79/352.19/240.95 \n","04/20/2023 03:58:33 PM - INFO - EVALUATION prior to epoch [80]...\n","04/20/2023 03:58:33 PM - INFO - [80] loss\t7884.00=\tBCE 7884.00 \tLL 0.03381 \n","04/20/2023 03:58:34 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/80_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:58:40 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/80_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:58:45 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/80_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/20/2023 03:58:45 PM - INFO - Training epoch 80.\n","04/20/2023 03:58:46 PM - INFO - [80:0] loss\t507.79 =\tBCE 507.79279 \tLL 0.01607 \tTotal 726.40/231.44/441.61 \n","04/20/2023 03:58:46 PM - INFO - [80:1] loss\t496.48 =\tBCE 496.48419 \tLL 0.01450 \tTotal 351.00/175.41/63.37 \n","04/20/2023 03:58:47 PM - INFO - [80:2] loss\t497.56 =\tBCE 497.55746 \tLL 0.01494 \tTotal 540.73/182.13/317.65 \n","04/20/2023 03:58:47 PM - INFO - Training epoch 81.\n","04/20/2023 03:58:47 PM - INFO - [81:0] loss\t493.92 =\tBCE 493.91812 \tLL 0.01609 \tTotal 418.90/331.20/89.11 \n","04/20/2023 03:58:48 PM - INFO - [81:1] loss\t498.94 =\tBCE 498.94064 \tLL 0.01585 \tTotal 1146.36/556.60/368.15 \n","04/20/2023 03:58:49 PM - INFO - [81:2] loss\t504.96 =\tBCE 504.96222 \tLL 0.01258 \tTotal 1252.56/870.52/343.67 \n","04/20/2023 03:58:49 PM - INFO - Training epoch 82.\n","04/20/2023 03:58:49 PM - INFO - [82:0] loss\t507.35 =\tBCE 507.35434 \tLL 0.01337 \tTotal 1148.93/1068.51/200.30 \n","04/20/2023 03:58:50 PM - INFO - [82:1] loss\t505.70 =\tBCE 505.70081 \tLL 0.01443 \tTotal 1188.60/1000.60/510.24 \n","04/20/2023 03:58:50 PM - INFO - [82:2] loss\t498.90 =\tBCE 498.90091 \tLL 0.01623 \tTotal 862.35/626.70/109.22 \n","04/20/2023 03:58:50 PM - INFO - Training epoch 83.\n","04/20/2023 03:58:51 PM - INFO - [83:0] loss\t501.02 =\tBCE 501.01733 \tLL 0.01540 \tTotal 847.18/263.83/570.53 \n","04/20/2023 03:58:51 PM - INFO - [83:1] loss\t500.53 =\tBCE 500.53122 \tLL 0.01585 \tTotal 902.90/772.76/292.41 \n","04/20/2023 03:58:52 PM - INFO - [83:2] loss\t493.51 =\tBCE 493.51465 \tLL 0.01618 \tTotal 1144.23/727.16/354.04 \n","04/20/2023 03:58:52 PM - INFO - Training epoch 84.\n","04/20/2023 03:58:52 PM - INFO - [84:0] loss\t497.15 =\tBCE 497.14984 \tLL 0.01475 \tTotal 994.83/289.84/500.57 \n","04/20/2023 03:58:53 PM - INFO - [84:1] loss\t495.58 =\tBCE 495.58490 \tLL 0.01516 \tTotal 714.85/478.52/205.60 \n","04/20/2023 03:58:53 PM - INFO - [84:2] loss\t493.72 =\tBCE 493.71725 \tLL 0.01630 \tTotal 1272.58/584.90/440.59 \n","04/20/2023 03:58:53 PM - INFO - Training epoch 85.\n","04/20/2023 03:58:54 PM - INFO - [85:0] loss\t497.13 =\tBCE 497.12567 \tLL 0.01573 \tTotal 364.77/229.19/208.93 \n","04/20/2023 03:58:55 PM - INFO - [85:1] loss\t487.69 =\tBCE 487.68735 \tLL 0.01506 \tTotal 1369.79/446.12/641.30 \n","04/20/2023 03:58:55 PM - INFO - [85:2] loss\t487.58 =\tBCE 487.57947 \tLL 0.01774 \tTotal 740.88/673.88/98.44 \n","04/20/2023 03:58:55 PM - INFO - Training epoch 86.\n","04/20/2023 03:58:56 PM - INFO - [86:0] loss\t493.40 =\tBCE 493.40216 \tLL 0.01809 \tTotal 1646.69/469.78/935.62 \n","04/20/2023 03:58:56 PM - INFO - [86:1] loss\t486.80 =\tBCE 486.80374 \tLL 0.01565 \tTotal 947.17/340.76/427.63 \n","04/20/2023 03:58:57 PM - INFO - [86:2] loss\t486.16 =\tBCE 486.15671 \tLL 0.01619 \tTotal 959.07/634.99/462.02 \n","04/20/2023 03:58:57 PM - INFO - Training epoch 87.\n","04/20/2023 03:58:57 PM - INFO - [87:0] loss\t485.89 =\tBCE 485.88535 \tLL 0.01720 \tTotal 765.30/447.54/320.09 \n","04/20/2023 03:58:58 PM - INFO - [87:1] loss\t485.07 =\tBCE 485.07114 \tLL 0.01617 \tTotal 860.42/290.97/436.49 \n","04/20/2023 03:58:58 PM - INFO - [87:2] loss\t499.63 =\tBCE 499.62524 \tLL 0.01601 \tTotal 1348.31/639.77/773.32 \n","04/20/2023 03:58:58 PM - INFO - Training epoch 88.\n","04/20/2023 03:58:59 PM - INFO - [88:0] loss\t484.77 =\tBCE 484.77438 \tLL 0.01603 \tTotal 540.27/437.36/113.56 \n","04/20/2023 03:58:59 PM - INFO - [88:1] loss\t489.02 =\tBCE 489.01968 \tLL 0.01795 \tTotal 2386.18/466.23/1422.54 \n","04/20/2023 03:59:00 PM - INFO - [88:2] loss\t488.58 =\tBCE 488.58255 \tLL 0.01461 \tTotal 1965.73/350.47/1107.23 \n","Not implemented\n","04/20/2023 03:59:00 PM - INFO - Training epoch 89.\n","04/20/2023 03:59:00 PM - INFO - [89:0] loss\t481.81 =\tBCE 481.81296 \tLL 0.01561 \tTotal 1020.72/423.98/624.96 \n","04/20/2023 03:59:01 PM - INFO - [89:1] loss\t479.93 =\tBCE 479.93134 \tLL 0.01881 \tTotal 1347.56/364.30/559.39 \n","04/20/2023 03:59:02 PM - INFO - [89:2] loss\t489.29 =\tBCE 489.29367 \tLL 0.01703 \tTotal 1722.37/519.11/1148.84 \n","04/20/2023 03:59:02 PM - INFO - EVALUATION prior to epoch [90]...\n","04/20/2023 03:59:02 PM - INFO - [90] loss\t8871.93=\tBCE 8871.93 \tLL 0.04455 \n","04/20/2023 03:59:03 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/90_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:59:09 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/90_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:59:14 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/90_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/20/2023 03:59:14 PM - INFO - Training epoch 90.\n","04/20/2023 03:59:15 PM - INFO - [90:0] loss\t491.45 =\tBCE 491.45450 \tLL 0.01441 \tTotal 1963.47/541.36/938.37 \n","04/20/2023 03:59:16 PM - INFO - [90:1] loss\t483.85 =\tBCE 483.85471 \tLL 0.01682 \tTotal 1027.95/230.81/620.16 \n","04/20/2023 03:59:16 PM - INFO - [90:2] loss\t480.56 =\tBCE 480.55905 \tLL 0.02029 \tTotal 1239.81/357.76/269.15 \n","04/20/2023 03:59:16 PM - INFO - Training epoch 91.\n","04/20/2023 03:59:17 PM - INFO - [91:0] loss\t474.51 =\tBCE 474.51035 \tLL 0.01866 \tTotal 1438.07/379.76/672.78 \n","04/20/2023 03:59:17 PM - INFO - [91:1] loss\t485.72 =\tBCE 485.71719 \tLL 0.01629 \tTotal 1492.99/422.91/662.46 \n","04/20/2023 03:59:18 PM - INFO - [91:2] loss\t479.58 =\tBCE 479.57602 \tLL 0.01718 \tTotal 875.02/196.31/163.46 \n","04/20/2023 03:59:18 PM - INFO - Training epoch 92.\n","04/20/2023 03:59:18 PM - INFO - [92:0] loss\t480.80 =\tBCE 480.79971 \tLL 0.01967 \tTotal 1485.13/380.33/926.62 \n","04/20/2023 03:59:19 PM - INFO - [92:1] loss\t480.11 =\tBCE 480.11353 \tLL 0.02009 \tTotal 776.61/442.90/405.42 \n","04/20/2023 03:59:19 PM - INFO - [92:2] loss\t480.45 =\tBCE 480.45200 \tLL 0.01953 \tTotal 1196.06/945.46/542.54 \n","04/20/2023 03:59:19 PM - INFO - Training epoch 93.\n","04/20/2023 03:59:20 PM - INFO - [93:0] loss\t477.12 =\tBCE 477.11560 \tLL 0.01799 \tTotal 1357.81/814.87/646.49 \n","04/20/2023 03:59:21 PM - INFO - [93:1] loss\t482.34 =\tBCE 482.33835 \tLL 0.02072 \tTotal 2470.47/663.18/1722.31 \n","04/20/2023 03:59:21 PM - INFO - [93:2] loss\t479.41 =\tBCE 479.41138 \tLL 0.01832 \tTotal 1513.21/620.36/718.54 \n","04/20/2023 03:59:21 PM - INFO - Training epoch 94.\n","04/20/2023 03:59:22 PM - INFO - [94:0] loss\t479.07 =\tBCE 479.07355 \tLL 0.01996 \tTotal 795.72/487.85/369.75 \n","04/20/2023 03:59:22 PM - INFO - [94:1] loss\t464.37 =\tBCE 464.37329 \tLL 0.01993 \tTotal 717.60/172.10/195.79 \n","04/20/2023 03:59:23 PM - INFO - [94:2] loss\t475.34 =\tBCE 475.33835 \tLL 0.01930 \tTotal 805.73/603.87/235.88 \n","04/20/2023 03:59:23 PM - INFO - Training epoch 95.\n","04/20/2023 03:59:23 PM - INFO - [95:0] loss\t481.04 =\tBCE 481.03516 \tLL 0.01903 \tTotal 767.38/690.18/273.18 \n","04/20/2023 03:59:24 PM - INFO - [95:1] loss\t474.11 =\tBCE 474.11060 \tLL 0.01843 \tTotal 895.83/514.10/175.65 \n","04/20/2023 03:59:24 PM - INFO - [95:2] loss\t458.36 =\tBCE 458.36310 \tLL 0.02010 \tTotal 258.69/137.12/87.97 \n","04/20/2023 03:59:24 PM - INFO - Training epoch 96.\n","04/20/2023 03:59:25 PM - INFO - [96:0] loss\t470.28 =\tBCE 470.28311 \tLL 0.02012 \tTotal 1073.00/408.83/493.58 \n","04/20/2023 03:59:26 PM - INFO - [96:1] loss\t463.28 =\tBCE 463.28308 \tLL 0.01828 \tTotal 1569.82/776.96/843.33 \n","04/20/2023 03:59:26 PM - INFO - [96:2] loss\t476.14 =\tBCE 476.14325 \tLL 0.01937 \tTotal 1860.46/1032.08/868.28 \n","04/20/2023 03:59:26 PM - INFO - Training epoch 97.\n","04/20/2023 03:59:27 PM - INFO - [97:0] loss\t465.31 =\tBCE 465.30914 \tLL 0.01689 \tTotal 1935.88/904.72/822.03 \n","04/20/2023 03:59:27 PM - INFO - [97:1] loss\t467.20 =\tBCE 467.20410 \tLL 0.01943 \tTotal 1384.92/488.39/783.08 \n","04/20/2023 03:59:28 PM - INFO - [97:2] loss\t465.05 =\tBCE 465.04797 \tLL 0.01850 \tTotal 430.76/167.50/250.02 \n","04/20/2023 03:59:28 PM - INFO - Training epoch 98.\n","04/20/2023 03:59:28 PM - INFO - [98:0] loss\t465.60 =\tBCE 465.60349 \tLL 0.01693 \tTotal 963.02/518.06/267.67 \n","04/20/2023 03:59:29 PM - INFO - [98:1] loss\t465.28 =\tBCE 465.27536 \tLL 0.01799 \tTotal 755.08/577.42/141.63 \n","04/20/2023 03:59:29 PM - INFO - [98:2] loss\t458.57 =\tBCE 458.57254 \tLL 0.01876 \tTotal 749.30/472.64/112.22 \n","Not implemented\n","04/20/2023 03:59:29 PM - INFO - Training epoch 99.\n","04/20/2023 03:59:30 PM - INFO - [99:0] loss\t455.40 =\tBCE 455.40414 \tLL 0.01826 \tTotal 464.02/159.86/310.92 \n","04/20/2023 03:59:30 PM - INFO - [99:1] loss\t462.13 =\tBCE 462.12628 \tLL 0.01829 \tTotal 777.96/354.59/424.47 \n","04/20/2023 03:59:31 PM - INFO - [99:2] loss\t468.74 =\tBCE 468.73541 \tLL 0.01905 \tTotal 1790.49/559.79/967.50 \n","04/20/2023 03:59:31 PM - INFO - EVALUATION prior to epoch [100]...\n","04/20/2023 03:59:31 PM - INFO - [100] loss\t10290.82=\tBCE 10290.82 \tLL 0.04150 \n","04/20/2023 03:59:33 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/100_reconstructions.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:59:38 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/100_repr_manifold_pca_varied=4,5_true=4.pdf\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('1').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('2').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('3').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('4').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","/content/drive/MyDrive/Advanced_Machine_Learning/homomorphismvae/displacementae/homomorphism/../utils/plotting_utils.py:306: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n","  f = ax.scatter(x=x, y=y, c=c,marker=MARKERS[m%len(MARKERS)],\n","04/20/2023 03:59:43 PM - INFO - Figure saved ./out/run_2023-04-20_15-54-11/figures/100_repr_manifold_pca_varied=4,5_true=5.pdf\n","04/20/2023 03:59:44 PM - INFO - Training epoch 100.\n","04/20/2023 03:59:45 PM - INFO - [100:0] loss\t459.70 =\tBCE 459.69992 \tLL 0.01691 \tTotal 2329.95/425.83/1385.57 \n","04/20/2023 03:59:45 PM - INFO - [100:1] loss\t465.85 =\tBCE 465.85263 \tLL 0.01861 \tTotal 2135.82/609.71/1222.36 \n","04/20/2023 03:59:46 PM - INFO - [100:2] loss\t472.43 =\tBCE 472.43063 \tLL 0.01706 \tTotal 1767.81/1308.68/795.90 \n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/bce_loss █▆▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train/ll_loss ▁▁▂▂▁▃▁▁▁▁▁▂▂▂▂▂▂▃▄▄▅▆▆▇█▇▅▅▅▅▄▄▄▄▄▄▄▅▅▅\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/total_loss █▆▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:     val/bce_loss ▁▁▁▁▂▂▂▄▆▇█\n","\u001b[34m\u001b[1mwandb\u001b[0m:        val/epoch ▁▂▂▃▄▅▅▆▇▇█\n","\u001b[34m\u001b[1mwandb\u001b[0m:      val/ll_loss ▁▁▁▁▂▃▄▅▆██\n","\u001b[34m\u001b[1mwandb\u001b[0m:   val/total_loss ▁▁▁▁▂▂▂▄▆▇█\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/bce_loss 468.73541\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train/epoch 99\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train/ll_loss 0.01905\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/total_loss 468.73541\n","\u001b[34m\u001b[1mwandb\u001b[0m:     val/bce_loss 10290.81641\n","\u001b[34m\u001b[1mwandb\u001b[0m:        val/epoch 100\n","\u001b[34m\u001b[1mwandb\u001b[0m:      val/ll_loss 0.0415\n","\u001b[34m\u001b[1mwandb\u001b[0m:   val/total_loss 10290.81641\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mancient-frog-15\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/simonecaldarella/homomorphism-autoencoder/runs/27unq9li\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 33 media file(s), 2 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230420_155441-27unq9li/logs\u001b[0m\n"]}]},{"cell_type":"markdown","source":["### Results"],"metadata":{"id":"5QhpBjbBalQl"}},{"cell_type":"markdown","source":["No Combinatorial Generalization \n","\n","```\n","wandb: Run summary:\n","wandb:   train/bce_loss 1.68986\n","wandb:      train/epoch 100\n","wandb:    train/ll_loss 0.00069\n","wandb: train/total_loss 1.68986\n","wandb:     val/bce_loss 1.81507\n","wandb:        val/epoch 100\n","wandb:      val/ll_loss 0.00067\n","wandb:   val/total_loss 1.81507\n","```"],"metadata":{"id":"Uqg5wnYlaVln"}},{"cell_type":"markdown","source":["Recombination to element\n","\n","```\n","wandb: Run summary:\n","wandb:   train/bce_loss 11.06963\n","wandb:      train/epoch 100\n","wandb:    train/ll_loss 0.01074\n","wandb: train/total_loss 11.06963\n","wandb:     val/bce_loss 10.48341\n","wandb:        val/epoch 100\n","wandb:      val/ll_loss 0.01068\n","wandb:   val/total_loss 10.48341\n","```"],"metadata":{"id":"05LyGhydZgp_"}},{"cell_type":"markdown","source":["Recombination to range\n","\n","```\n","wandb: Run summary:\n","wandb:   train/bce_loss 40.11845\n","wandb:      train/epoch 100\n","wandb:    train/ll_loss 0.02929\n","wandb: train/total_loss 40.11845\n","wandb:     val/bce_loss 1300.78259\n","wandb:        val/epoch 100\n","wandb:      val/ll_loss 0.04343\n","wandb:   val/total_loss 1300.78259\n","```"],"metadata":{"id":"ZJb46mIi9-Ym"}},{"cell_type":"markdown","source":["Extrapolation \n","\n","```\n","wandb: Run summary:\n","wandb:   train/bce_loss 468.73541\n","wandb:      train/epoch 99\n","wandb:    train/ll_loss 0.01905\n","wandb: train/total_loss 468.73541\n","wandb:     val/bce_loss 10290.81641\n","wandb:        val/epoch 100\n","wandb:      val/ll_loss 0.0415\n","wandb:   val/total_loss 10290.81641\n","```"],"metadata":{"id":"pbHyI8oGaEyc"}},{"cell_type":"code","source":[],"metadata":{"id":"CsPKL9AaZfiK"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["XlsXa95aC3h4","IID2cRc1F05c","Da4FlcKYMpLE","5QhpBjbBalQl"]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}